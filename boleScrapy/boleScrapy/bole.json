{"title": "回归树的原理及其 Python 实现 - 文章 - 伯乐在线", "tag": ["IT技术", "回归树", "机器学习", "算法"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n提到回归树，相信大家应该都不会觉得陌生（不陌生你点进来干嘛[捂脸]），大名鼎鼎的 GBDT 算法就是用回归树组合而成的。本文就回归树的基本原理进行讲解，并手把手、肩并肩地带您实现这一算法。完整实现代码请参考 github： 1. 原理篇我们用人话而不是大段的数学公式，来讲讲回归树是怎么一回事。1.1 最简单的模型如果预测某个连续变量的大小，最简单的模型之一就是用平均值。比如同事的平均年龄是 28 岁，那么新来了一批同事，在不知道这些同事的任何信息的情况下，直觉上用平均值 28 来预测是比较准确的，至少比 0 岁或者 100 岁要靠谱一些。我们不妨证明一下我们的直觉：定义损失函数 L，其中 y_hat 是对 y 预测值，使用 MSE 来评估损失：\n对 y_hat 求导:\n令导数等于 0，最小化 MSE，则:\n所以，\n结论，如果要用一个常量来预测 y，用 y 的均值是一个最佳的选择。1.2 加一点难度仍然是预测同事年龄，这次我们预先知道了同事的职级，假设职级的范围是整数1-10，如何能让这个信息帮助我们更加准确的预测年龄呢？一个思路是根据职级把同事分为两组，这两组分别应用我们之前提到的“平均值”模型。比如职级小于 5 的同事分到A组，大于或等于5的分到 B 组，A 组的平均年龄是 25 岁，B 组的平均年龄是 35 岁。如果新来了一个同事，职级是 3，应该被分到 A 组，我们就预测他的年龄是 25 岁。1.3 最佳分割点还有一个问题待解决，如何取一个最佳的分割点对不同职级的同事进行分组呢？我们尝试所有 m 个可能的分割点 P_i，沿用之前的损失函数，对 A、B 两组分别计算 Loss 并相加得到 L_i。最小的 L_i 所对应的 P_i 就是我们要找的“最佳分割点”。1.4 运用多个变量再复杂一些，如果我们不仅仅知道了同事的职级，还知道了同事的工资（貌似不科学），该如何预测同事的年龄呢？我们可以分别根据职级、工资计算出职级和工资的最佳分割点P_1, P_2，对应的Loss L_1, L_2。然后比较L_1和L2，取较小者。假设L_1 < L_2，那么按照P_1把不同职级的同事分为A、B两组。在A、B组内分别计算工资所对应的分割点，再分为C、D两组。这样我们就得到了AC, AD, BC, BD四组同事以及对应的平均年龄用于预测。1.5 答案揭晓如何实现这种1 to 2, 2 to 4, 4 to 8的算法呢？熟悉数据结构的同学自然会想到二叉树，这种树被称为回归树，顾名思义利用树形结构求解回归问题。2. 实现篇本人用全宇宙最简单的编程语言——Python实现了回归树算法，没有依赖任何第三方库，便于学习和使用。简单说明一下实现过程，更详细的注释请参考本人github上的代码。2.1 创建Node类初始化，存储预测值、左右结点、特征和分割点2.2 创建回归树类初始化，存储根节点和树的高度。2.3 计算分割点、MSE根据自变量X、因变量y、X元素中被取出的行号idx，列号feature以及分割点split，计算分割后的MSE。注意这里为了减少计算量，用到了方差公式：\n2.4 计算最佳分割点遍历特征某一列的所有的不重复的点，找出MSE最小的点作为最佳分割点。如果特征中没有不重复的元素则返回None。2.5 选择最佳特征遍历所有特征，计算最佳分割点对应的MSE，找出MSE最小的特征、对应的分割点，左右子节点对应的均值和行号。如果所有的特征都没有不重复元素则返回None2.6 规则转文字将规则用文字表达出来，方便我们查看规则。2.7 获取规则将回归树的所有规则都用文字表达出来，方便我们了解树的全貌。这里用到了队列+广度优先搜索。有兴趣也可以试试递归或者深度优先搜索。2.8 训练模型仍然使用队列+广度优先搜索，训练模型的过程中需要注意：控制树的最大深度max_depth；控制分裂时最少的样本量min_samples_split；叶子结点至少有两个不重复的y值；至少有一个特征是没有重复值的。2.9 打印规则模型训练完毕，查看一下模型生成的规则2.10 预测一个样本2.11 预测多个样本3 效果评估3.1 main函数使用著名的波士顿房价数据集，按照7:3的比例拆分为训练集和测试集，训练模型，并统计准确度。3.2 效果展示最终生成了15条规则，拟合优度0.801，运行时间1.74秒，效果还算不错~3.3 工具函数本人自定义了一些工具函数，可以在github上查看  1. run_time – 测试函数运行时间 2. load_boston_house_prices – 加载波士顿房价数据 3. train_test_split – 拆分训练集、测试机 4. get_r2 – 计算拟合优度总结回归树的原理：损失最小化，平均值大法。 最佳行与列，效果顶呱呱。回归树的实现：一顿操作猛如虎，加减乘除二叉树。 原文：https://zhuanlan.zhihu.com/p/41688007【关于作者】李小文：先后从事过数据分析、数据挖掘工作，主要开发语言是Python，现任一家小型互联网公司的算法工程师。Github: \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/04/ff247977ac3e5237654ad324e8c880ed.jpg"]}
{"title": "什么情况下不应该使用 Windows Linux 子系统 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux", "WSL"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n在我上个月的专栏文章中，我讨论了应该使用Windows Linux子系统（Windows Subsystem for Linux，WSL）的原因，该系统允许你在Windows 10和Windows 2016上运行Linux发行版。不过，仅仅因为你能够做什么并不意味这你应该这么做。相比于先前的文章着眼于勾勒WSL的好处，在此我会站在相反的角度讲述五个不应运行WSL的原因。微软并未基于生产环境负载设计或构建WSL。如果你的应用或作业流程需要达到特定服务水平协议，那么不要将其运行在WSL之上。运行一个虚拟机可能会更有效。WSL是一个超棒的工具，但是如果你需要Linux系统的全部能力和特性，最好还是在一个虚拟机上运行Linux实例。许多公司提供免费版本的Type 2 Hypervisor，它们可以很好地运行在Windows系统上。如果你确实想要获得完整的Linux体验，就在Vmware Player、Oracle Virtualbox、Microsoft Hyper-v或者其他Hypervisor上将Linux作为虚拟机运行。WSL缺乏可靠的图形界面。在另一篇文章中，我向大家演示了如何配置WSL与图形子系统协同工作。经过一番尝试之后，我可以让一些图形化程序跑起来，但是还有其他程序令我无能为力。因为让WSL与图形化子系统交互并没有包含在微软的设计目标内。如果你需要一个可靠的图形界面，不要在WSL运行它。WSL上的联网并不完全可靠。WSL允许你进行网络通信，但是这可能并不是最佳的实现途径，因为它要穿透几层才能生效。WSL的早期版本对于通过命令行实现联网存在一些限制。尽管事实上WSL已经以难以置信的速度变得成熟稳定，Windows和Linux的联网协议栈却已历经数十年的优化，因此我觉得WSL的联网变得完全可靠还需假以时日。WSL免费，但未必成本最低。直觉告诉我很多人会让WSL发挥超越其设计目的的作用，这会让他们投入比替代的付费方案更多的资源。使用正确的工具完成任务永远是最佳的问题解决之道。总之，不要买了雨伞就盼着下雨。WSL是一个值得拥有的优秀工具，可以很方便地用于非生产负载环境和快速简单的任务，但是它并非设计用于生产环境；恰如其分地使用它，而不是拿鸡毛当令箭。武斌，1984 年生，男，自由职业，做过网络管理、计算机图书编辑等工作，喜欢技术，对 IT 行业知识涉猎广泛。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/11/1d34dd467641215c527e32ede94fe494.jpg"]}
{"title": "Linux 内核 Git 历史记录中，最大最奇怪的提交信息是这样的 - 文章 - 伯乐在线", "tag": ["IT技术", "Git", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n我们通常认为 git merges 有两个父节点。例如，由我写的最新的 Linux 内核合并操作是提交2c5d955,这是 4.10-rc6 版本发行前准备工作的一部分。它有两个父节点:Git 还支持章鱼式的合并，这意味着可以有超过两个父节点的合并。这对于我们那些从事小型项目开发的人来说，这似乎很奇怪：与三四个父节点合并会不会令人感到困惑？这得看情况而定。有时候，一个内核的维护者需要一次同时合并几十个单独的历史记录。一个接着一个的30个合并提交比起单独的一个30路(30个父节点)合并更加令人困惑，特别是当30路合并没有冲突的时候。章鱼式合并可能比你想象地更常见。在内核的提交历史记录中有649,306个提交。其中 46,930 (7.2%) 个提交是合并提交。在合并提交中，有 1,549 (3.3%) 是章鱼式合并。(截止到我当前的 git HEAD 指向的提交 566cf87 。)作为比较，Rails 的所有提交中的 20% 是合并提交 (12,401/63,111),但没有一个章鱼式合并。Rails 大概更能代表一般的工程; 我认为大多数的 git 用户甚至都不知道章鱼式合并。现在，显而易见的问题是: 这些章鱼式合并的规模有多大？ 在这里每行开头的 “>” 是续行符；这个命令写了总共5行。这篇文章中的所有命令都是我在做实验的时候输入到终端里面的，所以它们未必容易看懂。我对于结果更感兴趣，贴出代码只是为了满足那些好奇的人。66 个父节点！这么多的父节点，这个提交到底发生了什么？这让许多历史记录可视化工具都无法正常运行，引出了 Linus Torvalds 的一个:我刚刚从 Takashi 那收到了一些消息，因此我看到了你的合并提交 2cde51fbd0f3 。这个提交有 66 个父节点。[…]它被拉取（pulled）了，并且状况良好，但显然它在 “章鱼式合并很好” 和 “上帝” 之间做到了平衡，这不是一个章鱼式合并，这是一个克苏鲁(一个章鱼头人神的巨人)式的合并。正如我所看到的，这个有66个父节点的不同寻常的提交在某种程度上只是对于ASoc代码修改的正常合并。ASoc 代表了芯片上的ALSA系统。ALSA系统是音频子系统；“单片系统是集成在单片硅芯片上计算机的术语。综上所述，ASoc 是对嵌入式设备的声音支持系统。那么这样的合并多久会发生一次呢？永远都不会发生。规模排第二的合并是 fa623d1 ,它仅仅有 30 个父节点。然而，因为足够的背景知识，从 30 到 66 之间的巨大差距并不会令人感到惊讶。一次 git 提交的父节点的数量大概是一种单侧分布(通常非正式的说法是幂律分布，因为这里对这个不感兴趣，所以不必严格正确)。软件系统的许多属性都属于单侧分布。等一下；我将会生成一个图表来确定…(大量严格的图表确定了)。是的，它确实是单侧分布:简单地说来, “单侧分布”意味着小事件比大事件多得多，而且大事件的最大规模是没有界限的。内核的提交历史中包含了 45,381 个两个父节点的合并，但仅仅有一个 66个父节点的合并。假如考虑足够多的开发历史记录的话，我们可能会看到多于66个父节点的合并。单个函数或是单个模块的代码行数也是单侧分布（大多数函数和模块都很小，但是其中一些很大；想想 web app 中的 “User” 类)。同样，对于模块的变化率（大多数模块都不会经常变动，只有其中一些会不断改动；再想想 “User” 类）。这些分布在软件开发中无处不在，而且经常在下面的双对数坐标图中呈直线分布。对于父节点的数量最大的提交，我们就讨论到这。那么在差异方面的合并又怎样呢？在差异方面，我的意思是被合并的两个分支之间的差异。我们可以通过简单地比较合并节点的父节点，然后统计它们差异的行数来衡量这一点。例如，如果一个分支一年前从 master 分支分离出去，改变了一行代码，之后被合并回 master 分支，在这段时间内对于 master 分支的所有修改都会被统计到，同样分离出去的分支上的改变也会被统计到。我们可以引出更直观的差异概念，但因为 git 不会保留分支的元数据，所以它们很难或者说是几乎不可能计算出来。在任何情况下，作为计算差异的起点，下面是最近内核合并的差异：在英语中，这个命令的含义是这样的：“比较最近合并的两个父节点，然后统计差异的行数。”为了找出差异最多的合并，我们可以遍历每个合并提交，用类似的方法统计差异的行数。然后，作为一个测试，我们将搜索所有合并中恰好有 2,000 行差异的分支。（这个命令需要花费很长的时间运行: 我想大约需要12小时，尽管我已经减少了许多。）我认为合并的差异大小遵循单侧分布，就像父节点数量的统计一样。所以它应该在双对数坐标图表中显示为一条直线。让我检查一下….对了:我把差异的大小定在1000行左右(注：前面用2000行，得到的数据太少)，否则没有足够的样本来生成有效的曲线。右下角难看的原因部分是因为量化问题，另一部分是由于缺乏大量的提交导致样本数量较小，与之前的图表情况一样。现在，显而易见的问题是: 提交历史中差异最大的合并是哪个？22,445,760 行差异！这看起来根本不可能这么大-因为差异的行数比整个内核源代码的行数都大。Greg Kroah-Hartman 在2016年9月19做了这一提交，当时正处在 4.8-rc6 版本的开发期间。Greg 是 Linus Torvalds 的 “副官” 之一 – 他（Linus）最亲近，最值得信赖的开发者。简单地说，副官们构成了内核 pull request 树中的第一层。Greg 负责维护内核的稳定分支，驱动程序内核，USB 子系统和其他几个子系统。在更加仔细的研究这个合并之前，我们需要一点背景知识。通常我们把合并作为菱形分支模式（先分支，然后合并，见下图）的一部分:在2014年，Greg 开始在一个新的仓库开发 Greybus ()，这就好像是他创建了一个全新的项目一样。最后，Greybus 的开发工作完成时，它就被合并到了内核中。但因为它是从一个崭新的仓库开始的，所以它和内核的中的其他源代码没有共同的历史记录。所以除了2005年我们公认的初始提交之外，这个合并为内核又添加了一个 “初始提交”。这个仓库现在有两条独立的初始提交，而不是通常的菱形分支模式：通过查看合并提交的两个父节点中分别存在多少文件，我们可以看到一些蛛丝马迹:一条分支存在大量的文件，因为它包含了整个内核的源文件。而另一条仅仅包含了很少的文件，因为它包含的只是 Greybus 的历史记录。像章鱼式合并一样，这会让一些 git 用户感到奇怪。但是内核开发人员是专家级的 git 用户，并倾向于放弃使用这个功能，但绝对不是盲目的放弃最后一个问题:这种情况到底发生了多少次？内核中有多少独立的 “初始化” 提交？事实上是四次:如果我们要画出这些提交，为了清楚起见，我们忽略所有其他的历史记录，如下图:这四个提交中的每一个都是离当前内核版本库 HEAD 节点很遥远的祖先节点，并且都没有父节点。从 git 的角度来看，内核历史“开始”了不同的四次，所有的这些提交最终都被合并在一起。这四个提交中的第一个（在我们输出的底部）是2005年的初始化提交，也就是我们通常认为的初始化提交。第二个是文件系统 btrfs 的开发，它是独立仓库完成的。第三个是 Greybus,同样也是独立仓库完成的，我们之前已经说过。第四个初始化提交，a101ad9，很奇怪，正如下面看到的:它刚创建了一个 README.md 文件。但随后，它就立即被合并到正常的内核历史的提交 e5451c8 中了！为什么有人会创建一个只包含两行文本的 README 文件的初始化提交，然后立即合并到主线的历史记录中呢？我想不出任何理由，所以我怀疑这是一个意外！但它没有造成任何危害；它只是很奇怪。（更新：，Linus用他一贯的方式回应了。）顺便提一句，这也是历史记录中差异数量排第二的提交，仅仅因为它是一个不相关提交的合并，就像我们仔细研究过的 Greybus 的合并一样。现在你知道了：Linux 内核的 git 历史记录一些最奇怪的事情。一共有 1,549 个章鱼式合并，其中有一个是拥有 66 个父节点的提交。差异最多的合并有 22,445,760 行差异，尽管它有点技术性因为它和仓库的其他部分没有公共的历史记录。内核拥有四个独立的初始化提交，其中一个是失误导致的。尽管上面的这些都不会出现在绝大多数的 git 仓库中，但是所有的这些功能都是在 git 的设计范围之内的。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://wx1.sinaimg.cn/mw690/7cc829d3gy1fu22uq61vrj20mr0d040p.jpg"]}
{"title": "在 Linux 上如何得到一个段错误的核心转储 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n本周工作中，我花了整整一周的时间来尝试调试一个段错误。我以前从来没有这样做过，我花了很长时间才弄清楚其中涉及的一些基本事情（获得核心转储、找到导致段错误的行号）。于是便有了这篇博客来解释如何做那些事情！在看完这篇博客后，你应该知道如何从“哦，我的程序出现段错误，但我不知道正在发生什么”到“我知道它出现段错误时的堆栈、行号了！ ”。“段错误segmentation fault”是指你的程序尝试访问不允许访问的内存地址的情况。这可能是由于：试图解引用空指针（你不被允许访问内存地址 ）；试图解引用其他一些不在你内存（LCTT 译注：指不在合法的内存地址区间内）中的指针；一个已被破坏并且指向错误的地方的 C++ 虚表指针C++ vtable pointer，这导致程序尝试执行没有执行权限的内存中的指令；其他一些我不明白的事情，比如我认为访问未对齐的内存地址也可能会导致段错误（LCTT 译注：在要求自然边界对齐的体系结构，如 MIPS、ARM 中更容易因非对齐访问产生段错误）。这个“C++ 虚表指针”是我的程序发生段错误的情况。我可能会在未来的博客中解释这个，因为我最初并不知道任何关于 C++ 的知识，并且这种虚表查找导致程序段错误的情况也是我所不了解的。但是！这篇博客后不是关于 C++ 问题的。让我们谈论的基本的东西，比如，我们如何得到一个核心转储？我发现找出为什么我的程序出现段错误的最简单的方式是使用 ：我运行这给了我一个故障时的堆栈调用序列。 简洁！但我想也希望做一个更深入调查，并找出些  没告诉我的信息！ 所以我想获得一个核心转储并探索它。核心转储core dump是您的程序内存的一个副本，并且当您试图调试您的有问题的程序哪里出错的时候它非常有用。当您的程序出现段错误，Linux 的内核有时会把一个核心转储写到磁盘。 当我最初试图获得一个核心转储时，我很长一段时间非常沮丧，因为 – Linux 没有生成核心转储！我的核心转储在哪里？这就是我最终做的事情：在启动我的程序之前运行 运行  设置核心转储的最大尺寸。 它往往设置为 0，这意味着内核根本不会写核心转储。 它以千字节为单位。  是按每个进程分别设置的 —— 你可以通过运行  看到一个进程的各种资源限制。例如这些是我的系统上一个随便一个 Firefox 进程的资源限制：内核在决定写入多大的核心转储文件时使用软限制soft limit（在这种情况下，）。 您可以使用 shell 内置命令 （） 将软限制增加到硬限制hard limit。 是一个内核参数，或者叫 “sysctl 设置”，它控制 Linux 内核将核心转储文件写到磁盘的哪里。内核参数是一种设定您的系统全局设置的方法。您可以通过运行  得到一个包含每个内核参数的列表，或使用  来专门查看  设置。所以  将核心转储保存到目录  下，并以  加上一系列能够标识（出故障的）进程的参数构成的后缀为文件名。如果你想知道这些形如 、 的参数都表示什么，请参考 。有一点很重要， 是一个全局设置 —— 修改它的时候最好小心一点，因为有可能其它系统功能依赖于把它被设置为一个特定的方式（才能正常工作）。默认情况下在 ubuntu 系统中， 被设置为下面的值：这引起了我的迷惑（这 apport 是干什么的，它对我的核心转储做了什么？）。以下关于这个我了解到的：Ubuntu 使用一种叫做 apport 的系统来报告 apt 包有关的崩溃信息。设定  意味着核心转储将被通过管道送给  程序。apport 的日志保存在文件  中。apport 默认会忽略来自不属于 Ubuntu 软件包一部分的二进制文件的崩溃信息我最终只是跳过了 apport，并把  重新设置为 ，因为我在一台开发机上，我不在乎 apport 是否工作，我也不想尝试让 apport 把我的核心转储留在磁盘上。好的，现在我们了解了  和  ，并且实际上在磁盘的  目录中有了一个核心转储文件。太好了！接下来干什么？我们仍然不知道该程序为什么会出现段错误！下一步将使用  打开核心转储文件并获取堆栈调用序列。你可以像这样用  打开一个核心转储文件：接下来，我们想知道程序崩溃时的堆栈是什么样的。在  提示符下运行  会给你一个调用序列backtrace。在我的例子里， 没有为二进制文件加载符号信息，所以这些函数名就像 “??????”。幸运的是，（我们通过）加载符号修复了它。下面是如何加载调试符号。这从二进制文件及其引用的任何共享库中加载符号。一旦我这样做了，当我执行  时，gdb 给了我一个带有行号的漂亮的堆栈跟踪！如果你想它能工作，二进制文件应该以带有调试符号信息的方式被编译。在试图找出程序崩溃的原因时，堆栈跟踪中的行号非常有帮助。:)通过以下方式在  中获取每个线程的调用栈！如果你有一个带调试符号的核心转储以及 ，那太棒了！您可以上下查看调用堆栈（LCTT 译注：指跳进调用序列不同的函数中以便于查看局部变量），打印变量，并查看内存来得知发生了什么。这是最好的。如果您仍然正在基于 gdb 向导来工作上，只打印出栈跟踪与bt也可以。 :)另一种搞清楚您的段错误的方法是使用 AddressSanitizer 选项编译程序（“ASAN”，即 ）然后运行它。 本文中我不准备讨论那个，因为本文已经相当长了，并且在我的例子中打开 ASAN 后段错误消失了，可能是因为 ASAN 使用了一个不同的内存分配器（系统内存分配器，而不是 tcmalloc）。在未来如果我能让 ASAN 工作，我可能会多写点有关它的东西。（LCTT 译注：这里指使用 ASAN 也能复现段错误）这个博客听起来很多，当我做这些的时候很困惑，但说真的，从一个段错误的程序中获得一个堆栈调用序列不需要那么多步骤：试试用 如果那没用，或者你想要拿到一个核心转储来调查：确保二进制文件编译时带有调试符号信息；正确的设置  和 ；运行程序；一旦你用  调试核心转储了，加载符号并运行 ；尝试找出发生了什么！我可以使用  弄清楚有个 C++ 的虚表条目指向一些被破坏的内存，这有点帮助，并且使我感觉好像更懂了 C++ 一点。也许有一天我们会更多地讨论如何使用  来查找问题！ \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "2 年面试 900 多位工程师后，我总结了这些经验 - 文章 - 伯乐在线", "tag": ["职场", "面试"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n我们在 Triplebyte上进行过很多场面试，实际上，我在过去两年内面试的工程师已经达到 900 余人，这到底算不算卓有成效还真是不好说！（有时我会冒着一身冷汗从梦中惊醒，对这一点充满质疑）。但是不管怎样，我们目标是改进应聘工程师的方式。为此，我们面试时不看求职者的背景，不在乎他们的文凭或简历，只关注他们的编程能力。一个工程师通过了我们这一关后，能直接到我们的合作方公司（包括 Apple、Facebook、Dropbox 和 Stripe）进行终面。我们面试时不知道应聘者的背景，这种情况下看他们是如何在众多顶尖科技公司前大展身手的，我觉得可以给我们的面试提供一些最佳的可用资料。伯乐在线补注：Triplebyte 是国外一家专注工程师招聘的网站。在这篇博客中，我要讲讲迄今为止我从这些资料中所学到的东西。技术面试在很多方面都是漏洞百出的，这一点口头说说很简单（而且许多博客都只是这样说说而已！），难的是想出实际的解决方法。我写这篇博客就是为了迎接这个挑战，并为招聘经理和 CTO 提供一些具体的建议。面试这件事有难度，但我想只要遵循一套缜密的流程，那么许多问题都会迎刃而解。现状大多数的面试过程主要包括两步：简历筛选面试对求职者的筛选就是为了提前淘汰一些求职申请者，节省面试工作的时间。通常筛选过程包括：招聘官大体浏览求职申请者的简历（大概用时 10 秒以内），然后进行 30~60 分钟的电话面试。我们的合作方公司中有 18% 的公司为了考验求职者，也会出编程题让他们回家完成（要么代替电话面试，要么作为电话面试以外的附加题）。有意思的是，绝大多数的求职申请者都是在筛选这一关被拒的。真是这样，我们合作的所有公司中，单纯因为简历就被筛掉的求职申请者已超过了 50%，另外有 30% 因为电话面试/带回家的项目完成不佳而被刷掉。筛选也是聘用过程最变化无常捉摸不定的环节，应聘者太多，导致招聘人员应接不暇，只能做出仓促的决定，因此这时候求职者的文凭资历和专业匹配度就派上了用场。终面几乎普遍都是由一系列 45 分钟到 1 小时的会谈组成，每次会谈的面试官都不一样，会谈主要考技术题（每个公司外加一两个针对文化适应和软技能的问题）。招聘经理和每个面试官会在求职申请者离开后，在决策会议上做出他们最终录用/淘汰的决定。在至少有一人力挺，且没人强烈反对的情况下，一个求职申请者才可能被录用。终面除了常见的形式之外，还有各种千变万化的类型。我们合作的公司中，39% 会使用白板面试。有 52% 允许求职者使用他们自己的电脑作答（剩下的 9% 视情况而定）。有 55% 让面试官随意提问（剩下的 45% 采用一套标准面试题）。有 40% 要考察求职者的 CS 学术技能后，才能确定去或留。有 15% 不喜欢 CS 学术技能（而且觉得探讨计算机科学只能暴露该求职者生产力低）。有 80% 允许求职申请者在面试时使用任何编程语言（剩下的20%要求他们使用特定编程语言）。有 5% 会在面试过程中直白地评价求职者编程语言的细节。放眼所有与我们合作的公司，终面后决定录用的占 22%。（这个数据是通过询问公司内部招聘渠道获得的。Triplebyte 上的求职者通过公司面试被录用的成功率为 53%。）其中大概 65% 会接受 offer（达成雇佣关系）。一年后，公司对录用了 30%、开除率 5% 的情况非常满意。漏招 VS 误招所以，现在的面试存在什么问题呢？毕竟开除员工的频率并非是不可控的。为了更清楚地看待这个问题，我们需要考虑导致面试失败的两种情况：面试了一个不合格的工程师，却将其聘用，过后只好开除（误招）；面试了一个工作能力很强的工程师，却认为他不合格，选择不予聘用（漏招）。误招一眼就能看出来，公司会（在薪水、管理成本和全团队的精神面貌上）付出很大代价，会把一个团队搞得萎靡不振。而与之对比，漏招的损失却看不出来。虽然以上任意一种情况都很有问题，但由于这误招和漏招引发的后果乍一看很不平衡，所以公司的面试很大程度上倾向于不予聘用。面试中存在的干扰会使公司不予聘用的倾向更加严重。在一小时内评估一个人的编程能力本来就是很难的，各种条件经历的匹配、某些直觉感受和以上谈到的公司的复杂喜好等因素掺杂进来，使得你在面试别人时被各种干扰团团围困。为了在受干扰环境下把误招率控制在一个较低的水平，公司在招聘时越来越偏向于不予聘用。这样会错过优秀的工程师，会使文凭的重要程度高过实力，也会由于反复无常，使参与其中的人（面试官和求职者等）感到失望。这个问题很骇人，几乎可以确定他们不可能都被录取。求职申请人会因为本有能力为公司好好效力却没被录用而神伤，公司也会因为找不到可用之才而遭受损失。要澄清一点，我不是说公司应该降低面试的门槛，相反，面试招人正因为会有拒绝才存在的意义！我更不是说公司对误招的担忧远大过漏招是不对的，招错人要付出高昂代价，减少面试中干扰因素的具体方法一个程序员不可能因为具备了哪一套技能就能被定义为优秀的程序员了，相反，世上的编程技能多得犹如汪洋大海，没有工程师能在所有的领域都游刃有余。实际上，我们在 Triplebyte上碰到过一些杰出、成功的软件工程师，他们在几个毫不相关的领域都颇有建树。面试成功的第一步就是决定你想要招聘哪方面的技术人才。我建议你问自己以下几个问题：你想要的程序员是效率高，但写的代码不完善需反复修改的，还是一丝不苟、思维严密的？你想要的程序员是热衷于解决技术难题的还是构建产品的？你想要已经具备某种特定技能的人才还是在工作中有很强的学习能力的？计算机科学学术/数学/算法方面的能力是至关重要的还是无关紧要的？了解并发/ C内存模型/ HTTP 很重要吗？这些问题没有正确答案，我们合作的成功企业对以上每个问题选任一方的都有。这样的话，公司的工程文化就会有一定倾向：淘汰掉越来越多虽然有一技之长但是对公司并没太大用处的、以及不具备公司所需技能（却具备其他重要技能）的工程师。专业程序员的任务是花数周数月的时间解决大型的、错杂延展的问题，但是面试官并没有数周数月的时间去评估求职申请者的能力，通常每个面试官只有一个小时去考核，所以他们会转而去考察求职申请者在强压下迅速解决小问题的能力。这是两种不同的能力测试。二者有一定的相关性（面试并不完全随机），但并不是完全相关。制定面试问题的一大目标就是减少面试考察和实际工作的差异。方法是在面试时向申请某一职位的求职者（或者为了衡量某一技能）问尽可能相似的问题。比如说，如果你关心后端编程，那就让求职申请者建一个简单的 API 端点，再添加特性，几乎可以肯定，这比让他们解决一个 BFS 词链问题有意义得多；如果你关心算法能力，那让求职者在问题中运用算法（比方说，建一个简单的搜索索引，可能使用 BST 和 hashmap，实现提升删除操作的性能），几乎可以肯定，这比让他们确定一点是否包含在一个凹多边形中有意义得多；让求职者在实际编程过程中去尝试调试程序，几乎可以肯定，这比让他们去解决一个白板上的小问题有意义得多。即便如此，面试中要不要让程序员在白板上作答还是有争议的。作为面试官，我不在乎工程师是否记住了 Python 中的 itertools 模块，我在乎的是他们是否想通了如何用 itertools 模块去解决问题。通过让他们在白板上答题，他们便可以不用遵循严格的编程语法，而完全专注于逻辑问题。但最终白板答题的提议还是行不通，因为白板上答案的形式五花八门，没有那么多的评判标准可以对它们一一进行对错评判。所以让求职申请者们回归到电脑上编程，同时告诉他们不必真正去运行代码（或者采用更好的方法，进行开卷面试，让他们在 Google 上查询任何所需的信息），那么考察他们的目的就已经达到了。面试问题应该对日后工作有所反应，对此要特别警告，面试不依赖于外部因素是至关重要的。比如说，让一个求职者用 Ruby 编写一个简单的爬虫看似是个很好的实际问题，但是，如果求职者为此需要先安装 Nokogiri （一个安装起来非常费劲的 Ruby 解析库），结果花了 30 分钟绞尽脑汁应对本地扩展，那么这次面试就糟透了，不仅浪费了时间，而且也让求职者一下子压力爆棚。另一个针对面试提问的经验之谈是避免提问有可能会“泄露”出去的问题。比如说，有些问题的某些信息可能求职申请者提前能从 Glassdoor 上读到，所以他们回答起来就会轻而易举，因此这类问题就要避免提问，否则求职者明显就不用动脑筋了，也抹杀了需要考验他们直觉洞察力的地方。而且除此之外，也意味着面试的问题应该由一系列相互承载的部分组成，而不是一个单一的中心。换种有用的方式去想，问问你自己，能不能在面试时帮助一个陷于困境的求职者，并让他在面试结束还能给大家留下一个不错的印象。对答案唯一的问题，如果你给求职申请者提供了明显的帮助，那么他就直接面临淘汰；而对于多面性的问题，你帮了求职申请者一步，那么他还有机会在其余部分大展身手，完美表现。伯乐在线补注：Glassdoor 是国外一家做企业点评和职位搜索网站。这一点很重要，不仅因为你的问题会在  Glassdoor 上泄露出来，而且（更重要的）是因为多面性的问题可以减少干扰。优秀的求职者会背负压力，陷于困境，面试时很重要的一点就是对他们提供帮助，从而让其好好发挥。考查他们解决任意小编程逻辑问题的能力时，他们最近一段时间是不是看到过、或可能只是恰巧碰到过类似的问题，会对考查造成明显干扰，而多面性的问题则可以消除一些干扰，也让求职者们有机会看到他们的努力像滚雪球一样越积越大。给他们提供一步的帮助，往往能帮他们解决紧接着的下一步，这给实际工作提供了重要动力，在面试时把握这一点就可以减少干扰。举例来说，让一个求职者在终端实现“四子连珠”游戏（一系列多个步骤），可能要比让他去旋转矩阵（一个单独步骤，外加之一些小操作）要好得多；让求职者实现 k 均值聚类（建立在彼此之上的多个操作）可能要比找到直方图中的最大矩形（leetcode 的一道算法题）要好得多。如果求职者很好地解决了一个很难的问题，那能极大地证明他的能力，但也正因为这个问题很难，所以大多数求职者都无力招架。你想要获得的信息量就很大程度上依赖于问题的难度，我们发现面试问题最合适的难度要明显比大多数面试官所想的简单得多。这一点影响更大，因为面试求职者时，获得的信息有两种来源：他们是否对一个问题给出了“正确的”答案、他们得出答案的过程/得出答案的容易程度。我们在 Triplebyte上收集了这方面的数据（同时给他们是否得出了正确答案和他们花费了多大努力这两项打分，然后衡量对公司而言哪个分数能更准确地对求职者能力进行预测）。我们发现这是一种权衡，对于更难的问题，求职者是否给出了正确的答案更能说明问题，相比之下，对于更简单的问题，求职者的答题过程和他们花费的努力程度则更有参考价值。考量了这两种信息来源后，面试问题最适宜的难度会往更加简单的方向偏移。我们现在遵循的经验法则是，面试官解决问题所用的时间应该是他们希望求职申请者们解决问题所花时间的25%。所以如果我在为时1小时的面试中提出了一个新的问题，我希望我的同事（没有提醒的情况下）能在15分钟内解答。外加之我们应问实际环境下的多面性问题，这意味着最佳的面试问题真的是相当直白和简单的。要澄清一点，我不是说要降低通过率的门槛。我支持问简单的问题，然后将他们回答的情况纳入考评范围；我支持问简单的问题，然后给予相当严苛的评判。这就是我们所找到的对面试环境进行优化的方式，这种方式额外产生的好处就是可以降低大部分求职者的面试压力。举例来说，让一个求职者创建一个简单的命令行接口，要求存储和检索键值对（如果做得好的话就再增添功能），可能要比让他们为算数表达式实现解析器要好得多；面试问题包含最普通的数据结构（表、哈希、还可能有树）可能要比涉及跳表、二叉排序树或其他更模糊的数据结构要好得多。面试就要对各个求职申请者进行比较，我们的目标就是将他们分为能为公司奉献光与热的和不能奉献的（在大家申请同一职位的情况下，选出申请人中最优秀的一个）。鉴于此，就没有理由向不同的求职申请者问不同的问题。如果你对申请同一职位的不同求职申请者采用不同的方式进行评判，那么你就引入了干扰因素。面试之所以一直都是当场选择问题，我觉得是因为面试官更喜欢这种方式。科技公司的工程师通常不喜欢面试别人，他们只是偶尔面试一下，面试会使他们偏离工作重点。为了将针对每个求职申请者的面试问题规范化，面试官们就需要花费更多的时间去学习如何制定面试问题，并且探讨面试打分、交接的方式。而且每次问题一发生变化，他们就需要重复以上过程。经常问同样的问题只是有些枯燥乏味而已。不幸的是，面试成功唯一的正解就是面试官需要花费心力。保证一致性是实现良好面试的关键所在，也就是说向每个求职申请者问相同的问题，并且要确保交接标准化，除此之外别无他法。与我之前的观点相悖，这里我们可以考虑提供几种截然不同的面试方法。筹备面试时，我们首先应该考虑想要招哪种类型的技术人才，但是我们想要的人才特质可能是相矛盾的，这一点很常见，例如想要招非常有数学天分的工程师，和一些高产/重复性强的工程师（甚至可能是针对同一职位）。在这种情况下，考虑采用多重的面试方法，其中关键在于你要很大程度上保证每种面试方法都是完全规范化的，我们在 Triplebyte上就在这样做。我们发现你仅需问每个求职申请者他们所青睐的面试方法即可。资历不是没用的，毕业于麻省理工或者斯坦福的，抑或在谷歌和苹果公司工作过的工程师组建的队伍确实要比没这些资历的工程师更加优秀，但问题是绝大多数工程师（包括我自己）都没有以上资历，在筛选环节将申请人的资历纳入考量范围并非毫无道理。我们在 Triplebyte 上没这么做（我们的考评是100%不看背景的），但是在筛选时对申请人的资历做一定的参考可能会有用。但是若让资历问题影响最终面试结果，那就没有道理了，数据表明这种情况确有发生。在我们不看背景进行考评的过程中，对于表现情况一定的求职申请者，那些简历上写有名校文凭的要在比没有名校文凭的人过关率高30%。如果面试官知道求职申请者手握麻省理工的文凭，那他们就更愿意原谅他们在面试环节暴露出来的一些瑕疵。这就是你应该避免的干扰，最显而易见的解决方式就是在开始面试前直接跳过申请者简历上的学校和公司名，有些求职申请者可能会提到他们的学校或公司，但是我们的面试都不看申请者的背景，而且在进行技术考评时，申请者自己提背景的情况也是相当少见的。面试失败的最丑恶的一种情况，就是招聘人员表现出一种羞辱的态度。他们不仅是对求职者技能进行考评的人，而且也代表即将要纳入成员的一个组或一支团队，在第二种身份下，面试是迎接新成员的重要仪式。面试确实让人有压力，很恐怖，但我们都会背负面试压力，所以求职者也自然会有压力，尤其在求职者表现不佳时，面试压力会更加凸显出来。当面试官看到求职者对着答案看上去那么显而易见的问题，就是答不出来急得砸脑袋时，就会觉得大失所望，气不打一处来，同时又万分沮丧，这样无疑会让求职者压力更大，形成恶性循环。一般这种情况面试官唯恐避之不及，为此应该展开探讨，并且对面试官进行培训。我们用的一个策略是，当求职者表现很差劲时，就将想要对其进行考评的评估模式切换成想要让其理解问题正解的教学模式。心理上的这种切换大有裨益，当你采用教学模式时，你就没有理由硬忍住不说答案了，也会变得完全亲和友善。迄今为止，我只探讨过单独的问题，却没有谈过最终的面试决策。我的建议：在做录用决定时应看求职者（在你所关心的技能中）具备的最高水平技能，而非中等或最低水平技能。无论是有意还是无意，你们好像就是这么做的。每个面试过求职者的面试官通过聚在一起开会，来制定最终的录用/淘汰决定。在至少有一人力挺，且没有人强烈反对的情况下，求职申请者就会被录用。要想让一人力挺，求职申请者就需要主攻面试的其中一个部分，大显身手。我们的数据显示，要在公司面试的至少其中一个部分表现优异，求职者具备的最高技能就是最紧密的影响因素了。然而，为了得到 offer，求职者也需要保证没有强烈反对的声音，而若回答问题时表现得非常愚蠢，那么就不会引发强烈的反对。这里我们会发现大量的干扰，技术高明的工程师具备的能力各式各样，因而几乎不可能有求职者能驾驭所有技能。那么求职者至少在一次面试中，体现了在一方面的优势（最高技能），且没有暴露在某些方面的明显劣势，才能获得 offer，而这里就有干扰出现。如同一个工程师在回答有关网络系统的面试问题时表现不好而遭到淘汰，但却在另一个面试中成绩优异，只因为面试没出网络系统的问题。我认为最好的解决方法就是让公司专注于求职者的最高技能，同时对于面试中部分环节表现不佳的人也能通融给过。我不想表现得过于绝对，当然有些领域对公司是至关重要的。而且对于企业文化，若团队中每个人在特定的领域都有特定的定位，那很可能大有裨益，但是将更多的注意力集中于最高技能着实可以减少面试中的干扰。到底为什么要搞面试？我应该回答的最后一个问题是为什么要搞面试？我确信有些读者已经咬牙切齿地问“对一个破败的系统想那么多干嘛？直接用带回家的项目进行考评不就行了！或者直接采取试用呗！”毕竟，一些非常成功的企业都会进行试用（求职者在团队中待一周），或者用带回家的项目取代当面面试。试用是很有意义的，几乎可以肯定的是，让他们花一周的时间跟在一个工程师旁边工作（或者看他们是如何完成一个实际的项目的），要比让他们回答1小时的面试问题更能反映能力。然而，有两个问题导致试用一直无法取代标准面试：1.要进行试用的话，公司要承受高昂成本，没有公司能为每个求职申请者承担整整一周的试用花销。因而公司必须采用其他的面试环节来决定试用的人选。2.试用（以及大型的带回家完成的项目）对求职者而言成本高昂，即使他们能获得报酬，那也未必有空参与。比如一个工程师的工作是全职的，就可能没法抽空干别的，而且就算能抽出时间，可能也不愿意。而且如果一个工程师已经获得了一些offer，那就不太可能再甘愿承受结果还充满不确定性的试用考验了，这一现象明显能从 Tripletype 上的求职者中看到。许多最优秀的求职申请者（拥有其他公司的offer）只是单纯不做大型项目或者不经受试用考验。我认为如果你有开展试用的经济实力，那么加上试用这种选人方式是很不错的。但要想让这取代技术面试，并不完全可行。了解工程师过去的开发经历也可以成为取代技术面试的一种方式。逻辑上来看，通过了解他们过去的开发情况，就可以推知他们未来是否可以将工作干得得心应手。遗憾的是，我们在 Triplebyte 上实行此方法时，收效甚微。表达能力（推销自己的能力）强的到头来要比技术能力强的人更有胜算，巧舌如簧的工程师对自己的职能夸夸其谈（将整个团队的功劳独吞），谦虚谨慎的工程师却对自己的成绩轻描淡写，这样的现象屡见不鲜。如果有充分的时间和大量的问题去刨根究底，就有可能弄清楚真实情况，但是我们发现，常规面试时间有限，谈论过去的开发经历通常并不能取代技术面试。虽然谈过去经历有助于破冰，拉近和求职申请者间的关系，能够对他们的兴趣有所了解，（而且能从中评判求职者的表达能力，还有可能看出他和企业的的文化契合度），但要想让这取代技术面试，并不完全可行。编程面试的好处！我想让这篇博客以更加乐观的角度作结，无论面试存在多大的问题，但采用这种方法其实也有颇多好处。面试是对申请者能力的直接评估，我有一些朋友是当老师的，他们告诉我教师面试基本上考察的是语言表达能力（推销自己的能力）和所具备的文凭资历，这一点似乎从很多职业中都能得到印证。硅谷没有非常完美的精英体制，但我们至少确实在设法对申请者应具备的重要能力进行直接衡量，并且秉持达观开放的思想，认为一个人无论背景如何，只要具备相应的能力，就能够成为非常优秀的工程师。对文凭资历的偏见会成为贯彻这种思想的阻力，但我们在 Triplebyte 上已经很大程度上克服了这种偏见，并帮助很多没有常规资历的人找到了很好的技术工作。我认为 Triplebyte 不太可能解决比如在法律层面的问题，因为社会对于求职者文凭资历实在是太重视了。程序员同时也在选择面试形式。尽管这个话题颇有争议（当然有程序员对此持异议），但我们提供了各式各样不同的考评形式，通过试验，我们发现绝大多数的程序员还是会挑选常规的面试形式，仅有一小部分人会对公司采用试用或带回家的项目进行考评的形式更感兴趣。无论怎样，我们这里要说的是编程面试，其他形式的考评都能作为很好的补充备选，但看起来不太可能取代面试成为考评工程师的主要形式。结论面试工作很难，无奈的是人类都是复杂的。从某种程度上来说，想要靠区区几小时的面试去评判一个人的能力，这是傻子才会干的事，因而我觉得保持谦逊的态度是至关重要的。任何面试在很多时候都注定会失败，只是因为人实在是太复杂了。但这并不是说着我们应该放弃，在 Triplebyte 上，面试就是我们的产品，我们集体讨论，想出考评测试方法，进而随着时间的推移不断优化面试方式。我在这篇博客中分享了过去两年多学到的一些重点，期待反馈，想知道这些观点是否能够让大家受益。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://wx1.sinaimg.cn/mw690/63918611gy1fstj3g5udqj20gh0b4wi2.jpg"]}
{"title": "三款 Linux 下的 Git 图形客户端 - 文章 - 伯乐在线", "tag": ["IT技术", "Git", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n了解这三个 Git 图形客户端工具如何增强你的开发流程。在 Linux 下工作的人们对  非常熟悉。一个理所当然的原因是，Git 是我们这个星球上最广为人知也是使用最广泛的版本控制工具。不过大多数情况下，Git 需要学习繁杂的终端命令。毕竟，我们的大多数开发工作可能是基于命令行的，那么没理由不以同样的方式与 Git 交互。但在某些情况下，使用带图形界面的工具可能使你的工作更高效一点（起码对那些更倾向于使用图形界面的人们来说）。那么，有哪些 Git 图形客户端可供选择呢？幸运的是，我们找到一些客户端值得你花费时间和金钱（一些情况下）去尝试一下。在此，我主要推荐三种可以运行在 Linux 操作系统上的 Git 客户端。在这几种中，你可以找到一款满足你所有要求的客户端。在这里我假设你理解如何使用 Git 和具有 GitHub 类似功能的代码仓库，，因此我不再花费时间讲解如何使用这些工具。本篇文章主要是一篇介绍，介绍几种可以用在开发任务中的工具。提前说明一下：这些工具并不都是免费的，它们中的一些可能需要商业授权。不过，它们都在 Linux 下运行良好并且可以轻而易举的和 GitHub 相结合。就说这些了，快让我们看看这些出色的 Git 图形客户端吧。 是一个商业工具，不过如果你在非商业环境下使用是免费的。如果你打算在商业环境下使用的话，一个许可证每人每年需要 99 美元，或者 5.99 美元一个月。还有一些其它升级功能（比如分布式评审Distributed Reviews和智能同步SmartSynchronize），这两个工具每个许可证需要另加 15 美元。你也能通过下载源码或者 deb 安装包进行安装。我在 Ubuntu 18.04 下测试，发现 SmartGit 运行良好，没有出现一点问题。不过，我们为什么要用 SmartGit 呢？有许多原因，最重要的一点是，SmartGit 可以非常方便的和 GitHub 以及 Subversion 等版本控制工具整合。不需要你花费宝贵的时间去配置各种远程账号，SmartGit 的这些功能开箱即用。SmartGit 的界面（图 1）设计的也很好，整洁直观。安装完 SmartGit 后，我马上就用它连接到了我的 GitHub 账户。默认的工具栏是和仓库操作相关联的，非常简洁。推送、拉取、检出、合并、添加分支、cherry pick、撤销、变基、重置 ——　这些 Git 的的流行功能都支持。除了支持标准 Git 和 GitHub 的大部分功能，SmartGit 运行也非常稳定。至少当你在 Ubuntu上使用时，你会觉得这一款软件是专门为 Linux 设计和开发的。SmartGit 可能是使各个水平的 Git 用户都可以非常轻松的使用 Git，甚至 Git 高级功能的最好工具。为了了解更多 SmartGit 相关知识，你可以查看一下其。 是另外一款商业 Git 图形客户端，它可以使你感受到一种绝不会后悔的使用 Git 或者 GitHub 的美妙体验。SmartGit 具有非常简洁的界面，而 GitKraken 拥有非常华丽的界面，它一开始就给你展现了很多特色。GitKraken 有一个免费版（你也可以使用完整版 15 天）。试用期过了，你也可以继续使用免费版，不过不能用于商业用途。对那些想让其开发工作流发挥最大功效的人们来说，GitKraken 可能是一个比较好的选择。界面上具有的功能包括：可视化交互、可缩放的提交图、拖拽、与 Github、GitLab 和 BitBucked 的无缝整合、简单的应用内任务清单、应用内置的合并工具、模糊查找、支持 Gitflow、一键撤销与重做、快捷键、文件历史与追责、子模块、亮色和暗色主题、Git 钩子支持和 Git LFS 等许多功能。不过用户倍加赞赏的还是精美的界面（图 2)。除了令人惊艳的图形界面，另一个使 GitKraken 在 Git 图形客户端竞争中脱颖而出的功能是：GitKraken 使得使用多个远程仓库和多套配置变得非常简单。不过有一个告诫，使用 GitKraken 需要花钱（它是专有的）。如果你想商业使用，许可证的价钱如下：一人一年 49 美元10 人以上团队，39 美元每人每年100 人以上团队， 29 美元每人每年专业版账户不但可以在商业环境使用 Git 相关功能，还可以使用 Glo Boards（GitKraken 的项目管理工具）。Glo Boards 的一个吸引人的功能是可以将数据同步到 GitHub 工单Issues。Glo Boards 具有分享功能还具有搜索过滤、问题跟踪、Markdown 支持、附件、＠ 功能、清单卡片等许多功能。所有的这些功能都可以在 GitKraken 界面里进行操作。GitKraken 可以通过 deb 文件或者源码进行安装。 是我们推荐列表中一款自由开源的 Git 图像客户端。不像 GitKraken 和 SmartGit，Git Cola是一款比较难啃的骨头，一款比较实用的 Git 客户端。Git Cola 是用 Python 写成的，使用的是 GTK 界面，因此无论你用的是什么 Linux 发行版和桌面，都可以无缝支持。并且因为它是开源的，你可以在你使用的发行版的包管理器中找到它。因此安装过程无非是打开应用商店，搜索 “Git Cola” 安装即可。你也可以通过下面的命令进行安装：或者Git Cola 看起来相对比较简单（图 3）。事实上，你无法找到更复杂的东西，因为 Git Cola 是非常基础的。因为 Git Cola 看起来回归自然，所以很多时间你必须同终端打交道。不过这并不是什么难事儿（因为大多数开发人员需要经常使用终端）。Git Cola 包含以下特性：支持多个子命令自定义窗口设置可设置环境变量语言设置支持自定义 GUI 设置支持快捷键尽管 Git Cola 支持连接到远程仓库，但和像 GitHub 这样的仓库整合看起来也没有 GitKraken 和 SmartGit 直观。不过如果你的大部分工作是在本地进行的，Git Cola 并不失为一个出色的工具。Git Cola 也带有有一个高级的 DAG（有向无环图）可视化工具，叫做 Git DAG。这个工具可以使你获得分支的可视化展示。你可以独立使用 Git DAG，也可以在 Git Cola 内通过 “view->DAG” 菜单来打开。正是 Git DAG 这个威力巨大的工具使用 Git Cola 跻身于应用商店中 Git 图形客户端前列。还有更多的 Git 图形客户端。不过，从上面介绍的这几款中，你已经可以做很多事情了。无论你在寻找一款更有丰富功能的 Git 客户端（不管许可证的话）还是你本身是一名坚定的 GPL 支持者，都可以从上面找到适合自己的一款。如果想学习更多关于 Linux 的知识，可以通过学习Linux基金会的课程。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/08/747d1597878c971c3e72f3c3ce03cde9.jpg"]}
{"title": "Linus 定义 Linux - 文章 - 伯乐在线", "tag": ["IT技术", " 2 评论 ", "Linux"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": " 2 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nLINUX是什么？LINUX是一个免费类unix内核，适用于386-AT计算机，附带完整源代码。主要让黑客、计算机科学学生使用，学习和享受。它大部分用C编写，但是一小部分是用gnu格式汇编，而且引导序列用的是因特尔086汇编语言。C代码是相对ANSI的，使用一些GNU增强特性（大多为 __asm__ 和 inline）。然而有很多可用于386电脑的unices，他们大部分要花很多钱，而且不附带源码。因此他们是使用计算机的理想选择，但是如果你想了解他们如何工作，那是不可能的。也有一些  Unix 是附带源码的。Minix，Andrew S. Tanenbaum编写的学习工具，已经在大学中作为教学工具使用了很多年了。BSD-386系统是附带源码的，但是有版权限制，而且要花很多钱（我记得起始价格为$995）。GNU内核（Hurd）将会是免费的，但是现在还没有准备好，而且对于了解和学习它们来说有点庞大。LINUX与Minix是最相似的，由于它很小而且不是非常复杂，因此易于理解（嗯…）。LINUX是基于Minix编写的，因此有相当多的相同点，任何Minix黑客在使用LINUX的时候都感觉非常熟悉。不过，没有在项目中使用Minix代码，因此Minix版权没有限制到这个新系统。它也是完全免费的，而且它的版权非常宽松。因此不像使用Minix，它不需要几兆字节大小的区别。LINUX版权虽然是免费的发布版，我还是从以下几个方面限制了LINUX的使用：你可以自由复制和重新发布源码和二进制，只要是：完全开源。因此不能单独发布二进制，即使你只修改了一点。你不能从发布版获取利益。事实上甚至“装卸费用”都是不被接受的。你要保持完整的适当版权。根据需要你可能会修改源码，但是如果你发布了新系统的一部分（或者只有二进制），必须将新的代码包含进去。除了不包含版权的代码之外，你可能会做一些小的修改。这由你来定，但是如果能将相关内容或者代码告诉我，将不胜感激。对任何使用或者扩展系统的人来说，这应该足够宽松而不会引起任何担忧。如果你有朋友真的不想要源码，只想要一个能运行的二进制，你当然可以给他而不用担心我会起诉你。不过最好只在朋友之间这么做。LINUX运行所需的硬件/软件LINUX是在一个运行Minix的386-AT上开发的。由于LINUX是一个真正的操作系统，而且需要直接与硬件交互来做一些事情，你必须有一个非常相似的系统来让他顺利运行：386-AT（PS/2之类是不同的，不能正常运行）VGA或者EGA屏幕硬件。标准AT硬盘接口，IDE盘可以运行（实际上我用的就是这个）。正常实模式BIOS。一些机器看起来是用虚-86模式运行启动程序，而且在这样的机器LINUX不会启动和正常运行。LINUX会发展成为一个自给自足的系统，现在需要Minix-386才能正常运行。你需要Minix让初始化启动文件系统，和编译OS二进制。在那之后LINUX是一个自给自足的系统，但是为了做文件系统检查（fsck）和修改之后重编译系统，推荐使用Minix。获取LINUXLINUX现在可以使用匿名ftp从‘nic.funet.fi’的‘/pub/OS/Linux’目录获取。这个目录包含操作系统的所有源码，还有一些二进制文件，因此你可以真正使用系统了。此目录中各类文件如下：linux-0.03.tar.Z–系统的完全源码，16位tar压缩文件格式。Linux.tex–这个文件的LATEX源码。bash.Z–在LINUX下运行的bash二进制文件。这个二进制文件应该放到预留给LINUX文件系统中的/bin/sh下（参见installation）。update.Z–更新二进制文件，要放到/bin/update。gccbin.tar.Z–GNU cc二进制文件需要由一个可运行的编译器。这个tar压缩包含有编译器，加载器，汇编程序和支持程序（nm，strip等）。它还包含一个小型的库，可用于大部分程序。include.tar.Z–让gcc运行的必要include文件。unistd.tar.Z–unistd库程序的源码（即系统调用接口）。通过这个你可以使用系统独立库源码编译一个大一些的库。utilbin.tar.Z–各种GNU工具的二进制文件，包括GNU的fileutils，make和tar。也包含克隆emacs的uemacs。README, RELNOTES-0.01, INSTALLATION–包含一些（有点过时的）LINUX相关的信息的ascii文件。让系统运行的最少文件是OS源码和bash和更新二进制文件。不过只用这些，你做不了什么事。安装在你拿到了必要LINUX文件之后，你需要编译系统和创建root目录。必要的二进制文件需要放到root文件系统中。按如下操作：\n1. 备份你的软件。虽然LINUX从没有毁坏过我的任何文件，但没有什么是必然的。安全胜过遗憾。\n2. 选择/创建一个标准MinixHD-分区作为新的LINUX root文件系统。\n3. 在新的root创建必要的设备节点。LINUX与Minix使用相同类型的节点，所以使用Minix的mknod命令创建下面的设备：节点号与在Minix中相同。/dev/tty/dev/tty[0-2]/dev/hd[0-9]4. 将必要文件放到新的root分区。文件应该放在下面目录中：\n希望你现在有一个功能正常的unix，而且你已经root权限登录。LINUX现在没有‘init’过程，只要你注销，系统会同步并等待。使用三指键（Ctrl+Alt+Del）重启机器。gcc添加链接到你选择的/usr/local/lib中的文件。我将ld，as，nm，strip和size链接到他们相应的 /usr/local/lib/gcc-XXX。gccbin.tar.Z中的内容，除了gccinclude.tar.Z的内容utilbin.tar.Z的内容sh，即bash.Zupdate/bin:/usr/bin:/usr/include:/usr/local/lib:/usr/local/bin:编辑系统中的linux/include/linux/config.h。这个文件包含了针对于系统的信息：内存空间，硬盘类型，root分区号（同样的与Minix中的编号相同），键盘类型（现在只有US和Finnish）等。编译LINUX源码。一个简单技巧就可以完成，在你编辑makefiles为适合你的系统之后（即，删除-mstring-insnsflag，和修改适合你的路径。）1.40之前版本gcc的用户可能需要添加gnulib到makefile中‘LIBS=’一行。复制产生的镜像文件到软盘（即，cp Image /dev/PS0 或者之类的）。使用新的软盘重启。启动界面应该告诉你系统正在启动（加载系统…），然后是一些必要的文件系统信息（xxx/XXX inodes/blocks free），接下来是一个确定，还有bash提示（如果你没有.bashrc文件，则初始化bash#）。LINUX 是打算作为一个全部自给自足的内核，但现在并非如此。作为上面已经提到的，你需要 Minix 来设置启动设备并且检查文件系统当它运行起来的时候。这里有一些其它的不足之处：硬件的不兼容。一些 AT 标准特性当前还没有支持。最值得注意的是软盘驱动，利用 LINUX 进行实际工作（备份 etc）当前是不可能的[译者：这个是 oldlinux，这个是 Linus Torvalds 1991 年 10 月写的文章，肯定当时是不行的]。还有串行连接的一些特性没有被实现（2400 bps 波特率的硬连接，没有挂断（hang-up）提示等等 ）。标准 c 库的不兼容。gcc 分发版的 libc.a 没有完成，我对免费可发布的库功能很感兴趣。一些系统调用没有完全实现。这些设计绝大多数“极少调用”的特性比如调试（谁无论如何需要它的话，你的程序第一次是无法工作的:-)）以及其它的特性。如上所述，没有登陆和初始化进程。当前 LINUX 启动在单用户模式，以 root 作为控制台用户。对于一些移植工作足够了，但不是实际可用的。387支持[译者：硬件浮点，当时 Intel 发布了外接式 FPU] 没有被实现，即使已有一些基础程序被提供出来。”nic.funet.fi” 的 gcc 二进制包使用软浮点（ie 仿真功能调用）来支持 4 个基础数学运算操作。387-支持将尽快实现当我的电脑安装了这个硬件。希望在一个月或者两个月。现在还没有重要的系统管理命令实现在 LINUX 中。这些包括 mkfs, format, fsck, mknod 等。这些命令需要的内核特性还没有实现（format, mknod），一些命令只需要实现它。作为一个库，我欢迎任何免费分发文件。如您所见，LINUX还不是一个完整的系统。 感谢您的帮助，使其变得更好。 我对为LINUX重写的Minix命令不感兴趣，除非你自己从头开始编写它们。 您当然可以免费（并鼓励）将您的Minix发行版中的所有内容用于您自己的LINUX系统，但由于Minix的版权，它们无法分发给更广泛的受众。这里提到的一些问题将由我（即lines/387/floppy支持）尽快修复，但我希望得到库函数的支持。感谢你们提交的错误报告及补丁还有愿望清单，如果你真的有针对问题的补丁，我会立即尝试去修复它。 小的更改将作为补丁形式发送到邮件列表，并在nic.funet.fi’更新。LINUX移植软件LINUX被设计得让移植相对容易。因此，就有了完整的termios实现和一些POSIX库。我所移植的（诚然相对较少）程序没有任何问题。尽管LINUX与Minix非常相似，但Minix程序通常并不会比为其他nuix设计的程序更容易移植。因此，我不建议从一个特定程序的Minix版本开始，而应该尝试从头开始移植‘’virgin‘’程序。比BSD更接近SYSV，这意味着当给定一个-DUSG或者-DSYSV标识时，大多数程序很容易移植。移植过程中最困难的一点就是缺少库函数。这些必须由你来编写，或者从其他的来源复制（Minix可能是个有缘人）。另外，一些程序（特别是GNU）有各种各样的标识，这些标识可以定义哪些函数不可用（一旦在Makefile中添加了足够量的-DXXX_MISSING标识，GNU fileutils将编译的很好）。已经移植的程序下面这些程序已经移植到LINUX：GNU cc (gcc, cc1, cpp)GNU assembler (as386)GNU binutils (ld, ar, nm, size, strip, ranlib)GNU compress (16-bit)GNU tarGNU makeGNU bash (Bourne Again SHell)GNU sedGNU bison (yacc-lookalike)GNU awkGNU fileutils (ls, cp, rm, mkdir, rmdir, tail etc)lessuemacs所有上述程序都能在‘nic.funet.fi’(主要在’/pub/gnu’)中找到，大多数LIINUX-binaries都可以在‘/pub/OS/Linux’目录中找到。包括gcc（cc1）有一些我自己增强的功能，所有这些程序都在没有变化的情况下编译的。先尝试自己编译，遇到问题可以将差异或者资源发邮件给我。另外，我提起过明确地GNU差异编译和运行。技术帮助LINUX目前有一个邮件列表，您可以通过邮件发送到这个地址订阅： ，并要求包括在列表中。然后你可以通过这个邮箱： 提问题，这将复制你的问题/答案/无论什么，并发送给列表中其他所有人。请注意Linux-activists和Linux0activists-request的不同——第一个用于给列表中的所有人发送邮件，第二个仅用于订阅和取消订阅。当然，您也可以直接发送邮件至 。我会尽量在一两天内回答所有的问题。尽管‘nic.funet.fi’可能会保持合理的更新状态，但是它还有些问题（即，我无法因为个人得到文件，但可以通过几个人）。因此，如果邮件列表上的人想要补丁或二进制文件，他们将会更快得到。感谢我要感谢学院…说真的，如果没有其他人的帮助，这个系统将永远不会有曙光，甚至会变得更糟。Bruce Evans 帮助我找到了需要更改的位置，以便gcc能正确地处理浮点数，并提供许多有用的想法/建议（他的Minix-386用于构建系统）。此外，Earl Chew 的estdio包被用于标准的IO库。像这样更自由地分发包！Alain W Black和Richard Tobin为Minix制作了gcc，没有它我就无法编译这个东西。GNU完成了我在Linux下使用的大部分程序。Alfred Leung发送了美国键盘补丁。附：“感谢”他的“建设性”批评和“诙谐”的评论。他是我第一个-测试者，他应该被授予勇气奖章。()年月日\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2014/03/5215e39e39eb546d1689aa26f8d633be.jpg"]}
{"title": "Linux 的内存分页管理 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n内存是计算机的主存储器。内存为进程开辟出进程空间，让进程在其中保存数据。我将从内存的物理特性出发，深入到内存管理的细节，特别是了解虚拟内存和内存分页的概念。简单地说，内存就是一个数据货架。内存有一个最小的存储单位，大多数都是一个字节。内存用内存地址（memory address）来为每个字节的数据顺序编号。因此，内存地址说明了数据在内存中的位置。内存地址从0开始，每次增加1。这种线性增加的存储器地址称为线性地址（linear address）。为了方便，我们用十六进制数来表示内存地址，比如0x00000003、0x1A010CB0。这里的“0x”用来表示十六进制。“0x”后面跟着的，就是作为内存地址的十六进制数。内存地址的编号有上限。地址空间的范围和地址总线（address bus）的位数直接相关。CPU通过地址总线来向内存说明想要存取数据的地址。以英特尔32位的80386型CPU为例，这款CPU有32个针脚可以传输地址信息。每个针脚对应了一位。如果针脚上是高电压，那么这一位是1。如果是低电压，那么这一位是0。32位的电压高低信息通过地址总线传到内存的32个针脚，内存就能把电压高低信息转换成32位的二进制数，从而知道CPU想要的是哪个位置的数据。用十六进制表示，32位地址空间就是从0x00000000 到0xFFFFFFFF。内存的存储单元采用了随机读取存储器（RAM， Random Access Memory）。所谓的“随机读取”，是指存储器的读取时间和数据所在位置无关。与之相对，很多存储器的读取时间和数据所在位置有关。就拿磁带来说，我们想听其中的一首歌，必须转动带子。如果那首歌是第一首，那么立即就可以播放。如果那首歌恰巧是最后一首，我们快进到可以播放的位置就需要花很长时间。我们已经知道，进程需要调用内存中不同位置的数据。如果数据读取时间和位置相关的话，计算机就很难把控进程的运行时间。因此，随机读取的特性是内存成为主存储器的关键因素。内存提供的存储空间，除了能满足内核的运行需求，还通常能支持运行中的进程。即使进程所需空间超过内存空间，内存空间也可以通过少量拓展来弥补。换句话说，内存的存储能力，和计算机运行状态的数据总量相当。内存的缺点是不能持久地保存数据。一旦断电，内存中的数据就会消失。因此，计算机即使有了内存这样一个主存储器，还是需要硬盘这样的外部存储器来提供持久的储存空间。内存的一项主要任务，就是存储进程的相关数据。我们之前已经看到过进程空间的程序段、全局数据、栈和堆，以及这些这些存储结构在进程运行中所起到的关键作用。有趣的是，尽管进程和内存的关系如此紧密，但进程并不能直接访问内存。在Linux下，进程不能直接读写内存中地址为0x1位置的数据。进程中能访问的地址，只能是虚拟内存地址（virtual memory address）。操作系统会把虚拟内存地址翻译成真实的内存地址。这种内存管理方式，称为虚拟内存（virtual memory）。每个进程都有自己的一套虚拟内存地址，用来给自己的进程空间编号。进程空间的数据同样以字节为单位，依次增加。从功能上说，虚拟内存地址和物理内存地址类似，都是为数据提供位置索引。进程的虚拟内存地址相互独立。因此，两个进程空间可以有相同的虚拟内存地址，如0x10001000。虚拟内存地址和物理内存地址又有一定的对应关系，如图1所示。对进程某个虚拟内存地址的操作，会被CPU翻译成对某个具体内存地址的操作。图1 虚拟内存地址和物理内存地址的对应应用程序来说对物理内存地址一无所知。它只可能通过虚拟内存地址来进行数据读写。程序中表达的内存地址，也都是虚拟内存地址。进程对虚拟内存地址的操作，会被操作系统翻译成对某个物理内存地址的操作。由于翻译的过程由操作系统全权负责，所以应用程序可以在全过程中对物理内存地址一无所知。因此，C程序中表达的内存地址，都是虚拟内存地址。比如在C语言中，可以用下面指令来打印变量地址：本质上说，虚拟内存地址剥夺了应用程序自由访问物理内存地址的权利。进程对物理内存的访问，必须经过操作系统的审查。因此，掌握着内存对应关系的操作系统，也掌握了应用程序访问内存的闸门。借助虚拟内存地址，操作系统可以保障进程空间的独立性。只要操作系统把两个进程的进程空间对应到不同的内存区域，就让两个进程空间成为“老死不相往来”的两个小王国。两个进程就不可能相互篡改对方的数据，进程出错的可能性就大为减少。另一方面，有了虚拟内存地址，内存共享也变得简单。操作系统可以把同一物理内存区域对应到多个进程空间。这样，不需要任何的数据复制，多个进程就可以看到相同的数据。内核和共享库的映射，就是通过这种方式进行的。每个进程空间中，最初一部分的虚拟内存地址，都对应到物理内存中预留给内核的空间。这样，所有的进程就可以共享同一套内核数据。共享库的情况也是类似。对于任何一个共享库，计算机只需要往物理内存中加载一次，就可以通过操纵对应关系，来让多个进程共同使用。IPO中的共享内存，也有赖于虚拟内存地址。虚拟内存地址和物理内存地址的分离，给进程带来便利性和安全性。但虚拟内存地址和物理内存地址的翻译，又会额外耗费计算机资源。在多任务的现代计算机中，虚拟内存地址已经成为必备的设计。那么，操作系统必须要考虑清楚，如何能高效地翻译虚拟内存地址。记录对应关系最简单的办法，就是把对应关系记录在一张表中。为了让翻译速度足够地快，这个表必须加载在内存中。不过，这种记录方式惊人地浪费。如果树莓派1GB物理内存的每个字节都有一个对应记录的话，那么光是对应关系就要远远超过内存的空间。由于对应关系的条目众多，搜索到一个对应关系所需的时间也很长。这样的话，会让树莓派陷入瘫痪。因此，Linux采用了分页（paging）的方式来记录对应关系。所谓的分页，就是以更大尺寸的单位页（page）来管理内存。在Linux中，通常每页大小为4KB。如果想要获取当前树莓派的内存页大小，可以使用命令：得到结果，即内存分页的字节数：返回的4096代表每个内存页可以存放4096个字节，即4KB。Linux把物理内存和进程空间都分割成页。内存分页，可以极大地减少所要记录的内存对应关系。我们已经看到，以字节为单位的对应记录实在太多。如果把物理内存和进程空间的地址都分成页，内核只需要记录页的对应关系，相关的工作量就会大为减少。由于每页的大小是每个字节的4000倍。因此，内存中的总页数只是总字节数的四千分之一。对应关系也缩减为原始策略的四千分之一。分页让虚拟内存地址的设计有了实现的可能。无论是虚拟页，还是物理页，一页之内的地址都是连续的。这样的话，一个虚拟页和一个物理页对应起来，页内的数据就可以按顺序一一对应。这意味着，虚拟内存地址和物理内存地址的末尾部分应该完全相同。大多数情况下，每一页有4096个字节。由于4096是2的12次方，所以地址最后12位的对应关系天然成立。我们把地址的这一部分称为偏移量（offset）。偏移量实际上表达了该字节在页内的位置。地址的前一部分则是页编号。操作系统只需要记录页编号的对应关系。\n图2 地址翻译过程内存分页制度的关键，在于管理进程空间页和物理页的对应关系。操作系统把对应关系记录在分页表（page table）中。这种对应关系让上层的抽象内存和下层的物理内存分离，从而让Linux能灵活地进行内存管理。由于每个进程会有一套虚拟内存地址，那么每个进程都会有一个分页表。为了保证查询速度，分页表也会保存在内存中。分页表有很多种实现方式，最简单的一种分页表就是把所有的对应关系记录到同一个线性列表中，即如图2中的“对应关系”部分所示。这种单一的连续分页表，需要给每一个虚拟页预留一条记录的位置。但对于任何一个应用进程，其进程空间真正用到的地址都相当有限。我们还记得，进程空间会有栈和堆。进程空间为栈和堆的增长预留了地址，但栈和堆很少会占满进程空间。这意味着，如果使用连续分页表，很多条目都没有真正用到。因此，Linux中的分页表，采用了多层的数据结构。多层的分页表能够减少所需的空间。我们来看一个简化的分页设计，用以说明Linux的多层分页表。我们把地址分为了页编号和偏移量两部分，用单层的分页表记录页编号部分的对应关系。对于多层分页表来说，会进一步分割页编号为两个或更多的部分，然后用两层或更多层的分页表来记录其对应关系，如图3所示。 图3 多层分页表\n在图3的例子中，页编号分成了两级。第一级对应了前8位页编号，用2个十六进制数字表示。第二级对应了后12位页编号，用3个十六进制编号。二级表记录有对应的物理页，即保存了真正的分页记录。二级表有很多张，每个二级表分页记录对应的虚拟地址前8位都相同。比如二级表0x00，里面记录的前8位都是0x00。翻译地址的过程要跨越两级。我们先取地址的前8位，在一级表中找到对应记录。该记录会告诉我们，目标二级表在内存中的位置。我们再在二级表中，通过虚拟地址的后12位，找到分页记录，从而最终找到物理地址。多层分页表就好像把完整的电话号码分成区号。我们把同一地区的电话号码以及对应的人名记录同通一个小本子上。再用一个上级本子记录区号和各个小本子的对应关系。如果某个区号没有使用，那么我们只需要在上级本子上把该区号标记为空。同样，一级分页表中0x01记录为空，说明了以0x01开头的虚拟地址段没有使用，相应的二级表就不需要存在。正是通过这一手段，多层分页表占据的空间要比单层分页表少了很多。\n多层分页表还有另一个优势。单层分页表必须存在于连续的内存空间。而多层分页表的二级表，可以散步于内存的不同位置。这样的话，操作系统就可以利用零碎空间来存储分页表。还需要注意的是，这里简化了多层分页表的很多细节。最新Linux系统中的分页表多达3层，管理的内存地址也比本章介绍的长很多。不过，多层分页表的基本原理都是相同。综上，我们了解了内存以页为单位的管理方式。在分页的基础上，虚拟内存和物理内存实现了分离，从而让内核深度参与和监督内存分配。应用进程的安全性和稳定性因此大为提高。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "Linux 下 cut 命令的 4 个基础实用的示例 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n 命令是用来从文本文件中移除“某些列”的经典工具。在本文中的“一列”可以被定义为按照一行中位置区分的一系列字符串或者字节，或者是以某个分隔符为间隔的某些域。先前我已经介绍了。在本文中，我将解释 linux 下  命令的 4 个本质且实用的例子，有时这些例子将帮你节省很多时间。假如你想，你可以观看下面的视频，视频中解释了本文中我列举的 cut 命令的使用例子。当启用  命令行选项时， 命令将移除一系列字符。和其他的过滤器类似，  命令不会直接改变输入的文件，它将复制已修改的数据到它的标准输出里去。你可以通过重定向命令的结果到一个文件中来保存修改后的结果，或者使用管道将结果送到另一个命令的输入中，这些都由你来负责。假如你已经下载了上面视频中的，你将看到一个名为  的数据文件，这些数据是直接从我妻子在她工作中使用的某款会计软件中导出的：上述文件是一个固定宽度的文本文件，因为对于每一项数据，都使用了不定长的空格做填充，使得它看起来是一个对齐的列表。这样一来，每一列数据开始和结束的位置都是一致的。从  命令的字面意思去理解会给我们带来一个小陷阱： 命令实际上需要你指出你想的数据范围，而不是你想的范围。所以，假如我需要上面文件中的  和  列，我需要这么做：正如我们上面看到的那样，  命令需要我们特别指定需要保留的数据的。所以，下面我将更正式地介绍如何定义范围：对于  命令来说，范围是由连字符()分隔的起始和结束位置组成，范围是基于 1 计数的，即每行的第一项是从 1 开始计数的，而不是从 0 开始。范围是一个闭区间，开始和结束位置都将包含在结果之中，正如它们之间的所有字符那样。如果范围中的结束位置比起始位置小，则这种表达式是错误的。作为快捷方式，你可以省略起始结束值，正如下面的表格所示： 命令允许你通过逗号分隔多个范围，下面是一些示例： 命令的一个限制（或者是特性，取决于你如何看待它）是它将 。所以下面的命令和先前的命令将产生相同的结果，尽管范围的顺序做了改变：你可以轻易地使用  命令来验证：类似的， 命令 ：值得提及的是，曾经有一个提议，建议使用  选项来去除上面提到的两个限制，使得  工具可以重排或者重复数据。但这个提议被 ，。据我所知，我还没有见过哪个版本的  程序实现了上面的提议，以此来作为扩展，假如你知道某些例外，请使用下面的评论框分享给大家！当使用  命令行选项时， 命令将移除字节范围。咋一看，使用范围和使用没有什么明显的不同：这是因为我们的示例数据文件使用的是 （字符集），使用  便可以正确地猜出来：在 US-ASCII 编码中，字符和字节是一一对应的。理论上，你只需要使用一个字节就可以表示 256 个不同的字符（数字、字母、标点符号和某些符号等）。实际上，你能表达的字符数比 256 要更少一些，因为字符编码中为某些特定值做了规定（例如 32 或 65 就是）。即便我们能够使用上述所有的字节范围，但对于存储种类繁多的人类手写符号来说，256 是远远不够的。所以如今字符和字节间的一一对应更像是某种例外，并且几乎总是被无处不在的 UTF-8 多字节编码所取代。下面让我们看看如何来处理多字节编码的情形。正如我前面提到的那样，示例数据文件来源于我妻子使用的某款会计软件。最近好像她升级了那个软件，然后呢，导出的文本就完全不同了，你可以试试和上面的数据文件相比，找找它们之间的区别：上面的标题栏或许能够帮助你找到什么被改变了，但无论你找到与否，现在让我们看看上面的更改过后的结果：我复制了上面命令的输出。所以可以很明显地看出列对齐那里有些问题。对此我的解释是原来的数据文件只包含 US-ASCII 编码的字符（符号、标点符号、数字和没有发音符号的拉丁字母）。但假如你仔细地查看经软件升级后产生的文件，你可以看到新导出的数据文件保留了带发音符号的字母。例如现在合理地记录了名为 “ALNÉENRE” 的公司，而不是先前的 “ALNEENRE”（没有发音符号）。 正确地识别出了改变，因为它报告道现在这个文件是  的。如果想看看 UTF-8 文件中那些带发音符号的字母是如何编码的，我们可以使用 ，它可以让我们直接以字节形式查看文件：在   输出的 00000030 那行，在一系列的空格（字节 ）之后，你可以看到：字母  被编码为 ，字母  被编码为 ，字母  被编码为 。但对于大写的 （这是它在 Unicode 标准中字母  的官方名称），则是使用  个字节  来编码的。这样便出现问题了：对于使用固定宽度编码的文件， 使用字节位置来表示范围的  命令工作良好，但这并不适用于使用变长编码的 UTF-8 或者  编码。这种情况在下面的  中被明确地解释过：先前版本的  程序将字节和字符视作等同的环境下运作（正如在某些实现下对退格键 <backspace>  和制表键 <tab> 的处理）。在针对多字节字符的情况下，特别增加了  选项。嘿，等一下！我并没有在上面“有错误”的例子中使用 ‘-b’ 选项，而是  选项呀！所以，难道能够成功处理了吗！？是的，确实：但是很不幸，即便我们现在已身处 2018 年，GNU Coreutils 的版本为 8.30 了， 程序的 GNU 版本实现仍然不能很好地处理多字节字符。引用  的话说，。需要提及的是，这个问题距今已有 10 年之久了！另一方面， 的实现版本和 POSIX 相吻合，这将归功于当前的本地化（）设定来合理地处理多字节字符：正如期望的那样，当使用  选项而不是  选项后， OpenBSD 版本的  实现和传统的  表现是类似的：从某种意义上说，使用  来处理用特定分隔符隔开的文本文件要更加容易一些，因为只需要确定好每行中域之间的分隔符，然后复制域的内容到输出就可以了，而不需要烦恼任何与编码相关的问题。下面是一个用分隔符隔开的示例文本文件：你可能知道上面文件是一个  格式的文件（它以逗号来分隔），即便有时候域分隔符不是逗号。例如分号（）也常被用来作为分隔符，并且对于那些总使用逗号作为 的国家（例如法国，所以上面我的示例文件中选用了他们国家的字符），当导出数据为 “CSV” 格式时，默认将使用分号来分隔数据。另一种常见的情况是使用  来作为分隔符，从而生成叫做  的文件。最后，在 Unix 和 Linux 领域，冒号 () 是另一种你能找到的常见分隔符号，例如在标准的  和  这两个文件里。当处理使用分隔符隔开的文本文件格式时，你可以向带有  选项的  命令提供需要保留的域的范围，并且你也可以使用  选项来指定分隔符（当没有使用  选项时，默认以 tab 字符来作为分隔符）：但要是输入文件中的某些行没有分隔符又该怎么办呢？很容易地认为可以将这样的行视为只包含第一个域。但  程序并  这样做的。默认情况下，当使用  选项时， 将总是原样输出不包含分隔符的那一行（可能假设它是非数据行，就像表头或注释等）：使用  选项，你可以做出相反的行为，这样  将总是忽略这些行：假如你好奇心强，你还可以探索这种特性，来作为一种相对隐晦的方式去保留那些只包含给定字符的行：作为一种扩展， GNU 版本实现的  允许通过使用  选项来为结果指定一个不同的域分隔符：需要注意的是，在上面这个例子中，所有出现域分隔符的地方都被替换掉了，而不仅仅是那些在命令行中指定的作为域范围边界的分隔符。说到非 POSIX GNU 扩展，它们中的某些特别有用。特别需要提及的是下面的扩展也同样对字节、字符或者域范围工作良好（相对于当前的 GNU 实现来说）。：想想在 sed 地址中的感叹符号()，使用它， 将只保存被匹配到的范围:：使用  来作为行终止符，而不是 。当你的数据包含 新行字符时，  选项就特别有用了，例如当处理文件名的时候（因为在文件名中新行字符是可以使用的，而 NUL 则不可以）。为了展示  选项，让我们先做一点实验。首先，我们将创建一个文件名中包含换行符的文件：现在假设我想展示每个  文件的前 5 个字符。一个想当然的解决方法将会失败：你可以已经知道  是为了而特别设计的，并且在一个命令管道中使用它是一个反模式（确实是这样的）。所以让我们用  来替换它：上面的命令基本上产生了与先前类似的结果（尽管以不同的次序，因为  会隐式地对文件名做排序，而  则不会）。在上面的两个例子中，都有一个相同的问题， 命令不能区分 新行 字符是数据域的一部分（即文件名），还是作为最后标记的 新行 记号。但使用 NUL 字节（\\0）来作为行终止符就将排除掉这种混淆的情况，使得我们最后可以得到期望的结果：通过上面最后的例子，我们就达到了本文的最后部分了，所以我将让你自己试试  后面那个有趣的  参数或者理解为什么我在管道的最后使用了  命令。我只是列举了  命令的最常见且在我眼中最基础的使用方式。你甚至可以将它以更加实用的方式加以运用，这取决于你的逻辑和想象。不要再犹豫了，请使用下面的评论框贴出你的发现。最后一如既往的，假如你喜欢这篇文章，请不要忘记将它分享到你最喜爱网站和社交媒体中！ \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/08/5902a39fabff80e97a3156ede1ace4b2.jpg"]}
{"title": "数据压缩算法：LZ77 算法的分析与实现 - 文章 - 伯乐在线", "tag": ["IT技术", " 2 评论 ", "LZ77", "数据压缩"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": " 2 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nZiv和Lempel于1977年发表题为“顺序数据压缩的一个通用算法（A Universal Algorithm for Sequential Data Compression ）”的论文，论文中描述的算法被后人称为LZ77算法。值得说的是，LZ77严格意义上来说不是一种算法，而是一种编码理论。同Huffman编码一样，只定义了原理，并没有定义如何实现。实际上这类算法已经有很多了，比如LZSS、LZB、LZH等。至今，几乎我们日常使用的所有通用压缩工具，象ARJ，PKZip，WinZip，LHArc，RAR，GZip，ACE，ZOO，TurboZip，Compress，JAR„„甚至许多硬件如网络设备中内置的压缩算法，无一例外，都可以最终归结为这两个以色列人的杰出贡献。不同的基于字典的算法使用不同的方法来维护它们的字典。。。为了便于理解前向缓冲区如何存储短语并形成字典，我们将缓冲区描绘成S，…，S的字符序列，P是由字符组成的短语集合。从字符序列S，…，S，组成n个短语，定义如下：P = {(S),(S,S),…,(S,…,S)}例如，如果前向缓冲区包含字符(A,B,D)，那么缓冲区中的短语为{(A),(A,B),(A,B,D)}。为理解短语是如何在滑动窗口中表示的，首先，把窗口想象成S，…，S的字符序列，且P是由这些字符组成的短语集合。从序列S，…，S产生短语数据集合的过程如下：P = {P,P,…,P}，其中P = {(S),(S,S+1),…,(S,S+1,…,S)}例如，如果滑动窗口中包含符号(A,B,C)，那么窗口和字典中的短语为{(A),(A,B),(A,B,C),(B),(B,C),(C)}。以上面描述的前向缓冲区和滑动窗口为例，其最长的匹配短语为(A,B)。前向缓冲区和滑动窗口之间的匹配有两种情况：要么找到一个匹配短语，要么找不到匹配的短语。当找到最长的匹配时，将其编码成短语标记。当没有找到匹配时，将未匹配的符号编码成符号标记。这个符号标记仅仅包含符号本身，没有压缩过程。事实上，我们将看到符号标记实际上比符号多一位，所以会出现轻微的扩展。一旦把n个符号编码并生成相应的标记，就将这n个符号从滑动窗口的一端移出，并用前向缓冲区中同样数量的符号来代替它们。然后，重新填充前向缓冲区。这个过程使滑动窗口中始终有最新的短语。滑动窗口和前向缓冲区具体维护的短语数量由它们自身的容量决定。下图（1）展示了用LZ77算法压缩字符串的过程，其中滑动窗口大小为8个字节，前向缓冲区大小为4个字节。在实际中，滑动窗口典型的大小为4KB（4096字节）。前向缓冲区大小通常小于100字节。图（1）：使用LZ77算法对字符串ABABCBABABCAD进行压缩我们通过解码标记和保持滑动窗口中符号的更新来解压缩数据，其过程类似于压缩过程。下图（2）展示了解压缩图（1）中数据的过程。图（2）：使用LZ77算法对图（1）中压缩的字符串进行解压缩用LZ77算法压缩的程度取决于很多因素，例如，选择滑动窗口的大小，为前向缓冲区设置的大小，以及数据本身的熵。最终，压缩的程度取决于能匹配的短语的数量和短语的长度。大多数情况下，LZ77比霍夫曼编码有着更高的压缩比，但是其压缩过程相对较慢。用LZ77算法压缩数据是非常耗时的，国为要花很多时间寻找窗口中的匹配短语。然而在通常情况下，LZ77的解压缩过程要比霍夫曼编码的解压缩过程耗时要少。LZ77的解压缩过程非常快是因为每个标记都明确地告诉我们在缓冲区中哪个位置可以读取到所需要的符号。事实上，我们最终只从滑动窗口中读取了与原始数据数量相等的符号而已。返回值：如果数据压缩成功，返回压缩后数据的字节数；否则返回-1；描述：   用LZ77算法压缩缓冲区original中的数据，original包含size个字节的空间。压缩后的数据存入缓冲区compressed中。lz77_compress需要调用malloc来动态的为compressed分配存储空间，当这块空间不再使用时，由调用者调用函数free来释放空间。复杂度：O(n)，其中n是原始数据中符号的个数。返回值：如果解压缩数据成功，返回恢复后数据的字节数；否则返回-1；描述：   用LZ77算法解压缩缓冲区compressed中的数据。假定缓冲区包含的数据之前由lz77_compress压缩。恢复后的数据存入缓冲区original中。lz77_uncompress函数调用malloc来动态的为original分配存储空间。当这块存储空间不再使用时，由调用者调用函数free来释放空间。复杂度：O（n）其中n是原始数据中符号的个数。LZ77算法，通过一个滑动窗口将前向缓冲区中的短语编码成相应的标记，从而达到压缩的目的。在解压缩的过程中，将每个标记解码成短语或符号本身。要做到这些，必须要不断地更新窗口，这样，在压缩过程中的任何时刻，窗口都能按照规则进行编码。在本节所有的示例中，原始数据中的一个符号占一个字节。首先，它将数据中的符号写入压缩数据的缓冲区中，并同时初始化滑动窗口和前向缓冲区。随后，前向缓冲区将用来加载符号。压缩发生在一个循环中，循环会持续迭代直到处理完所有符号。使用ipos来保存原始数据中正在处理的当前字节，并用opos来保存向压缩数据缓冲区写入的当前位。在循环的每次迭代中，调用compare_win来确定前向缓冲区与滑动窗口中匹配的最长短语。函数compare_win返回最长匹配串的长度。当找到一个匹配串时，compare_win设置offset为滑动窗口中匹配串的位置，同时设置next为前向缓冲区中匹配串后一位的符号。在这种情况下，向压缩数据中写入一个短语标记（如图3-a）。在本节展示的实现中，对于偏移量offset短语标记需要12位，这是因为滑动窗口的大小为4KB（4096字节）。此时短语标志需要5位来表示长度，因为在一个32字节的前向缓冲区中，不会有匹配串超过这个长度。当没有找到匹配串时，compare_win返回，并且设置next为前向缓冲区起始处未匹配的符号。在这种情况下，向压缩数据中写入一个符号（如图3-b）。无论向压缩数据中写入的是一个短语还是一个符号，在实际写入标记之前，都需要调用网络函数htonl来转换串，以保证标记是大端格式。这种格式是在实际压缩数据和解压缩数据时所要求的。图3：LZ77中的短语标记（A）和符号标记（B）的结构一旦将相应的标记写入压缩数据的缓冲区中，就调整滑动窗口和前向缓冲区。要使数据通过滑动窗口，将数据从右边滑入窗口，从左边滑出窗口。同样，在前向缓冲区中也是相同的滑动过程。移动的字节数与标记中编码的字符数相等。lz77_compress的时间复杂度为O(n)，其中n是原始数据中符号的个数。这是因为，对于数据中每个n/c个编码的标记，其中1/c是一个代表编码效率的常量因素，调用一次compare_win。函数compare_win运行一段固定的时间，因为滑动窗口和前向缓冲区的大小均为常数。然而，这些常量比较大，会对lz77_compress的总体运行时间产生较大的影响。所以，lz77_compress的时间复杂度是O(n)，但其实际的复杂度会受其常量因子的影响。这就解释了为什么在用lz77进行数据压缩时速度非常慢。首先，该函数从压缩数据中读取字符，并初始化滑动窗口和前向缓冲区。解压缩过程在一个循环中执行，此循环会持续迭代执行直到所有的符号处理完。使用ipos来保存向压缩数据中写入的当前位，并用opos来保存写入恢复数据缓冲区中当前字节。在循环的每次迭代过程中，首先从压缩数据读取一位来确定要解码的标记类型。在解析一个标记时，如果读取的首位是1，说明遇到了一个短语标记。此时读取它的每个成员，查找滑动窗口中的短语，然后将短语写入恢复数据缓冲区中。当查找每个短语时，调用网络函数ntohl来保证窗口中的偏移量和长度的字节顺序是与操作系统匹配的。这个转换过程是必要的，因为从压缩数据中读取出来的偏移量和长度是大端格式的。在数据被拷贝到滑动窗口之前，前向缓冲区被用做一个临时转换区来保存数据。最后，写入该标记编码的匹配的符号。如果读取的标记的首位是0，说明遇到了一个符号标记。在这种情况下，将该标记编码的匹配符号写入恢复数据缓冲区中。一旦将解码的数据写入恢复数据的缓冲区中，就调整滑动窗口。要将数据通过滑动窗口，将数据从右边滑入窗口，从左边滑出窗口。移动的字节数与从标记中解码的字符数相等。lz77_uncompress的时间复杂度为O(n)，其中n是原始数据中符号的个数。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/95f95341b03e66babaadc935b51d6a24.jpg"]}
{"title": "数据科学领域，你该选 Python 还是 R ？ - 文章 - 伯乐在线", "tag": ["IT技术", "Python", "R", "数据"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n根据需求，为了那些希望知道在数据科学方面选择 Python 还是 R 编程语言的人，我发布了这篇指导文章。你可能在数据科学方面是个新手，或者你需要在一个项目中选出一个语言，这篇文章可能会帮助到你。 RStudio 的首席数据科学家，已经给出了答复“使用‘and’替代‘vs’”。由此，同时使用Python/R 是我将提到的第三种选择。这个选项引起了我的好奇心，而且我会在本文末尾介绍这一点。下面是这两种语言之间一些值得比较的因素，这并不是一个完全的列表。：R 和 Python 具有明显不同的历史，有时候会交叉。：通过实际调查发现的很多复杂的社会人类学因素。：详尽的比较以及为什么比较起来这么难。：模块，代码库，可视化，存储库，组织和开发环境。：有些任务和工作类型适合其中一种或者另一种。Python 调用 R 和 R 调用 Python 。：吃你自家的狗粮的一个预测练习。：最终答案。简短概要：ABC -> Python 发布（1989 Guido van Rossum）-> Python 2 (2000) -> Python 3 (2008)Fortan -> S(贝尔实验室)-> R 发布（1991 Ross Ihaka 和 Robert Gentleman）-> R 1.0.0 (2000) ->R  3.0.2 (2013)当比较Python和R的用户时，首先要记住的就是：只有50%的Python用户与R重叠那是假定所有R程序员会用“科学和数字（Scientific and Numeric）”来称呼他。我们也确定，无论程序员的等级如何，这个分布都是正确的。要进一步了解Python“宣传”，请阅读关于Python宣传调查结果：如果我们只看科学和数字社区，这就会把我们带到第二类社区，哪个社区？在所有的科学和数字社区中有一些子社区。尽管也许还会有一些重叠，因为你会怀疑他们与大一些的R/Python社区之间的交互方式确实不同。一些使用Python/R的子社区的例子：深度学习机器学习高级分析预测分析统计探索和数据分析学术可惜研究几乎无穷无尽的然而每个领域看起来都只致力于一个专门社区，你会发现R在如统计和探索之类的领域中更加流行。不久前，你可能会使用R进行构建运行或者做一些非常有意义的探索，而使用的时间比安装Python或者用它来做相同的探索的时候短得多。这一切都被颠覆性的技术改变了，他们是Jupyter notebook和Anaconda。注：Jupyter Notebokks：在浏览器中可以编辑Python/R代码；Anaconda：可以为Python和R简单的安装和打包既然你可以在一个方便提供报告和现成的分析的环境启动运行，就已经排除了一个横在那些想要完成这些任务的人和他们喜爱的语言之间的障碍。Python现在可以使用独立于平台的方式打包，而且可以更快的提供快速、低成本的分析比。在社区中影响了语言选择的另一个区别就是“开源”思想。不仅是开源库，还有致力于开源的协作社区的影响。讽刺的是，开源许可软件，像Tensorflow这样的软件到GNU Scientific Library（各自为Apache和GPL），他们看起来都有Python和R绑定。尽管有R的公共版权，还是有更多人纯粹的支持Python社区。另一方面，看起来有更多的企业支持R，特别是那些有统计方面历史的。最后，考虑到社区和协作，在Github上Python的支持更多。如果我要看，我会看到有超过3.5万个关注的Tensorflow之类的项目。相反，如果我看，像Shiny，Stan…之类的包，他们都少于2千个关注。性能提升很困难，因为有太多的指标和情况需要测试了，也很难基于特定的硬件来测试。一些操作在某个语言里已经做了优化，但其它语言里却还没有实现。确实，你可能会失去一些东西，比如：一些人会抱怨，一些人会离开，整个分析报告也可能会被丢弃。无论如何，生活还是要继续… …在继续之前，让我们先看一下 Python 和 R 是怎么样使用的。在 R 中，你是如何做循环迭代的呢？R 语言有稍微的不同。通过一个快速的完整性检查, 包括加载时间和命令行运行时间: R 耗时 0m0.238s, Python 耗时是0m0.147s. 再次，这不是一个严谨的测试。一个快速的测试显示 Python 代码会快很多，通常，这并不是太重要。既然速度不是重点，那数据科学家更关心哪些东西呢？从这两门语言最新的趋势发现，它们被用作命令式语言的能力是一个重要的因素。比如，大多数 Python 程序员严重依赖 Pandas 来工作。这又引出了下一个主题：两种语言都有哪些模块和库，它们又是如何实现的？这是一个更有意义的比较。Python 使用 PyPi ，R 使用 CRAN ，Anaconda 同时支持二者。CRAN 使用它内部的“install.packages”命令做分发管理。截至目前为止，CRAN 上有大约 12000 个有效的软件包。浏览一下你就会发现，大约二分之一的包是关于数据科学的，占了大约 6000 个还不止。PyPi 上有超过 CRAN 十倍数量的包，大约 141000 个左右。其中有大约 3700 个包被标识为科学工程相关的。当然还有大量的包实际是科学相关的，但并没有被正确标识出来。这两种语言好像并没有受到大量的重复劳动的影响。确实，当我在 PyPi 上搜索“随机森林”时，我搜到了 170 个项目，可是，这些包之间又有些许的不同。尽管 Python 包的数量超过 R 十倍之多，但做数据科学计算的包的数量却差不多，也许 Python 更少一些。大量有效的第三方库是非常重要的，所有东西都要从头写是非常痛苦的。同样地，我也希望你做一些工作来回馈社区。DataFrames vs Pandas可能是一个更有意义和更重要的比较。我们进行一个实验：在进行复制的时候进行一个复杂的遍历，比较两者的执行时间。下面是结果：源代码： 正如我们看到的结果，Python+Pandas要比原生的R DataFrames快很多。请注意这并不意味着Python要比R快。Pandas是基于C语言写的Numpy库的。我真正想说的是ggplot2 vs matplotlib。声明：matplotlib是Python社区里我最看重的一个人写的，他教会了我Python，他就是 John D. Hunter。Matplotlib是一个强大而且可个性化定制的库，虽然不太容易学但是扩展性非常好。ggplot不但不易个性化定制而且可以说更加困难。如果你喜欢漂亮的绘图图案，而且并不需要自定义绘图，R是我的选择。如果你需要做更多的事情选择Matplotlib，他甚至可以帮助与bokeh进行交互。同样，你可能在寻找的ShinnyR对R而言也会增加其交互性。有些人可能要问：你为什么不能同时使用两种语言呢？有一些情况你可以同时使用这两个。比如当：你的项目组或组织允许的时候。你能比较容易地同时维护这两种环境。你的代码不需要迁移到另一个系统。你不会给别人制造一些混乱。一些可以使两者同时工作的方法：Python 对 R 的包装器，比如：rpy2，pyRserve，Rpython，… (rpy2 扩展在 Jupyter 中有使用)R 也有一些包，比如：rPython，PythonInR，，rJython，SnakeCharmR，XRPython在 Jupyter 里，混合这两种语言，举例如下：然后，我们可以传递 pandas 数据帧，它会通过 rpy2 被自动转换为 R 数据帧，传递时加上 “-i df”开关。代码源: 写了一个关于 的内核。他根据这些数据得出了一些有趣的观察结果:如果你希望明年转向 Linux ，你更有可能是一个 Python 用户。如果你研究统计学，你更有可能是 R 用户。如果你研究计算机科学，你可能是 Python 用户。如果你年轻（18-24岁），你更可能是 Python 用户。如果你进行代码竞赛，你更可能是 Python 用户。如果你明年想使用安卓，你更可能是 Python 用户。如果你明年想学习 SQL ，你更可能是 R 用户。如果你使用 MS office ，你更可能是 R 用户。如果你明年想使用 Rasperry Pi ，你更可能是一个 Python 用户。如果你是全日制学生，你更可能是 Python 用户。如果你使用敏捷方法，你更可能是 Python 用户。如果你对 AI 的看法是担忧而不是兴奋，你更可能是 R 用户。偏好当我与Alex Martelli, Googler 和 Stack Overflow的统治者通信时，他向我解释为什么Google开始使用他们官方支持的一些语言。即使在像Google这样的自由精神创新空间，似乎有一些制度。这是在这里能起作用的偏好，公司偏好。除了企业偏好，有些人在组织里经常创造第一。我知道在Deloitte第一个使用R语言的是谁。他仍然在公司，他是数据学家的领军人。重点是，在所有事情上我通常会建议，遵循你的爱。爱你所追随的，引领潮流，爱你所做的。一个合格的声明，虽然我从未成为工具的第一思考着，但如果你正在做一写重要的事情，那可能不是做实验的最佳时机。错误是可能的。然而，每个精心的设计数据科学项目都给数据学家留下了一定的空间。使用其中的一部分来学习和实验。保持开源心态，拥抱多样性。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/07/dd000831704fa240c532ce5ef32a7094.png"]}
{"title": "MySQL 事务隔离级别 - 文章 - 伯乐在线", "tag": ["IT技术", "MySQL", "数据库"], "goodNum": "2", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n本文会根据实际工作中碰到的例子，梳理清楚数据库事务的隔离级别。内容很简单，如果你能静下心来看完，一定会对你理解隔离级别有很大的帮助。想象一个场景。抽奖，如果用户中奖了，一般有如下几个流程：扣减奖品数量；记录用户中奖信息；试想如果扣减奖品数量了，结果记录用户中奖数据的时候失败了，那么数据就会出现不一致的问题。这种场景，就可以使用事务。因为事务的一个特性，就是上述问题解决了。再想一下这样的场景：在抽奖前，先查询奖品剩余数量，如果剩余数量<1，则任务抽奖活动已经结束，不再进行抽奖。如果事务A扣减奖品数量但未提交，事务B查询剩余奖品数量，此时应该是多少呢？这就和事务的隔离级别有关系了。在讨论隔离级别前，我们先做一些数据库的初始化操作：建表：初始化1个奖品：事务中的修改，即使没有提交，也会被其他事务读取。下面通过mysql演示：设置隔离级别为为提交读：  可以看到，事务B读取到了事务A未提交的数据，它任务抽奖活动已经结束。但如果此时事务A回滚，count仍然为1，则活动实际是未结束的，这就是。因此，实际中，一般不会采用这种隔离级别。提交读隔离级别可以解决上述脏读问题，其只能读到其他事务已经提交的数据。更改数据库隔离级别：可以看到，在事务A提交前的改动，事务B是读取不到的。只有A事务提交后，B才能读取到事务A的改动。我们看到，在事务B中，先后两次读取，count的值是不一样的，这就是而隔离级别可以解决这个问题更改数据库隔离级别： 可以看到，不论事务A是否提交，事务B读到的count值都是不变的。这就是除了上面提到的脏读、不可重复读，还有一种情况是比如事务B是事务A插入一条记录的前后执行查询，会发现相同的查询条件，查出来的记录数不一样。由于mysql的RR（可重复读）一并解决了幻读的问题，所以我们直接看上述场景，在mysql中的表现： 可见，在事务A提交前后，事务B查询的结果数量是一直的，并没有出现幻读的情况。一点思考下面默认都是讨论的msyql RR隔离级别的情况。如果两个用户同时抽奖，而且同时中奖。两者都进入了中奖的事务。A事务扣减了奖品数量，B也执行了扣减数量。假设奖品数量是N，如果是可重复读，那么，如果两个事务并行进行，那么不论A有没有提交，B读到的数量都是N，执行后为N-1，而事务A也是N-1，这样不就有问题了吗？我们期望的是N-2。当初这个问题让我很困惑。这反应了当时我对数据库锁和快照读、当前读两个知识点的欠缺。将设事务A已经提交，由于是可重复读，那事务B读到的奖品数量一致是N，执行-1，数据变成N-1，而不是我们期望的N-2。如果理解了快照读和当前读的概念，上面的困惑就不会存在了。在事务中，执行普通select查询之后，会创建快照，后面再执行相同的select语句时，查询的其实是前面生成的快照。这也就是为什么会有可重复读。而如果执行会执行当前读，获取最新数据。回到前面的问题，如果事务B执行N-1操作，会触发当前读，读取事务A提交后的数据，也就是N-1，在此基础上执行-1操作，最终N变成N-2。上面解决了事务A已经提交的额情况。但如果事务A更新奖品数量后但还未提交呢？此时事务B执行当前读拿到的也是N啊。了解数据库锁机制的话，就不会有这种困惑了。事务A提交前，会一直持有排他锁（具体是行锁还是表锁，要看查询条件有没有走索引），此时事务B更新是会阻塞的。也就是说，只有事务A提交，或回滚之后，事务B才能获得排它锁，从而进行更新奖品的操作。 关于数据库的锁，大家可以参考这篇文章：http://hedengcheng.com/?p=771\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2015/11/e78e36715813f49e9e62fe0c6050075c.png"]}
{"title": "10 个你不知道的 PostgreSQL 功能：创建统计信息 - 文章 - 伯乐在线", "tag": ["IT技术", "PostgreSQL", "数据库"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n如果你曾使用 Postgres 做过一些性能优化，你或许已经使用过 EXPLAIN 。EXPLAIN 向你展示了 PostgreSQL planner 为提供的语句生成的执行计划。它说明了语句涉及到的表将会使用顺序扫描、索引扫描等方式进行扫描，在使用多表的情况下将会使用连接算法。但是， Postgres 是如何产生这些规划的？决定使用哪种规划的一个非常重要的输入是 planner 收集到的。这些统计的数据能够使 planner 评估执行规划的某一部分会返回多少行，继而影响到使用哪一种规划或连接算法。它们主要是通过运行 ANALYZE 或 VACUUM（和一些 DDL 命令，比如说 CREATE INDEX )来采集或更新的。这些统计信息由 planner 存储在  和  中。Pg_class 基本上存储了每个表和索引中的条目总数，以及它们所占用的磁盘块数。Pg_statistic 存储关于每列的统计信息，例如哪些列的 % 值为 nul l，哪些是最常见的值，直方图边界等。你可以查看下面的示例，以了解 Postgres 在下表中为 col1 收集的统计信息类型。下面的查询输出展示了 planner（正确地）预估表中列 col1 中有 1000 个不同的值，并且还对最常见的值、频率等进行了其他预估。请注意，我们已经查询了 （一个拥有更多可读版本的列统计信息的视图）。这些单列统计信息可帮助 planner 估算你的条件选择性（这是 planner 用来估算将选择多少行的内容）。 当查询中存在多个条件时，planner 假定列（或 where 子句条件）彼此独立。 当列相互关联或相互依赖并导致 planner 低估或高估这些条件将返回的行数时，就不适用。我们来看下面的几个例子。 为了使查询计划易于阅读，我们通过设置 max_parallel_workers_per_gather  为 0 来关闭每个查询的并行性：正如你看到的那样，planner 估计 col1 的值为 1 的行数是 9584 ，而查询返回的实际行数是 10000 ，所以相当准确。当你在 column 1 和 column 2 都包含过滤器时会发生什么情况。planner 的估计减少了100倍！ 让我们试着理解为什么发生这种情况。\n第一个列的选择性约为 0.001（1/1000），第二个列的选择性为 0.01（1/100）。 要计算将由这两个“独立”条件过滤的行数，planner 会将它们的选择性相乘。 所以，我们得到：选择性= 0.001 * 0.01 = 0.00001。当它乘以我们在表中的行数即 10000000 时，我们得到 100。这就是 planner 对 100 的估计值的来源。 但是，这些列不是独立的，那么我们如何告知 planner ？在 Postgres 10 之前，没有一种简易的方式去告诉 planner 采集捕捉列之间关系的数据统计。但是， Postgres 10 有一个新特性正好解决了这个问题，可以使用  来创建扩展统计的对象，告诉服务器去采集这些有意思的相关列的额外的统计信息。回到我们先前评估的问题，col2 的值仅仅是 col1/10 。在数据库的术语中，我们会说 col2 是函数依赖于 col1 ，也就是说，col1 的值足以决定 col2 的值，并且不存在有两行数据拥有相同的 col1 值的同时有不同的 col2 值。因此，在 col2 列上的第二个过滤筛选并没有移除任何行！但是，planner 捕捉到了足够的统计信息去知道这件事情。让我们来创建一个统计对象去捕获这些列和运行分析（ANALYZE）所依赖的函数统计。 让我们来看看现在的计划是怎么来的。 很好！让我们看一下对计划的测量。 看这里，我们可以看到， Postgres 意识到 col1 完全决定 col2 ，因此用系数1来捕获这些信息。现在，所有的查询都过滤这些列之后，计划将会得到更好的评估。函数依赖是你可以在列之间捕获的一种关系。 你可以捕获的另一种统计信息是一组列的不同值。 我们之前指出，planner 可以获取每列不同值的统计数字，但再次合并多列时，这些统计数据往往是错误的。这些不好的数据是在什么时候影响我们的呢？ 下面来看一个例子。聚合行时，Postgres 选择做散列聚合或组合。 如果它认为散列表合适，则选择散列聚合，否则它会选择对所有行进行排序，然后按照 col1、col2 对它们进行分组。现在，planner 估计组的数量（等于 col1、col2 的不同值的数量）将为 100000。它预计到它没有足够的 work_mem 将该散列表存储在内存中。 因此，它使用基于磁盘的排序来运行该查询。 但是，正如在查询计划中所看到的那样，实际行数仅为 1001。也许，我们有足够的内存来执行哈希聚合。让 planner 去捕获 n_distinct 统计信息，重新运行查询并找出结果。可以看到，现在的估算精度更高了（即 1000 ），查询速度也提高了2倍左右。 通过运行下面的查询，我们可以看到 planner 学到了什么。在实际的生产模式中，你总是会有某些与数据库不知道的相互依赖或关系的列。 以下是我们与  客户见过的一些例子：有月份，季度和年份的列，因为你希望在报告中显示按所有人分组的统计信息。地理层次之间的关系。 例如。 具有国家，州和城市的列，并由它们来过滤/分组。这里的例子仅仅是在数据集中只有 10M 行的情况，并且我们已经看到，在存在相关列的情况下，使用 CREATE 统计信息可显着改善查询计划，并显示性能改进。在 Citus 使用案例中，我们有存储数十亿行数据，糟糕查询计划的影响可能非常严重。在上述示例中，当 planner 选择了一个糟糕的查询计划时，我们不得不为 10M 行做一个基于磁盘的分类。想象一下如果是数十亿行，那会有多糟糕。  \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2013/03/PostgreSQL-logo.gif"]}
{"title": "程序员，热爱你的 bug - 文章 - 伯乐在线", "tag": ["开发", "Bug"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n2017 年 10 月初，我在贝洛奥里藏特(巴西) 的 Python Brasil 大会做了一个主题演讲。下面是这个演讲的笔记 。 可以下载视频。我热爱 bug我现在是 Pilot.com 的高级工程师，为初创公司开发自动记账系统。在这之前，我在 Dropbox 的桌面客户端团队工作，后面我会讲到在那里工作时的一些小故事。在那之前，我是 Recurse Center 的一个推进者，Recurse Center 对于程序员的感觉很像写作者的隐居地。 我在大学学习的是天体物理学，在成为工程师之前在金融机构工作了几年。但是这些事情没有一件是重要的—你只需要记住我热爱 bug 就足够了。我热爱 bug 是因为它们非常有趣。它们富有戏剧性。一个大 bug 的查找过程曲折离奇。一个大 bug 很像一个很好的笑话或谜语，你期待一个输出，但结果却大相径庭。第一个 Bug好，直接进入 第一个 Bug。这是我在 Dropbox 遇到的一个 bug 。你可能知道，Dropbox 是个应用程序，可以将文件从一台计算机同步到云端，并同步到其它计算机。这是一个简化的 Dropbox 架构图。桌面客户端在本地监控文件系统的变化。当它找到一个改变的文件，将阅读文件并对 4MB 块中的内容进行哈希处理。这些块存储在一个巨大的键值对存储后端，我们称之为 blockserver。键是经哈希处理的内容的摘要，值是内容本身。当然，我们要避免多次上传同一个块。想象一下，你正在写一个文档，很可能只是更改了结尾–我们不希望一次又一次的上传开头部分。因此，在将块上传到 blockserver 之前，客户端与另一个管理 metadata 和权限的服务器通信，客户端询问 meta 服务器是否需要这个块或者是否见过这个块。meta 服务器对每个块是否需要上传进行响应。所以，请求和响应看起来是这样的：客户端：’我有一个由哈希块 组成的更改文件。服务器响应”我有前面两个，上传第三个”。然后客户端将第三个上传到 blockserver。上面是设想，下面的则是 bug 。有时，客户端会发出一个奇怪的请求：每个哈希值应该是16个字符长，但是请求的长度是33个字符，比期望长度的两倍还多 1 。服务器不知道该怎么处理这个异常，会抛出一个异常。我们看到这个异常报告，并查看客户端的日志文件，真是奇怪的现象—客户端本地数据库损坏了，或者 python 将抛出 MemoryErrors ，所有这些都没有道理。如果你从没有见过这个问题，那么这完全是个谜。但是一旦见过一次，之后的每一次都会认出它。这里有个提示：我们经常看到的 33 个字符长的字符串的中间的字符不是逗号而是。下面是我们在中间位置看到的其他字符：逗号的 ascii 码是 44 ，的 ascii 码是 108，在二进制中，它们是这表示的：你将发现与逗号仅仅相差 1 位。而这就是问题所在：一个位翻转 (bitflip）。客户端使用的内存有一个 bit 损坏了，现在客户端正在向服务器发送垃圾请求。下面是出现位翻转时我们经常看到代替逗号的其他字符：我热爱这个 bug 是因为它证明了位翻转是真实存在的，而不只是理论概念。实际上，这种情况在一些领域中比其他领域更常见。 从低端或老硬件的用户获得请求是其中一个，这是很多运行 Dropbox 的笔记本电脑的真实情况。 另外一个有很多位翻转的领域是外层空间——太空没有大气层来保护内存免受高能粒子和辐射的影响，所以位翻转很常见。在太空中，你可能真的非常关心数据的正确性。比如，你的代码可能用于让国际空间站中的宇航员生存下去，即使不是这样的关键任务，在太空中进行软件更新是很难的。如果真的需要应用程序不存在位翻转 ，可以采取多种硬件和软件方法。对于这个问题，Katie Betchold 有一个。Dropbox 不需要处理位翻转 。损坏内存的电脑是用户的，我们可以检测到逗号是否发生了位翻转，但如果它是不同的字符，我们不一定会知道，如果位翻转发生在磁盘读取的实际文件中，我们就不知道了。我们可以发现这个问题的空间太有限了，因此我们决定不对异常进行处理并继续。这类 bug 通常可以通过客户端重启电脑解决。这是它成为我最喜欢的 bug 的原因之一。 它可以提醒我们 unlikely 和 impossible 的区别。 在足够的规模下， unlikely 事件以明显的速率发生。我最喜欢这个错误的第二个原因在于通用。 这个 bug 可能发生在桌面客户端与 server 通信的任何位置，系统中有很多不同的端点和组件。这意味着 Dropbox 的许多工程师将会看到这个 bug 的不同版本。当你第一次看到它时，真的非常伤脑筋，但是之后很容易诊断，而且检查非常快：只需要看看中间的字符是不是。这个 bug 的一个有趣的副作用是它暴露了服务器团队和客户端团队的文化差异。 有时候服务器小组的成员会发现这个 bug 并进行调查。 如果一台服务器正在翻转位，这可能不是偶然的现象 – 很可能是内存损坏，你需要找到受影响的机器并尽快将其从服务器池中移出，否则可能会损坏大量的用户数据。 这是一个事件，你需要快速回应。 但是，如果用户的机器正在损坏数据，那么可以做的事情就不多了。所以，如果你正在研究一个令人困惑的 bug ，特别是大系统中的一个 bug ，不要忘了与别人交流。 也许你的同事之前看到过一个这样 bug 。 如果他们看到过，可以节省很多时间。 如果他们不知道，记得告诉别人解决问题的方法 – 写下来或在团队会议上讲出来。 下一次你们的队伍有类似的事情发生时，你们会更有准备。Bug 如何帮助我们学习加入 Dropbox 之前，我在 Recurse Center (RC) 工作。RC 是一个社区，它的的理念是帮助具备自我导向的学习者通过协作共同成长为更好的程序员。这是 RC 的全部：这里没有任何课程、作业或者截止日期。唯一的课题是分享变为更好的程序员的目标。我们看到很多获得 CS 学位但是对实际编程没有把握的人参加这个项目，或者写了十年 Java 又想学习 Clojure 或者 Haskell 的人参加这个项目，当然还有很多其他的参与者。我的工作是推进者，工作职责是帮助用户填补缺乏的结构和根据从以前的参与者身上学到的东西提供指导。 所以我和我的同事对于帮助自我激励的成年人学习最好的技术非常感兴趣。这个领域有很多不同的研究，我认为最有趣的一项研究是刻意练习的思想。刻意练习试图解释专家与业余爱好者的差别。这里的指导原则是，如果你只关注与生俱来的特征-遗传或其他-它们不会对解释差异做出太大贡献。因此研究人员（开始是 Ericsson , Krampe 和 Tesch-Romer ）开始研究是什么造成了这些差异。他们的结论是花费在刻意练习上的时间。刻意练习定义的范围非常狭窄：不是为了报酬，也不是为了玩乐。我们必须在自己能力的边缘进行练习，做一个适合自己水平的项目（不会容易的学不到任何东西，也不会困难到毫无进展）。还必须获得做法是否有效的及时反馈。这非常令人兴奋，因为这是如何构建专业知识的框架。但是挑战在于，对于程序员来讲，这个建议难以实现。程序员很难知道自己是否在能力边缘工作，及时反馈也非常罕见（在某些情况下可能会立即得到反馈，而在其他情况下可能需要几个月的时间才会有反馈）。你可以在 REPL 等一些小事上得到快速反馈，但是如何进行设计决策或者选择技术，很可能很长时间都无法得到反馈。但是刻意练习对于调试代码非常有用。如果编写代码，编代码时会有代码如何工作的心智模式。如果代码有一个 bug ，那么心智模式并不完全正确。根据刻意练习的定义，你处在理解的边缘，太棒了，你即将学习新的东西。如果你能够重现 bug ，那么可以立即获得修复是否正确的反馈（这种情况非常罕见）。这种类型的 bug 可能会使你了解一些关于自己程序的信息，也有可能学到代码所运行的系统的更多内容。我这里有一个这样的 bug 的故事。第二个 Bug这个 bug 也是在 Dropbox 工作时遇到的。那时，我正在研究为什么有些桌面客户端不按时发送日志 。我深入研究了客户端日志系统并发现一些有意思的 bug 。我们这里谈到的只是其中与这个故事有关一部分 。下面是系统架构简图。桌面客户端将生成日志 。这些日志被压缩、加密并写入磁盘，然后客户端定期将它们发送到服务器。客户端将从磁盘读取日志并将它们发送到日志服务器。日志服务器将解密并存储，然后返回 200 响应。如果客户端无法连接日志服务器，它不会让日志目录无限增大。当日志目录达到一定大小时，客户端将删除日志从而保证日志目录的大小在最大范围之内。最初的两个 bug 是些小问题。第一个是桌面客户端向服务器发送日志时从最旧的开始（而不是从最新的开始）。这不是我们想要的，比如，如果客户端报告了一个异常，服务器将要求客户端发送日志文件，这时你可能关心刚刚发生的情况的日志，而不是磁盘上最旧的日志。第二个 bug 与第一个类似：如果日志目录达到设置的最大值，客户端将从最新的日志开始删除（而不是删除最旧的日志）。这时，哪种方法都会删除日志，只是我们更关心比较新的日志。第三个 bug 与加密有关。有时，服务器无法解密日志文件（我们通常无法找到原因-可能是字节反转）。后端无法正确处理这个错误，因此服务器会返回 500 响应。客户端在接收到 500 响应时的表现相当合理：它将假设服务器已关闭。因此，它会停止发送日志文件，不再尝试发送其它文件。对损坏的日志文件返回 500 响应显然是错误的行为。我们可以考虑返回 400 响应，因为这是客户端的问题。但是客户端也无法解决这个问题-如果日志文件现在无法解密，将来也无法解密。因此，我们真正想让客户端做的只是删除日志文件并继续工作。实际上，客户端从服务器获取 200 响应时默认日志文件存储成功。所以，如果日志文件无法解密，返回 200 响应就可以了。所有这些 bug 都很容易修复。前两个错误发生在客户端，所以我们在 alpha 版本进行修复，但是还没有发布给大多数客户。我们在服务器上修复第三个错误并部署。突然之间，日志集群流量激增。服务团队询问我们是否知道发生了什么事情。我花了一分钟的时间把所有情况放在一起。在这些问题修复之前，四件事情正在发生：日志文件从最老版本开始发送日志文件从最新版本开始删除如果服务器无法解密日志文件，它将返回 500 响应如果客户端接收到 500 响应，它将停止发送日志客户端可能会尝试发送损坏的日志文件，服务器返回 500 响应，客户端放弃发送日志。下一次运行时，它会尝试再次发送相同的文件，再次失败并再次放弃。最终日志目录会变满，客户端将开始删除最新日志文件，并将损坏的日志文件保留在磁盘上。这三个 bug 的结果是：如果客户端曾经有一个损坏的日志文件，我们将再也看不到来自该客户端的日志文件。问题在于，处于这种状态的客户端比我们想象的要多得多。 任何具有单个损坏文件的客户端都无法将日志文件发送到服务器。 现在这个问题被解决了，他们都在发送日志目录中的其余内容。世界各地的机器会造成很大的流量，我们可以做什么呢？（在与 Dropbox 规模相当的公司工作是件有趣的事情，特别是 Dropbox 的桌面客户端规模：你可以轻易地触发自我 DDOS ）。进行部署时，发现问题的第一个选择是回滚。这是完全合理的选择，但是在这种情况下没有任何帮助。我们要转换的不是服务器上的状态，而是客户端上的状态–我们已经删除了这些文件。回滚服务器将防止其它客户端进入这个状态，但是不能解决问题。增加日志集群的规模可行吗？我们这样做了，并开始接收到更多的请求，现在我们已经进行了扩容。我们又进行了一次扩容，但是不能总这样。为什么不能？这些集群不是隔离的，它将请求另外一个集群(这里是为了处理异常)。如果遇到指向一个集群的 DDOS ，并且持续扩大集群规模，那么需要解决它们的依赖关系，这样就变成两个问题了。我们考虑的另一个选择是减轻负担-你不需要每个日志文件，所以我们可以放弃请求。这里的一个挑战在于很难确定哪个需要哪个不需要，我们无法快速区分新日志和旧日志。我们确定的解决方案是 Dropbox 在许多不同场合使用的解决方案：我们有一个自定义标头这个 bug 的第一个教训是了解你的系统。我头脑中有一个很好的客户端和服务器进行交互的模型。但是，我并没有想到服务器同时与所有客户端交互时会发生什么？这是我从来没有想到过的复杂程度。第二个教训是了解你的工具。如果事情发生了，你可以采取什么措施？你可以反转迁移吗？如果事情发生了，你如何了解它，如何找到更多信息？最好在危机发生之前了解这些内容，如果你没有这样做，你将在危机发生过程中学到，然后永远不会忘记。如果写移动或客户端应用，这是第三个教训：需要服务端特性门控和服务端标志位。当你发现一个问题并且无法控制服务端，发布一个新的版本或者向应用商店提交一个新版本可能需要几天甚至几周的时间。那是一种很不好的方法。Dropbox 客户端不需要处理应用商店审查流程，但是向几千万客户端推送也需要时间。我们也可以这样解决，出现问题时翻转服务器上的开关然后十分钟解决问题。但是，这个策略也有开销。添加很多标志位会增加代码的复杂度。在测试中会遇到组合问题：如何同时启用了功能 A 和功能 B，或者只有一个，或者一个都不启动 —如果具有 N 个特性则会非常复杂。完成之后请工程师清理功能标志位也将会非常困难（我也犯了这个错误）。对于桌面客户端来讲，可能同时会有很多版本，这将很难处理。但是好处在于—当你需要它们时，你真的非常需要它。如何热爱 bugs我谈到了我喜欢的一些 bug，并且谈到了为什么热爱这些 bug 。 现在我想告诉你如何去热爱 bug 。 如果你还不喜欢 bug，我知道一种学习方式–具有成长思维模式。社会学家 Carol Dweck 在人们如何看待能力方面做过很多有趣的研究。她发现人们使用两种不同的框架认识能力。第一个，她称之为固定思维模式，认为能力是一成不变的，人们无法改变自己的能力。另一个思维模式为成长思维模式，在成长思维模式下，人们认为能力是可塑的，不断的努力可以让能力变得更强。Dweck 发现一个人的能力框架-他们持有固定思维模式还是成长思维模式-会非常明显的影响他们选择任务的方式、他们应对挑战的方式、他们的认知表现、甚至他们的诚实。我在 Kiwi PyCon 主题演讲中也谈到了成长思维，下面这些只是部分摘录，你可以阅读完整版本关于诚实：之后，他们让学生把这项研究的结果写信告诉笔友：“我们在学校做了这项研究，这是我得到的分数。” 他们发现近一半因为聪明被称赞的学生篡改了分数，因为努力工作而受称赞的学生则基本没有不诚实的。关于努力：几项研究发现，有固定思维模式的人可能不愿意付出努力，因为他们认为需要努力意味着他们不擅长正在从事的事情。Dweck 指出：“ 如果每次任务都需要努力，那么很难保持对自己能力的信心，你的能力将会受到质疑。”对混乱的反应：他们发现，不管资料里是否含有混乱的段落，成长思维的学生大约能够掌握资料的 70% 。固定思维的学生中，如果阅读不包括混乱段落的书，他们也可以掌握资料的 70%。但是当固定思维的学生遇到混乱的段落，他们的掌握率下降到 30% 。固定思维的学生在从混乱恢复过来的过程中会遇到很大的困难。这些发现表明，debug 过程中成长思维非常关键。我们需要从混乱过程中恢复过来，对我们理解的局限性保持坦诚，有时找到解决方案的道路真的非常曲折—所有这些，具有成长思维的人更容易处理，遇到痛苦也会少一些。通过在 Recurse Center 工作时的庆祝挑战，我学会了热爱 bug 。一位参与者会坐到我旁边说：“[叹气] 我想我遇到了一个奇怪的 Python 错误”，我说：“太棒了，我热爱奇怪的 Python 错误！”首先，这是绝对正确的，但是更重要的是，这强调参与者找出一些他们努力取得成就的东西，完成它对于他们来说是件好事。正如我提到的， Recurse Center 没有截止期限和重要节点，这种环境非常自由。我会说：“你可以花一整天的时间去查找 Flask 中这个奇怪的 bug ，多么刺激！” 在 Dropbox 和 Pilot，我们要发布产品、有截止日期、有用户，我并不总能花一天的时间解决一个奇怪的 bug 。因此，我对具有截止日期的现实世界深表同情。但是，如果我有一个需要修复的 bug ，我必须修复它，抱怨这个错误并不会帮助我更快地修复它。 我认为，即使在最终期限的即将到来的时候，你仍然可以持这种态度。如果你热爱 bug ，在解决棘手问题时可能会获得更多的乐趣。你可能不那么担心并更加专注。最终会从中学到更多。最后，你可以与朋友和同事分享 bug ，这可以帮助你和你的队友。感谢那些对这次演讲给我反馈以及帮助我来到这里的朋友：Sasha LaundyAmy HanlonJulia EvansJulian CooperRaphael Passini Diniz 和 Python Brasil 团队的其他成员任选一种支付方式\n                        \n            \n                            \n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2014/06/2034139cf13a5d2840500f5a15322217.png"]}
{"title": "一个安卓程序媛的人生经验 - 文章 - 伯乐在线", "tag": ["职场", "程序员"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n引言博主有一个差不多认识了9年的程序媛朋友，从09年读大一开始认识的，现在已经毕业五年，所以相识是九年。目前她就职于网龙、是一个做安卓组件开发的程序媛，。本文基本上反应了她的心酸血泪史，经其同意，整理成文。为了方便描述，下面的第一人称”我”指的就是该妹纸本人。糊里糊涂的大学生涯高考毕业后，也不知道自己的兴趣是啥，稀里糊涂的报了一个专业，最后阴差阳错的来了一个电子类专业。来了这个专业后，发现了一个现象。(博主ps：博主明白强迫自己学一个自己不敢兴趣的科目是件多无聊的事情。所以针对这个现象，并不是很排斥，毕竟有些人的家境，并不需要太努力的奋斗。)大一上，无外乎就是一些公共课什么的，计算机一级考的是一些关于word、excel等操作，和编程没有什么关系。所以严格算起来，第一次接触到编程，是在大一下学期的C语言课程。非常有意思的是，没接触过编程的我，最后计算机二级考试居然考了满分。当时，我就明白，我在编程方面有着一种天赋，起码不会排斥。\n俗话说对编程有兴趣的我，本来应该在这个领域继续深造。然而在大二和大三并没有接触到其他语言，因此水平一直停滞不前。或许你会说，你可以去自学啊。这里要说一下，我在大学期间的性格是属于一种 换句话说，如果当初大一下的C语言不需要参加计算机二级考试，我就不会那么努力学习，不会发现自己在编程方面的天赋。因此大二和大三，仅仅满足于上课所传授的知识，沉溺于奖学金的优越感之中。\n转眼间到了大四，那会是12年。记得11年的时候，NOKIA的塞班机基本上已经退出市场，android那会的火热程度就和现在的微服务一样，于是当时就想着毕业从事一个和android开发相关的工作。由于自己性格的原因，选了一个android的项目作为自己的毕业设计。前面也说了，我需要一定压力来逼迫自己，才会有动力去做。所以在自己没有任何JAVA基础的情况下，选android项目作为自己的毕业设计，也是希望逼迫自己学有所成。这里有一点需要注意，坦白说，在学习过程中，不止一次怕来不及，怕做不出来毕设，怕毕不了业，不止一次动过要去某宝买一个的念头。而且一个人默默的学习，遇到不会的，容易浮躁。当时只有一个信念,我一定能做出来。最后的结果就是，我做出来了，是一个支持各种格式的手机端阅读器。有意思的是，这个项目当时拿到了优秀毕业设计。也因为这个项目找到了工作。(大家想想，面试的时候，直接掏出手机晒自己的项目，比简历上写一堆经验有意义的多了。)懵懵懂懂的工作生涯工作时第一家公司，是一家创业小公司，做的是影城里头的那种，订票的APP。这里有几条经验其实需要和大家进行分享。\n千万不要有如下想法坦白说，我很讨厌女生有这种想法。人一旦有了这种想法，就给自己套上了一层枷锁，无法发挥出自己的潜力。我们必须承认一点，人都是有惰性的。而且经常会给自己的懒惰，找寻各种各样的合理的理由。比如，把这个电视剧看完，再开始学习，等等。总之，你只要给自己找了一个这样的理由，每次你偷懒的时候，都会以这种理由给自己洗脑。从此，技术水平止步不前，它会成为你不思进取的借口。\n或许正是因为，自己没有给自己套上这层枷锁，在毕业后的一年内努力学习，于是跳槽进入了网龙。网上有一个图很出名，如下所示\n这个情况在工作中，确实还是存在的。其实可能是因为开发行业，男生比较多的原因，女生会受到优待一些。基本上女程序员遇到问题，一些男程序员会加班给你调BUG，当然加班程度取决于颜值。至于男程序员们遇到问题，那就真的只能靠自己了。但是，大家要注意这里就不得不说了，有些同事，特别是女同事吧。反正总爱问一些，比如环境怎么搭建这种问题。坦白说，这些问题，你问出去了，只会耽误老员工的时间。人家脾气好，跟你说。遇到一些脾气差的，索性就直接不理你了。总之，予人方便就是予己方便。像一些业务上的知识就是可以去问老员工，千万不要去问一些什么语法啊、环境搭建的问题。男生和女生还是存在着很大的体力差距的，这个不得不承认。包括在很多长辈眼里，都是觉得:”女生嘛，找一个轻松的工作，将来嫁人就好了。”\n这里我想说的是在当程序员的时候，还是要保持一种学习的热情。就我来说，目前还是这种学习的热情还是没有褪去。如果一旦发现自己的学习热情褪去，就可以思考一下自己是否能在开发的路上走的更远，是不是做管理会更合适呢？不过，不可否认，肯定会有一些直男癌患者，跟你说:”你们女生体力不行啊，什么什么的，就应该去切切图，做做产品啊，什么什么的。”对于这一切质疑，我们要要走自己的路。\n有一句话叫做大致意思就是，不论你在做什么事,心中感到自在安然，这就是禅。人生有很多痛苦都是因为别人的”中伤”，我们都避免不了心中会有疑虑，只要拥有一颗安详的心，别人就不可能在此作怪。当程序员后，一定要注意自己的发际线。女生也不例外，大家要注意保养。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2012/03/career.jpg"]}
{"title": "数据科学家的命令行技巧 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "数据"], "goodNum": "4", "saveNum": " 2 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n对于许多数据科学家来说，数据操作起始于Pandas或Tidyverse。从理论上看，这个概念没有错。毕竟，这是为什么这些工具首先存在的原因。然而，对于分隔符转换等简单任务来说，这些选项通常可能是过于重量级了。有意掌握命令行应该在每个开发人员的技能链上，特别是数据科学家。学习shell中的来龙去脉无可否认地会让你更高效。除此之外，命令行还在计算方面有一次伟大的历史记录。例如，awk – 一种数据驱动的脚本语言。Awk首次出现于1977年，它是在传奇的一书中的K，的帮助下出现的。在今天，大约50年之后，awk仍然与每年出现的保持相关联！ 因此，可以肯定的是，对命令行技术的投入不会很快贬值的。我们会谈及的内容ICONVHEADTRWCSPLITSORT & UNIQCUTPASTEJOINGREPSEDAWKICONV文件编码总是棘手的问题。目前大部分文件都是采用的 UTF-8 编码。要想了解 UTF-8 的魔力，可以看看这个。尽管如此，有时候我们还是会收到非 UTF-8 编码的文件。这种情况下就需要尝试转码。iconv 就是这种状况下的救世主。iconv 是一个简单的程序，可以输入某种编码的文本，然后以另一种编码输出。常用选项：\niconv -l 列出所有支持的编码iconv -c 不作提示就丢弃无法转换的字符\nHEAD如果你是重度Pandas的用户，那么你会对head很熟悉。通常在处理新数据时，我们想要做的第一件事就是了解究竟存在那些东西。这会引起Panda启动，读取数据，然后调用df.head() – 很费劲，至少可以说。head，不需要任何标志，将输出文件的前10行。head真正的能力在于彻查清除操作。 例如，如果我们想将文件的分隔符从逗号改变为pipe通配符。一个快速测试将是：head mydata.csv | sed ‘s/,/|/g’有用的选项:\nhead -n 输出指定行head -c 输出指定的字节\nTr类似于翻译，它是基于文件清理的一个强大使用的工具。一个理想的用法是替换文件中的分隔符。Tr的另一个特性是在你的处理中设置上所有的[:class:]变量。包括：可以将这些多样化的变量链接在一起，组成一个强大的程序。下面是一个基于字数统计的程序，用来检查你的README文件是否使用过度。另外一个例子用于正则表达式有用的选项：\ntr -d删除字符tr -s压缩字符\\b退格\\f换页\\v垂直选项卡\\NNN八进制值为NNN的字符\nWC字数统计。它的价值主要体现在使用 -l 参数可以进行行数统计。个用这个工具来验证各个命令的输出实在方便。因此，如果我们要在文件中转换分隔符，然后运行 wc -l，验证总行数是相同的。如果不同，我们就知道一定是哪里出错了。常用选项：\nwc -c 打印字节数wc -m 打印字符数wc -L 打印最长一行的长度wc -w 打印字数\nSPLIT命令文件大小可以有显著变化。根据工作的不同，拆分文件是有益的，就像split。基本用法如下：两个地方很奇怪：一个是命名方式，一个是缺少扩展名。后缀约定可以通过-d标识来数字化。添加文件扩展名，你需要执行下面这个find命令。他会给当前文件夹下的所有文件追加.csv后缀，所以需要小心使用。有效的选项：\nsplit -b按特定字节大小拆分split -a生成长度为N的后缀split -x使用十六进制后缀分割\nSORT & UNIQ前面的命令是显而易见的：他们按照自己说的做。这两者提供了最重要的一击（即去重单词计数）。这是由于有uniq，它只处理重复的相邻行。因此在管道输出之前进行排序。一个有趣的事情是，sort -u将获得与sort file.txt | uniq相同的结果。Sort确实对数据科学家来说是一种很有用的小技巧：能够根据特定的列对整个CSV进行排序。这里的-t选项是指定逗号作为分隔符。通常假设是空格或制表符。此外，-k标志是用来指定我们的键的。它的语法是-km,n，m是起始字段，n是最后一个字段。有用的选项:\nsort -f 忽略大小写sort -r 逆序sort -R 乱序uniq -c 计算出现次数uniq -d 只打印重复行\nCUT命令cut用于删除列。举个栗子，如果我们只想要第一列和第三列。选择除了第一列以外的所有列与其他的命令组合使用，cut命令作为过滤器找出第二列中唯一值的数量。PASTEpaste 是个有趣的小命令。如果你想合并两个文件，而这两个文件的内容又正好是有序的，那 paste 就可以这样做。关于更多 SQL_-esque 变体，请看下面。JOINJoin是一种简单的、准切向的SQL。最大的区别在于Join将返回所有列，匹配可能只发生在一个字段上。默认情况下，join将尝试使用第一列作为匹配键。对于不同的结果，需要以下语法：标准连接是一个内部连接。然而，外部连接也可以通过-af滞后来实现。另一个值得注意的是-e标志，如果发现有字段丢失，它可以用来替换成其他值。虽然它不是最容易使用的命令，但是在绝望的时刻，它就是唯一可用的措施。常用的选项:\njoin -a 打印未成对的行join -e 替换缺失字段join -j 等同于 -1 FIELD -2 FIELD\n全局搜索正则表达式并输出，或使用grep;可能是最知名的命令，并且有很好的理由。 Grep具有很强的能力，特别是在大型代码库中查找方法。在数据科学领域，它充当了其他命令的改进机制。但其标准用法也很有用。对包含word/pattern的行数进行计数Grep使用or运算符- \\|来检索多个值.有用的选项\nalias grep=”grep –color=auto” 使grep支持彩色输出grep -E 使用扩展正则表达式grep -w 仅匹配完整单词grep -l 打印匹配文件的名称grep -v 倒序匹配\nSed和Awk是本文两个最有用的命令。为了简洁，我不会讨论那些令人费解的细节。相反，我会讨论各种各样的命令来证明他们令人印象深刻的实力。如果你想了解的更多，就可以。在内核中sed是一个流编辑器。它擅长替换，但是也可以用来重构。\n最基本的sed命令包含了s/old/new/g。也就是全局搜索旧值，替换新值。没有/g 我们的命令可能在第一次出现旧值就会终止。\n为了尽快了解它的能力，我们来看一个例子。在这个情况你会拿到下面的文件：我们要做的第一件事就是移除美元符。-i 标识表示就地修改。”就是代表一个零长度文件扩展，因此重写我们的初始文件。理想情况下，你会单独测试这些并输出到一个新文件。下一步，我们的balance列的逗号。最终，Jack有一天起来并准备辞职了。所以，再见吧，我的朋友。就像你所看到的，sed功能强大，但是乐趣不止于此。最好的放最后。Awk不仅是一个简单的命令：它是一个成熟的语言。在本文中包含的每一个命令中，awk目前是最酷的。如果你发现它令你印象深刻，这有大量的资源- 看，，和。\nawk包含的常用案例：文本处理格式化文本报告执行计算操作执行字符串操作Awk在其最初雏形可以与grep平行。或者多使用一点魔法，让grep和cut结合。在这，awk对所有行通过word打印了以tab分隔的第三和第四列。-F，只是将分隔符变为逗号。Awk具有大量有用的内置变量。例如， NF -字段数 – 和NR – 记录数。为了获取文件中这53个记录：添加一个小窍门可以基于一个值或者多个值过滤。下面的第一个例子，会打印这些记录中第一列为string的行数和列。多数值表达式：计算第三列之和：计算那些第一列值为“something”的第三列之和。获取文件的行数列数：打印出现过两次的行：移除多行：使用内置函数gsub()替换多个值。这个awk命令合并了多个CSV文件，忽略头并在结尾追加。需要精简一个大文件？好的，awk可以在sed的帮助下完成这件事。具体来说，基于一个行数，这个命令将一个大文件分为多个小文件。这个一行文件也会添加一个扩展名。命令行拥有无穷的力量。本文所涵盖的命令行知识足以让你从零基础到入门。除了这些已涉及的内容外，针对日常数据操作还有需要可考虑的实用程序。, 和是其中三个值得关注的。如果你希望进一步深入到命令行的数据科学领域，那么请看。它也可以免费获得！\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/07/566b3ec9129f73743155c2f1cc063225.png"]}
{"title": "关于 Feed 流的几个热门问题 - 文章 - 伯乐在线", "tag": ["IT技术", "API", "Feed", "架构设计"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n本篇聊一下 Feed 流技术，由于这个话题在业界有丰富的实践经验，所以我特意选了个小的切入点，从相对微观的角度说几个具体的问题，避免一些无意义的重复。希望提炼实践中的具体问题来做讨论，使事情变得更有实际意义。当要做一个 Feed 流，摆在我们眼前的第一个问题就是到底选推模型还是选拉模型，因为这个选择将影响接下来一系列的架构方式。推模型和拉模型各自的优缺点已经被罗列了很多了，比如推模型的存储量大，或者拉模型的效率可能低，但如果你从无到有做这个事情，这些优缺点的罗列还是无法帮助你做出最初的决定，所谓的“知道了许多道理，还是过不好这一生”，当然除非你有实际的构造大流量 Feed 流的经验。然而根据我们的经验：基于正确规范的架构和基础设施，对于一个千万日活量级的应用 Feed 流， 拉模型完全可以扛得住。我想，上面这个结论是很有意义的，尤其是对中小创业公司，因为拉模型本身节省存储资源，开发成本低，上线速度快，在业务爆发之前做这样一个 Feed 流，有这样一个明确经验可以帮助你快速做出决定。另外，上面说的千万日活，并不是说就是拉模型的上限，而是说，如果你做到千万日活，你将会有丰富的实践经验帮助你走下一步，那时也会有更多的资源让你使用，是继续深挖拉模型潜能，还是上推拉结合消灭性能问题，将是另外一个够挑战的问题了。上一节我的描述有些极端，本意上我是想给出更明确的实践结论，因为对于推拉模型的积累对比已经够多了，现在难的似乎是做决定时的信心。那这一节，我就来聊推模型的几个问题。。推模型可以理解为给每个粉丝维护一个单独的存储，举例来说，如果某个大 V 有一千万粉丝，他发的一条内容，将被存储一千万份，这个存储放大是非常可观的。于是这里就会常见的问题：一、有多少存储资源能用，这些资源贵不贵？二、如果省掉这些资源存储，响应时间性能到底能打多少折扣，这些折扣值不值？这是个时间和空间的冲突，程序员每天都在做这种问题的衡量，每个系统的要求基准也不一样，我就不妄下结论了。推模型有一个写峰值的问题，通常，我们做推模型，给粉丝写数据的时候一般是离线的，也就是大 V 发布完内容，触发离线写任务推给各个粉丝。可大 V 是少数，大部分时候，都是普通用户在发布，写任务没有那么多，这时，离线写任务的 worker 数可能用不了几个，可一旦大 V 发布了内容，这个写任务会骤增，突然来一个大峰值，如何处理这个峰值是个问题。有些方案：一、把资源调度系统做的超级棒，worker 数量自动化跟着调整，峰值来了的时候，worker 自动迅速扩容，消费离线任务，并在离线任务处理完毕之后缩容，避免资源浪费，这个调度确实需要很棒，因为大多时候，Feed 流对这些任务的要求是很严苛的，比如，产品上希望粉丝至少也是在分钟级看到大 V 发的内容，甚至秒级，这对调度系统的挑战是巨大的。二、推拉结合，大 V 走拉模型逻辑，这个方案的问题就是，你其实做了两套系统，开发成本大。这一点是从业务逻辑开发上来说的，这个也是在具体业务开发过程中推模型让人觉得很难受的点，就是：当我解决很多问题之后，从业务逻辑开发层面，我还是避不开很多业务逻辑。为什么这么说呢，就是在推模型里，每个粉丝都存有一个属于他的数据，但这部分数据在接口设计和数据返回上，也仅仅就是元数据，这份元数据，还是要经过很多处理才能返回给用户，比如过滤、Format，我们希望推模型维护的那个存储是一份尽可能干净的数据，但事情却没那么简单。不过，以上是我个人的一些总结，由于在推模型上我没有走的更远，这些问题到底是不是真正的问题，欢迎来喷。模型的事情就不过多说了，再来聊几个关于数据的具体问题。这是 Feed 流的 API 接口设计相关的问题。举个例子，在拉取 Feed 流数据时候， API 层面基于数量 offset/limit 的分页方案是完全不行的，因为用户 Feed 流的新数据会 insert 到流最开始位置，仅仅给出 offset 会导致分页数据错乱，所以会给出一种 after/limit 的分页方案，就是有一个标志数据，意义是“从 after 这个数据向后取 limit 条数据”；但是，这仅仅是一个干净的 Feed 流的情况下，在实际的业务需求中，Feed 流中的数据会更复杂，复杂到打乱这个看起来可行的分页方式。以分页这个例子来说，它为什么会这么脆弱呢? 我总结是因为 API 的数据请求是无状态的，用户在取第二页数据的时候，并不知道取第一页数据时到底发生了什么，仅仅知道在接口层面传递的几个值（offset/after/limt），而许多时候尤其是对于 Feed 流的一些时候这些值不够用，导致数据拉取变得棘手。所以，如果 Feed 流的数据获取是有状态就好了，就像浏览器与服务器之间的 Session，保持用户一个访问周期的上下文数据，这样想做什么就都好做了。通常，Feed 流中的数据会来自多个不同的源，最后返回给用户之前需要做数据的 Format，这个过程是个性能黑洞，经常包含了很多 IO，你可能要读大量存储，读大量 RPC来获取到数据才能成功组装。所以针对数据 Format 有很多性能优化的点，包括不限于：消灭慢查询、减少调用放大、并行获取数据、做好缓存、操作批量。要做好性能优化，好的结构是必需的，比如要减少调用放大，那就要尽量保证数据复用和批量获取，只有你的代码结构好，才会有更合适的地方去获取数据和复用数据；也同样，只有你把可以并行部分都很清晰的摘离出来了，才能更合适地去做统一并行。而诸如消灭慢查询、做好缓存，此类其他细节也都是重要的，这里就不展开。几乎所有的 Feed 流都有过滤需求，比如对已经读过的内容进行过滤，或者对已经被作者删除的内容进行过滤。过滤是个具体的事情，有的时候你仅仅需要元数据就能过滤，有的时候你需要对拿到完整数据才能过滤。总结一句话就是过滤的繁琐与否取决于产品需求，但好的结构可以让过滤变得更符合逻辑，性能表现更好。Feed 流是个不小的系统，三言两语只是管中窥豹，长时间没写分享文章了行文也变得不太流畅，希望看完这篇你会有所收获吧。任选一种支付方式\n                        \n            \n                            \n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2011/11/software-development-logo.jpg"]}
{"title": "GitHub 的 MySQL 高可用性实践分享 - 文章 - 伯乐在线", "tag": ["IT技术", "MySQL", "高可用"], "goodNum": "2", "saveNum": " 2 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nGitHub 使用 MySQL 作为所有非 git 仓库数据的主要存储, 它的可用性对 GitHub 的访问操作至关重要。GitHub 站点本身、GitHub 的 API、身份验证等等都需要进行数据库访问。我们运行着多个 MySQL 集群来为不同的服务和任务提供支持。我们的集群使用经典的主从配置, 主集群中的某个节点能够接受写入。其余的从集群节点异步同步来自主服务器的更改, 并提供数据的读取服务。主节点的可用性尤为重要。没有主服务器, 集群无法接受写入：任何需要保留的写入数据都不能持久化保存，任何传入的更改（如提交、问题、用户创建、审阅、新存储库等）都将失败。为了支持写操作，我们显然需要有一个可用的数据写入节点，一个主集群。但同样重要的是，我们需要能够识别或找到该节点。在一个写入失败，提示说主节点崩溃的场景中，我们必须确保能启用一个新的主节点，并快速表明其身份。检测故障所需的时间、进行故障转移并公布新的主节点所花费的时间，构成了总的停机时间。本文将介绍 GitHub 的 MySQL 高可用性和主服务发现解决方案，它使我们能够可靠地运行跨数据中心操作，容忍数据中心隔离，并使得出现故障时耗费的停机时间变得更短。高可用目标本文描述的解决方案，迭代并改进了之前在 GitHub 实现的高可用(HA)解决方案。随着规模的扩大，MySQL 的高可用策略必须适应变化。我们希望为 GitHub 中的 MySQL 和其他服务，提供类似的高可用策略。在考虑高可用和服务发现时，有些问题可以引导你找到合适的解决方案。包含但不限于：你能容忍多长的中断时间？崩溃检测的可靠性如何？你能容忍错误报告（过早的故障转移）吗？故障转移的可靠性如何？什么情况下可以失败？解决方案在跨数据中心的场景下效果如何？在低延迟和高延迟的网络情况下如何？解决方案是否允许一个完整的数据中心故障或者出现网络隔离？有没有防止或缓解脑裂（两台服务器都宣称是某个集群的主节点，不知情对方的存在，并且都能接受写操作）的机制。你能允许数据丢失吗？在多大程度上？为了说明上面的一些情况，首先让我们讨论一下之前的高可用方案，并说说我们为什么要修改它。移除基于 VIP 和 DNS 的服务发现在之前的迭代版本中，我们：使用  来做检测和故障转移使用 VIP 和 DNS 做主节点的发现在这个迭代版本中，客户端使用名字服务（比如 mysql-writer-1.github.net）来发现写节点。名字可以解析为一个虚拟 IP(VIP)，这个 VIP 指向主节点。因此，在正常情况下，客户端只需要解析名称，连接到解析后的 IP上，然后发现主节点也正在另一边监听链接（也就是客户端连上了主节点）。考虑这个跨越三个不同数据中心的复制拓扑：当主节点发生故障时，必须在副本集中选出一个服务器，提升为新的主节点。orchestrator 将会检测到故障，选举出一个新的主节点，然后重新分配 name（名称）和 VIP（虚拟 IP）。客户端实际上并不知道主节点的真实身份：它们只知道 name（名字），而这个名字现在必须解析给新的主节点。不过，需要考虑：VIP 是需要协作的：它们由数据库服务器自己声明和拥有。为了获得或释放 VIP，服务器必须发送 ARP 请求。拥有 VIP 的服务器必须在新提升的主节点获得 VIP 之前先释放掉。这还有一些额外的影响：有秩序的故障转移操作会首先通知故障主节点并要求它释放 VIP，然后再通知新提升的主节点并要求它获取 VIP。如果无法通知到原主节点或者拒绝释放 VIP 怎么办？首先要考虑到，该服务器上存在故障场景，它不可能会不及时响应，或根本不响应。\n我们最终可能会出现脑裂情况：两个注解同时声称拥有同一个 VIP。根据最短的网络路径，不同的客户端可能会连接到不同的服务器。事实源于两个独立服务器间的协作，并且这个设置是不可靠的。\n即使原主节点确实配合，工作流程也浪费了宝贵的时间：当我们通知原主节点时，切换到新主节点的操作一直在等待。即使 VIP 发生变化，现有的客户端连接也不能保证与原服务器断开连接，而且我们可能仍然会经历脑裂。VIP 受限于物理位置。它们属于交换机或者路由器。所以，我们只能将 VIP 重新分配到位于同一位置的服务器上。特别是，当新提升的服务器位于不同的数据中心时，我们无法分配 VIP，只能修改 DNS。修改 DNS 需要较长的传播时间。根据配置，客户端会缓存 DNS 一段时间。跨数据中心(cross-DC)故障转移则意味着更多的中断时间：为了让所有客户端知晓新主节点的身份，需要花费更长的时间。仅这些限制，就足以促使我们寻求新的解决方案，但考虑更多的是：主节点通过 pt-heartbeat 心跳服务进行自行注入，目的是。这项服务必须从新提升的主节点开始。如果有可能的话，原主节点的服务将被关闭。同样的， 注入也是主节点自己管理的。它将从新的主节点开始，并在原主节点结束。新的主节点被设为可写。如果可能的话，原主节点被设为只读。这些额外的步骤是导致中断总时间的一个因素，并且引入了它们自己的故障和摩擦。该解决方案生效了，GitHub 已经成功完成 MySQL 的故障迁移，但我们希望我们的 HA 在以下方面有所改进：数据中心不可知允许数据中心出现故障删除不可靠的协作工作流减少总的中断时间尽可能地进行无损故障转移GitHub 的高可用解决方案：orchestrator, Consul, GLB我们的新策略，除了附带的改进外，还解决或减轻了上面的许多问题。在今天的高可用设置中，我们有：使用  来做监测和故障转移。我们使用跨数据中心的  方案，如下图。使用 Hashicorp 的  来做服务发现。使用  作为客户端和写节点的代理层。使用选播(anycast)做网络路由。新的设置将完全删除 VIP 和 DNS 的修改。在我们引入更多组件的同时，我们能够将组件解耦并简化任务，并且能够使用可靠、稳定的解决方案。下面逐一分析。正常情况下，应用程序通过 GLB/HAProxy 连接到写节点。应用程序永远不知道主节点的身份。和之前一样，它们使用名字。例如，cluster1 的主节点命名为 mysql-writer-1.github.net。在我们当前的设置中，名字被解析为一个选播() IP。使用选播时，名字在任何地方都被解析为相同的 IP，但流量会根据客户端位置的不同进行路由。需要指出的是，在我们的每个数据中心，都有 GLB（我们的高可用负载均衡）被部署在不同的容器中。指向 mysql-writer-1.github.net 的流量总是路由到本地数据中心的 GLB 集群。因此，所有客户端都由本地代理提供服务。我们在  上运行 GLB。我们的 HAProxy 维护了一个写连接池：每个 MySQL 集群一个连接池，其中每个连接池只有一个后端服务器：集群的主节点。DC 中的所有 GLB/HAProxy 容器都具有相同的连接池，并且它们都指向相同的后端服务器。这样，如果一个应用程序想要写入 mysql-writer-1.github.net，它连接到哪个 GLB 服务器并不重要。它总会被路由到实际的 cluster1 主节点上。对于应用程序而言，服务发现结束于 GLB，并且不再需要重新发现。就这样，通过 GLB 将流量路由到正确地址。GLB 如何知道哪些服务器可以作为后端服务器，以及如何将更改传播到 GBL 呢？Consul 是著名的服务发现解决方案，它也提供 DNS 服务。然而，在我们的解决方案中，我们用它作为高效的键值存储系统。在 Consul 的键值存储中，我们写入了集群主控的标识。对于每一个集群，都有一个键值对记录标识集群的主 FQDN，端口，IPV4，IPV6。每一个 GLB/HAProxy 节点都运行 consul 模板：每一个服务都在监听 consul 数据的变更（这里主要是对集群主控的数据变更）。consul 模板会生成一个有效的配置文件并且当配置变更时，能够自动重载 HAProxy。因此，Consul 中主控标识的变更会被每一个 GLB/HAProxy 观察到，然后它们立即重新配置它们自己，在集群后端池中设置新的主控作为单一对象，并且进行重载以反映这些变更。在 GitHub 中，每一个数据中心都有一个 Consul 设置，并且每一个设置都具有高可用性。然而，这些设置又互相独立，它们之间不进行互相复制或数据共享。那么 Consul 是如何获得变更通知，在交叉数据中心中，信息又是如何分布的呢？运行一个 orchestrator/raft 设置：orchestrator 节点之间通过 raft 一致性算法进行通信。每一个数据中心有 1~2 个 orchestrator 节点。orchestrator 负责失败检测，MySQL 故障转移，以及 Consul 主控的变更通知。故障转移通过单个 orchestrator/raft 主导节点进行操作，但是对于主控变更，产生新主控的消息会通过 raft 机制被传播到所有 orchestrator 节点。一旦 orchestrator 节点接收到主控变更的消息，它们会与自己对应的本地 Consul 设置通信：它们都执行 KV 写操作。具有多个 orchestrator 节点的数据中心会有多个完全相同的 Consul 写操作。在主节点故障的场景中：orchestrator 节点检测到故障。orchestrator/raft 主导节点开始恢复。一个新的主节点被设置为 promoted 状态。orchestrator/raft 向所有 raft 集群节点通知主节点变更。所有 orchestrator/raft 成员接收到主节点变更的通知。每个成员都向本地 Consul 写入包含新主节点身份的 KV 记录。每个 GLB/HAProxy 都运行一个 consul 模版，用于监视 Consul KV 存储的变化，并重新配置和重新加载 HAProxy。客户端流量被重定向到新的主节点上。每个组件都有明确的责任归属，而且整个设计简单并且解耦。orchestrator 不需要知道负载均衡。Consul 不需要知道这些信息是从哪里来的。代理只关心 Consul，客户端只关心代理。而且：没有 DNS 的变更需要传播。没有 TTL。整个流程不需要原故障主节点的配合，它在很大程度上已被忽略。为了进一步确保流程的安全，我们还提供了以下内容：将 HAProxy 的配置项 hard-stop-after 设置为一个非常短的时间。当在写连接池中使用新的后端服务器重新加载时，它会自动终止所有到原主节点的连接。\n通过使用 hard-stop-after 配置项，我们甚至不需要客户端的配合，这也就缓解了脑裂的情况。值得注意的是，这并不是绝对的，我们还是需要一些时间来消灭旧连接。但是，在某个时间点之后，我们就会感到舒服，因为不会出现令人厌恶的意外。\n我们并不严格要求 Consul 随时可用。实际上，我们只需要它在故障转移期间可用。如果 Consul 恰好这时不可用，GLB 将继续使用已知的信息运作，不采用任何极端的行动。GLB 被用于验证新提升的主节点的身份。类似于我们的 （上下文感知的 MySQL 线程池），在后端服务器上进行检查，以确保它确实是一个可写的节点。如果我们恰好在 Consul 中删除了主节点的身份，没有问题；空的条目会被忽略。如果我们在 Consul 中错误的写入了一个非主节点的名称，没有问题；GLB 将拒绝更新它并以最后已知的状态继续运行。我们会在以下章节进一步完成备受关注和期望的高可用目标。orchestrator使用来检测失败，因此这种方法非常可靠。我们不会观察到误报 —— 因为我们没有进行过早的故障转移，所以也不会产生不必要的中断时间。通过完全的 DC 网络隔离（又称 DC 栅栏），orchestrator/raft 进一步处理这个问题。一个 DC 网络隔离会引起一些混淆：这个 DC 中的服务器是可以互相通信的。他们是与其他 DC 网络隔离，还是其他 DC 被网络隔离？在一个 orchestrator/raft 设置中，raft 的 leader 节点就是运行故障转移的那个节点。leader 是取得了大多数节点支持的节点（特定数量）。我们的 orchestrator 节点部署就是这样，没有单一数据中心可以占大多数，任何 n-1 的 DC 也是如此。在一个完全 DC 网络隔离的事件中，这个 DC 的 orchestrator 节点与其它 DC 中的对应节点失去连接。最终，隔离 DC 中的 orchestrator 节点不能作为 raft 集群的 leader 节点。如果任何这种节点碰巧成为了 leader 节点，它就会退出。一个新的 leader 节点可以从任何一个其他 DC 分配。leader 节点会得到其他所有 DC 的支持，这些 DC 彼此之间可以进行通信。因此，调用 shots 的 orchestrator 节点将位于网络隔离数据中心之外。一个隔离 DC 应该有一个主服务器，orchestrator 会使用可用 DC 中的其中一个服务器将它替换来初始化故障转移。我们委托非隔离 DC 中的那些节点来做这个决定，以此来缓解 DC 隔离。通过发出公告说主分支即将修改，可以进一步减少运行停机的总时间。如何实现这个想法？当 orchestrator 开始进行故障迁移的时候，它会观察可用于升级的服务器队列。在了解自我复制的规则，以及接受提示和限制的情况下，在最好的行动方针中，它能做出基于一定训练的决策。它可能意识到一个可以升级的服务器也是一个理想的候选策略，例如：没有什么可以阻止服务器的升级（潜在用户已经暗示服务器优先升级），而且认为服务器可以将它所有的版本视为复本。在这个例子中 orchestrator 首先将服务器设置为可写，然后立即公告服务器的升级（我们的例子中是写到了 Consul KV），即使异步开始修复复制树，这种操作通畅会花费更多几秒的运算。有可能当我们的 GLB 服务器完全重载时，复制树已经完好无损，但是这不是严格要求的。服务器可以接收到写操作！半同步复制在 MySQL 的中，在获知更改已发送到一个或多个副本之前，主服务器不会确认事务已提交。它提供了一种实现无损故障转移的方法：应用于主服务器的任何更改都将应用于或等待应用于其中一个副本。一致性带来的成本是：可用性风险。如果没有副本确认收到更改，主服务器将被阻塞并且写入操作将停止。幸运的是，这里有一个超时设置，在这之后主服务器可以恢复到异步复制模式，使写入操作再次可用。我们已经把我们的超时设置在一个合理的低值：500ms。将更改从主服务器发送到本地 DC 副本，通常也发送到远程 DC，这个阈值是绰绰有余的。设置这个超时时间之后，我们可以观察到完美的半同步行为（无需回退到异步复制），并且在确认失败的情况下，可以在非常短的阻塞周期内获得让人满意的表现。我们在本地 DC 副本上启用半同步，并且在主服务器宕机的情况下，我们期望（尽管不严格地执行）无损故障转移。对完整的 DC 故障进行无损故障转移的代价很高昂，我们并不期待这么做。在试验半同步超时的同时，我们还观察到一种对我们有利的行为：主服务器在发生故障时，我们能够影响最佳候选人的标识。通过在指定的服务器上启用半同步，并将它们标记为候选服务器，我们可以通过影响故障的结果来减少总的停机时间。在我们的中，我们观察到，我们通常最终会得到最佳候选服务器，并因此发布快速公告。心跳注入我们没有在已提升/已降级的主设备上管理 pt-heartbeat 服务的启动/关闭，作为替代，我们选择随时随地运行它。这需要进行打一些，以便使 pt-heartbeat 可以支持服务器端来回更改它们的 read_only 状态或其完全崩溃。在我们目前的设置中，在主服务器及其副本上运行 pt-heartbeat 服务。在主服务器上，他们产生心跳事件。在副本服务器上，他们识别到服务器是只读的，并定期重新检查其状态。只要服务器升级为主服务器，该服务器上的 pt-heartbeat 会将服务器标识为可写，并开始注入心跳事件。orchestrator 所有权委托我们进一步委托到 orchestrator：伪-GTID注入设置被提升的主控作为可写的，清除它的复写状态如果可能，设置老的主控为只读状态对于新主控，以上所有这些操作减少了冲突的可能性。一个刚刚被提升的主控应该是在线的并且可接入，否则我们就不应该提升它。然后让 orchestrator 直接应用变更到被晋升的主控上也应该是合理的。限制和缺点代理层使得应用程序不知道主服务器的身份，但是对于主服务器它也掩盖了应用程序的身份。所有主服务器看到的连接都来自代理层，我们丢失了关于连接实际来源的信息。随着分布式系统的发展，我们仍然遗留了未处理的场景。值得注意的是，在数据中心隔离场景中，假设主服务器位于 DC 中，DC 中的应用程序仍然能写入主服务器。一旦网络恢复正常，可能会导致状态不一致。我们正努力在非常独立的 DC 中，通过实现一个可靠的  来缓解这种脑裂。和以前一样，在将主服务器之前需要花费一些时间，可能出现短暂的脑裂。而避免脑裂的操作成本非常高。更多的场景存在：故障转移时 Consul 的终端；部分 DC 隔离；其他的。我们知道，使用这种性质的分布式系统不可能消除所有的漏洞，因此，我们将焦点放在最重要的案例上。结果orchestrator/GLB/Consul 设置给我们提供以下功能：可靠的故障检测数据中心不可知的故障迁移典型的无损故障迁移对数据中心网络隔离的支持缓解脑裂的问题（仍在实现中）无合作相关的依赖多数场景下大约 10~13 秒的断电恢复能力。（我们观察到一些场景下最长 20 秒的断电恢复和极端场景下最长 25 秒的情况）结语编排/代理/服务发现范例在解耦架构中使用众所周知的可信组件，这使得部署、运维和观察变得更加容易，并且每个组件可以独立扩展或缩减。我们将不断测试我们的设置，以继续寻求改进。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/01/e4ff41fe57fa22949c5909f50e5b2ca6.jpg"]}
{"title": "如何成为 StackOverflow 上合格的提问者与回答者 - 文章 - 伯乐在线", "tag": ["其他", "StackOverflow"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n写这篇文章最直接的原因是我的朋友 Rob Conery 发了一条，解释他为什么放弃在 Stack Overflow 贡献答案。然而，那已经是很长时间的事了。前不久，我开始写一篇与本文类似的文章，但是文章越写越长，并且没有得出任何结论。现在我用一个小时的时间写这篇文章，然后不论写了什么都要发出去（稍后可能会重新排版）。我了解很多用户对 Stack Overflow 的复杂感情。有些人认为它完全没有价值，但是我相信更多的人认为它“资源有价值，但是潜在的反对意见让人很难做出贡献”。有些人则定期做出贡献，在合理的时间范围内，偶尔解释或者查看反对意见。这篇文章，我将谈谈我的经历，和我的一些看法，关于 Stack Overflow 存在的问题、我对一些察觉到的问题持反对态度、和如何改善目前的状况。下面是我希望在二月份拜访 Stack Overflow 团队时详细讨论的主题，但我们却忙于。在这篇文章中，我大部分讨论的是”提问者” 和 “回答者”，这是特意进行的简化。许多用户可能既是求助者又是回答者，我很多时候还会用不写答案但是用“view” 写评论的方式成为回答者。尽管任何用户都可以担任不同的角色，但是对提交的每个问题，每个人通常只有一个角色。当然还有其他的角色，例如“评论其它答案的评论者”，我不想花费过多的时间讨论这个问题。与生活中大多数事情相似，当所有人目标一致时 Stack Overflow 的表现最好，因为我们可以共同迈向那个目标。相反，当人们的目标不同时则通常会出现问题。对于 Stack Overflow 而言，最普遍的问题在于这两个目标的差异：– 提问者：尽量减少解决面临的问题所需要的时间– 回答者：最大限度地提高网站所有问题的价值，将网站视为长久的资源就我而言，我经常有一个“试图帮助提高软件工程师的诊断能力，使他们能够更好地解决自己的问题”的子目标。例如，考虑这个问题（编造的，但并不牵强） ：Random 总是返回相同的数值，它出问题了吗？在我看来这是一个低质量的问题（稍后我将对其进行详细讨论）。我基本知道哪里存在问题，但是为了达到我的目标我希望提问者改善这个问题，我希望看到他们的代码、结果等。如果我的答案是正确的（快速连续创建多个使用相同的基于系统时间的种子的 System.Random 的多个实例），那么这个问题很可能由于重复而被关闭，并且很可能被删除。以现在的形式，这个问题对网站没有任何好处。我不想没有确定是否重复之前就将这个问题以重复的原因关闭。现在，从提问者的角度来看，这些并不重要。如果他们知道我知道问题可能出现在哪，他们可能会认为我应该告诉他们，以便他们可以继续工作。如果现在就可以得到答案，为什么还需要花费 10 分钟来重现问题？更糟糕的是，如果他们花时间做了这些事情，然后由于重复的原因又立刻关闭这个问题，这样看上去很像在浪费时间。如果忽略情绪，我认为时间没有被浪费：– 提问者可以了解到，提出一个清晰的问题可以更快的得到答案。– 提问者可以了解到，搜索重复问题很有价值，因为这可能意味着根本不需要提出这个问题。但是我们都是普通人，忽略感情显然是个不可取的方法。在这种情况下可能发生的情况是 ( 即使我始终很有礼貌) 提问者会认为 Stack Overflow 中到处是只关心自己权利的“交警”。 我当然可以认为这是不公平的（虽然这可能会突出我的实际目标 ） 但这可能无法改变任何人的想法。因此，这是个问题。Stack Overflow 社区认同网站的目标，那么在用户提出问题时向用户明确说明网站的目标了吗？ 值得注意的是(奇怪的是网站首页没有设置该链接) 包含以下内容：在您的帮助下，我们正在共同努力，为每个关于编程的问题建立一个详细答案库。我倾向于稍作更改：Stack Overflow 的目标在于创建高质量的问题库以及问题的高质量答案库。这真的是一个共同愿景吗？如果提问者意识到这点，会有帮助吗？我是希望如此，但是我怀疑它会阻止掉所有问题（我不认为有什么能做到阻止所有问题的提问，世界不是一个完美的地方）。让我们转到另一个我与其他人有不同意见的话题：低质量问题。即使不能以完全客观的方式衡量，我也敢肯定有高质量问题和低质量问题（还有很多介于中间的）。我认为 Stack Overflow 中这样的问题可以看做高质量问题：– 提出一个问题，并且明确知道该问题的要求。这个问题应该能够非常明显地看出答案是否回答了问题（这与答案是否正确无关）– 避免无关紧要。这可能很困难，但是我认为这是有效工作的一部分：如果在开发 web 应用程序时遇到问题，至少应该尝试确定 web 应用程序的上下文是否与问题有关。– 对其他人尽量有帮助。这是避免不相关因素的非常重要的原因。很多用户需要将字符串解析为日期。较少人需要使用 X 框架的 Y 版本通过定制及专有网络协议与 COBOL 编写的客户端交互时将字符串解析为日期。– 阐述提问者进行过的尝试、进展以及卡住的位置。– 在适当的情况下（通常情况）包含一个证明问题的小例子。– 格式正确。不要使用整页的段落，不要使用没有格式化的代码等等。Stack Overflow 上有很多符合所有这些要求的问题，或符合以上大部分要求的问题。我有理由认为这样的问题比另外一些问题质量高，一些问题可能只是一个家庭作业的照片。我曾经见过这样的问题，虽然，它们并不总是那么糟糕，但是我真的不知道如果这都不能认为是一个低质量的问题，我们还能达成什么一致意见。当然，在此之间还有很多问题——但我认为接受存在低质量问题的观点非常重要，或者至少经过讨论并找出不同意见。我看过许多文章声称 Stack Overflow 对于新用户来讲过于困难，因为，新用户很难写出一个好问题。我认为接受网站协议并愿意为之付出努力的新人，至少能提出一个合理的问题。他们可能需要花费更长的时间进行研究并写出问题，而且写出的问题可能不会像有经验的人在相同情况下写出的问题那样简单。但是我相信，整体而言，新用户能够写出质量足够好的问题。他们可能没有意识到他们需要做什么或者为什么这样做，但这是一个拥有不同解决方案的问题。而不仅仅是”提问者可能是技术新手，所以我们需要回答没有任何帮助的糟糕问题”。一个稍稍不同的问题是用户是否具有写出真正优秀问题所需的诊断技能。这是一个，而且我真的希望有一个好的解决方案，但是我真的没有。我坚信，帮助程序员提高自己的诊断能力，除了在 Stack Overflow 中提出更好的问题之外，将对他们有巨大的好处。我当然不会宣称 Stack Overflow 社区是完美的。我看到过一些用户对提出低质量问题的人非常无理，我不是要为此进行申辩。如果你看我非常不礼貌，那么请阻止我。我不认为要求改进问题本身是粗鲁的，我们可以非常礼貌地要求改进问题，也可以非常刻薄地要求改进问题。我完全赞成提高 Stack Overflow 的文明水平，但是我认为这不能以牺牲网站质量为代价。我还经历过要求提问者提供更多信息时，提问者的反应非常无理的情况。这不是一个单向的问题。在这个方向上，我看到过比回答者更加粗鲁的行为。事实上，这些问题通常被关闭或删除，所以只是随便浏览网站的人通常不会看到这些。我的时间非常有限，所以我们来看最重要的一点，我们需要对彼此更友好。我故意把它称为宣誓，因为这不是将我的要求强加于他人的地方。如果你认为这也是你想遵循的原则（或许有一些修正），那再好不过了。如果 Stack Overflow 决定在网站指南的某个地方采用它，我非常欢迎，并且他们可以对其做任何适当的修改。从本质上来讲，我认为许多问题看起来像是提问者和回答者之间的一种交易。因此，建立一种契约是合理的（虽然这听起来更像是商业用语），因此，我倾向于使用一个诚心的宣誓。不表现的像个混蛋。记住我正在回应的是人，是有感情的。认定我正在回应的人是诚心地希望得到帮助。要明确，对问题质量的评论不是对提问者的价值的指责。记住，有些时候，我正在回应的人可能会感到他们正在被指责，即使我不认为我有这个意思。要明确，评论如何改善问题时提出积极的具体建议，不要消极地强调现状。答案要清楚，记住不是每个人都与我的技术背景相同（所以有些术语可能需要链接等)。花点时间好好展示我的答案，使用尽可能易读的格式。不表现的像个混蛋。记住任何一个回答问题的都是人类，都是有感情的。认定任何一个回答我问题的人都充满善意并试图帮助我。记住我是在要求其他人放弃自己的时间来帮助我解决问题。在提问之前先研究自己的问题、尽可能的缩小问题范围、给出尽可能详细的相关信息来减少回答问题的人需要花费的时间。花点时间好好提出自己的问题，使用尽可能易读的格式。我希望大部分时间我可以遵循这些誓言。我怀疑自己有时候做不到，所有希望通过明确的写出来，阅读它，使自己成为一个更好的社区成员。我认为如果每个人在 Stack Overflow 上发布任何内容之前都遵循这样的誓言，我们的社区将会更加美好。任选一种支付方式\n                        \n            \n                            \n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/03/6dd085bf97f82f786b71b4fbcdb37e88.jpg"]}
{"title": "谈谈微信支付曝出的漏洞 - 文章 - 伯乐在线", "tag": ["IT技术", "安全"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n昨天（2018-07-04）微信支付的SDK曝出重大漏洞（XXE漏洞），通过该漏洞，攻击者可以获取服务器中目录结构、文件内容，如代码、各种私钥等。获取这些信息以后，攻击者便可以为所欲为，其中就包括众多媒体所宣传的“0元也能买买买”。漏洞报告地址；http://seclists.org/fulldisclosure/2018/Jul/31.  XXE漏洞此次曝出的漏洞属于XXE漏洞，即XML外部实体注入（XML External Entity Injection）。XML文档除了可以包含声明和元素以外，还可以包含文档类型定义（即DTD）；如下图所示。在DTD中，可以引进实体，在解析XML时，实体将会被替换成相应的引用内容。该实体可以由外部引入(支持http、ftp等协议，后文以http为例说明)，如果通过该外部实体进行攻击，就是XXE攻击。可以说，在利用XXE漏洞可以做的事情当中，最常见最容易实现的，便是读取服务器的信息，包括目录结构、文件内容等；本次微信支付爆出的漏洞便属于这一种。2.  微信支付漏洞本次漏洞影响的范围是：在微信支付异步回调接口中，使用微信支付SDK进行XML解析的应用。注意这里的SDK是服务器端的SDK，APP端使用SDK并不受影响。SDK下载地址如下（目前微信官方宣传漏洞已修复）：https://pay.weixin.qq.com/wiki/doc/api/download/WxPayAPI_JAVA_v3.zipSDK中导致漏洞的代码是WXPayUtil工具类中的xmlToMap()方法：如上图所示，由于在解析XML时没有对外部实体的访问做任何限制，如果攻击者恶意构造xml请求，便可以对服务器进行攻击。下面通过实例介绍攻击的方法。3.  攻击复现下面在本机环境下进行复现。假设本地的web服务器127.0.0.1:8080中存在POST接口：/wxpay/callback，该接口中接收xml字符串做参数，并调用前述的WXPayUtil.xmlToMap(strXml)对xml参数进行解析。此外，/etc/password中存储了重要的密码数据（如password1234）。攻击时构造的请求如下：其中xml内容如下：其中/etc/password为要窃取的对象，http://127.0.0.1:9000/xxe.dtd为攻击者服务器中的dtd文件，内容如下：通过xml+dtd文件，攻击者便可以在服务器http://127.0.0.1:9000中收到如下请求：http://127.0.0.1:9000/evil/password1234这样，攻击者便得到了/etc/password文件的内容。在本例中，攻击者窃取了/etc/password文件中的内容，实际上攻击者还可以获取服务器中的目录结构以及其他文件，只要启动web应用的用户具有相应的读权限。如果获取的信息比较复杂，如包含特殊符号，无法直接通过http的URL发送，则可以采用对文件内容进行Base64编码等方法解决。解决该漏洞的原理非常简单，只要禁止解析XML时访问外部实体即可。漏洞曝出以后，微信进行了紧急修复，一方面是更新了SDK，并提醒开发者使用最新的SDK；SDK中修复代码如下：加入了如下两行代码：更新：微信表示上述2条语句无法禁止该漏洞，又双叒叕更新了官方SDK，加了以下语句（对于微信的这波操作，不知如何评价）：此外，微信官方也给出了关于XXE漏洞的最佳安全实践，可以参考：笔者本人使用上述方案中建议的如下代码修复了该漏洞：1.  危害不只是“0元也能买买买”在很多媒体的报道中，强调该漏洞的风险在于攻击者可以不支付也可以获得商品。确实，攻击者在通过上述漏洞获得微信支付的秘钥以后，有不止一种途径可以做到不支付就获得商品：例如，攻击者首先在系统中下单，获得商户订单号；然后便可以调用微信支付的异步回调，其中的签名参数便可以使用前面获取的秘钥对订单号等信息进行MD5获得；这样攻击者的异步回调就可以通过应用服务器的签名认证，从而获得商品。不过，在很多有一定规模的购物网站（或其他有支付功能的网站），会有对账系统，如定时将系统中的订单状态与微信、支付宝的后台对比，如果出现不一致可以及时报警并处理，因此该漏洞在这方面的影响可能并没有想象的那么大。然而，除了“0元也能买买买”，攻击者可以做的事情还有很多很多；理论上来说，攻击者可能获得应用服务器上的目录结构、代码、数据、配置文件等，可以根据需要进行进一步破坏。2.  漏洞不限于微信支付SDK虽然微信支付曝出该漏洞受到了广泛关注，但该漏洞绝不仅仅存在于微信支付中：由于众多XML解析器默认不会禁用对外部实体的访问，因此应用的接口如果有以下几个特点就很容易掉进XXE漏洞的坑里：（1）接口使用xml做请求参数（2）接口对外公开，或容易获得：例如一些接口提供给外部客户调用，或者接口使用http很容易抓包，或者接口比较容易猜到(如微信支付的异步回调接口)（3）接口中解析xml参数时，没有禁用对外部实体的访问建议大家最好检查一下自己的应用中是否有类似的漏洞，及时修复。3.  xml与jsonxml 与 json是系统间交互常用的两种数据格式，虽然很多情况下二者可以互换，但是笔者认为，json 作为更加轻量级更加纯粹的数据格式，更适合于系统间的交互；而xml，作为更加重量级更加复杂的数据格式，其 DTD 支持自定义文档类型，在更加复杂的配置场景下有着更好的效果，典型的场景如 spring 相关的配置。4.  题外话：微信支付的签名认证在前面曾经提到，应用中存储的秘钥一旦泄露，攻击者便可以完全绕过签名认证，这是因为微信支付使用的是对称式的签名认证：微信方和应用方，使用相同的秘钥对相同的明文进行MD5签名，只要应用方的秘钥泄露，签名认证就完全成了摆设。在这方面支付宝的做法更规范也更安全：支付宝为应用生成公私钥对，公钥由应用方保存，私钥由支付宝保存；在回调时，支付宝使用私钥进行签名，应用方使用公钥进行验证；这样只要支付宝保存的私钥不泄露，攻击者只有公钥则难以通过签名认证。https://pay.weixin.qq.com/wiki/doc/api/jsapi.php?chapter=23_5https://www.cnblogs.com/tongwen/p/5194483.html\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/09/3fb6592ac92133a71f0ae78e43683e83.jpg"]}
{"title": "Vim-plug：极简 Vim 插件管理器 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux", "Vim"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n当没有插件管理器时，Vim 用户必须手动下载 tarball 包形式的插件，并将它们解压到  目录中。在少量插件的时候可以。但当他们安装更多的插件时，就会变得一团糟。所有插件文件分散在单个目录中，用户无法找到哪个文件属于哪个插件。此外，他们无法找到他们应该删除哪个文件来卸载插件。这时 Vim 插件管理器就可以派上用场。插件管理器将安装插件的文件保存在单独的目录中，因此管理所有插件变得非常容易。我们几个月前已经写了关于  的文章。今天，我们将看到又一个名为 “Vim-plug” 的 Vim 插件管理器。Vim-plug 是一个自由、开源、速度非常快的、极简的 vim 插件管理器。它可以并行地安装或更新插件。你还可以回滚更新。它创建浅层克隆shallow clone最小化磁盘空间使用和下载时间。它支持按需加载插件以加快启动时间。其他值得注意的特性是支持分支/标签/提交、post-update 钩子、支持外部管理的插件等。安装和使用起来非常容易。你只需打开终端并运行以下命令：Neovim 用户可以使用以下命令安装 Vim-plug：要安装插件，你必须如下所示首先在 Vim 配置文件中声明它们。一般 Vim 的配置文件是 ，Neovim 的配置文件是 。请记住，当你在配置文件中声明插件时，列表应该以  开始，并以  结束。例如，我们安装 “lightline.vim” 插件。为此，请在  的顶部添加以下行。在 vim 配置文件中添加上面的行后，通过输入以下命令重新加载：或者，只需重新加载 Vim 编辑器。现在，打开 vim 编辑器：使用以下命令检查状态：然后输入下面的命令，然后按回车键安装之前在配置文件中声明的插件。要更新插件，请运行：更新插件后，按下  查看更改。或者，你可以之后输入 。有时，更新的插件可能有新的 bug 或无法正常工作。要解决这个问题，你可以简单地回滚有问题的插件。输入  命令，然后按回车键查看上次 的更改，并在每个段落上按  将每个插件回滚到更新前的前一个状态。删除一个插件删除或注释掉你以前在你的 vim 配置文件中添加的  命令。然后，运行  或重启 Vim 编辑器。最后，运行以下命令卸载插件：该命令将删除 vim 配置文件中所有未声明的插件。要升级vim-plug本身，请输入：如你所见，使用 Vim-plug 管理插件并不难。它简化了插件管理。现在去找出你最喜欢的插件并使用 Vim-plug 来安装它们。就是这些了。我将很快在这里发布另一个有趣的话题。在此之前，请继续关注我们。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/06/e10fe1fd7da125e34ea34b9f5dad9c30.png"]}
{"title": "2018 年 Java 程序员必读的十本书 - 文章 - 伯乐在线", "tag": ["书籍与教程", "java", "书籍"], "goodNum": "2", "saveNum": " 6 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n大家好，如果你是一名 Java 程序员，正在考虑 2018 年读什么书，那么这篇文章正适合你。本文中，我将分享 10 本有关 Java、Spring 及其他相关技术的书籍。 这里面既有适合经验丰富的 Java 程序员的书，它们介绍了架构、云开发、微服务、Java 9、Spring 5，以及用于提高生产效率的 Kotlin。同时也照顾到了初级的、缺乏经验的、或正打算 2018 年开始入门 Java 的新手。同时，我也介绍了一些在 2018 年学习 Java 9 的书籍。有些已经针对 Java SE 9 全面更新，比如 《写给大忙人看的Java SE 9》和 《Java 9 编程入门官方教程》。如果你刚开始学习 Java 或者正打算要学，这些书都非常适合。不推荐读旧版本的书来入门，除非是《Head First Java》。我特别希望《Head First Java》的第三版是一个长期的版本，作者和出版方最好针对 Java 8 和 Java 9 进行全面更新。不过对于入门 Java 的编程小白来说，旧版本的《Head First Java》仍然是一本好书。我最近添加到这个书单的就是这本今天刚发现的《云原生 Java》。这本书看起来特别棒，它介绍了目前急需的，利用 Spring Boot、Spring Cloud 和 Cloud Foundry 在云上开发 Java 应用的知识。虽然还没读完，但它看起来特别棒。2018 年可以用来提升 Java 知识技能的书太多了，你不可能把他们都读完。不过有些书你绝对不想错过，比如《Effective Java（第三版）》，我把它放在了书单的最上面。书单里的书介绍了 Java 9、Spring 5、Kotlin、软件架构、微服务、云以及 Java 8 的一些特性。这个书单不是很长，但里面的书都很棒，都挺适合在上下班路上读。如果你还没读过这本书，那它绝对是 2018 年你必须读的第一本书。第三版是一个长期版本，其实它早就该出版了。这版书也囊括了 JDK 7、8、9 的新特性。我在 1 月份的第一个星期就拿到了这本书，它绝对是约书亚·布洛克（Joshua Bloch）给 Java 程序员最好的新年礼物。我花了大概一个星期就读完了这本书。我发现读的过程中，时常碰到新的知识点，特别是关于 Java 8 和 Java 9 的。我从这本书中学到了 Java 的模块化，它也帮我理顺了之前对于 Java 8 的一些误解。如果你喜欢范例类型的书，那这本书就很不错。就像简介里提到的，这本书提供了解决 Java 8 和 Java 9 中一些难题的简单方案。你会学到如何使用 Java 8 的 lambda 表达式、方法引用以及 Stream API 写代码。如果你想通过手册和范例来学习 Java 8 和 Java 9 ，这本书就很完美。Java 9 的一个亮点就是 Java 的模块化，本书对这部分做了最全面的介绍。作者桑德斯·马克（Sanders Mak）是 Java 9 模块化的权威。我听过很多他讲 Java 9 的课程，比如在 Pluarlsight 做的《Java 9 模块化及新特性》。我可以保证，读完此书之后，你绝不会后悔。如果你急着学 Java 那我推荐这本书给你。我是凯 S·霍斯特曼 (Cay S. Horstmann)的一个忠实粉丝，他的文采之优美、涉猎之广，都让我很是佩服。你读了他写的关于 Java 8、Scala 的书以及《Java 核心编程》之后，绝对也会成为他的粉丝。这本书已经针对 Java SE 9 全面更新。如果你想学习 Java 9，那2018年你应该先读读这本书。 尽管已经发布快 4 年了，仍然有很多 Java 程序员还没有开始使用 Java 8。如果你是这些人的一员，或者还不是很理解 lambda 表达式、Stream API、Optional 及 Java 8 其他的特性，那你一定要读这本书。这是一个系列，共有3卷，此卷通俗易懂的讲解了 Java 8 的基础知识。另外两卷则延伸到 Java 8 的高级特性，比如 JDBC、Swing、 Java FX，以及 Java 网络 API。软件开发世界正在加速转向微服务架构，它在开发、维护、部署、扩容性及可靠性等方面有很多优势。感谢 Spring framework 提供这么多开发微服务的 Java 工具，比如 Spring Boot 和 Spring Cloud。如果你对用 Spring framework 开发微服务有兴趣，那么这本书很适合你。我是在2017年读的这本书，特别喜欢。我是罗伯特 C·马丁（Robert C. Martin）的一个忠实粉丝（大家称之为“ Bob 大叔”）。加上之前的《代码整洁之道（Clean Code）》和《代码整洁之道 程序员的职业素养（Clean Coder book）》，这本书完成了代码整洁之道三部曲。它介绍了如何构建可以经受时间考验的软件架构，还消除了对设计模式和软件架构的一些误解。如果你是一名经验丰富的 Java 程序员，正想转变为一个方案设计师，那这本书2018年你一定要读完。抛开 JDK 9 不谈，2017年另外一个大的版本更新就是 Spring 5 ，它将响应式编程引入了 Spring 。既然对 Java 程序员来说， Spring 是无可争议的、最流行的架构，那么学习 Spring 5 让自己紧跟技术潮流，是非常值得的。我个人非常喜欢目标导向的范例类图书，这也是我为什么选择了这本书用来学习 Spring 5。它不仅覆盖了 Spring 5 的新特性，也讲了其他早期版本的增强。一句话，它教你如何在 Spring 5 的环境下写代码。 Java 程序员通过学习 Scala、Groovy、Closure 等 JVM 语言来成为一名多语言的开发者是很常见的。而 Kotlin 正是当下的热门。自从 2017 年 Google 在 Google IO 上宣布将 Kotlin 作为 Android 的官方语言之后，很多人都开始对学习 Kotlin 感兴趣。更重要的是，它能提高你的生产效率，而且它和 Java 非常相似。因此，如果你想在 2018 年学习一种 JVM 语言，我建议学习 Kotlin。这是另一本从零开始学习 Java 的经典书籍。第七版已经针对 Java SE 9 全面更新。如果你想在 2018 年开始你的 Java 程序员生涯，这本书可以帮你学到最新版本的 Java。这本书比书单里的第二本更全面。 恭喜读到这里的朋友，你们收获了一个彩蛋 ——《云原生 Java》，2018 年最有用的 Java 书籍。当今的软件开发，大都是关于云、微服务、分布式架构等等。乔氏·隆（Josh Long）和肯尼·巴斯塔尼（Kenny Bastani）在这本书里向 Java/JVM 开发者展示了如何使用 Spring Boot、Spring Cloud 和 Cloud Foundry 构建更好、更快的 Java 应用程序。对于经验丰富的 Java 开发者来说，它绝对是一本必读书。尽管它介绍了相对高级的内容，我还是强烈推荐每一位 Java 程序员都读一下。实际上，我还没有读完这本书。但是读完前言之后，我就对所讨论的话题非常感兴趣。我可能在读完之后再写一篇详细的文章。但它绝对值得各位至少读一遍。这就是 2018 年 Java 程序员可以读的一些有趣、有用的书籍。实话实说，即使是让自己紧跟 Java 世界的技术潮流，比如 Java 9、Sprig 5、微服务、Kotlin 等，也还有一大堆东西等着你去学习。这些书不仅仅更新你的知识，还能让你对一些技术的理解更加深刻。多谢阅读。如果你喜欢这些书，就把它们分享给你的朋友和同学吧。如果有任何建议，或有书籍想在2018年分享给大家，欢迎留言。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2012/03/stack-of-books2.jpg"]}
{"title": "PacVim：一个学习 vim 命令的命令行游戏 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux", "Vim"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n你好，Vim用户！今天，我偶然发现了一个很酷的程序来提高 Vim 的使用技巧。Vim 是编写和编辑代码的绝佳编辑器。然而，你们中的一些人（包括我）仍在陡峭的学习曲线中挣扎。再也不用了！来看看 ，一款可帮助你学习 Vim 命令的命令行游戏。PacVim 的灵感来源于经典游戏 ，它以一种好玩有趣的方式为你提供了大量的 Vim 命令练习。简而言之，PacVim 是一种深入了解 vim 命令的有趣而自由的方式。请不要将 PacMan 与  （arch Linux 包管理器）混淆。 PacMan 是 20 世纪 80 年代发布的经典流行街机游戏。在本简要指南中，我们将看到如何在 Linux 中安装和使用 PacVim。首先按如下链接安装  库和。请注意，如果没有 gcc 4.8.X 或更高版本，这款游戏可能无法正确编译和安装。我在 Ubuntu 18.04 LTS 上测试了 PacVim，并且完美运行。安装 Ncurses 和 gcc 后，运行以下命令来安装 PacVim。要玩这个游戏，只需运行：例如，以下命令以普通模式启动游戏第 5 关。这里， 表示等级，表示模式。有两种模式： – 普通模式。 – 困难模式。默认模式是 ，这很难：要从头开始（ 级），请运行：以下是我 Ubuntu 18.04 LTS 的示例输出。要开始游戏，只需按下回车。现在开始游戏。阅读下一节了解如何玩。要退出，请按下  或 。以下命令以困难模式启动游戏第  关。或者，PacVim 的使用与 PacMan 非常相似。你必须跑过屏幕上所有的字符，同时避免鬼魂（红色字符）。PacVim有两个特殊的障碍：你不能移动到墙壁中（黄色）。你必须使用 vim 动作来跳过它们。如果你踩到波浪字符（青色的 ），你就输了！你有三条生命。每次打赢 0、3、6、9 关时你都会获得新生命。总共有 10 关，从 0 到 9，打赢第 9 关后，游戏重置为第 0 关，但是鬼魂速度变快。使用 vim 命令将光标移动到字母上并高亮显示它们。所有字母都高亮显示后，你就会获胜并进入下一关。如果你碰到鬼魂（用 表示）或者，你就会失去一条命。如果命小于 0 条，你将会输掉整个游戏。这是实现的命令列表：玩过几关之后，你可能会注意到 vim 的使用有改善。一段时间后继续玩这个游戏，直到你掌握 Vim 的使用。今天就是这些。希望这篇文章有用。PacVim 好玩又有趣并且让你有事做。同时，你应该能够彻底学习足够的 Vim 命令。试试看，你不会感到失望。还有更多的好东西。敬请关注！ \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/06/57beea594a88813722998ea81bc96125.png"]}
{"title": "IT程序员的抉择：我要离开帝都了 - 文章 - 伯乐在线", "tag": ["职场", " 4 评论 ", "职业生涯"], "goodNum": "1", "saveNum": "  收藏", "sayNum": " 4 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n不知不觉在北京已经漂泊了近5年了，共为3家公司打过工，其中有几十人的小公司，也有几万人的大公司。随着工作技能的提升和工作经验的积累，薪水自然也涨了不少，但是看着北京的房价、物价飞涨，感觉自己赚多少都是小钱，还不如尽早卷铺盖回内蒙老家发展。那里毕竟是老家，亲戚朋友相对多一点。随着年龄的增长，也想有个自己的家了。之前犹犹豫豫的好长时间，不知道自己是留是走，今天还是详细的罗列了两个地方发展的坏处：（1）工作压力大尤其是互联网公司，研发需求还是比较多的，有些需求还比较急，清闲的时候少。不过现在觉得还好，技术上有很大的进步，能独立扛事儿，一般的IT研发岗位还是可以得心应手的。（2）房价高，落户难在北京落户，有一套自己的房子，这想都不敢想了。看着日益飙高的房价和近乎不可能满足的帝都落户条件，如果要呆在北京发展，那注定一辈子只能租房了，像我的同学一样，在偏远一点的地方租个小两居，再买个\n15万以下的车代步，总感觉这不是我想要的生活。（3）空气差，雾霾严重每天吸雾霾，我都不知道的少活多少年了。随着年龄的增长，感觉身体才最重要，尤其是看到认识的人得了重病后更感觉身体的宝贵。如果继续呆在帝都的话，那也只能是天天吸了。（4）漂泊孤独感没亲戚，只有几个在大学交好的同学，不过现在也都各忙各的，聚的少，大部分时间还是自己一个人。工作这么多年，也少有能交心的同事。一直感觉自己的生活过的并不快乐，也许有个人陪伴会好很多吧。（5）离父母太远父母已经上年纪了，而且也不希望离他们太远，万一有个病痛啥的，照顾实在不方便。（1）知名IT企业少，岗位技术含量低去年中旬专门休了年假回内蒙面试了几家IT公司，挑来挑去还是选择回京继续工作。主要是外包的多，充其量也就给企业做定制化软件，有的还要求驻场开发，几乎没有做自家产品的。这种性质的岗位貌\n似也不轻松。（2）薪水低薪水和帝都比起来，都不能用腰斩来形容了，要1万都觉得太多，这个心理落差的承受，而且内蒙还不是强制单位上五险一金，所以只有2家公司有五险一金，而且按最低额度缴纳。如果没有房贷，车贷，这个薪水也不是不能接受。这些年在北京也赚了一点钱，再找父母凑点，房子还是能勉强买的起的。（3）容易不满足现状，不甘心如果岗位技术含量低，而且活儿还多的话，肯定干不长久。而且本人很喜欢技术，很爱在技术上玩儿点高端的。哎，实在不行就自个儿干吧，写写技术书，录录网络课程啥的，相对来说即能选择性学习一些\n感兴趣的技术，又不至于饿死吧。（4）空气干燥，对某些植物过敏，容易引发过敏性鼻炎内蒙是没有雾霾，但是有沙尘暴，而且为了绿化植被，防止沙漠化，种了一些叫不上名的植物，我很过敏。（5）回去容易出来难我30出头的年龄，回去肯定要成家的，有家了出来可就难了。反正选择在哪个地方发展坏处都不少。但是这么多年在北京奋斗，我感觉除了看上北京的工作机会，就再也没有让我留恋的东西了。我要辞职了，我要离开北京了，再见！2018.6.16\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2012/03/career.jpg"]}
{"title": "推荐系统概述 - 文章 - 伯乐在线", "tag": ["IT技术", " 2 评论 ", "Pandas", "协同过滤", "推荐系统"], "goodNum": "4", "saveNum": " 6 收藏", "sayNum": " 2 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n“聆忠言者众，惟智者受益。” — 哈珀·李许多人把推荐系统视为一种神秘的存在，他们觉得推荐系统似乎知道我们的想法是什么。Netflix 向我们推荐电影，还有亚马逊向我们推荐该买什么样的商品。推荐系统从早期发展到现在，已经得到了很大的改进和完善，以不断地提高用户体验。尽管推荐系统中许多都是非常复杂的系统，但其背后的基本思想依然十分简单。推荐系统是什么？推荐系统是信息过滤系统的一个子类，它根据用户的偏好和行为，来向用户呈现他(或她)可能感兴趣的物品。推荐系统会尝试去预测你对一个物品的喜好，以此向你推荐一个你很有可能会喜欢的物品。如何构建一个推荐系统？现在已经有很多种技术来建立一个推荐系统了，我选择向你们介绍其中最简单，也是最常用的三种。他们是：我会解释前面的每个系统相关的弱点，潜在的缺陷，以及如何去避免它们。最后，我在文章末尾为你们准备了一个推荐系统的完整实现。协同过滤，是首次被用于推荐系统上的技术，至今仍是最简单且最有效的。协同过滤的过程分为这三步：一开始，收集用户信息，然后以此生成矩阵来计算用户关联，最后作出高可信度的推荐。这种技术分为两大类：一种基于用户，另一种则是基于组成环境的物品。基于用户的协同过滤本质上是寻找与我们的目标用户具有相似品味的用户。如果Jean-Pierre和Jason曾对几部电影给出了相似的评分，那么我们认为他们就是相似的用户，接着我们就可以使用Jean Pierre的评分来预测Jason的未知评分。例如，如果Jean-Pierre喜欢星球大战3:绝地武士归来和星球大战5:帝国反击战，Jason也喜欢绝地武士归来，那么帝国反击战对Jason来说是就是一个很好的推荐。一般来说，你只需要一小部分与Jason相似的用户来预测他的评价。在下表中，每行代表一个用户，每列代表一部电影，只需简单地查找这个矩阵中行之间的相似度，就可以找到相似的用户了。然而，基于用户的协同过滤在实现中存在一些以下问题：用户偏好会随时间的推移而改变，推荐系统生成的许多推荐可能会随之变得过时。用户的数量越多，生成推荐的时间就越长。基于用户会导致对托攻击敏感，这种攻击方法是指恶意人员通过绕过推荐系统，使得特定物品的排名高于其他物品。\n(托攻击即Shilling Attack,是一种针对协同过滤根据近邻偏好产生推荐的特点，恶意注入伪造的用户模型，推高或打压目标排名，从而达到改变推荐系统结果的攻击方式)基于物品的协同过滤过程很简单。两个物品的相似性基于用户给出的评分来算出。让我们回到Jean-Pierre与Jason的例子，他们两人都喜欢“绝地武士归来”和“帝国反击战”。 因此，我们可以推断，喜欢第一部电影的大多数用户也可能会喜欢第二部电影。所以，对于喜欢“绝地武士归来”的第三个人Larry来说，”帝国反击战“的推荐将是有意义的。所以，这里的相似度是根据列而不是行来计算的(与上面的用户-电影矩阵中所见的不同)。基于物品的协同过滤常常受到青睐，因为它没有任何基于用户的协同过滤的缺点。首先，系统中的物品(在这个例子中物品就是电影)不会随着时间的推移而改变，所以推荐会越来越具有关联性。此外，通常推荐系统中的物品都会比用户少，这减少了推荐的处理时间。最后，考虑到没有用户能够改变系统中的物品，这种系统要更难于被欺骗或攻击。在基于内容的推荐系统中，元素的描述性属性被用来构成推荐。“内容Content”一词指的就是这些描述。举个例子，根据Sophie的听歌历史，推荐系统注意到她似乎喜欢乡村音乐。因此，系统可以推荐相同或相似类型的歌曲。更复杂的推荐系统能够发现多个属性之间的关系，从而产生更高质量的推荐。例如，音乐基因组计划(Music Genome Project)根据450个不同的属性将数据库中的每支歌曲进行分类。该项目为Pandor的歌曲推荐提供技术支持。(Pandor提供在线音乐流媒体服务，类似Spolify)基于知识的推荐系统在物品购买频率很低的情况下特别适用。例如房屋、汽车、金融服务甚至是昂贵的奢侈品。在这种情况下，推荐的过程中常常缺乏商品的评价。基于知识的推荐系统不使用评价来作出推荐。相反，推荐过程是基于顾客的需求和商品描述之间的相似度，或是对特定用户的需求使用约束来进行的。这使得这种类型的系统是独一无二的，因为它允许顾客明确地指定他们想要什么。关于约束，当应用时，它们大多是由该领域的专家实施的，这些专家从一开始就知道该如何实施这些约束。例如，当用户明确指出在一个特定的价格范围内寻找一个家庭住宅时，系统必须考虑到这个用户规定的约束。推荐系统中的冷启动问题推荐系统中的主要问题之一是最初可用的评价数量相对较小。当新用户还没有给电影打分，或者一部新的电影被添加到系统中时，我们该怎么做呢？在这种情况下，应用传统的协同过滤模型会更加困难。尽管基于内容和基于知识的推荐算法在面临冷启动问题时比协同过滤更具有鲁棒性，但基于内容和基于知识并不总是可用的。因此，一些新方法，比如混合系统，已经被设计出用来解决这个问题了。混合推荐系统文章到目前为止所介绍的不同类型的推荐系统都各有优劣，他们根据不同的数据给出推荐。 一些推荐系统，如基于知识的推荐系统，在数据量有限的冷启动环境下最为有效。其他系统，如协同过滤，在有大量数据可用时则更加有效。在多数情况下，数据都是多样化的，我们可以为同一任务灵活采用多种方法。 因此，我们可以结合多种不同技术的推荐来提高整个系统的推荐质量。许多的组合性技术已经被探索出来了，包括：加权：为推荐系统中的每种算法都赋予不同的权重，使得推荐偏向某种算法交叉：将所有的推荐结果集合在一起展现，没有偏重增强：一个系统的推荐将作为下一个系统的输入，循环直至最后一个系统为止切换：随机选择一种推荐方法混合推荐系统中的一个最有名的例子是于2006至2009年举行的Netflix Price算法竞赛。这个竞赛的目标是将Netflix的电影推荐系统Cinematch的算法准确率提高至少10%。Bellkor’s Pragmatix Chaos团队用一种融合了107种不同算法的方案将Cinematch系统的推荐准确率提高了10.06%，并最终获得了100万美元奖金。你可能会对这个例子中的准确率感到好奇，准确率其实就是对电影的预测评分与实际评分接近程度的度量。推荐系统与AI？推荐系统常用于人工智能领域。推荐系统的能力 – 洞察力，预测事件的能力和突出关联的能力常被用于人工智能中。另一方面，机器学习技术常被用于实现推荐系统。例如，在Arcbees，我们使用了神经网络和来自IMdB的数据成功建立了一个电影评分预测系统。神经网络可以快速地执行复杂的任务并轻松地处理大量数据。通过使用电影列表作为神经网络的输入，并将神经网络的输出与用户评分进行比较，神经网络可以自我学习规则以预测特定用户的未来评分。专家建议在我读过许多资料中，我注意到有两个很重要的建议经常被推荐系统领域内的专家提及。第一，基于用户付费的物品进行推荐。当一个用户有购买意愿时，你就可以断定他的评价一定是更具有相关性与准确的。第二，使用多种算法总是比改进一种算法要好。Netflix Prize竞赛就是一个很好的例子。实现一个基于物品的推荐系统下面的代码演示了实现一个基于物品的推荐系统是多么的简单与快速。所使用的语言是Python，并使用了Pandas与Numpy这两个在推荐系统领域中最流行的库。所使用的数据是电影评分，数据集来自MovieLens。1.读取数据2.构造用户的电影矩阵3.选择一部电影并生成这部电影与其他所有电影的相似度4.去除不流行的电影以避免生成不合适的推荐5.提取与目标电影相类似的流行电影1.生成每两部电影之间的相似度，并只保留流行电影的相似度2.对于每部用户看过并评分过的电影，生成推荐（这里我们选择用户0）3.将所有相同电影的相似度加和4.只保留用户没有看过的电影如何更进一步？在上面的实例中，Pandas与我们的CPU足以处理MovieLens的数据集。然而，当数据集变得更庞大时，处理的时间也会变得更加漫长。因此，你应该转为使用具有更强大处理能力的解决方案，如Spark或MapReduce。我希望我已经成功让你看到，实现一个简单而有效的推荐系统中并没有什么复杂之处。如果你有任何问题，不要犹豫，直接评论就好了。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/05/1a58c225e4d199c6b01c7dcec81cea65.png"]}
{"title": "深入学习 Redis（3）：主从复制 - 文章 - 伯乐在线", "tag": ["IT技术", "Redis", "数据库"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n前言在前面的两篇文章中，分别介绍了和。在Redis的持久化中曾提到，Redis高可用的方案包括持久化、主从复制（及读写分离）、哨兵和集群。其中持久化侧重解决的是Redis数据的单机备份问题（从内存到硬盘的备份）；而主从复制则侧重解决数据的多机热备。此外，主从复制还可以实现负载均衡和故障恢复。这篇文章中，将详细介绍Redis主从复制的方方面面，包括：如何使用主从复制、主从复制的原理（重点是全量复制和部分复制、以及心跳机制）、实际应用中需要注意的问题（如数据不一致问题、复制超时问题、复制缓冲区溢出问题）、主从复制相关的配置（重点是repl-timeout、client-output-buffer-limit slave）等。主从复制，是指将一台Redis服务器的数据，复制到其他的Redis服务器。前者称为主节点(master)，后者称为从节点(slave)；数据的复制是单向的，只能由主节点到从节点。默认情况下，每台Redis服务器都是主节点；且一个主节点可以有多个从节点(或没有从节点)，但一个从节点只能有一个主节点。主从复制的作用主要包括：数据冗余：主从复制实现了数据的热备份，是持久化之外的一种数据冗余方式。故障恢复：当主节点出现问题时，可以由从节点提供服务，实现快速的故障恢复；实际上是一种服务的冗余。负载均衡：在主从复制的基础上，配合读写分离，可以由主节点提供写服务，由从节点提供读服务（即写Redis数据时应用连接主节点，读Redis数据时应用连接从节点），分担服务器负载；尤其是在写少读多的场景下，通过多个从节点分担读负载，可以大大提高Redis服务器的并发量。高可用基石：除了上述作用以外，主从复制还是哨兵和集群能够实施的基础，因此说主从复制是Redis高可用的基础。为了更直观的理解主从复制，在介绍其内部原理之前，先说明我们需要如何操作才能开启主从复制。1. 建立复制需要注意，从节点开启主从复制，有3种方式：（1）配置文件在从服务器的配置文件中加入：slaveof <masterip> <masterport>（2）启动命令redis-server启动命令后加入 –slaveof <masterip> <masterport>（3）客户端命令Redis服务器启动后，直接通过客户端执行命令：slaveof <masterip> <masterport>，则该Redis实例成为从节点。上述3种方式是等效的，下面以客户端命令的方式为例，看一下当执行了slaveof后，Redis主节点和从节点的变化。2. 实例方便起见，实验所使用的主从节点是在一台机器上的不同Redis实例，其中主节点监听6379端口，从节点监听6380端口；从节点监听的端口号可以在配置文件中修改：启动后可以看到：两个Redis节点启动后（分别称为6379节点和6380节点），默认都是主节点。此时在6380节点执行slaveof命令，使之变为从节点：下面验证一下，在主从复制建立后，主节点的数据会复制到从节点中。（1）首先在从节点查询一个不存在的key：（2）然后在主节点中增加这个key：（3）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：（4）然后在主节点删除这个key：（5）此时在从节点中再次查询这个key，会发现主节点的操作已经同步至从节点：3. 断开复制通过slaveof <masterip> <masterport>命令建立主从复制关系以后，可以通过slaveof no one断开。需要注意的是，从节点断开复制后，不会删除已有的数据，只是不再接受主节点新的数据变化。从节点执行slaveof no one后，打印日志如下所示；可以看出断开复制后，从节点又变回为主节点。主节点打印日志如下：上面一节中，介绍了如何操作可以建立主从关系；本小节将介绍主从复制的实现原理。主从复制过程大体可以分为3个阶段：连接建立阶段（即准备阶段）、数据同步阶段、命令传播阶段；下面分别进行介绍。1. 连接建立阶段该阶段的主要作用是在主从节点之间建立连接，为数据同步做好准备。从节点服务器内部维护了两个字段，即masterhost和masterport字段，用于存储主节点的ip和port信息。需要注意的是，这个过程中，可以看到从节点打印日志如下：从节点每秒1次调用复制定时函数replicationCron()，如果发现了有主节点可以连接，便会根据主节点的ip和port，创建socket连接。如果连接成功，则：从节点：为该socket建立一个专门处理复制工作的文件事件处理器，负责后续的复制工作，如接收RDB文件、接收命令传播等。主节点：接收到从节点的socket连接后（即accept之后），为该socket创建相应的客户端状态，这个过程中，从节点打印日志如下：从节点成为主节点的客户端之后，发送ping命令进行首次请求，目的是：检查socket连接是否可用，以及主节点当前是否能够处理请求。从节点发送ping命令后，可能出现3种情况：（1）返回pong：说明socket连接正常，且主节点当前可以处理请求，复制过程继续。（2）超时：一定时间后从节点仍未收到主节点的回复，说明socket连接不可用，则从节点断开socket连接，并重连。（3）返回pong以外的结果：如果主节点返回其他结果，如正在处理超时运行的脚本，说明主节点当前无法处理命令，则从节点断开socket连接，并重连。在主节点返回pong情况下，从节点打印日志如下：如果从节点中设置了masterauth选项，则从节点需要向主节点进行身份验证；没有设置该选项，则不需要验证。从节点进行身份验证是通过向主节点发送auth命令进行的，auth命令的参数即为配置文件中的masterauth的值。如果主节点设置密码的状态，与从节点masterauth的状态一致（一致是指都存在，且密码相同，或者都不存在），则身份验证通过，复制过程继续；如果不一致，则从节点断开socket连接，并重连。身份验证之后，从节点会向主节点发送其监听的端口号（前述例子中为6380），主节点将该信息保存到该从节点对应的客户端的slave_listening_port字段中；该端口信息除了在主节点中执行info Replication时显示以外，没有其他作用。2. 数据同步阶段主从节点之间的连接建立以后，便可以开始进行数据同步，该阶段可以理解为从节点数据的初始化。具体执行的方式是：从节点向主节点发送psync命令（Redis2.8以前是sync命令），开始同步。数据同步阶段是主从复制最核心的阶段，根据主从节点当前状态的不同，可以分为全量复制和部分复制，下面会有一章专门讲解这两种复制方式以及psync命令的执行过程，这里不再详述。需要注意的是，在数据同步阶段之前，从节点是主节点的客户端，主节点不是从节点的客户端；而到了这一阶段及以后，主从节点互为客户端。原因在于：在此之前，主节点只需要响应从节点的请求即可，不需要主动发请求，而在数据同步阶段和后面的命令传播阶段，主节点需要主动向从节点发送请求（如推送缓冲区中的写命令），才能完成复制。3. 命令传播阶段数据同步阶段完成后，主从节点进入命令传播阶段；在这个阶段主节点将自己执行的写命令发送给从节点，从节点接收命令并执行，从而保证主从节点数据的一致性。在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。由于心跳机制的原理涉及部分复制，因此将在介绍了部分复制的相关内容后单独介绍该心跳机制。需要注意的是，命令传播是异步的过程，即主节点发送写命令后并不会等待从节点的回复；因此实际上主从节点之间很难保持实时的一致性，延迟在所难免。数据不一致的程度，与主从节点之间的网络状况、主节点写命令的执行频率、以及主节点中的repl-disable-tcp-nodelay配置等有关。repl-disable-tcp-nodelay no：该配置作用于命令传播阶段，控制主节点是否禁止与从节点的TCP_NODELAY；默认no，即不禁止TCP_NODELAY。当设置为yes时，TCP会对包进行合并从而减少带宽，但是发送的频率会降低，从节点数据延迟增加，一致性变差；具体发送频率与Linux内核的配置有关，默认配置为40ms。当设置为no时，TCP会立马将主节点的数据发送给从节点，带宽增加但延迟变小。一般来说，只有当应用对Redis数据不一致的容忍度较高，且主从节点之间网络状况不好时，才会设置为yes；多数情况使用默认值no。在Redis2.8以前，从节点向主节点发送sync命令请求同步数据，此时的同步方式是全量复制；在Redis2.8及以后，从节点可以发送psync命令请求同步数据，此时根据主从节点当前状态的不同，同步方式可能是全量复制或部分复制。后文介绍以Redis2.8及以后版本为例。全量复制：用于初次复制或其他无法进行部分复制的情况，将主节点中的所有数据都发送给从节点，是一个非常重型的操作。部分复制：用于网络中断等情况后的复制，只将中断期间主节点执行的写命令发送给从节点，与全量复制相比更加高效。需要注意的是，如果网络中断时间过长，导致主节点没有能够完整地保存中断期间执行的写命令，则无法进行部分复制，仍使用全量复制。1. 全量复制Redis通过psync命令进行全量复制的过程如下：（1）从节点判断无法进行部分复制，向主节点发送全量复制的请求；或从节点发送部分复制的请求，但主节点判断无法进行全量复制；具体判断过程需要在讲述了部分复制原理后再介绍。（2）主节点收到全量复制的命令后，执行bgsave，在后台生成RDB文件，并使用一个缓冲区（称为复制缓冲区）记录从现在开始执行的所有写命令（3）主节点的bgsave执行完成后，将RDB文件发送给从节点；，将数据库状态更新至主节点执行bgsave时的数据库状态（4）主节点将前述复制缓冲区中的所有写命令发送给从节点，从节点执行这些写命令，将数据库状态更新至主节点的最新状态（5）如果从节点开启了AOF，则会触发bgrewriteaof的执行，从而保证AOF文件更新至主节点的最新状态下面是执行全量复制时，主从节点打印的日志；可以看出日志内容与上述步骤是完全对应的。主节点的打印日志如下：从节点打印日志如下图所示：其中，有几点需要注意：从节点接收了来自主节点的89260个字节的数据；从节点在载入主节点的数据之前要先将老数据清除；从节点在同步完数据后，调用了bgrewriteaof。通过全量复制的过程可以看出，全量复制是非常重型的操作：（1）主节点通过bgsave命令fork子进程进行RDB持久化，该过程是非常消耗CPU、内存(页表复制)、硬盘IO的；关于bgsave的性能问题，可以参考 （2）主节点通过网络将RDB文件发送给从节点，对主从节点的带宽都会带来很大的消耗（3）从节点清空老数据、载入新RDB文件的过程是阻塞的，无法响应客户端的命令；如果从节点执行bgrewriteaof，也会带来额外的消耗2. 部分复制由于全量复制在主节点数据量较大时效率太低，因此Redis2.8开始提供部分复制，用于处理网络中断时的数据同步。部分复制的实现，依赖于三个重要的概念：主节点和从节点分别维护一个复制偏移量（offset），代表的是；主节点每次向从节点传播N个字节数据时，主节点的offset增加N；从节点每次收到主节点传来的N个字节数据时，从节点的offset增加N。offset用于判断主从节点的数据库状态是否一致：如果二者offset相同，则一致；如果offset不同，则不一致，此时可以根据两个offset找出从节点缺少的那部分数据。例如，如果主节点的offset是1000，而从节点的offset是500，那么部分复制就需要将offset为501-1000的数据传递给从节点。而offset为501-1000的数据存储的位置，就是下面要介绍的复制积压缓冲区。复制积压缓冲区是由主节点维护的、固定长度的、先进先出(FIFO)队列，默认大小1MB；当主节点开始有从节点时创建，其作用是备份主节点最近发送给从节点的数据。注意，无论主节点有一个还是多个从节点，都只需要一个复制积压缓冲区。在命令传播阶段，主节点除了将写命令发送给从节点，还会发送一份给复制积压缓冲区，作为写命令的备份；除了存储写命令，复制积压缓冲区中还存储了其中的每个字节对应的复制偏移量（offset）。由于复制积压缓冲区定长且是先进先出，所以它保存的是主节点最近执行的写命令；时间较早的写命令会被挤出缓冲区。由于该缓冲区长度固定且有限，因此可以备份的写命令也有限，当主从节点offset的差距过大超过缓冲区长度时，将无法执行部分复制，只能执行全量复制。反过来说，为了提高网络中断时部分复制执行的概率，可以根据需要增大复制积压缓冲区的大小(通过配置repl-backlog-size)；例如如果网络中断的平均时间是60s，而主节点平均每秒产生的写命令(特定协议格式)所占的字节数为100KB，则复制积压缓冲区的平均需求为6MB，保险起见，可以设置为12MB，来保证绝大多数断线情况都可以使用部分复制。从节点将offset发送给主节点后，主节点根据offset和缓冲区大小决定能否执行部分复制：如果offset偏移量之后的数据，仍然都在复制积压缓冲区里，则执行部分复制；如果offset偏移量之后的数据已不在复制积压缓冲区中（数据已被挤出），则执行全量复制。每个Redis节点(无论主从)，在启动时都会自动生成一个随机ID(每次启动都不一样)，由40个随机的十六进制字符组成；runid用来唯一识别一个Redis节点。通过info Server命令，可以查看节点的runid：主从节点初次复制时，主节点将自己的runid发送给从节点，从节点将这个runid保存起来；当断线重连时，从节点会将这个runid发送给主节点；主节点根据runid判断能否进行部分复制：如果从节点保存的runid与主节点现在的runid相同，说明主从节点之前同步过，主节点会继续尝试使用部分复制(到底能不能部分复制还要看offset和复制积压缓冲区的情况)；如果从节点保存的runid与主节点现在的runid不同，说明从节点在断线前同步的Redis节点并不是当前的主节点，只能进行全量复制。3. psync命令的执行在了解了复制偏移量、复制积压缓冲区、节点运行id之后，本节将介绍psync命令的参数和返回值，从而说明psync命令执行过程中，主从节点是如何确定使用全量复制还是部分复制的。psync命令的执行过程可以参见下图（图片来源：《Redis设计与实现》）：（1）首先，从节点根据当前状态，决定如何调用psync命令：如果从节点之前未执行过slaveof或最近执行了slaveof no one，则从节点发送命令为psync ? -1，向主节点请求全量复制；如果从节点之前执行了slaveof，则发送命令为psync <runid> <offset>，其中runid为上次复制的主节点的runid，offset为上次复制截止时从节点保存的复制偏移量。（2）主节点根据收到的psync命令，及当前服务器状态，决定执行全量复制还是部分复制：如果主节点版本低于Redis2.8，则返回-ERR回复，此时从节点重新发送sync命令执行全量复制；如果主节点版本够新，且runid与从节点发送的runid相同，且从节点发送的offset之后的数据在复制积压缓冲区中都存在，则回复+CONTINUE，表示将进行部分复制，从节点等待主节点发送其缺少的数据即可；如果主节点版本够新，但是runid与从节点发送的runid不同，或从节点发送的offset之后的数据已不在复制积压缓冲区中(在队列中被挤出了)，则回复+FULLRESYNC <runid> <offset>，表示要进行全量复制，其中runid表示主节点当前的runid，offset表示主节点当前的offset，从节点保存这两个值，以备使用。4. 部分复制演示在下面的演示中，网络中断几分钟后恢复，断开连接的主从节点进行了部分复制；为了便于模拟网络中断，本例中的主从节点在局域网中的两台机器上。网络中断一段时间后，主节点和从节点都会发现失去了与对方的连接（关于主从节点对超时的判断机制，后面会有说明）；此后，从节点便开始执行对主节点的重连，由于此时网络还没有恢复，重连失败，从节点会一直尝试重连。主节点日志如下：从节点日志如下：网络恢复后，从节点连接主节点成功，并请求进行部分复制，主节点接收请求后，二者进行部分复制以同步数据。主节点日志如下：从节点日志如下：在命令传播阶段，除了发送写命令，主从节点还维持着心跳机制：PING和REPLCONF ACK。心跳机制对于主从复制的超时判断、数据安全等有作用。1.主->从：PING每隔指定的时间，，这个PING命令的作用，主要是为了让从节点进行超时判断。PING发送的频率由repl-ping-slave-period参数控制，单位是秒，默认值是10s。关于该PING命令究竟是由主节点发给从节点，还是相反，有一些争议；因为在Redis的官方文档中，对该参数的注释中说明是从节点向主节点发送PING命令，如下图所示：但是根据该参数的名称(含有ping-slave)，以及代码实现，我认为该PING命令是主节点发给从节点的。相关代码如下：2. 从->主：REPLCONF ACK在命令传播阶段，频率是每秒1次；命令格式为：REPLCONF ACK {offset}，其中offset指从节点保存的复制偏移量。REPLCONF ACK命令的作用包括：（1）实时监测主从节点网络状态：该命令会被主节点用于复制超时的判断。此外，在主节点中使用info Replication，可以看到其从节点的状态中的lag值，代表的是主节点上次收到该REPLCONF ACK命令的时间间隔，在正常情况下，该值应该是0或1，如下图所示：（2）检测命令丢失：从节点发送了自身的offset，主节点会与自己的offset对比，如果从节点数据缺失（如网络丢包），主节点会推送缺失的数据（这里也会利用复制积压缓冲区）。（3）辅助保证从节点的数量和延迟：Redis主节点中使用min-slaves-to-write和min-slaves-max-lag参数，来保证主节点在不安全的情况下不会执行写命令；所谓不安全，是指从节点数量太少，或延迟过高。例如min-slaves-to-write和min-slaves-max-lag分别是3和10，含义是如果从节点数量小于3个，或所有从节点的延迟值都大于10s，则主节点拒绝执行写命令。而这里从节点延迟值的获取，就是通过主节点接收到REPLCONF ACK命令的时间来判断的，即前面所说的info Replication中的lag值。1. 读写分离及其中的问题在主从复制基础上实现的读写分离，可以实现Redis的读负载均衡：由主节点提供写服务，由一个或多个从节点提供读服务（多个从节点既可以提高数据冗余程度，也可以最大化读负载能力）；在读负载较大的应用场景下，可以大大提高Redis服务器的并发量。下面介绍在使用Redis读写分离时，需要注意的问题。前面已经讲到，由于主从复制的命令传播是异步的，延迟与数据的不一致不可避免。如果应用对数据不一致的接受程度程度较低，可能的优化措施包括：优化主从节点之间的网络环境（如在同机房部署）；监控主从节点延迟（通过offset）判断，如果从节点延迟过大，通知应用不再通过该从节点读取数据；使用集群同时扩展写负载和读负载等。在命令传播阶段以外的其他情况下，从节点的数据不一致可能更加严重，例如连接在数据同步阶段，或从节点失去与主节点的连接时等。从节点的slave-serve-stale-data参数便与此有关：它控制这种情况下从节点的表现；如果为yes（默认值），则从节点仍能够响应客户端的命令，如果为no，则从节点只能响应info、slaveof等少数命令。该参数的设置与应用对数据一致性的要求有关；如果对数据一致性要求很高，则应设置为no。在单机版Redis中，存在两种删除策略：惰性删除：服务器不会主动删除数据，只有当客户端查询某个数据时，服务器判断该数据是否过期，如果过期则删除。定期删除：服务器执行定时任务删除过期数据，但是考虑到内存和CPU的折中（删除会释放内存，但是频繁的删除操作对CPU不友好），该删除的频率和执行时间都受到了限制。在主从复制场景下，为了主从节点的数据一致性，从节点不会主动删除数据，而是由主节点控制从节点中过期数据的删除。由于主节点的惰性删除和定期删除策略，都不能保证主节点及时对过期数据执行删除操作，因此，当客户端通过Redis从节点读取数据时，很容易读取到已经过期的数据。Redis 3.2中，从节点在读取数据时，增加了对数据是否过期的判断：如果该数据已过期，则不返回给客户端；将Redis升级到3.2可以解决数据过期问题。在没有使用哨兵的读写分离场景下，应用针对读和写分别连接不同的Redis节点；当主节点或从节点出现问题而发生更改时，需要及时修改应用程序读写Redis数据的连接；连接的切换可以手动进行，或者自己写监控程序进行切换，但前者响应慢、容易出错，后者实现复杂，成本都不算低。在使用读写分离之前，可以考虑其他方法增加Redis的读负载能力：如尽量优化主节点（减少慢查询、减少持久化等其他情况带来的阻塞等）提高负载能力；使用Redis集群同时提高读负载能力和写负载能力等。如果使用读写分离，可以使用哨兵，使主从节点的故障切换尽可能自动化，并减少对应用程序的侵入。2. 复制超时问题主从节点复制超时是导致复制中断的最重要的原因之一，本小节单独说明超时问题，下一小节说明其他会导致复制中断的问题。在复制连接建立过程中及之后，主从节点都有机制判断连接是否超时，其意义在于：（1）如果主节点判断连接超时，其会释放相应从节点的连接，从而释放各种资源，否则无效的从节点仍会占用主节点的各种资源（输出缓冲区、带宽、连接等）；此外连接超时的判断可以让主节点更准确的知道当前有效从节点的个数，有助于保证数据安全（配合前面讲到的min-slaves-to-write等参数）。（2）如果从节点判断连接超时，则可以及时重新建立连接，避免与主节点数据长期的不一致。主从复制超时判断的核心，在于repl-timeout参数，该参数规定了超时时间的阈值（默认60s），对于主节点和从节点同时有效；主从节点触发超时的条件分别如下：（1）主节点：每秒1次调用复制定时函数replicationCron()，在其中判断当前时间距离上次收到各个从节点REPLCONF ACK的时间，是否超过了repl-timeout值，如果超过了则释放相应从节点的连接。（2）从节点：从节点对超时的判断同样是在复制定时函数中判断，基本逻辑是：如果当前处于连接建立阶段，且距离上次收到主节点的信息的时间已超过repl-timeout，则释放与主节点的连接；如果当前处于数据同步阶段，且收到主节点的RDB文件的时间超时，则停止数据同步，释放连接；如果当前处于命令传播阶段，且距离上次收到主节点的PING命令或数据的时间已超过repl-timeout值，则释放与主节点的连接。主从节点判断连接超时的相关源代码如下：下面介绍与复制阶段连接超时有关的一些实际问题：（1）数据同步阶段：在主从节点进行全量复制bgsave时，主节点需要首先fork子进程将当前数据保存到RDB文件中，然后再将RDB文件通过网络传输到从节点。如果RDB文件过大，主节点在fork子进程+保存RDB文件时耗时过多，可能会导致从节点长时间收不到数据而触发超时；此时从节点会重连主节点，然后再次全量复制，再次超时，再次重连……这是个悲伤的循环。为了避免这种情况的发生，除了注意Redis单机数据量不要过大，另一方面就是适当增大repl-timeout值，具体的大小可以根据bgsave耗时来调整。（2）命令传播阶段：如前所述，在该阶段主节点会向从节点发送PING命令，频率由repl-ping-slave-period控制；该参数应明显小于repl-timeout值(后者至少是前者的几倍)。否则，如果两个参数相等或接近，网络抖动导致个别PING命令丢失，此时恰巧主节点也没有向从节点发送数据，则从节点很容易判断超时。（3）慢查询导致的阻塞：如果主节点或从节点执行了一些慢查询（如keys *或者对大数据的hgetall等），导致服务器阻塞；阻塞期间无法响应复制连接中对方节点的请求，可能导致复制超时。3. 复制中断问题主从节点超时是复制中断的原因之一，除此之外，还有其他情况可能导致复制中断，其中最主要的是复制缓冲区溢出问题。前面曾提到过，在全量复制阶段，主节点会将执行的写命令放到复制缓冲区中，该缓冲区存放的数据包括了以下几个时间段内主节点执行的写命令：bgsave生成RDB文件、RDB文件由主节点发往从节点、从节点清空老数据并载入RDB文件中的数据。当主节点数据量较大，或者主从节点之间网络延迟较大时，可能导致该缓冲区的大小超过了限制，此时主节点会断开与从节点之间的连接；这种情况可能引起全量复制->复制缓冲区溢出导致连接中断->重连->全量复制->复制缓冲区溢出导致连接中断……的循环。复制缓冲区的大小由client-output-buffer-limit slave {hard limit} {soft limit} {soft seconds}配置，默认值为client-output-buffer-limit slave 256MB 64MB 60，其含义是：如果buffer大于256MB，或者连续60s大于64MB，则主节点会断开与该从节点的连接。该参数是可以通过config set命令动态配置的（即不重启Redis也可以生效）。当复制缓冲区溢出时，主节点打印日志如下所示：4. 各场景下复制的选择及优化技巧在介绍了Redis复制的种种细节之后，现在我们可以来总结一下，在下面常见的场景中，何时使用部分复制，以及需要注意哪些问题。此时全量复制不可避免，但仍有几点需要注意：如果主节点的数据量较大，应该尽量避开流量的高峰期，避免造成阻塞；如果有多个从节点需要建立对主节点的复制，可以考虑将几个从节点错开，避免主节点带宽占用过大。此外，如果从节点过多，也可以调整主从复制的拓扑结构，由一主多从结构变为树状结构（中间的节点既是其主节点的从节点，也是其从节点的主节点）；但使用树状结构应该谨慎：虽然主节点的直接从节点减少，降低了主节点的负担，但是多层从节点的延迟增大，数据一致性变差；且结构复杂，维护相当困难。主节点重启可以分为两种情况来讨论，一种是故障导致宕机，另一种则是有计划的重启。主节点宕机重启后，runid会发生变化，因此不能进行部分复制，只能全量复制。实际上在主节点宕机的情况下，应进行故障转移处理，将其中的一个从节点升级为主节点，其他从节点从新的主节点进行复制；且故障转移应尽量的自动化，后面文章将要介绍的哨兵便可以进行自动的故障转移。在一些场景下，可能希望对主节点进行重启，例如主节点内存碎片率过高，或者希望调整一些只能在启动时调整的参数。如果使用普通的手段重启主节点，会使得runid发生变化，可能导致不必要的全量复制。为了解决这个问题，Redis提供了debug reload的重启方式：避免了全量复制。如下图所示，debug reload重启后runid和offset都未受影响：但debug reload是一柄双刃剑：它会清空当前内存中的数据，重新从RDB文件中加载，这个过程会导致主节点的阻塞，因此也需要谨慎。从节点宕机重启后，其保存的主节点的runid会丢失，因此即使再次执行slaveof，也无法进行部分复制。如果主从节点之间出现网络问题，造成短时间内网络中断，可以分为多种情况讨论。第一种情况：网络问题时间极为短暂，只造成了短暂的丢包，主从节点都没有判定超时（未触发repl-timeout）；此时只需要通过REPLCONF ACK来补充丢失的数据即可。第二种情况：网络问题时间很长，主从节点判断超时（触发了repl-timeout），且丢失的数据过多，超过了复制积压缓冲区所能存储的范围；此时主从节点无法进行部分复制，只能进行全量复制。为了尽可能避免这种情况的发生，应该根据实际情况适当调整复制积压缓冲区的大小；此外及时发现并修复网络中断，也可以减少全量复制。第三种情况：介于前述两种情况之间，主从节点判断超时，且丢失的数据仍然都在复制积压缓冲区中；此时主从节点可以进行部分复制。5. 复制相关的配置这一节总结一下与复制有关的配置，说明这些配置的作用、起作用的阶段，以及配置方法等；通过了解这些配置，一方面加深对Redis复制的了解，另一方面掌握这些配置的方法，可以优化Redis的使用，少走坑。配置大致可以分为主节点相关配置、从节点相关配置以及与主从节点都有关的配置，下面分别说明。首先介绍最特殊的配置，它决定了该节点是主节点还是从节点：1)   slaveof <masterip> <masterport>：Redis启动时起作用；作用是建立复制关系，开启了该配置的Redis服务器在启动后成为从节点。该注释默认注释掉，即Redis服务器默认都是主节点。2)   repl-timeout 60：与各个阶段主从节点连接超时判断有关，见前面的介绍。1)   repl-diskless-sync no：作用于全量复制阶段，控制主节点是否使用diskless复制（无盘复制）。所谓diskless复制，是指在全量复制时，主节点不再先把数据写入RDB文件，而是直接写入slave的socket中，整个过程中不涉及硬盘；diskless复制在磁盘IO很慢而网速很快时更有优势。需要注意的是，截至Redis3.0，diskless复制处于实验阶段，默认是关闭的。2)   repl-diskless-sync-delay 5：该配置作用于全量复制阶段，当主节点使用diskless复制时，该配置决定主节点向从节点发送之前停顿的时间，单位是秒；只有当diskless复制打开时有效，默认5s。之所以设置停顿时间，是基于以下两个考虑：(1)向slave的socket的传输一旦开始，新连接的slave只能等待当前数据传输结束，才能开始新的数据传输 (2)多个从节点有较大的概率在短时间内建立主从复制。3)   client-output-buffer-limit slave 256MB 64MB 60：与全量复制阶段主节点的缓冲区大小有关，见前面的介绍。4)   repl-disable-tcp-nodelay no：与命令传播阶段的延迟有关，见前面的介绍。5)   masterauth <master-password>：与连接建立阶段的身份验证有关，见前面的介绍。6)   repl-ping-slave-period 10：与命令传播阶段主从节点的超时判断有关，见前面的介绍。7)   repl-backlog-size 1mb：复制积压缓冲区的大小，见前面的介绍。8)   repl-backlog-ttl 3600：当主节点没有从节点时，复制积压缓冲区保留的时间，这样当断开的从节点重新连进来时，可以进行全量复制；默认3600s。如果设置为0，则永远不会释放复制积压缓冲区。9)   min-slaves-to-write 3与min-slaves-max-lag 10：规定了主节点的最小从节点数目，及对应的最大延迟，见前面的介绍。1)   slave-serve-stale-data yes：与从节点数据陈旧时是否响应客户端命令有关，见前面的介绍。2)   slave-read-only yes：从节点是否只读；默认是只读的。由于从节点开启写操作容易导致主从节点的数据不一致，因此该配置尽量不要修改。6. 单机内存大小限制在  一文中，讲到了fork操作对Redis单机内存大小的限制。实际上在Redis的使用中，限制单机内存大小的因素非常之多，下面总结一下在主从复制中，单机内存过大可能造成的影响：（1）切主：当主节点宕机时，一种常见的容灾策略是将其中一个从节点提升为主节点，并将其他从节点挂载到新的主节点上，此时这些从节点只能进行全量复制；如果Redis单机内存达到10GB，一个从节点的同步时间在几分钟的级别；如果从节点较多，恢复的速度会更慢。如果系统的读负载很高，而这段时间从节点无法提供服务，会对系统造成很大的压力。（2）从库扩容：如果访问量突然增大，此时希望增加从节点分担读负载，如果数据量过大，从节点同步太慢，难以及时应对访问量的暴增。（3）缓冲区溢出：（1）和（2）都是从节点可以正常同步的情形（虽然慢），但是如果数据量过大，导致全量复制阶段主节点的复制缓冲区溢出，从而导致复制中断，则主从节点的数据同步会全量复制->复制缓冲区溢出导致复制中断->重连->全量复制->复制缓冲区溢出导致复制中断……的循环。（4）超时：如果数据量过大，全量复制阶段主节点fork+保存RDB文件耗时过大，从节点长时间接收不到数据触发超时，主从节点的数据同步同样可能陷入全量复制->超时导致复制中断->重连->全量复制->超时导致复制中断……的循环。此外，主节点单机内存除了绝对量不能太大，其占用主机内存的比例也不应过大：最好只使用50%-65%的内存，留下30%-45%的内存用于执行bgsave命令和创建复制缓冲区等。7. info Replication在Redis客户端通过info Replication可以查看与复制相关的状态，对于了解主从节点的当前状态，以及解决出现的问题都会有帮助。主节点：从节点：对于从节点，上半部分展示的是其作为从节点的状态，从connectd_slaves开始，展示的是其作为潜在的主节点的状态。info Replication中展示的大部分内容在文章中都已经讲述，这里不再详述。下面回顾一下本文的主要内容：1、主从复制的作用：宏观的了解主从复制是为了解决什么样的问题，即数据冗余、故障恢复、读负载均衡等。2、主从复制的操作：即slaveof命令。3、主从复制的原理：主从复制包括了连接建立阶段、数据同步阶段、命令传播阶段；其中数据同步阶段，有全量复制和部分复制两种数据同步方式；命令传播阶段，主从节点之间有PING和REPLCONF ACK命令互相进行心跳检测。4、应用中的问题：包括读写分离的问题（数据不一致问题、数据过期问题、故障切换问题等）、复制超时问题、复制中断问题等，然后总结了主从复制相关的配置，其中repl-timeout、client-output-buffer-limit slave等对解决Redis主从复制中出现的问题可能会有帮助。主从复制虽然解决或缓解了数据冗余、故障恢复、读负载均衡等问题，但其缺陷仍很明显：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制；这些问题的解决，需要哨兵和集群的帮助，我将在后面的文章中介绍，欢迎关注。《Redis开发与运维》《Redis设计与实现》《Redis实战》https://blog.csdn.net/qbw2010/article/details/50496982https://mp.weixin.qq.com/s?__biz=MzIxMzEzMjM5NQ==&mid=2651029484&idx=1&sn=5882f4c7c390a0a0e4f6dfd872e203b5&chksm=8c4caae8bb3b23fe77909e307d45a071186f55069e5207602c61383eab573885615c1d835904&mpshare=1&scene=1&srcid=0327SokqtxEY3WojWNDMHLYl#rd\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"]}
{"title": "计算机专业太难不适合女生学？来看 N 多小姐姐的回应 - 文章 - 伯乐在线", "tag": ["职场", " 4 评论 ", "程序员", "计算机专业"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": " 4 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n高考结束了，填志愿选专业的时候也要来了。最近我们微博收到一个私信求助：在 微博发布后，有位小姐姐还感叹：@刘不刘二小姐：没想到“计算机太难不适合女生学”的观点五年前我上大学的时候有，现在都火成这样了还有[二哈]很多关注我们的小姐姐都冒泡留言，鼓励那位求助的女生。汇总如下：@澈海情深：计算机女生出来说一句，现在干啥都挺难的。学计算机也没有想象中那么恐怖。感兴趣就学呗。@眠眠阿卷：选吧，学计算机又不是以后当码农，计算机是个工具，你学了计算机，以后去哪里再读其他专业都受欢迎@J家蠢萌痴汉夏：怎么会，我就毕业了呀，毕业还是简单的，只要好好听课，也不会挂科的[二哈] 当年高考结束填志愿，五个全是计算机第一顺位，🙊回过头想想也是有勇气啊@凃小斐：老子就是女孩子，毕业的时候专业第一的成绩保送985研究生，谁跟你说女孩子不适合学计算机的出来我打死他@于梦杰呀：计算机系女生表示难确实是难，有时还会感觉痛苦，但是只要你好好学肯定是能学好的@enchantereyes：喜欢就选。首先再菜毕业也不会难，另外学一行跟干一行是两码事。难得有想学的东西，不试试不会不甘心吗？@geekInfo：我也是计算机出来的女生。最初的专业是应用数学选修经济，学了一学期不开心反而喜欢计算机课就转了专业。读大学之前一点编程基础也没有，也不就这么顺利研究生毕业了。毕业成绩年级第二，文凭还没到手就被公司定下来了，到现在一直很喜欢这职业，庆幸当初转了专业，要学自己感兴趣的。@月光少爷金：时代不一样了，女程序猿不知道多受欢迎。况且，不学计算机，学统计将来做策略也不错呀@芒果很忙busybusy：学吧，入门没有想象中那么难的，我就是程序媛，IT公司女生少，环境相对比较单纯，是非也少，女生挺受宠的@茶杯茶茶茶：计算机有脑子的都能学，很好学的，相比于其他的专业，至少很多东西可以直接上手及时反馈，网上教程一大堆，只有计算机方面的可以。@翡翠梦境里睡觉的猫：有兴趣就可以选，当年报志愿之前也有人再三强调学计算机累（倒是没说女生不适合，现在想来在当时已经难得），然而我高中学了一点编程觉得有趣，于是选了，于是一路计算机好多年仍然觉得很有趣其他几个男生的留言：@MSP-GawainAntarx：难的不是计算机科学，而且怎么让自己抛弃“女生不适合学计算机”的刻板印象@mtedrrqcmws2017：1. 年轻女程序员在应聘过程中不但不会被歧视，反而会被有所偏袒，因为公司（尤其是大公司）普遍男生太多，需要女生来平衡工作环境。2. 现代编程语言已经被高度抽象，脱离硬件，倒更加靠近“技术设计”，入门并非男式，比如前端，手机app等。如果以后还有人和你说「计算机专业不适合女生」之类的，可以把本文发给他们看，让他们看看 IT 行业小姐姐们是如何说的。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/06/cebf98169b4fd1e38a35c3537129ceaa.jpg"]}
{"title": "8 个基本的 Docker 容器管理命令 - 文章 - 伯乐在线", "tag": ["IT技术", "Docker", "Linux", "容器"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n利用这 8 个命令可以学习 Docker 容器的基本管理方式。这是一个为 Docker 初学者准备的，带有示范命令输出的指南。在这篇文章中，我们将带你学习 8 个基本的 Docker 容器命令，它们操控着 Docker 容器的基本活动，例如 运行run、 列举list、 停止stop、 查看历史纪录logs、 删除delete 等等。如果你对 Docker 的概念很陌生，推荐你看看我们的 ，来了解 Docker 的基本内容以及  在 Linux 上安装 Docker。 现在让我们赶快进入要了解的命令：众所周知，Docker 容器只是一个运行于宿主操作系统host OS上的应用进程，所以你需要一个镜像来运行它。Docker 镜像以进程的方式运行时就叫做 Docker 容器。你可以加载本地 Docker 镜像，也可以从 Docker Hub 上下载。Docker Hub 是一个提供公有和私有镜像来进行拉取pull操作的集中仓库。官方的 Docker Hub 位于 。 当你指示 Docker 引擎运行容器时，它会首先搜索本地镜像，如果没有找到，它会从 Docker Hub 上拉取相应的镜像。让我们运行一个 Apache web 服务器的 Docker 镜像，比如 httpd 进程。你需要运行  命令。旧的命令为 ， 但后来 Docker 添加了子命令部分，所以新版本支持下列命令：Docker 的  命令将镜像名作为强制参数，另外还有很多可选参数。常用的参数有：：从当前 shell 脱离容器：绑定容器的端口 Y 到宿主机的端口 X：命名你的容器。如果未指定，它将被赋予随机生成的名字：当启动容器时传递环境编辑及其值通过以上输出你可以看到，我们将  作为镜像名来运行容器。接着，本地镜像没有找到，Docker 引擎从 Docker Hub 拉取了它。注意，它下载了镜像 ， 其中  后面跟着版本号。如果你需要运行特定版本的容器，你可以在镜像名后面注明版本名。如果不提供版本名，Docker 引擎会自动拉取最新的版本。输出的最后一行显示了你新运行的 httpd 容器的唯一 ID。现在，你的容器已经运行起来了，你可能想要确认这一点，或者你想要列出你的机器上运行的所有容器。你可以使用  命令。在旧的 Docker 版本中，对应的命令为 。列出的结果是按列显示的。每一列的值分别为：Container ID ：一开始的几个字符对应你的容器的唯一 IDImage ：你运行容器的镜像名Command ：容器启动后运行的命令Created ：创建时间Status ：容器当前状态Ports ：与宿主端口相连接的端口信息Names ：容器名（如果你没有命名你的容器，那么会随机创建）在第一步我们使用了  参数来将容器，在它一开始运行的时候，就从当前的 shell 中脱离出来。在这种情况下，我们不知道容器里面发生了什么。所以为了查看容器的历史纪录，Docker 提供了  命令。它采用容器名称或 ID 作为参数。这里我使用了容器名称作为参数。你可以看到在我们的 httpd 容器中与 Apache 相关的历史纪录。容器是一个使用宿主资源来运行的进程。这样，你可以在宿主系统的进程表中定位容器的进程。让我们在宿主系统上确定容器进程。Docker 使用著名的  命令作为子命令的名称，来查看容器产生的进程。它采用容器的名称或 ID 作为参数。在旧版本的 Docker 中，只可运行  命令。在新版本中， 和  命令都可以生效。在第一个输出中，列出了容器产生的进程的列表。它包含了所有细节，包括用户号uid、进程号pid，父进程号ppid、开始时间、命令，等等。这里所有的进程号你都可以在宿主的进程表里搜索到。这就是我们在第二个命令里做得。这证明了容器确实是宿主系统中的进程。只需要  命令！同样，它采用容器名称或 ID 作为参数。现在我们停止了我们的容器，这时如果我们使用  命令，它将不会出现在列表中。所以，在这种情况下，如果想要查看停止的或不活动的容器，你需要在  命令里同时使用  参数。有了  参数，现在我们可以查看已停止的容器。注意这些容器的状态被标注为 已退出exited。既然容器只是一个进程，那么用“退出”比“停止”更合适！现在，我们来启动这个已停止的容器。这和运行一个容器有所区别。当你运行一个容器时，你将启动一个全新的容器。当你启动一个容器时，你将开始一个已经停止并保存了当时运行状态的容器。它将以停止时的状态重新开始运行。我们使用  命令来移除容器。你不可以移除运行中的容器。移除之前需要先停止容器。你可以使用  参数搭配  命令来强制移除容器，但并不推荐这么做。你看，一旦移除了容器，即使再使用  命令也查看不到容器了。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/06/91d1e9a10762cf7191f39f8e66ebefa7.png"]}
{"title": "RabbitMQ 发布订阅实战：实现延时重试队列 - 文章 - 伯乐在线", "tag": ["开发", "RabbitMQ"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nRabbitMQ是一款使用Erlang开发的开源消息队列。本文假设读者对RabbitMQ是什么已经有了基本的了解，如果你还不知道它是什么以及可以用来做什么，建议先从官网的  入门教程开始学习。本文将会讲解如何使用RabbitMQ实现延时重试和失败消息队列，实现可靠的消息消费，消费失败后，自动延时将消息重新投递，当达到一定的重试次数后，将消息投递到失败消息队列，等待人工介入处理。在这里我会带领大家一步一步的实现一个带有失败重试功能的发布订阅组件，使用该组件后可以非常简单的实现消息的发布订阅，在进行业务开发的时候，业务开发人员可以将主要精力放在业务逻辑实现上，而不需要花费时间去理解RabbitMQ的一些复杂概念。概要我们将会实现如下功能结合RabbitMQ的Topic模式和Work Queue模式实现生产方产生消息，消费方按需订阅，消息投递到消费方的队列之后，多个worker同时对消息进行消费结合RabbitMQ的  和  实现消息的延时重试功能消息达到最大重试次数之后，将其投递到失败队列，等待人工介入处理bug后，重新将其加入队列消费具体流程见下图生产者发布消息到主Exchange主Exchange根据Routing Key将消息分发到对应的消息队列多个消费者的worker进程同时对队列中的消息进行消费，因此它们之间采用“竞争”的方式来争取消息的消费消息消费后，不管成功失败，都要返回ACK消费确认消息给队列，避免消息消费确认机制导致重复投递，同时，如果消息处理成功，则结束流程，否则进入重试阶段如果重试次数小于设定的最大重试次数（3次），则将消息重新投递到Retry Exchange的重试队列重试队列不需要消费者直接订阅，它会等待消息的有效时间过期之后，重新将消息投递给Dead Letter Exchange，我们在这里将其设置为主Exchange，实现延时后重新投递消息，这样消费者就可以重新消费消息如果三次以上都是消费失败，则认为消息无法被处理，直接将消息投递给Failed Exchange的Failed Queue，这时候应用可以触发报警机制，以通知相关责任人处理等待人工介入处理（解决bug）之后，重新将消息投递到主Exchange，这样就可以重新消费了技术实现 曾经说过Talk is cheap. Show me the code我分别用Java和PHP实现了本文所讲述的方案，读者可以通过参考代码以及本文中的基本步骤来更好的理解为了实现消息的延时重试和失败存储，我们需要创建三个Exchange来处理消息。 主Exchange，发布消息时发布到该Exchange 重试Exchange，消息处理失败时（3次以内），将消息重新投递给该Exchange 失败Exchange，超过三次重试失败后，消息投递到该Exchange所有的Exchange声明(declare)必须使用以下参数Java代码PHP代码在RabbitMQ的管理界面中，我们可以看到创建的三个Exchange消息发布时，使用方法，参数如下发布消息时，对于对象，其内容建议使用，同时消息需要标识以下属性Java代码PHP代码消息订阅的实现相对复杂一些，需要完成队列的声明以及队列和Exchange的绑定。对于每一个订阅消息的服务，都必须创建一个该服务对应的队列，将该队列绑定到关注的路由规则，这样之后，消息生产者将消息投递给Exchange之后，就会按照路由规则将消息分发到对应的队列供消费者消费了。消费服务需要declare三个队列 队列名称，格式符合  重试队列 失败队列是客户端自己对订阅的分类标识符，比如用户中心服务（服务名称ucenter），包含两个订阅：user和enterprise，这里两个订阅的队列名称就为 和，其对应的重试队列为 和。Declare队列时，参数规定规则如下对于重试队列，需要指定额外参数这里的两个header字段的含义是，在队列中延迟30s后，将该消息重新投递到对应的Exchange中Java代码PHP代码在RabbitMQ的管理界面中，Queues部分可以看到我们创建的三个队列查看队列的详细信息，我们可以看到  队列与其它两个队列的不同创建完队列之后，需要将队列与Exchange绑定（），不同队列需要绑定到之前创建的对应的Exchange上面绑定时，需要提供订阅的路由KEY，该路由KEY与消息发布时的路由KEY对应，区别是这里可以使用通配符同时订阅多种类型的消息。Java代码PHP代码在RabbitMQ的管理界面中，我们可以看到该队列与Exchange和routing-key的绑定关系使用  对消息进行消费的时候，需要注意下面参数消费端在消费消息时，需要从消息中获取消息被消费的次数，以此判断该消息处理失败时重试还是发送到失败队列。Java代码   PHP代码消息消费完成后，需要发送消费确认消息给服务端，使用方法Java代码PHP代码如果消息处理中出现异常，应该将该消息重新投递到重试Exchange，等待下次重试如果判断重试次数大于3次，仍然处理失败，则应该讲消息投递到失败Exchange，等待人工处理一定不要忘记ack消息，因为重试、失败都是通过将消息重新投递到重试、失败Exchange来实现的，如果忘记ack，则该消息在超时或者连接断开后，会重新被重新投递给消费者，如果消费者依旧无法处理，则会造成死循环。Java代码如果任务重试三次仍未成功，则会被投递到失败队列，这时候需要人工处理程序异常，处理完毕后，需要将消息重新投递到队列进行处理，这里唯一需要做的就是从失败队列订阅消息，然后获取到消息后，清空其头信息，然后重新投递到这个Exchange即可。Java代码PHP代码队列和Exchange以及发布订阅的关系我们就说完了，那么使用起来是什么效果呢？这里我们以Java代码为例总结使用RabbitMQ时，实现延时重试和失败队列的方式并不仅仅局限于本文中描述的方法，如果读者有更好的实现方案，欢迎拍砖，在这里我也只是抛砖引玉了。本文中讲述的方法还有很多优化空间，读者也可以试着去改进其实现方案，比如本文中使用了三个Exchagne，是否只使用一个Exchange也能实现本文中所讲述的功能。任选一种支付方式\n                        \n            \n                            \n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/11/a099bdc26462540c4ca8ac310b8a24b8.png"]}
{"title": "在 Linux 上复制和重命名文件 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\ncp 和 mv 之外，在 Linux 上有更多的复制和重命名文件的命令。试试这些命令或许会惊艳到你，并能节省一些时间。Linux 用户数十年来一直在使用简单的  和  命令来复制和重命名文件。这些命令是我们大多数人首先学到的，每天可能有数百万人在使用它们。但是还有其他技术、方便的方法和另外的命令，这些提供了一些独特的选项。首先，我们来思考为什么你想要复制一个文件。你可能需要在另一个位置使用同一个文件，或者因为你要编辑该文件而需要一个副本，并且希望确保备有便利的备份以防万一需要恢复原始文件。这样做的显而易见的方式是使用像  这样的命令。但是，如果你想复制大量的文件，那么这个策略可能就会变得很老。更好的选择是：在开始编辑之前，使用  创建所有要备份的文件的存档。使用  循环来使备份副本更容易。使用  的方式很简单。对于当前目录中的所有文件，你可以使用如下命令：对于一组可以用模式标识的文件，可以使用如下命令：在每种情况下，最终都会生成一个  文件，其中包含目录中的所有文件或扩展名为 .txt 的所有文件。一个简单的循环将允许你使用修改后的名称来制作备份副本：当你备份单个文件并且该文件恰好有一个长名称时，可以依靠使用  来补全文件名（在输入足够的字母以便唯一标识该文件后点击  键）并使用像这样的语法将  附加到副本的名字后。然后你有一个  和一个 。重命名文件的传统方法是使用  命令。该命令将文件移动到不同的目录，或原地更改其名称，或者同时执行这两个操作。但我们也有  命令来做重命名。使用  命令的窍门是习惯它的语法，但是如果你了解一些 Perl，你可能发现它并不棘手。有个非常有用的例子。假设你想重新命名一个目录中的文件，将所有的大写字母替换为小写字母。一般来说，你在 Unix 或 Linux 系统上找不到大量大写字母的文件，但你可以有。这里有一个简单的方法来重命名它们，而不必为它们中的每一个使用  命令。  告诉  命令将范围  中的任何字母更改为  中的相应字母。你也可以使用  来删除文件扩展名。也许你厌倦了看到带有 .txt 扩展名的文本文件。简单删除这些扩展名 —— 用一个命令。现在让我们想象一下，你改变了心意，并希望把这些扩展名改回来。没问题。只需修改命令。窍门是理解第一个斜杠前的  意味着“替代”。前两个斜线之间的内容是我们想要改变的东西，第二个斜线和第三个斜线之间是改变后的东西。所以， 表示文件名的结尾，我们将它改为 。你也可以更改文件名的其他部分。牢记  规则。在上面的例子中注意到，当我们在  中使用  时，我们用另一个名称替换名称的一部分。当我们使用  时，我们就是直译（将字符从一个范围替换为另一个范围）。现在有很多复制和重命名文件的方法。我希望其中的一些会让你在使用命令行时更愉快。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/05/77d80105fd15f2465894827e23cc4842.jpeg"]}
{"title": "工作 8 个月后，一名工程师竟然被机器解雇了 - 文章 - 伯乐在线", "tag": ["业界", "自动化"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nIbrahim Diallo 发表了一篇博客，描述了自己认真地工作却被“强大”的机器系统强制解雇的真实经历，并表示，事情发生的从始至终都没有人能够阻止它。Diallo 在文中描述，自己在某天上班时，发现门卡失效，当他找到主管时，又意外发现了自己已经被解雇的邮件，却不知道是谁发的：Diallo 随后来到工作岗位，发现自己的 Jira（项目与事务跟踪工具）账号被禁用，当他找经理重新启用账号时，系统却不允许经理进行重新启用的操作。Diallo 回到办公桌前，发现系统提示他重启电脑，但他知道重启后会导致数据丢失，因此并未进行此操作，可 Windows 电脑最后却自动重启了，导致几十万条记录丢失，Web 界面也不响应了。随后 Diallo 用他 CentOS 的机器黑进他的服务器去重启，调试，重启所有访问，然后重新处理所有数据。后来问题终于得到解决，谈到整件事情的起因时，Diallo 解释道：我的合同期限是三年，而我仅工作了八个月。原来在我被解雇之前，公司被一家更大的公司收购，而我正是在收购的过程中加入的。当时由于经理的疏忽，没有给我的合同续约，导致合同中止。而按照我们的系统设定，一旦员工合同中止的工作单发出后，系统就会接管一切。所有中止合同所需的工作单会自动发出，每个都会触发其他的工作单。于是就有了我的门卡失效，Windows 账号和 Jira 账号被禁用事情的发生，等等。我只能以新员工的方式被重新雇佣，意味着我得重新填写各种文件，设置银行卡账号，等联邦快递给我发送新的门卡。作者在文中将整个过程称为：自动化也许给我们的生活和办公带来许多便利，但当机器犯错误时，人必须能够干预。如若不能，可能就会出现上面作者描述的情况，甚至会导致更加严重的问题。想详细了解事件发生的读者可以查看作者的。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://wx1.sinaimg.cn/mw690/63918611gy1fsnj3dqw5ij20hj0cpn3g.jpg"]}
{"title": "在 Linux 上用 DNS 实现简单的负载均衡 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nDNS 轮询将多个服务器映射到同一个主机名，并没有为这里展示的魔法做更多的工作。如果你的后端服务器是由多台服务器构成的，比如集群化或者镜像的 Web 或者文件服务器，通过负载均衡器提供了单一的入口点。业务繁忙的大型电商在高端负载均衡器上花费了大量的资金，用它来执行各种各样的任务：代理、缓存、状况检查、SSL 处理、可配置的优先级、流量整形等很多任务。但是你并不需要做那么多工作的负载均衡器。你需要的是一个跨服务器分发负载的简单方法，它能够提供故障切换，并且不太在意它是否高效和完美。DNS 轮询和使用轮询的子域委派是实现这个目标的两种简单方法。DNS 轮询是将多台服务器映射到同一个主机名上，当用户访问  时多台服务器都可用于处理它们的请求，使用的就是这种方式。当你有多个子域或者你的服务器在地理上比较分散时，使用轮询的子域委派就比较有用。你有一个主域名服务器，而子域有它们自己的域名服务器。你的主域名服务器将所有的到子域的请求指向到它们自己的域名服务器上。这将提升响应时间，因为 DNS 协议会自动查找最快的链路。轮询和旅鸫鸟robins没有任何关系，据我相熟的图书管理员说，它最初是一个法语短语，、或者 。很久以前，法国政府官员以不分级的圆形、波浪线、或者直线形状来在请愿书上签字，以盖住原来的发起人。DNS 轮询也是不分级的，简单配置一个服务器列表，然后将请求转到每个服务器上。它并不做真正的负载均衡，因为它根本就不测量负载，也没有状况检查，因此如果一个服务器宕机，请求仍然会发送到那个宕机的服务器上。它的优点就是简单。如果你有一个小的文件或者 Web 服务器集群，想通过一个简单的方法在它们之间分散负载，那么 DNS 轮询很适合你。你所做的全部配置就是创建多条 A 或者 AAAA 记录，映射多台服务器到单个的主机名。这个 BIND 示例同时使用了 IPv4 和 IPv6 私有地址类：Dnsmasq 在  文件中保存 A 和 AAAA 记录：请注意这些示例都是很简化的，解析完全合格域名有多种方法，因此，关于如何配置 DNS 请自行学习。使用  命令去检查你的配置能否按预期工作。将  替换为你的域名服务器：它将同时显示出 IPv4 和 IPv6 的轮询记录。子域委派结合轮询要做的配置会更多，但是这样有一些好处。当你有多个子域或者地理位置比较分散的服务器时，就应该去使用它。它的响应时间更快，并且宕机的服务器不会去响应，因此客户端不会因为等待回复而被挂住。一个短的 TTL，比如 60 秒，就能帮你做到。这种方法需要多台域名服务器。在最简化的场景中，你需要一台主域名服务器和两个子域，每个子域都有它们自己的域名服务器。在子域服务器上配置你的轮询记录，然后在你的主域名服务器上配置委派。在主域名服务器上的 BIND 中，你至少需要两个额外的配置，一个区声明以及在区数据文件中的 A/AAAA 记录。主域名服务器中的委派应该像如下的内容：接下来的每台子域服务器上有它们自己的区文件。在这里它的关键点是每个服务器去返回它 IP 地址。在  中的区声明，所有的服务上都是一样的：然后数据文件也是相同的，除了那个 A/AAAA 记录使用的是各个服务器自己的 IP 地址。SOA 记录都指向到主域名服务器：接下来生成子域服务器上的轮询记录，方法和前面一样。现在你已经有了多个域名服务器来处理到你的子域的请求。再说一次，BIND 是很复杂的，做同一件事情它有多种方法，因此，给你留的家庭作业是找出适合你使用的最佳配置方法。在 Dnsmasq 中做子域委派很容易。在你的主域名服务器上的  文件中添加如下的行，去指向到子域的域名服务器：然后在子域的域名服务器上的  中配置轮询。获取配置方法的详细内容和帮助，请参考这些资源：通过来自 Linux 基金会和 edX 的免费课程  学习更多 Linux 的知识。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "为什么码农要了解业务？ - 文章 - 伯乐在线", "tag": ["职场", "程序员"], "goodNum": "1", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n 最近一位分析界的老前辈对我很无奈地摇摇头，“这帮程序员，不食人间烟火哪！”我也深有感触，全世界的码农都一个样。这让我想起了，同样也是他，在多年之前，对我提了警醒——要重视业务。从那之后，我一直狂奔在技术+业务的双修道路上。放在以前，码农这个族群一定是稀罕动物。但在今天，这个世界最不缺的应该就是码农了，未来最廉价的也将是码农。仅有泛泛一技，在未来并不吃香，因为那是要被机器人所取代的。这个世界，缺的是技术过硬又精通业务的工程师，缺的是真正能解决实际业务问题的人，缺的是复合型的人才。码农不是工程师，码农只是会写代码，只会明确需求和逻辑的情况下写代码。工程师则不一样，懂得用技术怎么解决实际业务问题，用技术驱动业务的发展。先来明确这个问题。业务是一个很实在的东西，看得见感受得到，接地气儿。业务就是我们所能理解和感受的世界，就是这个世界或者某个行业的运转逻辑、流程与现状，是结果表象，是能够被看见和感受的，也是内在本质，是能够被洞察和感知的。业务就是这个世界发生了什么，什么时候，谁参与，怎么发生，结果如何。业务就是什么时候，谁在哪里，买了什么东西，花了多少钱，用什么支付。业务就是这个行业怎么发展起来的，现状如何，未来趋势如何，用了什么技术，有什么企业，商业模式如何，盈利能力如何，目前主要面临什么问题，消费者有什么特点，等等。世界很复杂，单个细分行业的业务也很复杂。谈到这个，码农们一定有所不悦，“熟悉业务是需求分析师做的事，跟我们没有关系。”打个不恰当的比喻。有10个人经过一栋写字楼，突然从楼上掉下来几块砖头，砸中了9个人，其中就有7个码农，3个硕士，1个博士（原谅我又犯职业病，拿数据说话了）。而没被砸到的那个人，恰好因为了解到之前经常发生这样的事而绕道行走。如果你只会写代码，你不是不可替代的，而是可有可无的。因为这年头，会JAVA、C、Python的程序员，在大街上一抓一大把。现在已经开始提倡，编程从娃娃抓起了。10后都开始跟你抢饭碗了，你怕不怕？但话也不是那么极端，除非你的技术很牛逼，在国内或者某个行业内能够排上号的。但技术牛逼的人，也不是只是技术超群，还常常因为能够利用手中的技术解决某方面的业务问题，做了哪些突出的贡献。我们出来混，也是要拿成果说话的，做过什么项目，有什么价值。这种价值往往就是针对业务而说的。IT研发与业务需求方常常是一对冤家，常常因为一个业务功能实现争辩得耳红面赤。研发觉得这个功能很low，没什么技术含量，业务方却认为这个功能却很有用，需要花功夫做细做深做好。现实情况是，功能做出来了，却很难用，或者经常用不了，或者数据不对。研发想做点高大上的功能，业务方却认为太虚了，没什么用。（IT与业务方那点事就不多说了，大家都心知肚明~~）多年经验反复告诫我，鉴定一个功能是不是好功能，唯一的标准是看它能否支撑业务、改善业务、推动业务，也即应用效果。一个产品，只要有30%的功能，让业务用户用起来很爽，感觉帮助很大，就已经是一个不错的产品了。我们都认同，技术驱动业务。但我们不一定明白，正是由于业务的某些强烈需求，才推动技术的发展与落地。说这些，我是想说，作为技术人员，我们既要仰望星空，也要脚踏实地，既要追逐腾飞的技术，也要重视落地的业务。如果一个业务人员很懂技术，那将很可能是技术人员的灾难。因为那样的话，业务人员会很强势，又或者那样就没有技术人员什么事了。当然，也不难想象，一个真正懂看数据的测试人员，就好比一个真正懂用算法的业务人员一样难得。真实（而不是杜撰、模拟、伪造）、可量化、可被记录的数据一定会反映真实世界某方面的业务情形。而现实当中很多业务场景都可由数据体现出来。零售是业务场景最繁多且最贴近我们生活的行业，可以从中找到很多方便理解的例子。当你在一个酷热难耐的夏天上午10点，走进位于公司附近的全家便利店，使用微信支付，花了3.5元，买了一瓶无糖330ml摩登罐的可乐，而且刷会员卡攒了100积分，而收银员MM返回给了你一张POS单据，这时你所发生的这一切都已经通过收银记录在了全家的数据库里。更糟糕的是，店里的摄像头也已经把你在店里的一举一动录了下来了，转化成为一帧帧图像数据。这就是，业务数据化。店长通过数据分析发现，最近3.5元330ml摩登罐可乐的销量比上月增长了20%，而消费者中75%是20-35岁的男性，相比之下，300ml塑料瓶装的可乐销量却下滑40%。店长权衡比较了一下，300ml塑料瓶装可乐利润低，330ml摩登罐可乐目前更受年轻人欢迎，考虑到日渐增长的租金压力，做了一个大胆的决定——下架300ml塑料瓶装可乐，增加330ml摩登罐可乐的商品。（又拿数据说话了。）这就是，数据业务化。或者，数据驱动业务。当我开始接触一个行业时，我通常会花2-3周的时间去了解这个行业的业务，然后就大致清楚这个行业有什么样的数据，可以做哪方面的分析，解决什么问题。当遇到不好理解的分析结果时，我经常使用业务联想法，设身处地去体会结果所反映的业务场景是什么样的。这个说大了，就是如何看这个世界。每个人有每个人的方法论，每个人有每个人的世界观，每个人有每个人的逻辑思维。我们都知道，观念的转变是最难的，也有很多不确定性。有些人可能因为自己的切身体会一天就改变了之前几十年根深蒂固的看法，有些人任由三姑六婆苦口婆心地劝说就是不肯改变自己的择偶观，却有可能因为自己年岁渐大不断降低自己的标准。但最好也及早要形成科学的思考方法，帮助正确地理解这个世界。以“面-线-点”的方式可以较为全面、系统、深入地了解一个行业，然后是某个垂直领域，最后再到具体业务场景。佛系文化的流行，使得年轻一代降低对这个世界的关注度，一切都无所谓，一切都漠不关心。这个世界从来没有变好过，但我们每个人都是这个世界的匆匆过客，都是行走在自己的人生路上不断领略这个世界的美与丑。这世间的风景，这世间的悲欢离合，如果我们积极地探索与领悟，也不枉来这世间走一遭。保持好奇心，可以驱动我们的思考，强化我们的认知，丰富我们的内在。这是我想说的第二个方面。怀有好奇心，就会渐渐地敏锐观察这个世界，多问自己一些为什么。我家附近原来有个沃尔玛超市，现在地产商将它装修一番，引入了不少餐厅，刚开张不久，我就去那里吃饭，吃的是烤鸭，一个多两个月后，再去那里吃饭，发现有一半的餐厅已经关门了。在去地铁站的那条路上，每天人流如梭，一点点，即使到了深夜，依然有很多人在门口排队买奶茶。然而，仅仅隔了一个店铺的喜茶，做不下去，关门了。两三个月前又换成粉店，路转粉。每天下班路过时，发现店里顾客不到10个，门可罗雀。为什么每家一点点奶茶店门口，不管是什么时候都是很多人，他们是托儿还是真的顾客？因为喜欢新鲜，不喜欢在冰箱里存太多菜，且附近没有菜市场，所以常去买菜的还是附近的钱大妈。但我却没怎么去更近的一家生活超市，店面比较大，除果肉蔬菜外，也卖油盐酱醋，还有生活用品，但奇怪的是顾客却不到钱大妈的1/10。为什么几乎所有潮州牛肉店都很多人，有很多甚至在门口排了很长的队？观察到这些，常常会陷入思考，为什么会发生这些，新零售到底改变了什么？再举个例子。去年拿保温杯泡着枸杞的中年男火了。关于这个，我又问了自己几个问题：拿着保温杯泡着枸杞的是不是都是中年男？如果是，这个特征能否被数据量化？可否考虑加入到算法模型当中，加以应用起来？虽然很多问题，我没有找到答案，但多问自己问题，会引发自己不断深入思考，不断激发自己好奇心，不断去研究。很多业务知识都是零散的，不可能在短时间内完全了解，可以在日常不断积累。关于日常积累业务知识，可以经常询问懂业务的人。这是我想说的第三个方面。刚进公司的时候，我以为业务很简单。很快，我就发现里面的坑不少。加上所在团队的成员也是刚入职不久的，问问题没处可问。过了一个月之后，我发现隔壁团队有两个十年左右的老员工，业务很熟，而且人特好。于是，我几乎一遇到业务问题，就跑过去“骚扰”他们，他们也很乐意解答，如果他们不清楚，他们也会告诉我应该去找谁了解。大约半年之后，我基本摸透了顺丰的数据和业务情况。我也和那两位老员工建立了不错的友谊，即使后来换了部门，我也经常过去找他们。跟懂业务的人搞好关系，遇到业务问题，多咨询他们，这是最有效最接地气的办法。多看书，这是我想说的第四个方面。比如说，从事新零售领域方面的工作，总得先了解新零售是怎么回事。你可以去听专家们忽悠，但这样的机会很少，而且时间也有限，说不定成本还很高。读书则不一样。读书，意味着主动了解，主动去构建自己的知识体系。读书的重要性，这里不多言了。如果您读这篇文章的时候，您恰好也是一位数据人。我还想告诫一句：我们不能脱离业务去看数据，而是要时刻从业务角度去理解数据。我们不敢期望可以完全理解这个世界，但也憧憬着我们不单可以在代码的世界里畅快驰骋，论剑江湖，也可以放下身段洞察芸芸众生之百态，领悟人间世俗之真情。如果真的可以的话，就没有需求分析师什么事了。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://ww3.sinaimg.cn/mw690/7cc829d3gw1eizj4iuehrj20eq0b2gn2.jpg"]}
{"title": "Linux 权限控制的基本原理 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n这里，我们主要介绍  系统中，权限控制的基本原理。安全模型在  系统中，我们所有的操作实质都是在进行进程访问文件的操作。我们访问文件需要先取得相应的访问权限，而访问权限是通过  系统中的安全模型获得的。对于  系统中的安全模型，我们需要知道下面两点 系统上最初的安全模型叫 , 全称是  ，翻译为自主访问控制。后来又增加设计了一个新的安全模型叫 , 全称是 , 翻译为强制访问控制。注意,  和  不是互斥的，  是最基本的安全模型，也是通常我们最常用到的访问控制机制是  必须具有的功能， 而  是构建在  之上的加强安全机制，属于可选模块。访问前， Linux系统通常都是先做  检查， 如果没有通过则操作直接失败; 如果通过  检查并且系统支持  模块，再做  权限检查。为区分两者，我们将支持  的  系统称作 , 表示它是针对  的安全加强系统。这里，我们将讲述  系统中的  安全模型。 安全模型 的核心内容是：在  中，进程理论上所拥有的权限与执行它的用户的权限相同。其中涉及的一切内容，都是围绕这个核心进行的。通过  和  保存用户和组信息，通过  保存密码口令及其变动信息， 每行一条记录。用户和组分别用  和  表示，一个用户可以同时属于多个组，默认每个用户必属于一个与之  同值同名的  。对于  , 每条记录字段分别为 对于  ， 每条记录字段分别为 对于  ，每条记录字段分别为： 以下是对用户和组信息的举例。  中的口令信息为加密存储，不举例。 中的文件有如下类型：普通文件， 又包括文本文件和二进制文件， 可用  创建；套接字文件， 用于网络通讯，一般由应用程序在执行中间接创建；管道文件是有名管道，而非无名管道， 可用  创建；字符文件和块文件均为设备文件， 可用  创建；链接文件是软链接文件，而非硬链接文件, 可用  创建。分为三组进行控制： 包含对文件属主设定的权限 包含对文件属组设定的权限 包含对其他者设定的权限下面给出常见（但非全部）的权限值， 包括： 表示具有读权限。 表示具有写权限。 一般针对可执行文件/目录，表示具有执行/搜索权限。 一般针对可执行文件/目录，表示具有赋予文件属主权限的权限，只有  和  组可以设置该权限。 一般针对目录，设置粘滞位后，有权限的用户只能写、删除自己的文件,否则可写、删除目录所有文件。旧系统还表示可执行文件运行后将text拷贝到交换区提升速度。通过  可以查看到其文件类型及权限，通过  修改权限。举例来说，输出中， 第1个字符表示文件类型，其中，普通文件()、目录文件 ()、套接字文件()，管道文件()，字符文件()，块文件()，链接文件()； 第2个字符开始的  部分表示文件的权限位，共有9位。对于文件  , 这个权限控制的含义是：第2~4位的  表示该文件可被它的  （属主）以  或  或  的权限访问。第5~7位的  表示该文件可被与该文件同一属组的用户以  或  的权限访问第8~10位的  表示该文件可被其它未知用户以  或  的权限访问。对于  设定的权限： 权限对每一权限控制组的权限用一位8进制来表示； 例如：  表示  。 权限会替代  位置显示；设定  权限则需在对应的、用于控制  的8进制权限控制组前追加数字；  权限用于属主属组控制，  用于其它控制。设定属主  需追加 , 设定属组  追加 , 设定其它者  权限追加  ； 例如前面对  设定 , 则用 , 表示  。对于进程，有如下属性与文件访问权限相关： : 进程访问文件权限相关的  （简写为  ）。 : 进程访问文件权限相关的  （简写为  ）。 : 创建该进程的用户登录系统时的  （简写为  ）。 : 创建该进程的用户登录系统时的  （简写为  ）。 : 拷贝自  。 : 拷贝自  。我们可以使用  和  选择查看具有  和  的进程。或者通过  来查看进程的  和 通过  来查看的例子：首先输入  得到类似如下\n\r\n\r\n\t\t\r\n\r\n\n这里通过  选项延长  的刷新频率便于操作。此处可见，只有  字段，表示相应进程的 .打开  的显示选项\n在  命令运行期间，输入 , 可以看见类似如下行：\n\r\n\r\n\t\t\r\n\r\n\n输入  即可打开  的显示开关。\n\r\n\r\n\t\t\r\n\r\n\n最后  回车回到  中，即可看到  的选项此时输入 ,可调整列次序最终我们可看到包含  和  的输出如下：\n\r\n\r\n\t\t\r\n\r\n\n其中，  是对应进程，  是对应的 ,  是对应的  。\n对于进程访问文件而言，最重要的是 , 所以其权限属性均以  为 “中心”。进程的  一般默认即为 其  值若可执行文件的可执行权限位为  ，进程对其调用  后，其  被设置为该可执行文件的 进程的  拷贝自 .当进程的  与文件的  匹配时，进程才具有文件  权限位所设定的权限组权限  的控制规则类似。通过  调用可执行文件之时：进程  值始终不变； 始终来自  ； 值取决于文件的  位是否被设置。如下：通过  修改权限属性之时： 可顺利修改 , ,  ； 只能在  与  相等时修改 , 其它无法修改。如下：再举几个比较特别的例子：如前所述，这个输出的含义是，对于  文件，第1~3位的  表示该文件可被它的owner（属主）以  或  或  的权限访问第4~6位的  表示该文件可被与该文件同一属组的用户以  或  的权限访问。第7~9位的  表示该文件可被其它未知用户以  或  的权限访问。这样设置之后，对于owner，具有读、写、执行权限，这一点没有什么不同。但是对于不属于  组的普通用户进程来说，却大不相同。普通用户进程执行  命令时通过其  中的  获得执行权限，再通过  中的  使得普通用户进程临时具有了  可执行文件属主(  )的权限，即超级权限。这也是为什么通过  命令就可以让普通用户执行许多管理员权限的命令的原因。这样设置之后，对于  目录，任何人都具有读、写、执行权限，这一点没有什么不同。但是对于  部分设置了粘滞位 , 其功能却大不相同。若目录没设置粘滞位，任何对目录有写权限者都则可删除其中任何文件和子目录，即使他不是相应文件的所有者，也没有读或写许可; 设置粘滞位后，用户就只能写或删除属于他的文件和子目录。这也是为什么任何人都能向  目录写文件、目录，却只能写和删除自己拥有的文件或目录的原因。 程序可以用来显示在线帮助手册，  程序可以被安装指定  或者  为一个指定的用户或者组。 程序可以读取或者覆盖某些位置的文件，这一般由一个配置文件(通常是  或者  )或者命令行选项来进行配置。 程序可能会执行一些其它的命令来处理包含显示的  手册页的文件。为防止处理出错，  会从两个特权之间进行切换：运行  命令的用户特权，以及  程序的拥有者的特权。需要抓住的主线：当只执行  之时，进程特权就是  用户的特权， 当通过  执行子进程（如通过  引出shell命令）时，用户切换为当前用户，执行完又切换回去。过程如下：假设  程序文件被用户  所拥有，并且已经被设置了它的  位，当我们  它的时候，我们有如下情况：\n = 我们的用户UID = man用户UID = man用户UID\n 程序会访问需要的配置文件和  手册页。这些文件由  用户所拥有，但是由于  是 ,文件的访问就被允许了。在  为我们运行任何命令的时候，它会调用  ( 返回的是 ).因为我们不是  进程，这个变化只能改变 . 我们会有如下情况：\n = 我们的用户UID(不会被改变) = 我们的用户UID = man 的用户UID(不会被改变)\n现在  进程运行的时候把我们得UID作为它的 .这也就是说，我们只能访问我们拥有自己权限的文件。也就是说，它能够代表我们安全地执行任何 .当  做完了的时候，  会调用 .这里，  是  用户的UID.(这个ID是通过  调用  来保存的)这个调用是可以的，因为  的参数和  是相等的。(这也就是为什么我们需要 ).这时候我们会有如下情况：\n = 我们的用户UID(不会被改变) = man的UID = man 的用户UID(不会被改变)\n由于  是 ,现在  程序可以操作它自己的文件了。通过这样使用 ,我们可以在进程开始和结束的时候通过程序文件的  来使用额外的权限。然而，期间我们却是以我们自己的权限运行的。如果我们无法在最后切换回 ,我们就可能会在我们运行的时候保留额外的权限。下面我们来看看如果  启动一个  的时候会发生什么：这里的  是  使用  和  来启动的。因为这时  和  都是我们的普通用户UID(参见step3)， 所以  没有其它额外的权限.启动的  无法访问  的  ,因为  的  是由  从  拷贝过来的。在执行  的子进程(  )中，所有的  都是我们的普通用户ID.实际上，我们描述  使用  函数的方法不是特别正确，因为程序可能会  为  .这时候，  会把所有三种uid都变成你设置的id，但是我们只需要设置 .\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "九年程序人生 - 文章 - 伯乐在线", "tag": ["职场", " 1 评论 ", "工作"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n时间一晃而过，大学毕业转眼间已经工作9年了，总结一下自己这些年来感受。一次做规划局的项目，规划局的职员很是钦佩地说：“你们真了不起，在电脑上敲敲键盘就能做出软件来。”，规划局领导说：“跟电脑打交道是最简单的，难的是跟人打交道。”。领导的话很有深意，一语道破了本质，做程序的人，是比较简单的。大学本科，读“计算机科学与技术专业”（相信看这篇博客的人多半也是学这个专业的 ^_*），课程重理论而轻实践。最初学习C语言，对于编程没有任何概念，我清楚的记得，一次在课堂上问老师：“计算机输入法，可视化操作界面已经很完善了，为什么要用C语言中 Print() 函数输出一段字符呢？而且我们学习使用Console控制台的黑白屏输入输出，也不像是平时使用的软件啊？”。老师听后也是一脸的懵逼，说：“你好好学，慢慢就明白了”。你不懂的，老师也没法回答你，只有靠自己慢慢地摸索，慢慢去领悟。初学Java，这是我接触的第一个最具有实用意义的编程语言（可以做网站，做软件，虽然C语言，C++也可以开发应用软件，但毕竟使用的人较少，对于初学者，找到一个合适的教程都困难）。当时的学习，基本是自学，上网下载视频教程，一集一集地看，不懂的概念上网查，去图书馆借阅相关书籍资料，什么JSP标签，Servlet，JDBC，到Struts MVC，Hibernate，Spring，设计模式，半年时间，算是初步入门，尽管对知识还是一知半解，但还是成功用Java做了毕业设计，做过几个小程序。工作之后，开始使用C#，算是与.NET平台结缘，一行一行地敲代码，一个接一个的做项目，一版又一版的升级软件，一晃9年了。从最初的ASP.NET WebForm，ADO.NET，到ASP.NET MVC，WebAPI，EntityFramework，面向服务架构的WCF，以及最新的跨平台.NET Core，微软为软件开发人员，提供了编程最大的便利性。仅从开发语言本身角度讲，C#并不比Java差，并且很多细微的地方，C#比Java做的要好，比如，C#中的get，set属性访问，要比Java的字段访问方便很多，相同逻辑代码运行效率方面，C#的MSIL比Java的字节码允许效率还要稍微高一些，但是无奈，.NET平台发展始终不及Java平台。诚然，平台的发展不能仅从开发语言本身考虑，平台运行环境，平台参与人员整体水平，使用成本等，更是起着决定性作用，.NET平台在互联网大潮中，逐渐被边缘化，免费的Java平台，被开源社区拥抱，成为互联网项目开发平台的中流砥柱。微软似乎意识到问题所在，逐步加入开源队伍，并提供了跨平台方案.Net Core，但并没有明显起色，.NET平台开发人员心中不免有一丝悲观情绪，.Net平台开发人员似乎比Java开发人员始终矮一头的感觉。做Web开发，离不开HTML，CSS，JavaScript，尽管日常工作以后台开发为主，但接触的多了，慢慢地理解深入，从只会使用JS写函数，发展到使用JS面向对象的功能，理解了JS中闭包的概念（好烧脑，用离散数学中的概念来表示函数集合，让没学过集合概念的同学情何以堪）。明白了JS的面向对象编程，通过JS自定义前端控件，数据与逻辑代码分离，达到优雅地实现前端逻辑。学习的过程是曲折的，有时候一个概念始终理解不了，但一旦明白过来，会有一种眼前一亮，豁然开朗的感觉。起初一直不明白，为什么JQuery中的“$”这么牛，一个“$”符号能操作一切，读过JQuery源码之后才明白，这个“$”原来是jQuery在Window中定义的的一个变量，同时也是jQuery这个函数的别名，每次调用$(…)时，其实间接地创建了一个JQuery的示例。当然，这种操作得益于JS是一直动态语言，可以给对象任意添加属性和方法（相比较Java和C#是不能这样操作的）。技术之路要不断学习，路漫漫其修远技术更新迭代的速度，远超想象，往往是刚学会一个新技术，另一个更新的技术又变的火热，似乎新技术的产生，也在遵循一个摩尔定律。追赶技术的脚步，就如同夸父追日一般，你一直在追赶，但它一直在你前面。好在，每一个新技术，新架构的产生，都是在为更简单、更高效的解决现有的问题，所以，新的技术，虽然增加了学习的负担，但是新技术的应用，能够解决现实的问题，是效率的提升。从这个角度讲，学习是值得的。通常来说，没有谁天生就会做什么，只要肯学习，别人能做到的，你也能做到。React火热的时候，学习React，了解了这种基于模板的开发方式，见识了这种类似于MVC，实现数据与业务逻辑分离的编程方式在JS中的实际应用，对于这种仅需要一个render()函数的超简洁的框架赞叹不已。Facebook搞出了React，国人也不示弱，于是诞生了Vue，相对来说更简洁，使用更方便。React发展出了React Native，圈子里更是为止振奋，为火热的移动端开发又添了一把柴，让移动端开发，在Android和IOS原生开发之外，又多了一种全新的选择。我用3天时间，学会了开发微信小程序，完成了原有Web功能向小程序的移植。Node.JS火热的时候，我用了一周的业余时间，学习NodeJS编程，配合MongoDB，搭建了简单的日志系统。说起来有点吹牛的意思，但却是事实。一方面，不管是React，微信小程序，Node.JS，本质上都是JavaScript，Html，CSS的组合使用，相似度很高，只是各自有各自特点的规范特色而已，学习难度是逐渐降低的。另一方面，我相信大多数人也有感受，当工作经验，认知水平达到一定积累之后，学习其实是一件水到渠成的事情。总结有一次跟朋友聊天，朋友说，“感觉自己越学习，越感觉到不懂的方面更多了”。我笑笑，表示同意他的观点，这是一个叫做“知识边界”的问题，每个人的知识，就如同是一个圆，圆内是你已经了解的知识，圆之外就是还不懂的知识，一个人掌握的知识越多，这个圆也就越大，而圆越大，圆周所接触的那些未知领域也就越多。如果一个人说自己没有什么不懂的，那只能说明他知识面太小。如此，当我们意识到自己有很多不懂的东西的时候，也不用焦虑，因为我们的知识在扩展，保持一颗开放，学习的心，这是人生路上所必须的。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2014/03/2b70b826c50f6f6721d816371ec7fd6a.jpg"]}
{"title": "听说你立志要做数据分析，不如先听听老司机的建议？ - 文章 - 伯乐在线", "tag": ["其他", " 1 评论 ", "数据分析"], "goodNum": "4", "saveNum": " 6 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n每年总有很多人，怀揣着对世界的一知半解、满腔似火的热情、还有对美好生活的向往，走出象牙塔，投身社会。世界很大，诱惑很多。对于未来，甚至在工作多年后，他们仍然没有清晰的方向，或者缺乏独立、深度的思考。方向很重要，而人生很短暂。往哪里走，怎么走，再怎么也得花点时间思考一下，不是吗？如果你决心要在数据科学领域有所作为，或者立志做数据分析，这篇文章提了点小建议，希望对你有所帮助。我们做每件事之前，都要先明确做这件事的目的和意义是什么。先来问问自己，做数据分析的目的和价值是什么？我的理解是，致力于用数据帮助企业解决业务问题，辅助业务决策。关于这个问题，你可以花3-5年时间来思考和领悟，不急，但需要想清楚。你还面临一个抉择，到底是去大厂还是去小厂？之前接到很多猎头电话，不少都会问：“你是做分析还是做挖掘的呀？”刚开始，也常会和猎头在电话里“理论”一番。后来在大厂待过才明白，大厂分工比较细，分析是偏向经营分析，即取数分析写报告，而挖掘则是建模调参部署等。小厂就不一样了，谈需求、确定思路、指标设计、平台搭建、接入数据、处理数据、建立宽表、模型训练、结果分析、撰写报告、模型部署、报表计算、数据可视化等一整个流程，一个人几乎都可能会参与。如果有机会，请一定要去大厂历练几年！大厂大多都很开放，常常敢为天下先，敢于引入一些新的东西，包括技术、思维、制度，技术比较先进，优秀的人也很多。大厂的管理制度也很完善，福利待遇当然会更好些。大厂的数据规模绝对够大，而且应用场景也多，可施展的空间应该会比较大。所以，抱着学习的态度在大厂里混几年，是可以成长很快的。（有好，当然也有不好）大厂流程繁杂，整体效率偏低，提一个取数申请可能需要1-2周。大厂的内部竞争也大，存在于不同项目团队，也存在于同一部门不同成员之间。大项目资源投入大，小项目资源申请很困难，重视程度也不一样。最主要的，大厂分工很明细，不同职位的轮换似乎不大容易，从入职到几年后离开一直做经营分析都是有可能的，容易导致能力的单一，不利于个人综合素质的培养。相比之下，小厂就灵活多了，人和事都不会很复杂，而且效率也高。小厂可能会优先考虑做这件事情的投入和产出，即看应用效果。（大厂反而愿意给资源去试，短期内不怎么关注投入产出。）所以，在小厂工作，既要学会帮公司赚钱，也要学会帮公司省钱。小厂分工不会很细，大多需要一个人做多种工作。所以，小厂里面的程序员常常身怀多技。但小厂数据规模小，技术实力较弱，团队成员整体素质不高，而且项目流程不大规范，常常怎么简单怎么来，怎么高效怎么来。有些小公司的码农，除了对外发过一两封邮件，平时的沟通几乎是在QQ里，结果待了几年之后连写一封邮件都不会。有些小厂自己没有数据，重要是作为乙方给大企业做项目，这种模式常常受甲方牵制，可发挥的空间很小，而且一个项目周期往往比想象中要长（我本人之前就厌倦做乙方），因此不大建议去这样的公司。不管大厂还是小厂，在选择时，建议都要看看所要加入的团队。综合来说，建议先去大厂混几年，再去小厂找个Title高点的职位发挥自己所长。再来说几句，什么场景下分析，什么场景下挖掘呢？分析其实是一个很笼统的概念。把当前营业额跟去年同期做对比发现增长了不少，这个也可以认为是分析。分析是从数据中发现问题或规律，并提出合理的建议。分析常常伴随着要写报告，进而要给业务方汇报分析结果。最好是给决策层汇报，因为决策层有拍板的权力，而且对数据结果的感知和可能的应用有自己独到的认知。如果需要把分析的结果固化下来，定期输出结果，提供给业务方，这个时候就需要开发数据产品了。挖掘是用算法解决某个具体的复杂问题，用常规分析方法解决不了的，如客户流失预警、商品最优推荐组合、最有投递路线规划等。所以，我一般认为，分析是从数据中发现问题或规律，而挖掘是其中的一块。在职业生涯的初期，请牢记，“所见即所得，所感即所知，多见即多得，多感即多知”。不管在大厂还是在小厂，一定要参与到实际项目当中，好好打磨自己的技术。不管是大项目还是小项目，一定要借助来之不易的机会，以极致的工匠精神修炼自身。你最好能从基础数据处理做起。只有这样，你才能早点知道，数据并不像在学校里做实验用到的数据那样“好”，它可能看起来“又脏又乱”。只有这样，你才能早点知道，给你取数的那个程序员是如何花了2-3天甚至一周时间才把数算好。如果你精通SQL，那就太好了，这样就可以直接能够在数据平台查看原始的数据了。最好要看一看最原始的数据长什么样。你不一定能一下子理解这些数据，但你可以慢慢地感受它们，因为它们所投射出来的是最真实的业务场景。举个例子吧，原始的会员注册信息数据里面，性别一般填“男”、“男性”、“女”、“女性”、“未知”、“其它”等值，但处理好之后的二手数据里面，性别就变成了“男”、“女”、“未知”等三个值了。仅看这三个值，可能会漏掉一些业务场景，填“男”可能是从移动端输入时选择的，填“男性”则可能是手工填写注册表格时勾选上的。而漏掉的这个场景，说不定就是所要找的那个分析点。 你最好还能熟练掌握一两门编程语言，比如当下流行的Python，作为入行的基础技能。（顺便说一下，码农界普遍认为只会SQL的不算真正的程序员~~）当今时代，编程已经从娃娃开始抓起。早在5年前，英国规定5岁以上儿童必须学习编程课，法国将编程列入初等教育选修课程，美国已有40个州制定政策支持计算机科学，有35个州将计算机科学课程纳入高中毕业学分体系。美国前总统奥巴马就曾在全美发起“编程一小时”的运动，旨在让全美小学生开始学习编程。2017年，浙江、北京、山东等省确定要把Python编程基础纳入信息技术课程和高考的内容体系。编程将是一项很基础的技能，也将是承接其他知识的基石。在未来，会编程很可能跟使用智能手机一样普遍。当处理基础数据的时候，必然会在数据库或数据平台上进行。你可能需要对这些存储数据的环境加以了解，如传统的结构化数据库Oracle、Mysql、DB2等，又如当下流行的Nosql数据库HBase、Redis、MongoDB、Cassandra等，再如大数据集群平台、原理及其相关概念，类似Hadoop、Hive、Hue、MapReduce、Spark、Scala、Sqoop、Pig、Zookeeper、Flume、Oozie等。你或者也需要了解数据传输的工具，如DataStage、Kafka、Sqoop等。你甚至也可能被安排做安装系统、部署软件、配置环境、同步数据等一些琐碎的工作。关于这些，如果你非常感兴趣，可以考虑往大数据平台方向发展，成为数据开发工程师、数据平台运维工程师、或者数据平台架构师。你不必理解太深，可仅仅停留在了解层面，但知道这些知识会让你和数据开发工程师、运维工程师和平台架构师沟通起来顺畅很多。当处理和分析数据时，有些关于数据的操作是必然需要掌握的。首先是常见格式的数据导入导出，如TXT、CSV、XLS，然后是主要的数据加工技巧，包括建表/视图、插入、更新、查询、并联、串联、汇总、排序、格式转换、循环、常用的函数、描述统计量、变量，等等。这些操作很基础，但不简单。你可能经常会遇到各种情况，如花了一个下午时间就是没能把一个很小的CSV数据文件正确地导入到数据库中，不是乱码就是错位，或者两表关联时老是报一些烦人的错误，或者日期字段进行格式转换时出现空值……反正状况百出，防不胜防。关于这些基础操作，需要不断积累经验，尽量能够做到在不同场景下快速高效地完成，轻松应付。如果有人已经给你取好了数，而你的工作是分析数据写报告，那么分析技巧首先是你需要培养起来的。对拿到的数据，要时刻保持疑问，不能太乐观，因为别人算好的数据未必完全是你想要的数据，又或者数据质量并不是你想的那样好。在分析之前，需要进行数据探索，看看数据质量如何。比如，你需要清楚有多少数据量，有什么信息，可衍生什么指标，缺失情况如何，如何填补缺失值，值的分布情况如何，如何处理极值，名义/字符变量是否需要转换，等等。分析时，要清楚指标不同形态的含义，如绝对值、占比、同比、趋势、均值、标准差，等等。在这里，我想指出，数据有对比才有意义。如果一个穷人捡到100元，他会很高兴，这够他吃好几天了。但如果让一个富人去捡100元，那感觉就不一样了，他可能觉得他不值得这么做，因为用弯腰去捡的时间挣到的钱远远不止这么多。统计学知识是必须要掌握的，这是基础。如果你非数学或统计学专业出身，那么请自学。另外，也请你一定要掌握主流算法的原理，比如线性回归、逻辑回归、决策树、神经网络、关联分析、聚类、协同过滤、随机森林，再深入一点，还可以掌握文本分析、深度学习、图像识别等相关的算法。关于这些算法，不仅需要了解其原理，你最好可以流畅地阐述出来，还需要你知晓其在各行业的一些应用场景。关于这些算法，你最好能够参与关于模型开发的具体项目实践。那样的话，你就可以清楚关于建模的大概流程是怎么样的，不同算法在建模中有不同，需要注意哪些地方。如果你打字速度不快，那也最好重视起来，这虽然是一个不痛不痒的问题，但也在较大程度上影响你的工作效率，进而影响到你的工作产出，当然也可能因此会影响到你的薪资哦！另外，还有一些提高工作效率的小技巧，也可以多学多掌握。例如，一些电脑的快捷键，定期保存文件，文件的归类存放和快速查找，等等。作为职场新人，你不仅需要打磨技术，纯技术之外的技能也需要不断修炼。职场的做事方式方法、为人处事以及一些潜规则，更多时候只能靠悟，说出来就可能不大好了，因此需要不断领悟。毕竟，悟性这东西是很重要的。还有，沟通是码农普遍的老大难问题，建议重视起来并加强。你甚至可以学一下投影仪或打印机怎么用。（说不定可以靠这个技能在老板或同事前面大攒人品哦~~）如果你有机会和很牛的人在一起工作，那你太幸运了。你可以多请教优秀的人一些问题，也可以平时多观察那些优秀之人的做事方式、工作习惯，看看有哪些好的地方、好的品质值得你学习。只要吸纳进来，就可以转化为你的优点，推动你进步。我毕业的第三年，看到俞敏洪老师在一些演讲中提及他大学时读了800多本书，很受触动，真正认识到了读书的重要性，于是给自己制定了一年读50本书的计划，什么书都读，三年左右时间，我的心智和心态都发生了很大的改变，完全不一样了。俗话说：“三人行，必有我师。”每个人都有每个人的优点，对于所遇到的每个人，建议多欣赏别人的优点，少抨击别人的缺点，这样你就可以“兼收并蓄”，逐步塑造更好的自己。当迈过了最初的3个年头后，你的技术越来越好，也做了不少项目，也越来越清楚自己未来的方向，但你也会发现有越来越多的东西还需要去学习和加强。这个时候，你的知识是零散的，还远未形成体系。你也许还需要花些时间好好梳理和总结过去几年积累的经验和知识，不断沉淀，形成自己的知识体系和方法论。在梳理的过程中，你会不断清楚自己有什么，缺什么，哪些地方弱，哪些地方强，未来需要花多少时间补强哪项技能，等等。你可以沿着数据的整个流程，即数据采集、数据存储、数据处理、数据分析/开发模型、报表计算、数据可视化，不断拓展自己的能力边界，最好在流程中的各个环节都做过项目。例如，在数据采集环节，你可以学一下爬虫技术。这个时候，你不再是新人。新人大多是等着别人安排工作，并在详细的指导之下完成。而你慢慢成长为老司机了，需要独立完成一个个任务了，如独立开发一个模型、写一份会员分析报告、梳理关于近期营业额下降原因分析的思路，等等。你需要不断适应在无人指点的情况自己去寻求问题解决办法，也可能需要应对此前没有遇到过的新情况并独立展开调查研究。几乎没有人帮你，你也没法指望别人明确告诉你怎么做。而你需要的是，历经3年之后成长路上的一个质变。在这过程中，你可能需要不断查找资料，咨询别人，并加以思考，梳理出有效的方案，最后落地执行。在这过程中，可以有效训练以下几方面的能力：查找资料会问问题总结梳理写作能力关于总结梳理，建议定期做，常常做，每天做，建议养成一个日常习惯。对于不同问题和场景的思路整理总结，常常需要方法论指导，如麦肯锡金字塔原理、结构化思维等。关于这些方法论，不仅要谙熟于心，也需要将其应用到实际工作当中。这是受用一生的知识，你也可将其运用到你的日常生活中，用以解决你日常的问题和需求。关于思路的整理，可以借助思维导图工具。另外，请注重培养自己的数据敏感性和数据思维，越早开始越好。关于如何培养数据思维，将以另外的文章单独阐述。EXCEL是操作和处理数据最方便的工具，也是必须掌握的办公软件。很多人会用EXCEL，但根本不精通EXCEL。简历里那句“精通EXCEL等办公软件”（你的简历里是否也这样写~~），常常是一个谎言。建议你好好学一下EXCEL，包括展示数据、透视表、函数、画图、动态图表、VBA等。不要仅仅停留在最粗的层面，比如画图，使用默认设置也可以画出一个图表，但是不好看，阅读体验不好。关于怎么用EXCEL画好图表，推荐阅读《EXCEL图表演示之道》、《最简单的图形与最复杂的信息》。写分析报告，难免会用到PPT。关于如何写好PPT这件事，从来就不是件轻松的事。但你可以给自己一些时间去学，比如3年、5年、甚至10年。刚开始，写得不好没关系，但一定不要放过每一次锻炼的机会。关于PPT的技巧，将有更多的文章单独阐述。在领导眼里，会写材料的人比会编程的人更有存在感。而且，会写材料的人总是显得那样“稀缺”。如果你是别的同事眼里的“会Coding的人中最会写PPT+会写材料的人中最懂技术”的那个人，那你将会很受重用。在别人眼里，数据分析和开发模型是很高大上的。但这高大上，常常处在很多尴尬的处境。数据分析汇报一次之后就没了下文，模型开发了，部署了，也定期出数了，但就是没用起来。用户方或业务方觉得这些东西对他们业务帮助不大，可有可无（虽然包装一下用来忽悠一下投资人可能也有点用处），还不如一个经验规则来得有效，简单粗暴，省时省力。关于经验规则和算法模型之争，如果你坚定认为你开发的模型比业务方所认为的经验规则更有效，那么，请你拿出“证据”，用数据说服业务方，让他们改变观念，觉得你是对的。之前信奉的那句“数据驱动业务”，是不是错了吗？此刻，请回到初心吧！我们的初心是什么？那就是用数据帮助业务解决问题，用数据辅助业务决策。数据分析只是其中一种形式，当然还有其它。因此，不要迷恋数据分析，不要迷恋算法模型。“不管黑猫白猫，抓到老鼠就是好猫。”如果你能够从数据分析和算法模型的困囿中挣脱出来，那么你将发现你面对的是广阔天地，你可以在数据的海洋里肆意遨游。你或许开始注重追求数据解决方案的实用性，强调落地执行，更看重应用效果。你必须真正理解业务方的需求。当业务方进行选品和定价时，他们需要一份关于竞品的商品数据来做参考；当业务方想随时看到当前时刻的订单量（特别是618或双11），你需要实时汇总数据并实时呈现给他们；当业务方既想看总体的经营数据，也想看各区各部门各门店的经营数据，你需要开发一个多维度层层钻取查看的功能……而这些都不是数据分析和算法模型，但这些也是数据应用，也能产生数据价值。如果有机会，不妨尝试做个数据产品经理。数据产品经理需要从产品角度实现业务功能。在当前数据产品化的趋势下，这是一个很有挑战性的事情，不容易做好。毕竟，讨好一大群用户，比单独讨好一个用户要难得多。在数据产品设计里，数据可视化是一个重要的事情。好的图表会说话，好的功能会抓住用户的心。即便撇开数据产品，我们在分析报告里也会需要数据的可视化表达。数据可视化传递的是一种明确的数据信息，一目了然，赏心悦目。从画好一个数据图表，到功能版式的精心设计，再到对功能细节良苦用心的把握，你需要不断精进。一旦你感兴趣，你将会很快沉迷于其中，因为那是一种美的表达。是的，你已经做了十年，希望你无悔当初的选择与坚持。此时你也遇到很多瓶颈，或许你空有一身好武艺但得不到老板重用，或许你想做个实力派但处于各种原因离技术越来越远，或许你很努力但职务仍然上不去，或许你面对繁重的工作心有余而力不足，各种分身乏术……你一直在等待和寻找着机会，突破自己。此时你也渐渐步入了中年，或许你开始变得油腻，或许你的身材早已远离苗条，或许岁月在你的脸上、头发上开始留下痕迹，或许你的思想渐渐固化，不能与时俱进了……最重要的，或许就是你早已没有了当初的激情。如果你在一个行业待了十年，在别人眼里，无论怎样，都已是个专家，所以，请自信！你还需要在圈里有一定的影响力，需要树立个人品牌，最好能在圈里外有较好的传播。如此这样，当别人提起你的时候，他们常会这样说，“这个人分析能力很强”，“他在数据领域造诣很深”，“他建模能力出众”……如此种种，在他们眼里对你印象最深刻的标签将会是你最想要的那个。或许你需要逐步提升讲课程的能力，这是一种知识分享与传递，也是提高个人影响力的有效途径。不要放过任何露脸的机会哦！你或许已经深刻明白，分析的结果、开发的模型、数据产品只有被应用起来，才真正算是产生价值。你会越来越关注数据应用的问题。当你开始聚焦这个问题时，你会问自己，”用户或业务方真正需要什么？“这个时候，你得有用户思维了。你会加强对业务的重视程度，也会不断回到业务层面去思考数据的实际应用。你最好也时刻关注当前社会的趋势和潮流，特别是与互联网相关的。这样可以让你保持开放的心态，洞悉社会的风向，驱动自己的思考，挖掘潜在的机会。你可以从中了解当前行业中成功的数据应用案例，开拓自己的思路，多想想用数据还可以帮助各行业解决什么问题，可能的机会在哪里，自己应该怎么做。你可能要面对的是，数据应用对一个行业或一个企业来说，永远都是在探索。某个数据应用思路或项目一旦成功了，就会得到越来越多的资源投入，越做越大，如果失败了，就会立刻遭放弃。因此，要有创新精神，要有创新的勇气和自信。职位上来说，你可能开始担任一定的管理工作。因此，你还得学会团队管理，懂得如何向上管理和向下管理。你的日常事务会越来越多，你也需要学会有效管理自己的时间。你可以成为一名“清单控”。但必须指出的是，时间管理，最本质的还是自我的管理，对精力的管理。你需要开始意识到加强身体锻炼的重要性了。一来，保持身材，对发福说不，二来，保持精力的旺盛，抵抗疲倦，第三，通过不断挑战自己的身体极限来刺激自己，找回激情。你也需要开始认真考虑如何平衡工作和家庭的问题了。这个世界一直在变。我们也一定要“善变”，顺势而为。不管是10-20年前的BI（商务智能），过去几年的大数据，这年头炒得火爆的人工智能，还是未来涌现的更多概念，只要我们足够开放，敏感洞察，挖掘机会，创新、创业、创造，不断成就自己。汪国真在《热爱生命》里写道：“我不去想是否能够成功，既然选择了远方，便只顾风雨兼程。”英雄不问出身，只要你下定决心，即使再晚出发，也会达到，还可以走得更远。最后，作为数据人，与你共勉，“不做数据的搬运工，要做价值的缔造者”。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/06/03b5b99cd8b93d7c062277c5de23570b.jpg"]}
{"title": "通过可写文件获取 Linux root 权限的 5 种方法 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "Linux"], "goodNum": "2", "saveNum": " 2 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nLinux系统中，全部都是以文件形式存在的，包括目录、设备都是有权限的，共有读、写、可执行三种。管理员为文件设置好权限后，应该要考虑哪些Linux用户会被允许和限制上述的三个权限。通过可写脚本进行root提取的5种方法：复制 /bin/sh 到 /tmp设定 /bin/dash的SUID位通过sudoer给登录用户完全的权限设定/bin/cp的SUID位逆向连接到恶意代码开启攻击机器，黑掉目标系统，然后进行权限提升。假设成功地通过ssh登录到受害者的机器，并可以访问非root的用户终端。然后使用下面的命令，下面会举例所有有写权限的二进制文件。可以看到一个/lib/log中保存的python文件，在路径中我们看到了sanitizer.py文件的权限为777。Admin要将下面的脚本加入，来清理/tmp中的垃圾文件。如果攻击者能够识别受害者机器中的这类情形，就可以通过下面的方式来提升root权限来破坏系统。有许多的方法可以获取root权限，本方法中，我们将/bin/sh复制到/tmp文件夹中，然后设置/tmp/sh的SUID。这种方式非常简单，首先，通过nano编辑器打开文件，然后用rm -r /tmp/* 替换下面的命令：在/tmp目录创建一个有SUID权限的sh文件后，允许sh文件时会有root访问权限。可以通过下面的图片进行确认：同样地，可以用rm -r /tmp/* 替换下面行的内容在设置了/bin/dash的SUID权限后，运行后就可以获取root权限可以通过下面的图进行确认：通过netcat逆向了连接后，就可以获取root权限。可以通过下面的图进行确认：另一个方法是给登录的用户sudo权限。下面的图中可以看出当前用户wernerbrandes不能允许sudo命令。同样地，可以在下面替换rm -r /tmp/*当输入“sudo -l”命令时会发现，这是sudo用户的一个成员。可以利用sudo bash来获取root权限。因为在linux类系统中，passwd文件起着很重要的作用。所以，如果攻击者有机会修改passwd文件，那么这将会成为一种动态的权限提升的方式。\n同样地，可以利用cat命令查看etc/passwd文件的内容。\nUID:1000 & GID:1000 就是admin组队成员。下面编辑一下nemo记录来使其成为root组成员，选择etc/passwd的整个内容并复制粘贴到空text文件中。然后，在一个新的终端上生成一个含salt的密码，然后复制。然后粘贴之前复制的含salt的密码在用户nemo的记录词条的X位置处，并修改UID&GID为0:0。完成上面的步骤后，我们就可以将其保存为passwd。利用可写的脚本替换 “rm -r /tmp/*”设置/bin/cp的SUID来复制文件。将修改后的passwd文件下载受害者机器的/tmp文件夹中。用下面的命令检查/bin/cp的SUID位是否开启。下面确认是否改变了passwd文件的内容：可以看出passwd文件中的变化：可以执行下面的命令来获取root权限：本文证明了攻击者如何通过可写文件进行linux系统权限提升。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "我作为开发者犯过的两次愚蠢的错误 - 文章 - 伯乐在线", "tag": ["职场", "程序员", "职场"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n上周我和同事们简单地聊了聊我们工作中搞砸的那些事儿。如今早已不再犯那些错了，所以想起过去就觉得很好笑。但是笑归笑，其实当时犯的这些错让我们受益颇深。（credit：Snecx）分享自己犯错的经历至关重要，能让别人从中吸取经验教训，而且可能让他们工作起来更上手。我在这儿记录了几条自己最近犯的错。几个月之前，Reddit 上发了一篇，写的是一个入门级开发人员在上班第一天就误删了生产数据库。我们看到类似这种有人犯了特大的、不可磨灭的错误的文章，都不免心生畏惧。我们意识到自己并不是没可能犯那种错——大多数时候都是悬崖勒马。我在干第一份工作的时候，有一个高级数据库管理员在上班第一天就误删了生产数据库，这种例子简直比比皆是。工作团队用一周前旧的数据库备份帮他弥补了过失，让他保住了工作。如今十年过去了，都仍用这件事拿他开涮。今年年初有天早上，我被叫去调查一个客户生产中出现的问题。他们本来要针对一小部分用户进行产品的 β 测试，但是他们的网站首页突然什么都显示不出来了。我猜想可能是系统有 bug 或者有漏洞所致。我登录进生产机器，调出数据库，发现 articles 表是空的。OK，这证实了网页显示空白的情况。用户表里面还是有用户的，这就奇怪了，所以我们丢了所有的 articles，但起码他们的测试用户仍有他们的账号，我们可以解释说是这是个测试版，而且这种事情时有发生。接下来一会儿我就犯迷糊了。我记不清楚自己干了什么，我认为自己不会蠢到在控制台窗口输入了删除表中用户的指令，可情况就是这样——现在既没有 articles 表，也没有用户表。我呆坐着，感觉有点震惊。然后我的大脑高速运转，开始想办法修复问题。我真的删掉用户表了吗？是的。我们运行备份数据库了吗？没有。该怎么向客户解释呢？我不知道。我记得自己去找了项目经理，坐在她旁边解释事情发生的经过，articles 表中没有数据了，所以网站看上去是空的。哦对了，我还误删了用户表。现在他们需要重新邀请所有的用户——如果他们还能想清楚用户都有谁的话。哎呀。我回到自己的座位上，感觉深受挫败。于是我继续深究下去，一方面是因为难以接受这个结果，一方面是想挽回颜面。之后过了一小会儿，我注意到了关键问题。服务器上还有另外 5 个数据库，其中一个的名字和我正在看的那个数据库的名字非常相似。我一检查，发现 articles 都在里面，用户表也完好无损。事实证明是因为配置发生变化，无意间让它变成了生产数据库，导致网站指向了全新的数据库。我在里面看到的那些用户呢？种子数据罢了。真是如释重负！一早上神经紧绷、胃酸翻涌，搞得我浑身不适，但好在我们“修复”了所有的数据，并且找到了问题真正的症结所在，没有提前宣布误删数据库的坏消息。这个小插曲让我们受益良多，最简单的一个就是：现在我们总是在给数据库做备份……这可能是我们开发人员最有效的胃药。我最近所犯的另一个突出 错误没那么戏剧化，实际上是由一个个小错误最终累积造成了大麻烦。我们项目开发的一大挑战就是时间紧张（但也不全是？）第一次开会时，我们一致觉得项目需要的时间比我们能够拿出来的时间多了一倍。从项目一开始，截止日期就步步紧逼，所以我们三下五除二就通过了认证环节，以便进入客户真正关心的功能环节。我只是之前在一个单页 app 中落实了一次认证，但仍然没有彻底理解 app 各部分是如何协调的。尽己所能用最快的速度把 app 赶出来，就是大错特错，用户在登陆后，是通过 cookie 来加载的，但是我的 app 页面没有给加载提供等待时间，而是根据事件顺序来决定先后的，所以服务器会回复说你没有权限。这种错误很少见，而且很难再出现，因为大多数情况下事件都是按照正确的顺序来完成的。而且认证环节也从不检查用户令牌是否失效，如果你不经常访问网站，当发现了没法登上网站后，就需要注销登录再重新登进去。令牌应该在每次发起请求时都进行更新，但我从来都没有时间去理解这些规则。所以这里又产生了时间问题。如果我们一次同时发出几种请求，收到的回复取决于他们到来的顺序，那将来发送请求用到的令牌就是错的。我们卯足劲赶进度，但最终所用的时间还是要比给定的时间多一倍。区别就是我们开发出的 app 里面漏洞更多了，然后甚而要花更多的时间对漏洞进行追踪和修复。工作中的失误让我尴尬不已，在大家面前感到十分羞愧，因为我把一切都搞砸了。我要说一点：从那之后，我开始花时间学习认证机制，现在已经理解了 OAuth,、JWT、刷新令牌和失效。我仔细阅读了许多库里别人写的认证代码，而且建立了基于几种不同语言版本和框架的认证流程。这是每次失败的经历给予我的启发。只要你愿意学习，几乎每次这样的经历都会让你从中受益。如果人能够从错误中吸取教训，那么就会有所进步。如果一个队员是第一次犯错，我尽量不会对他表现出不满态度，他们往往已经知道自己把事情搞糟了。但我也努力不去苛责那些总是犯错、屡教不改的人，他们也需要被同情。对待犯错，如果你能够做到这四点，那么就会不断进步：对曾经犯过的错误可以自嘲一番从中吸取经验教训在之后努力为自己正名和他人分享，让他人也能从中获益。关于犯错的宝贵价值，我留给你们一则名人轶事：20 世纪初期，IBM 的总裁托马斯·J·沃森遇到了一位因为多次决策错误让公司损失惨重的员工，当问及是否要开除这个员工时，沃森答道：“不，我刚刚花了 60 万美元培训了他，我怎么会让其他人雇佣他来获得他的经历呢？”你过去犯过哪些有意思的错？来一起分享吧！\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://wx3.sinaimg.cn/mw690/7cc829d3gy1fsrtjp2o93j20hs0audih.jpg"]}
{"title": "这两年在大数据行业中的工作总结 - 文章 - 伯乐在线", "tag": ["职场", "大数据"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n写在前面今年广州的六月，在经历了大雨的洗礼之后，一切都变得更加明朗起来，新的工作，新的人和事。懒惰让我变得更焦虑，焦虑促使我进步，程序员的焦虑大家应该都有共同的感觉，时代的步伐太快了，在这个环境下的软件开发一定会淘汰掉那些不懂得学习，懒惰的人。希望跟大家共勉。今天呢，博主主要回顾这两年来，在大数据行业公司从事大数据类的前端开发的工作。最近刚刚换了一份工作，把我的经验稍作总结分享给大家，有什么建议大家在评论区踊跃。 谢谢。今天的主题，主要是从大数据开发的角度，到大数据治理的必要性，再到图形化建模的畅想，最后在数据质量的把关，然后到大数据可视化的应用，博主总结两年的见闻，和我学习的成果，也不知理解有无偏差吧，希望大家能给出建议。大数据开发大数据开发，有几个阶段：1.数据采集【原始数据】2.数据汇聚【经过清洗合并的可用数据】3.数据转换和映射【经过分类，提取的专项主题数据】4.数据应用 【提供api 智能系统  应用系统等】数据采集有线上和线下两种方式，线上一般通过爬虫、通过抓取，或者通过已有应用系统的采集，在这个阶段，我们可以做一个大数据采集平台，依托自动爬虫（使用python或者nodejs制作爬虫软件），ETL工具、或者自定义的抽取转换引擎，从文件中、数据库中、网页中专项爬取数据，如果这一步通过自动化系统来做的话，可以很方便的管理所有的原始数据，并且从数据的开始对数据进行标签采集，可以规范开发人员的工作。并且目标数据源可以更方便的管理。数据采集的难点在于多数据源，例如mysql、postgresql、sqlserver 、 mongodb 、sqllite。还有本地文件、excel统计文档、甚至是doc文件。如何将他们规整的、有方案的整理进我们的大数据流程中也是必不可缺的一环。数据的汇聚是大数据流程最关键的一步，你可以在这里加上数据标准化，你也可以在这里做数据清洗，数据合并，还可以在这一步将数据存档，将确认可用的数据经过可监控的流程进行整理归类，这里产出的所有数据就是整个公司的数据资产了，到了一定的量就是一笔固定资产。数据汇聚的难点在于如何标准化数据，例如表名标准化，表的标签分类，表的用途，数据的量，是否有数据增量？，数据是否可用？ 需要在业务上下很大的功夫，必要时还要引入智能化处理，例如根据内容训练结果自动打标签，自动分配推荐表名、表字段名等。还有如何从原始数据中导入数据等。经过数据汇聚的数据资产如何提供给具体的使用方使用？在这一步，主要就是考虑数据如何应用，如何将两个？三个？数据表转换成一张能够提供服务的数据。然后定期更新增量。经过前面的那几步，在这一步难点并不太多了，如何转换数据与如何清洗数据、标准数据无二，将两个字段的值转换成一个字段，或者根据多个可用表统计出一张图表数据等等。数据的应用方式很多，有对外的、有对内的，如果拥有了前期的大量数据资产，通过restful API提供给用户？或者提供流式引擎 KAFKA 给应用消费? 或者直接组成专题数据，供自己的应用查询？这里对数据资产的要求比较高，所以前期的工作做好了，这里的自由度很高。大数据开发的难点主要是监控，怎么样规划开发人员的工作？开发人员随随便便采集了一堆垃圾数据，并且直连数据库。 短期来看，这些问题比较小，可以矫正。 但是在资产的量不断增加的时候，这就是一颗定时炸弹，随时会引爆，然后引发一系列对数据资产的影响，例如数据混乱带来的就是数据资产的价值下降，客户信任度变低。如何监控开发人员的开发流程？答案只能是自动化平台，只有自动化平台能够做到让开发人员感到舒心的同时，接受新的事务，抛弃手动时代。这就是前端开发工程师在大数据行业中所占有的优势点，如何制作交互良好的可视化操作界面？如何将现有的工作流程、工作需求变成一个个的可视化操作界面？ 可不可以使用智能化取代一些无脑的操作？从一定意义上来说，大数据开发中，我个人认为前端开发工程师占据着更重要的位置，仅次于大数据开发工程师。至于后台开发，系统开发是第三位的。好的交互至关重要，如何转换数据，如何抽取数据，一定程度上，都是有先人踩过的坑，例如kettle，再例如kafka，pipeline ，解决方案众多。关键是如何交互？ 怎么样变现为可视化界面？ 这是一个重要的课题。现有的各位朋友的侧重点不同，认为前端的角色都是可有可无，我觉得是错误的，后台的确很重要，但是后台的解决方案多。 前端实际的地位更重要，但是基本无开源的解决方案，如果不够重视前端开发， 面临的问题就是交互很烂，界面烂，体验差，导致开发人员的排斥，而可视化这块的知识点众多，对开发人员的素质要求更高。大数据治理大数据治理应该贯穿整个大数据开发流程，它有扮演着重要的角色，浅略的介绍几点：数据血缘数据质量审查全平台监控从数据血缘说起，数据血缘应该是大数据治理的入口，通过一张表，能够清晰看见它的来龙去脉，字段的拆分，清洗过程，表的流转，数据的量的变化，都应该从数据血缘出发，我个人认为，大数据治理整个的目标就是这个数据血缘，从数据血缘能够有监控全局的能力。数据血缘是依托于大数据开发过程的，它包围着整个大数据开发过程，每一步开发的历史，数据导入的历史，都应该有相应的记录，数据血缘在数据资产有一定规模时，基本必不可少。数据开发中，每一个模型（表）创建的结束，都应该有一个数据质量审查的过程，在体系大的环境中，还应该在关键步骤添加审批，例如在数据转换和映射这一步，涉及到客户的数据提供，应该建立一个完善的数据质量审查制度，帮助企业第一时间发现数据存在的问题，在数据发生问题时也能第一时间看到问题的所在，并从根源解决问题，而不是盲目的通过连接数据库一遍一遍的查询sql。监控呢，其实包含了很多的点，例如应用监控，数据监控，预警系统，工单系统等，对我们接管的每个数据源、数据表都需要做到实时监控，一旦发生殆机，或者发生停电，能够第一时间电话或者短信通知到具体负责人，这里可以借鉴一些自动化运维平台的经验的，监控约等于运维，好的监控提供的数据资产的保护也是很重要的。大数据可视化大数据可视化不仅仅是图表的展现，大数据可视化不仅仅是图表的展现，大数据可视化不仅仅是图表的展现，重要的事说三遍，大数据可视化归类的数据开发中，有一部分属于应用类，有一部分属于开发类。在开发中，大数据可视化扮演的是可视化操作的角色， 如何通过可视化的模式建立模型？ 如何通过拖拉拽，或者立体操作来实现数据质量的可操作性？ 画两个表格加几个按钮实现复杂的操作流程是不现实的。在可视化应用中，更多的也有如何转换数据，如何展示数据，图表是其中的一部分，平时更多的工作还是对数据的分析，怎么样更直观的表达数据？这需要对数据有深刻的理解，对业务有深刻的理解，才能做出合适的可视化应用。可视化是可以被再可视化的，例如superset，通过操作sql实现图表，有一些产品甚至能做到根据数据的内容智能分类，推荐图表类型，实时的进行可视化开发，这样的功能才是可视化现有的发展方向，我们需要大量的可视化内容来对公司发生产出，例如服装行业，销售部门：进货出货，颜色搭配对用户的影响，季节对选择的影响   生产部门：布料价格走势？  产能和效率的数据统计？  等等，每一个部门都可以有一个数据大屏，可以通过平台任意规划自己的大屏，所有人每天能够关注到自己的领域动向，这才是大数据可视化应用的具体意义。写在最后洋洋洒洒写了很多，对我近两年的所见所闻所学所想进行了一些总结，有些童鞋会问，不是技术么？为什么没有代码？   博主要说，代码博主要学的，要写的，但是与工作无关，代码是我个人的技能，个人傍身，实现个人想法的重要技能。 但是，代码与业务的关系不大，在工作中，懂业务的人代码写的更好，因为他知道公司想要什么。 如果你业务很差，那也没关系，你代码好就行了呀，根据别人的交代干活，也是很不错的。技术和业务是相辅相成的，稍后博主总结代码的精进。写完了，博主的焦虑一丝未少，我的代码规范性不够，目前技术栈js、java、nodejs、python 。主业js熟练度80%吧，正在研究阮一峰的es6（看的差不多）和vuejs的源码（有点搁浅），vuejs算是中等，css和布局方面可以说还可以，另外d3.js，go.js都是处于会用，能干活。 nodejs呢，express和koa无问题，看过一些express的源代码，还写过两个中间件。java、python都处于能做项目的程度，目前也不想抽很多精力去深入它们，就想要保持在想用能用的地步吧。未来的几年，博主努力工作，多学学人工智能、大数据开发的知识，未来这块应该还有一些热度的吧。最后，和大家共勉，更希望大家能给一些规划建议，三人行，必有我师焉。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/07/cecb3d3562d80f7f904e989de853d49d.png"]}
{"title": "Linux 文件系统详解 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n这篇教程将帮你快速了解 Linux 文件系统。早在 1996 年，在真正理解文件系统的结构之前，我就学会了如何在我崭新的 Linux 上安装软件。这是一个问题，但对程序来说不是大问题，因为即使我不知道实际的可执行文件在哪里，它们也会神奇地工作。问题在于文档。你知道，那时候，Linux 不是像今天这样直观、用户友好的系统。你必须读很多东西。你必须知道你的 CRT 显示器的扫描频率以及拨号调制解调器的噪音来龙去脉，以及其他数以百计的事情。 我很快就意识到我需要花一些时间来掌握目录的组织方式以及 （不是用于“其它”文件），（不是用于“用户”文件）和  （不是“垃圾桶”）的意思。本教程将帮助你比我当时更快地了解这些。从终端窗口探索 Linux 文件系统是有道理的，这并不是因为作者是一个脾气暴躁的老人，并且对新孩子和他们漂亮的图形工具不以为然（尽管某些事实如此），而是因为终端，尽管只是文本界面，才是更好地显示 Linux 目录树结构的工具。事实上，帮助你了解这一切的、应该首先安装的第一个工具的名为：。如果你正在使用 Ubuntu 或 Debian ，你可以：在 Red Hat 或 Fedora :对于 SUSE/openSUSE 可以使用 ：对于使用 Arch （Manjaro，Antergos，等等）使用：……等等。一旦安装好，在终端窗口运行  命令：上述指令中的  指的是根目录。系统中的其他目录都是从根目录分支而出，当你运行  命令，并且告诉它从根目录开始，那么你就可以看到整个目录树，系统中的所有目录及其子目录，还有它们的文件。如果你已经使用你的系统有一段时间了，这可能需要一段时间，因为即使你自己还没有生成很多文件，Linux 系统及其应用程序总是在记录、缓存和存储各种临时文件。文件系统中的条目数量会快速增长。不过，不要感到不知所措。 相反，试试这个：你应该看到如图 1 所示。上面的指令可以翻译为“只显示以 （根目录） 开头的目录树的第一级”。  选项告诉树你想看到多少层目录。大多数 Linux 发行版都会向你显示与你在上图中看到的相同或非常类似的结构。 这意味着，即使你现在感到困惑，掌握这一点，你将掌握大部分（如果不是全部的话）全世界的 Linux 文件系统。为了让你开始走上掌控之路，让我们看看每个目录的用途。 当我们查看每一个目录的时候，你可以使用  来查看他们的内容。从上到下，你所看到的目录如下 目录是包含一些二进制文件的目录，即可以运行的一些应用程序。 你会在这个目录中找到上面提到的  程序，以及用于新建和删除文件和目录、移动它们基本工具。还有其它一些程序，等等。文件系统树的其他部分有更多的  目录，但我们将在一会儿讨论这些目录。 目录包含启动系统所需的文件。我必须要说吗？ 好吧，我会说：！ 如果你在这里弄乱了其中一个文件，你可能无法运行你的 Linux，修复被破坏的系统是非常痛苦的一件事。 另一方面，不要太担心无意中破坏系统：你必须拥有超级用户权限才能执行此操作。 的目录名称会让人变得非常的困惑。 得名于最早的 Unix 系统们，它的字面意思是 “etcetera”（诸如此类） ，因为它是系统文件管理员不确定在哪里放置的文件的垃圾场。现在，说  是“要配置的所有内容Everything To Configure”更为恰当，因为它包含大部分（如果不是全部的话）的系统配置文件。 例如，包含系统名称、用户及其密码、网络上计算机名称以及硬盘上分区的安装位置和时间的文件都在这里。 再说一遍，如果你是 Linux 的新手，最好是不要在这里接触太多，直到你对系统的工作有更好的理解。 是你可以找到用户个人目录的地方。在我的情况下， 下有两个目录：，其中包含我所有的东西；另外一个目录是  目录，以防有客人需要使用我的电脑。 是库文件所在的地方。库是包含应用程序可以使用的代码文件。它们包含应用程序用于在桌面上绘制窗口、控制外围设备或将文件发送到硬盘的代码片段。在文件系统周围散布着更多的  目录，但是这个直接挂载在  的  目录是特殊的，除此之外，它包含了所有重要的内核模块。 内核模块是使你的显卡、声卡、WiFi、打印机等工作的驱动程序。在  目录中，当你插入外部存储器试图访问它时，将自动挂载它。与此列表中的大多数其他项目不同， 并不追溯到 1970 年代，主要是因为当计算机正在运行而动态地插入和检测存储（U 盘、USB 硬盘、SD 卡、外部 SSD 等)，这是近些年才发生的事。然而， 目录是一些过去的残余。这是你手动挂载存储设备或分区的地方。现在不常用了。 目录通常是你编译软件（即，你从源代码构建，并不是从你的系统的软件库中安装软件）的地方。应用程序最终会出现在  目录，库会在  目录中出现。稍微的题外话：应用程序和库的另一个地方是 ，在这里安装软件时，也会有  和  目录。开发人员如何配置文件来控制编译和安装过程，这就决定了软件安装到哪个地方。，就像  是一个虚拟目录。它包含有关你的计算机的信息，例如关于你的 CPU 和你的 Linux 系统正在运行的内核的信息。与  一样，文件和目录是在计算机启动或运行时生成的，因为你的系统正在运行且会发生变化。 是系统的超级用户（也称为“管理员”）的主目录。 它与其他用户的主目录是分开的，。 所以把自己的东西放在你自己的目录中，伙计们。 是另一个新出现的目录。系统进程出于自己不可告人的原因使用它来存储临时数据。这是另一个的文件夹。 与  类似，但它包含的应用程序只有超级用户（即首字母的  ）才需要。你可以使用  命令使用这些应用程序，该命令暂时允许你在许多 Linux 发行版上拥有超级用户权限。 目录通常包含可以安装、删除和格式化各种东西的工具。你可以想象，如果你使用不当，这些指令中有一些是致命的，所以要小心处理。 目录是在 UNIX 早期用户的主目录所处的地方。然而，正如我们上面看到的，现在  是用户保存他们的东西的地方。如今， 包含了大量目录，而这些目录又包含了应用程序、库、文档、壁纸、图标和许多其他需要应用程序和服务共享的内容。你还可以在  目录下找到 ，， 目录，它们与挂载到根目录下的那些有什么区别呢？现在的区别不是很大。在早期， 目录（挂载在根目录下的）只会包含一些基本的命令，例如 、 和  ；这是一些在安装系统的时候就会预装的一些命令，用于维护系统的一个基本的命令。 而  目录则包含了用户自己安装和用于工作的软件，例如文字处理器，浏览器和一些其他的软件。但是许多现代的 Linux 发行版只是把所有的东西都放到  中，并让  指向 ，以防彻底删除它会破坏某些东西。因此，Debian、Ubuntu 和 Mint 仍然保持  和  （和  和  ）分离；其他的，比如 Arch 和它衍生版，只是有一个“真实”存储二进制程序的目录，，其余的任何  目录是指向 bin 的“假”目录。 目录包含服务器的数据。如果你正在 Linux 机器上运行 Web 服务器，你网站的 HTML文件将放到 （或 ）。 如果你正在运行 FTP 服务器，则你的文件将放到 。 是另一个类似  和  的虚拟目录，它还包含连接到计算机的设备的信息。在某些情况下，你还可以操纵这些设备。 例如，我可以通过修改存储在  中的值来更改笔记本电脑屏幕的亮度（在你的机器上你可能会有不同的文件）。但要做到这一点，你必须成为超级用户。原因是，与许多其它虚拟目录一样，在  中打乱内容和文件可能是危险的，你可能会破坏系统。直到你确信你知道你在做什么。否则不要动它。 包含临时文件，通常由正在运行的应用程序放置。文件和目录通常（并非总是）包含应用程序现在不需要但以后可能需要的数据。你还可以使用  来存储你自己的临时文件 ——  是少数挂载到根目录下而你可以在不成为超级用户的情况下与它进行实际交互的目录之一。 最初被如此命名是因为它的内容被认为是可变的variable，因为它经常变化。今天，它有点用词不当，因为还有许多其他目录也包含频繁更改的数据，特别是我们上面看到的虚拟目录。不管怎样， 目录包含了放在  子目录的日志文件之类。日志是记录系统中发生的事件的文件。如果内核中出现了什么问题，它将被记录到  下的文件中；如果有人试图从外部侵入你的计算机，你的防火墙也将记录尝试。它还包含用于任务的假脱机程序。这些“任务”可以是你发送给共享打印机必须等待执行的任务，因为另一个用户正在打印一个长文档，或者是等待递交给系统上的用户的邮件。你的系统可能还有一些我们上面没有提到的目录。例如，在屏幕截图中，有一个  目录。这是因为这张截图是在 Ubuntu 系统上截取的。Ubuntu 最近将  包作为一种分发软件的方式。 目录包含所有文件和从 snaps 安装的软件。这里仅仅谈了根目录，但是许多子目录都指向它们自己的一组文件和子目录。图 2 给出了基本文件系统的总体概念（图片是在 Paul Gardner 的 CC BY-SA 许可下提供的），。要自行探索文件系统，请使用  命令：将带你到你所选择的目录（  代表更改目录）。如果你不知道你在哪儿，会告诉你，你到底在哪里，（  代表打印工作目录 ），同时 命令在没有任何选项或者参数的时候，将会直接带你到你自己的主目录，这是一个安全舒适的地方。最后，将会带你到上一层目录，会使你更加接近根目录，如果你在  目录，然后你执行  命令，你将会跳转到  目录要查看目录里有什么内容，使用  或这简单的使用  列出你所在目录的内容。当然，你总是可以使用  来获得目录中内容的概述。在  上试试——里面有很多有趣的东西。尽管 Linux 发行版之间存在细微差别，但它们的文件系统的布局非常相似。 你可以这么说：一旦你了解一个，你就会都了解了。 了解文件系统的最好方法就是探索它。 因此，伴随  ， 和  进入未知的领域吧。你不会只是因为查看文件系统就破坏了文件系统，因此请从一个目录移动到另一个目录并进行浏览。 很快你就会发现 Linux 文件系统及其布局的确很有意义，并且你会直观地知道在哪里可以找到应用程序，文档和其他资源。通过 Linux 基金会和 edX 免费的 “” 课程了解更多有关 Linux 的信息。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "手把手指导您使用 Git - 文章 - 伯乐在线", "tag": ["IT技术", "Git", "Linux"], "goodNum": "1", "saveNum": " 5 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n如果您从未使用过 ，甚至可能从未听说过它。莫慌张，只需要一步步地跟着这篇入门教程，很快您就会在  上拥有一个全新的 Git 仓库。在开始之前，让我们先理清一个常见的误解：Git 并不是 GitHub。Git 是一套版本控制系统（或者说是一款软件），能够协助您跟踪计算机程序和文件在任何时间的更改。它同样允许您在程序、代码和文件操作上与同事协作。GitHub 以及类似服务（包括 GitLab 和 BitBucket）都属于部署了 Git 程序的网站，能够托管您的代码。在  网站上（免费）创建一个账户是最简单的方式。选择一个用户名（比如说，octocat123），输入您的邮箱地址和密码，然后点击 。进入之后，您将看到下方插图的界面：一个仓库（ repository），类似于能储存物品的场所或是容器；在这里，我们创建仓库存储代码。在  符号（在插图的右上角，我已经选中它了） 的下拉菜单中选择 。给您的仓库命名（比如说，Demo）然后点击 。无需考虑本页面的其他选项。恭喜！您已经在 GitHub.com 中建立了您的第一个仓库。当仓库创建完毕后，界面将和下方一致：不必惊慌，它比看上去简单。跟紧步骤。忽略其他内容，注意截图上的 “…or create a new repository on the command line,”。在您的计算机中打开终端。键入  然后回车。如果命令行显示 ，在您的操作系统或发行版  命令。键入  并回车检查是否成功安装；如果安装成功，您将看见大量关于使用该命令的说明信息。在终端内输入：这个命令将会创建一个名为 Demo 的目录（文件夹）。如下命令将会切换终端目录，跳转到 Demo 目录：然后输入：创建一个名为  的文件，并写入 。检查文件是否创建成功，请输入：这将会为您显示  文件的内容，如果文件创建成功，您的终端会有如下显示：使用 Git 程序告诉您的电脑，Demo 是一个被 Git 管理的目录，请输入：然后，告诉 Git 程序您关心的文件并且想在此刻起跟踪它的任何改变，请输入：目前为止，您已经创建了一个文件，并且已经通知了 Git，现在，是时候创建一次提交commit了。提交可以看作是一个里程碑。每当完成一些工作之时，您都可以创建一次提交，保存文件当前版本，这样一来，您可以返回之前的版本，并且查看那时候的文件内容。无论何时您修改了文件，都可以对文件创建一个上一次的不一样的新版本。创建一次提交，请输入：就是这样！刚才您创建了包含一条注释为 “first commit” 的 Git 提交。每次提交，您都必须编辑注释信息；它不仅能协助您识别提交，而且能让您理解此时您对文件做了什么修改。这样到了明天，如果您在文件中添加新的代码，您可以写一句提交信息：“添加了新的代码”，然后当您一个月后回来查看提交记录或者 Git 日志（即提交列表），您还能知道当时的您在文件夹里做了什么。现在，是时候用如下命令将您的计算机连接到 GitHub 仓库了：让我们一步步的分析这行命令。我们通知 Git 去添加一个叫做  （起源）的，拥有地址为 （它也是您的仓库的 GitHub 地址） 的  （远程仓库）。当您提交代码时，这允许您在 GitHub.com 和 Git 仓库交互时使用  这个名称而不是完整的 Git 地址。为什么叫做 ？当然，您可以叫点别的，只要您喜欢（惯例而已）。现在，我们已经将本地 Demo 仓库副本连接到了其在 GitHub.com 远程副本上。您的终端看起来如下：此刻我们已经连接到远程仓库，可以推送我们的代码 到 GitHub.com（例如上传  文件）。执行完毕后，您的终端会显示如下信息：然后，如果您访问 ，您会看到截图内显示的情况：就是这么回事！您已经创建了您的第一个 GitHub 仓库，连接到了您的电脑，并且从你的计算机推送（或者称：上传）一个文件到 GitHub.com 名叫 Demo 的远程仓库上了。下一次，我将编写关于 Git 复制（从 GitHub 上下载文件到你的计算机上）、添加新文件、修改现存文件、推送（上传）文件到 GitHub。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/02/2027c50856ddfe647e45b4ac2e86c9f1.jpg"]}
{"title": "Linux vs. Unix：有什么不同？ - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n深入了解这两个有许多共同的传统和相同的目标的操作系统之间的不同。如果你是位二、三十岁的软件开发人员，那么你已经成长在一个由 Linux 主导的世界。数十年来，它一直是数据中心的重要参与者，尽管很难找到明确的操作系统市场份额报告，但 Linux 的数据中心操作系统份额可能高达 70%，而 Windows 及其变体几乎涵盖了所有剩余的百分比。使用任何主流公共云服务的开发人员都可以预期目标系统会运行 Linux。近些年来，随着 Android 和基于 Linux 的嵌入式系统在智能手机、电视、汽车和其他设备中的应用，Linux 已经随处可见。即便如此，大多数软件开发人员，甚至是那些在这场历史悠久的 “Linux 革命”中长大的软件开发人员，也都听过说 Unix。它听起来与 Linux 相似，你可能已经听到人们互换使用这些术语。或者你也许听说过 Linux 被称为“类 Unix ”操作系统。那么，Unix 是什么？漫画喜欢将它画成巫师一样留着“灰胡子”的形象，坐在发光的绿色屏幕后面，写着 C 代码和 shell 脚本，由老式的、滴灌的咖啡提供动力。但是，Unix 的历史比上世纪 70 年代那些留着胡子的 C 程序员要丰富得多。虽然详细介绍 Unix 历史和 “Unix 与 Linux” 比较的文章比比皆是，但本文将提供高级背景和列出这些互补世界之间的主要区别。Unix 的历史始于 20 世纪 60 年代后期的 AT&T 贝尔实验室，有一小组程序员希望为 PDP-7 编写一个多任务、多用户操作系统。这个贝尔实验室研究机构的团队中最著名的两名成员是 Ken Thompson 和 Dennis Ritchie。尽管 Unix 的许多概念都是其前身（）的衍生物，但 Unix 团队早在 70 年代就决定用 C 语言重写这个小型操作系统，这是将 Unix 与其他操作系统区分开来的原因。当时，操作系统很少，更不要说可移植的操作系统。相反，由于它们的设计和底层语言的本质，操作系统与他们所编写的硬件平台紧密相关。而通过 C 语言重构 Unix、Unix 现在可以移植到许多硬件体系结构中。除了这种新的可移植性，之所以使得 Unix 迅速扩展到贝尔实验室以外的其他研究和学术机构甚至商业用途，是因为操作系统设计原则的几个关键点吸引了用户和程序员们。首先是 Ken Thompson 的 成为模块化软件设计和计算的强大模型。Unix 哲学推荐使用小型的、专用的程序组合起来完成复杂的整体任务。由于 Unix 是围绕文件和管道设计的，因此这种“管道”模式的输入和输出程序的组合成一组线性的输入操作，现在仍然流行。事实上，目前的云功能即服务（FaaS）或无服务器计算模型要归功于 Unix 哲学的许多传统。到 70 年代末和 80 年代，Unix 成为了一个操作系统家族的起源，它遍及了研究和学术机构以及日益增长的商业 Unix 操作系统业务领域。Unix 不是开源软件，Unix 源代码可以通过与它的所有者 AT&T 达成协议来获得许可。第一个已知的软件许可证于 1975 年出售给伊利诺伊大学University of Illinois。Unix 在学术界迅速发展，在 Ken Thompson 在上世纪 70 年代的学术假期间，伯克利成为一个重要的活动中心。通过在伯克利的各种有关 Unix 的活动，Unix 软件的一种新的交付方式诞生了：伯克利软件发行版Berkeley Software Distribution（BSD）。最初，BSD 不是 AT&T Unix 的替代品，而是一种添加类似于附加软件和功能。在 1979 年， 2BSD（第二版伯克利软件发行版）出现时，伯克利研究生 Bill Joy 已经添加了现在非常有名的程序，例如  和 C shell（）。除了成为 Unix 家族中最受欢迎的分支之一的 BSD 之外，Unix 的商业产品的爆发贯穿了二十世纪八、九十年代，其中包括 HP-UX、IBM 的 AIX、 Sun 的 Solaris、 Sequent 和 Xenix 等。随着分支从根源头发展壮大，“”开始了，标准化成为社区的新焦点。POSIX 标准诞生于 1988 年，其他标准化后续工作也开始通过 The Open Group 在 90 年代到来。在此期间，AT&T 和 Sun 发布了 System V Release 4（SVR4），许多商业供应商都采用了这一版本。另外，BSD 系列操作系统多年来一直在增长，最终一些开源的变体在现在熟悉的 下发布。这包括 FreeBSD、 OpenBSD 和 NetBSD，每个在 Unix 服务器行业的目标市场略有不同。这些 Unix 变体今天仍然有一些在使用，尽管人们已经看到它们的服务器市场份额缩小到个位数字（或更低）。在当今的所有 Unix 系统中，BSD 可能拥有最大的安装基数。另外，每台 Apple Mac 硬件设备从历史的角度看都可以算做是 BSD ，这是因为 OS X（现在是 macOS）操作系统是 BSD 衍生产品。虽然 Unix 的全部历史及其学术和商业变体可能需要更多的篇幅，但为了我们文章的重点，让我们来讨论 Linux 的兴起。今天我们所说的 Linux 操作系统实际上是 90 年代初期的两个努力的结合。Richard Stallman 希望创建一个真正的自由而开放源代码的专有 Unix 系统的替代品。他正在以 GNU 的名义开发实用程序和程序，这是一种递归的说法，意思是“GNU‘s not Unix!”。虽然当时有一个内核项目正在进行，但事实证明这是一件很困难的事情，而且没有内核，自由和开源操作系统的梦想无法实现。而这是 Linus Torvald 的工作 —— 生产出一种可工作和可行的内核，他称之为 Linux — 它将整个操作系统带入了生活。鉴于 Linus 使用了几个 GNU 工具（例如 GNU 编译器集合，即 ），GNU 工具和 Linux 内核的结合是完美的搭配。Linux 发行版采用了 GNU 的组件、Linux 内核、MIT 的 X-Windows GUI 以及可以在开源 BSD 许可下使用的其它 BSD 组件。像 Slackware 和 Red Hat 这样的发行版早期的流行给了 20 世纪 90 年代的“普通 PC 用户”一个进入 Linux 操作系统的机会，并且让他们在工作和学术生活中可以使用许多 Unix 系统特有的功能和实用程序。由于所有 Linux 组件都是自由和开放的源代码，任何人都可以通过一些努力来创建一个 Linux 发行版，所以不久后发行版的总数达到了数百个。今天， 列出了 312 种各种形式的独特的 Linux 发行版。当然，许多开发人员通过云提供商或使用流行的免费发行版来使用 Linux，如 Fedora、 Canonical 的 Ubuntu、 Debian、 Arch Linux、 Gentoo 和许多其它变体。随着包括 IBM 在内的许多企业从专有 Unix 迁移到 Linux 上并提供了中间件和软件解决方案，商用 Linux 产品在自由和开源组件之上提供支持变得可行。红帽公司围绕 Red Hat Enterprise Linux（红帽企业版 Linux） 建立了商业支持模式，德国供应商 SUSE 使用 SUSE Linux Enterprise Server（SLES）也提供了这种模式。到目前为止，我们已经了解了 Unix 的历史以及 Linux 的兴起，以及 GNU/自由软件基金会对 Unix 的自由和开源替代品的支持。让我们来看看这两个操作系统之间的差异，它们有许多共同的传统和许多相同的目标。从用户体验角度来看，两者差不多！Linux 的很大吸引力在于操作系统在许多硬件体系结构（包括现代 PC）上的可用性以及类似使用 Unix 系统管理员和用户熟悉的工具的能力。由于 POSIX 的标准和合规性，在 Unix 上编写的软件可以针对 Linux 操作系统进行编译，通常只有少量的移植工作量。在很多情况下，Shell 脚本可以在 Linux 上直接使用。虽然一些工具在 Unix 和 Linux 之间有着略微不同的标志或命令行选项，但许多工具在两者上都是相同的。一方面要注意的是，macOS 硬件和操作系统作为主要针对 Linux 的开发平台的流行可能归因于类 BSD 的 macOS 操作系统。许多用于 Linux 系统的工具和脚本可以在 macOS 终端内轻松工作。Linux 上的许多开源软件组件都可以通过  等工具轻松获得。Linux 和 Unix 之间的其他差异主要与许可模式有关：开源与专有许可软件。另外，在 Unix 发行版中缺少一个影响软件和硬件供应商的通用内核。对于 Linux，供应商可以为特定的硬件设备创建设备驱动程序，并期望在合理的范围内它可以在大多数发行版上运行。由于 Unix 家族的商业和学术分支，供应商可能必须为 Unix 的变体编写不同的驱动程序，并且需要许可和其他相关的权限才能访问 SDK 或软件的分发模型，以跨越多个二进制设备驱动程序的 Unix 变体。随着这两个社区在过去十年中的成熟，Linux 的许多优点已经在 Unix 世界中被采用。当开发人员需要来自不属于 Unix 的 GNU 程序的功能时，许多 GNU 实用程序可作为 Unix 系统的附件提供。例如，IBM 的 AIX 为 Linux 应用程序提供了一个 AIX Toolbox，其中包含数百个 GNU 软件包（如 Bash、 GCC、 OpenLDAP 和许多其他软件包），这些软件包可添加到 AIX 安装包中以简化 Linux 和基于 Unix 的 AIX 系统之间的过渡。专有的 Unix 仍然活着而且还不错，许多主要供应商承诺支持其当前版本，直到 2020 年。不言而喻，Unix 还会在可预见的将来一直出现。此外，Unix 的 BSD 分支是开源的，而 NetBSD、 OpenBSD 和 FreeBSD 都有强大的用户基础和开源社区，它们可能不像 Linux 那样显眼或活跃，但在最近的服务器报告中，在 Web 服务等领域它们远高于专有 Unix 的数量。Linux 已经显示出其超越 Unix 的显著优势在于其在大量硬件平台和设备上的可用性。树莓派Raspberry Pi受到业余爱好者的欢迎，它是由 Linux 驱动的，为运行 Linux 的各种物联网设备打开了大门。我们已经提到了 Android 设备，汽车（包括 Automotive Grade Linux）和智能电视，其中 Linux 占有巨大的市场份额。这个星球上的每个云提供商都提供运行 Linux 的虚拟服务器，而且当今许多最受欢迎的原生云架构都是基于 Linux 的，无论你是在谈论容器运行时还是 Kubernetes，或者是许多正在流行的无服务器平台。其中一个最显著的代表 Linux 的优势是近年来微软的转变。如果你十年前告诉软件开发人员，Windows 操作系统将在 2016 年“运行 Linux”，他们中的大多数人会歇斯底里地大笑。 但是 Windows Linux 子系统（WSL）的存在和普及，以及最近宣布的诸如 Docker 的 Windows 移植版，包括 LCOW（Windows 上的 Linux 容器）支持等功能都证明了 Linux 在整个软件世界中所产生的影响 —— 而且显然还会继续存在。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/11/1d34dd467641215c527e32ede94fe494.jpg"]}
{"title": "Git 分支操作介绍 - 文章 - 伯乐在线", "tag": ["IT技术", "Git", "Linux"], "goodNum": "1", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n在本系列的前两篇文章中，我们，学会如何。在这第三篇文章中，我将介绍 Git 分支，为何以及如何使用分支。不妨用树来描绘 Git 仓库。图中的树有很多分支，或长或短，或从树干延伸或从其它分支延伸。在这里，我们用树干比作仓库的 master 分支，其中  代指 ”master 分支”，是 Git 仓库的中心分支或第一个分支。为简单起见，我们假设  是树干，其它分支都是从该分支分出的。使用分支的主要理由为：如果你希望为项目增加新特性，但很可能会影响当前可正常工作的代码。对于该项目的活跃用户而言，这是很糟糕的事情。与其将特性加入到其它人正在使用的  分支，更好的方法是在仓库的其它分支中变更代码，下面会给出具体的工作方式。更重要的是，用于协作。如果所有人都在你代码仓库的  分支上操作，会引发很多混乱。对编程语言或项目的知识和阅历因人而异；有些人可能会编写有错误或缺陷的代码，也可能会编写你觉得不适合该项目的代码。使用分支可以让你核验他人的贡献并选择适合的加入到项目中。（这里假设你是代码库唯一的所有者，希望对增加到项目中的代码有完全的控制。在真实的项目中，代码库有多个具有合并代码权限的所有者）让我们回顾，看一下在我们的 Demo 目录中分支是怎样的。如果你没有完成上述操作，请按照文章中的指示从 GitHub 克隆代码并进入 Demo 目录。运行如下命令： 命令（是当前工作目录的英文缩写）返回当前你所处的目录（以便确认你在  目录中）， 列出该项目在你主机上的全部分支， 列出当前目录下的所有文件。你的终端输出类似于：在  分支中，只有一个文件 。（Git 会友好地忽略掉其它目录和文件。）接下来，运行如下命令：第一条命令  告知你当前位于 ，（就像在终端中看到的那样）它与  处于同步状态，这意味着 master 分支的本地副本中的全部文件也出现在 GitHub 中。两份副本没有差异，所有的提交也是一致的。下一条命令  中的  告知 Git 创建一个名为  的新分支，然后  命令将我们切换到新创建的分支。运行第三条命令  确保你已经位于刚创建的分支下。如你所见， 告知你当前处于  分支，没有变更需要提交。这是因为我们既没有增加新文件，也没有修改已有文件。如果希望以可视化的方式查看分支，可以运行  命令。如果遇到报错 ，请先安装  软件包（找到你操作系统对应的安装文档，以获得安装方式）。（LCTT 译注：需要在有 X 服务器的终端运行 ，否则会报错）下图展示了我们在 Demo 项目中的所作所为：你最后一次提交（的对应信息）是 ，在此之前有三次提交。当前的提交用黄点标注，之前的提交用蓝点标注，黄点和  之间的三个方块展示每个分支所在的位置（或者说每个分支中的最后一次提交的位置）。由于  刚创建，提交状态与  分支及其对应的记为  的远程  分支保持一致。（非常感谢来自 Red Hat 的  让我知道  这个工具）下面让我们在  分支下创建一个新文件并观察终端输出。运行如下命令：第一条命令中的  创建了名为  的文件，接着  打印出文件内容，最后  告知你我们  分支的当前状态。在下面的终端输出中，Git 告知  分支下有一个名为  的文件当前处于  状态。这表明我们没有让 Git 追踪发生在文件  上的变更。下一步是增加文件，提交变更并将  文件推送至  分支（请回顾本系列上一篇文章获得更多细节）。在上述命令中， 命令使用的分支参数为  而不是 。Git 添加  并将变更推送到你 GitHub 账号下的 Demo 仓库中，告知你在 GitHub 上创建了一个与你本地副本分支  一样的新分支。终端输出截图给出了运行命令的细节及命令输出。当你访问 GitHub 时，在分支选择的下拉列表中可以发现两个可供选择的分支。点击  切换到  分支，你可以看到在此分支上新增的文件。截至目前，我们有两个分支：一个是  分支，只有一个  文件；另一个是  分支，有两个文件。你已经知道如何创建分支了，下面我们再创建一个分支。输入如下命令：我不再给出终端输出，需要你自己尝试，但你可以在  中验证你的结果。由于我们增加了两个分支，下面删除其中的一个（），包括两步： 你不能删除正在操作的分支，故切换到  分支 （或其它你希望保留的分支），命令及终端输出如下： 可以列出可用的分支，使用  切换到  分支，然后使用  删除该分支。再次运行  检查是否只剩下两个分支（而不是三个）。 使用如下命令删除  的远程分支：\n\r\n\r\n\t\t\r\n\r\n\n上面  命令中分支名称前面的冒号（）告知 GitHub 删除分支。另一种写法为：其中  (也可以用 ) 也用于告知 GitHub 删除你的分支。我们学习了 Git 分支的使用，在本系列的下一篇文章中，我们将介绍如何执行  和  操作，对于多人同时的贡献的项目而言，这是很必须学会的。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/06/b84f8d56e47a8496314a55a39b08ad10.jpg"]}
{"title": "分布式之消息队列复习精讲 - 文章 - 伯乐在线", "tag": ["IT技术", "分布式", "数据库"], "goodNum": "2", "saveNum": " 9 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n引言博主有两位朋友分别是小A和小B:小A，工作于传统软件行业(某社保局的软件外包公司)，每天工作内容就是和产品聊聊需求，改改业务逻辑。再不然就是和运营聊聊天，写几个SQL，生成下报表。又或者接到客服的通知，某某功能故障了，改改数据，然后下班部署上线。每天过的都是这种生活，技术零成长。小B，工作于某国企，虽然能接触到一些中间件技术。然而，他只会订阅/发布消息。通俗点说，就是调调API。对为什么使用这些中间件啊？如何保证高可用啊？没有充分的认识。庆幸的是两位朋友都很有上进心，于是博主写这篇文章，帮助他们复习一下关于消息队列中间件这块的要点本文大概围绕如下几点进行阐述:为什么使用消息队列？使用消息队列有什么缺点?消息队列如何选型?如何保证消息队列是高可用的？如何保证消息不被重复消费?如何保证消费的可靠性传输?如何保证消息的顺序性？我们围绕以上七点进行阐述。需要说明一下，本文不是《消息队列从入门到精通》这种课程，因此只是提供一个复习思路，而不是去教你们怎么调用消息队列的API。建议对消息队列不了解的人，去找点消息队列的博客看看，再看本文，收获更大正文:一个用消息队列的人，不知道为啥用，这就有点尴尬。没有复习这点，很容易被问蒙，然后就开始胡扯了。\n:这个问题,咱只答三个最主要的应用场景(不可否认还有其他的，但是只答三个主要的),即以下六个字:\n\n传统模式的缺点：系统间耦合性太强，如上图所示，系统A在代码中直接调用系统B和系统C的代码，如果将来D系统接入，系统A还需要修改代码，过于麻烦！\n\n中间件模式的的优点：将消息写入消息队列，需要消息的系统自己从消息队列中订阅，从而系统A不需要做任何修改。\n\n传统模式的缺点：一些非必要的业务逻辑以同步的方式运行，太耗费时间。\n\n中间件模式的的优点：将消息写入消息队列，非必要的业务逻辑以异步的方式运行，加快响应速度\n\n传统模式的缺点：并发量大的时候，所有的请求直接怼到数据库，造成数据库连接异常\n\n中间件模式的的优点：系统A慢慢的按照数据库能处理的并发量，从消息队列中慢慢拉取消息。在生产中，这个短暂的高峰期积压是允许的。:一个使用了MQ的项目，如果连这个问题都没有考虑过，就把MQ引进去了，那就给自己的项目带来了风险。我们引入一个技术，要对这个技术的弊端有充分的认识，才能做好预防。\n:回答也很容易，从以下两个个角度来答:你想啊，本来其他系统只要运行好好的，那你的系统就是正常的。现在你非要加个消息队列进去，那消息队列挂了，你的系统不是呵呵了。因此，系统可用性降低:要多考虑很多方面的问题，比如一致性问题、如何保证消息不被重复消费，如何保证保证消息可靠传输。因此，需要考虑的东西更多，系统复杂性增大。但是，我们该用还是要用的。先说一下，博主只会ActiveMQ,RabbitMQ,RocketMQ,Kafka，对什么ZeroMQ等其他MQ没啥理解，因此只能基于这四种MQ给出回答。\n:既然在项目中用了MQ，肯定事先要对业界流行的MQ进行调研，如果连每种MQ的优缺点都没了解清楚，就拍脑袋依据喜好，用了某种MQ，还是给项目挖坑。如果面试官问:”你为什么用这种MQ？。”你直接回答”领导决定的。”这种回答就很LOW了。\n:首先，咱先上，看看该MQ的更新频率:我们可以看出，ActiveMq几个月才发一次版本，据说研究重心在他们的下一代产品Apollo。\n接下来，我们再去去看一下,RabbitMQ的更新频率我们可以看出，RabbitMQ版本发布比ActiveMq频繁很多。至于RocketMQ和kafka就不带大家看了，总之也比ActiveMQ活跃的多。详情，可自行查阅。\n再来一个性能对比表综合上面的材料得出以下两点:\n(1)中小型软件公司，建议选RabbitMQ.一方面，erlang语言天生具备高并发的特性，而且他的管理界面用起来十分方便。正所谓，成也萧何，败也萧何！他的弊端也在这里，虽然RabbitMQ是开源的，然而国内有几个能定制化开发erlang的程序员呢？所幸，RabbitMQ的社区十分活跃，可以解决开发过程中遇到的bug，这点对于中小型公司来说十分重要。不考虑rocketmq和kafka的原因是，一方面中小型软件公司不如互联网公司，数据量没那么大，选消息中间件，应首选功能比较完备的，所以kafka排除。不考虑rocketmq的原因是，rocketmq是阿里出品，如果阿里放弃维护rocketmq，中小型公司一般抽不出人来进行rocketmq的定制化开发，因此不推荐。\n(2)大型软件公司，根据具体使用在rocketMq和kafka之间二选一。一方面，大型软件公司，具备足够的资金搭建分布式环境，也具备足够大的数据量。针对rocketMQ,大型软件公司也可以抽出人手对rocketMQ进行定制化开发，毕竟国内有能力改JAVA源码的人，还是相当多的。至于kafka，根据业务场景选择，如果有日志采集功能，肯定是首选kafka了。具体该选哪个，看使用场景。:在第二点说过了，引入消息队列后，系统的可用性下降。在生产中，没人使用单机模式的消息队列。因此，作为一个合格的程序员，应该对消息队列的高可用有很深刻的了解。如果面试的时候，面试官问，你们的消息中间件如何保证高可用的？你的回答只是表明自己只会订阅和发布消息，面试官就会怀疑你是不是只是自己搭着玩，压根没在生产用过。\n:这问题，其实要对消息队列的集群模式要有深刻了解，才好回答。\n以rcoketMQ为例，他的集群就有多master 模式、多master多slave异步复制模式、多 master多slave同步双写模式。多master多slave模式部署架构图(网上找的,偷个懒，懒得画):\n\n其实博主第一眼看到这个图，就觉得和kafka好像，只是NameServer集群，在kafka中是用zookeeper代替，都是用来保存和发现master和slave用的。通信过程如下:\nProducer 与 NameServer集群中的其中一个节点（随机选择）建立长连接，定期从 NameServer 获取 Topic 路由信息，并向提供 Topic 服务的 Broker Master 建立长连接，且定时向 Broker 发送心跳。Producer 只能将消息发送到 Broker master，但是 Consumer 则不一样，它同时和提供 Topic 服务的 Master 和 Slave建立长连接，既可以从 Broker Master 订阅消息，也可以从 Broker Slave 订阅消息。\n那么kafka呢,为了对比说明直接上kafka的拓补架构图(也是找的，懒得画)\n\n如上图所示，一个典型的Kafka集群中包含若干Producer（可以是web前端产生的Page View，或者是服务器日志，系统CPU、Memory等），若干broker（Kafka支持水平扩展，一般broker数量越多，集群吞吐率越高），若干Consumer Group，以及一个Zookeeper集群。Kafka通过Zookeeper管理集群配置，选举leader，以及在Consumer Group发生变化时进行rebalance。Producer使用push模式将消息发布到broker，Consumer使用pull模式从broker订阅并消费消息。\n至于rabbitMQ,也有普通集群和镜像集群模式，自行去了解，比较简单，两小时即懂。\n要求，在回答高可用的问题时，应该能逻辑清晰的画出自己的MQ集群架构或清晰的叙述出来。:这个问题其实换一种问法就是，如何保证消息队列的幂等性?这个问题可以认为是消息队列领域的基本问题。换句话来说，是在考察你的设计能力，这个问题的回答可以根据具体的业务场景来答，没有固定的答案。\n:先来说一下为什么会造成重复消费?\n其实无论是那种消息队列，造成重复消费原因其实都是类似的。正常情况下，消费者在消费消息时候，消费完毕后，会发送一个确认信息给消息队列，消息队列就知道该消息被消费了，就会将该消息从消息队列中删除。只是不同的消息队列发送的确认信息形式不同,例如RabbitMQ是发送一个ACK确认消息，RocketMQ是返回一个CONSUME_SUCCESS成功标志，kafka实际上有个offset的概念，简单说一下(如果还不懂，出门找一个kafka入门到精通教程),就是每一个消息都有一个offset，kafka消费过消息后，需要提交offset，让消息队列知道自己已经消费过了。那造成重复消费的原因?，就是因为网络传输等等故障，确认信息没有传送到消息队列，导致消息队列不知道自己已经消费过该消息了，再次将该消息分发给其他的消费者。\n如何解决?这个问题针对业务场景来答分以下几点\n(1)比如，你拿到这个消息做数据库的insert操作。那就容易了，给这个消息做一个唯一主键，那么就算出现重复消费的情况，就会导致主键冲突，避免数据库出现脏数据。\n(2)再比如，你拿到这个消息做redis的set的操作，那就容易了，不用解决，因为你无论set几次结果都是一样的，set操作本来就算幂等操作。\n(3)如果上面两种情况还不行，上大招。准备一个第三方介质,来做消费记录。以redis为例，给消息分配一个全局id，只要消费过该消息，将<id,message>以K-V形式写入redis。那消费者开始消费前，先去redis中查询有没消费记录即可。:我们在使用消息队列的过程中，应该做到消息不能多消费，也不能少消费。如果无法做到可靠性传输，可能给公司带来千万级别的财产损失。同样的，如果可靠性传输在使用过程中，没有考虑到，这不是给公司挖坑么，你可以拍拍屁股走了，公司损失的钱，谁承担。还是那句话，\n:其实这个可靠性传输，每种MQ都要从三个角度来分析:生产者弄丢数据、消息队列弄丢数据、消费者弄丢数据\n从生产者弄丢数据这个角度来看，RabbitMQ提供transaction和confirm模式来确保生产者不丢消息。\ntransaction机制就是说，发送消息前，开启事物(channel.txSelect())，然后发送消息，如果发送过程中出现什么异常，事物就会回滚(channel.txRollback())，如果发送成功则提交事物(channel.txCommit())。\n然而缺点就是吞吐量下降了。因此，按照博主的经验，生产上用confirm模式的居多。一旦channel进入confirm模式，所有在该信道上面发布的消息都将会被指派一个唯一的ID(从1开始)，一旦消息被投递到所有匹配的队列之后，rabbitMQ就会发送一个Ack给生产者(包含消息的唯一ID)，这就使得生产者知道消息已经正确到达目的队列了.如果rabiitMQ没能处理该消息，则会发送一个Nack消息给你，你可以进行重试操作。处理Ack和Nack的代码如下所示（说好不上代码的，偷偷上了）:\n处理消息队列丢数据的情况，一般是开启持久化磁盘的配置。这个持久化配置可以和confirm机制配合使用，你可以在消息持久化磁盘后，再给生产者发送一个Ack信号。这样，如果消息持久化磁盘之前，rabbitMQ阵亡了，那么生产者收不到Ack信号，生产者会自动重发。\n那么如何持久化呢，这里顺便说一下吧，其实也很容易，就下面两步\n1、将queue的持久化标识durable设置为true,则代表是一个持久的队列\n2、发送消息的时候将deliveryMode=2\n这样设置以后，rabbitMQ就算挂了，重启后也能恢复数据\n\n消费者丢数据一般是因为采用了自动确认消息模式。这种模式下，消费者会自动确认收到信息。这时rahbitMQ会立即将消息删除，这种情况下如果消费者出现异常而没能处理该消息，就会丢失该消息。\n至于解决方案，采用手动确认消息即可。这里先引一张kafka Replication的\n\nProducer在发布消息到某个Partition时，先通过ZooKeeper找到该Partition的Leader，然后无论该Topic的Replication Factor为多少（也即该Partition有多少个Replica），Producer只将该消息发送到该Partition的Leader。Leader会将该消息写入其本地Log。每个Follower都从Leader中pull数据。\n针对上述情况，得出如下分析\n\n在kafka生产中，基本都有一个leader和多个follwer。follwer会去同步leader的信息。因此，为了避免生产者丢数据，做如下两点配置第一个配置要在producer端设置acks=all。这个配置保证了，follwer同步完成后，才认为消息发送成功。在producer端设置retries=MAX，一旦写入失败，这无限重试\n针对消息队列丢数据的情况，无外乎就是，数据还没同步，leader就挂了，这时zookpeer会将其他的follwer切换为leader,那数据就丢失了。针对这种情况，应该做两个配置。replication.factor参数，这个值必须大于1，即要求每个partition必须有至少2个副本min.insync.replicas参数，这个值必须大于1，这个是要求一个leader至少感知到有至少一个follower还跟自己保持联系这两个配置加上上面生产者的配置联合起来用，基本可确保kafka不丢数据\n这种情况一般是自动提交了offset，然后你处理程序过程中挂了。kafka以为你处理好了。再强调一次offset是干嘛的\n：指的是kafka的topic中的每个消费组消费的下标。简单的来说就是一条消息对应一个offset下标，每次消费数据的时候如果提交offset，那么下次消费就会从提交的offset加一那里开始消费。\n比如一个topic中有100条数据，我消费了50条并且提交了，那么此时的kafka服务端记录提交的offset就是49(offset从0开始)，那么下次消费的时候offset就从50开始消费。\n解决方案也很简单，改成手动提交即可。大家自行查阅吧:其实并非所有的公司都有这种业务需求，但是还是对这个问题要有所复习。\n:针对这个问题，通过某种算法，将需要保持先后顺序的消息放到同一个消息队列中(kafka中就是partition,rabbitMq中就是queue)。然后只用一个消费者去消费该队列。\n有的人会问:那如果为了吞吐量，有多个消费者去消费怎么办？\n这个问题，没有固定回答的套路。比如我们有一个微博的操作，发微博、写评论、删除微博，这三个异步操作。如果是这样一个业务场景，那只要重试就行。比如你一个消费者先执行了写评论的操作，但是这时候，微博都还没发，写评论一定是失败的，等一段时间。等另一个消费者，先执行写评论的操作后，再执行，就可以成功。\n总之，针对这个问题，我的观点是保证入队有序就行，出队以后的顺序交给消费者自己去保证，没有固定套路。总结写到这里，希望读者把本文提出的这几个问题，经过深刻的准备后，一般来说，能囊括大部分的消息队列的知识点。如果面试官不问这几个问题怎么办，简单，自己把几个问题讲清楚，突出以下自己考虑的全面性。\n最后，其实我不太提倡这样突击复习，希望大家打好基本功，。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/03/4bae6998d00f180d42c7da716e3d0bb2.jpg"]}
{"title": "我似乎理解了编程的意义 - 文章 - 伯乐在线", "tag": ["职场", " 1 评论 ", "程序员", "职场"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n编程的意义是什么，我又为什么要编程呢？这是一个不时会浮现在我脑海中的问题，它来得并不频繁，但每次却都伴随着对自己职业生涯或人生目标的质疑而产生，令我感到些许困惑和不安。而在这十几年的职业生涯中，我也似乎总能在每个阶段为自己找到一个继续热爱编程的理由，直到它已无法解答再一次疑惑的产生。就这样一次又一次的循环往复，我似乎渐渐理解了编程的意义……回想大学毕业刚成为一名程序员时，自己对技术是如此狂热，我不断地购买各类技术书籍，几乎所有的业余时间也都被用来钻研技术，提高自己的编程能力。我也因此很快成了同一批入职新人中，编码效率和质量最突出的一个。而在那段时间里所做的技术积累，也成了我日后工作的坚实基础，编程作为一项技能已经深深地嵌入到了我的身体里。即使到了今天，我仍非常怀念那段心无旁骛，一心钻研技术的日子。我为能在工作中写出的每一行优秀代码而兴奋，更为每一天能在技术上取得的点滴进步而喜悦，一切都是那么单纯，。“能力越大，责任也也大”，这句电影“蜘蛛侠”中的经典台词同样适用于程序员的职业生涯。随着技术能力的提升以及工作中获得的认可，我的职位也由原来的初级程序员变为了资深开发工程师，以及后来的架构师。相应的，除了编程之外，我工作中的很大一部分时间需要用来与用户进行沟通，并分析他们提出的需求。对于我来说这个角色转换的过程，是艰难甚至有些痛苦的。 我不得不用自己最薄弱的沟通技能去和用户打交道，更要命的是我所习惯使用的那些技术语言有时很难让他们理解。我很快意识到自己已不再是那个只需被动接受任务安排，并将自己的编程工作完成好就万事大吉的初级程序员。除了技术之外，我更需要能够突破程序员思维，去发现用户需求背后所隐含的真正问题。我比以前变得更加务实，不再刻意追求技术的高深，而是尽可能从问题本身出发，选择最有效的技术手段去解决它。此时，编程的意义也发生了改变，。就这样又过了几年，当“为什么要编程？”这个问题再次摆在我的面前时，自己也已过了而立之年。对于大多数中国程序员来说，这个年纪已经算是高龄，甚至还有很多人会认为 30 岁还在编程，一定是混得不够好吧。当然，对于这些质疑我也总是一笑了之。其实，在此之前我也有过很多转型的机会，比如去业务部门，或是转作管理等等，但最终我还是选择留在了技术岗位上，因为我觉得编程仍是我最喜欢的，或许也是我唯一擅长的吧。而这个时期也成了我整个程序员生涯的黄金期，我写了公司的核心框架以及一些重要业务系统的核心算法。我很享受这段时光，因为我已几乎感受不到那些技术上的牵绊，我更像雕刻师使用手中的刻刀一般，自如地运用编程来实现那些我认为优秀的东西。编程对于我来说已不再是一项技能或是工具，我是在，这种感受带给了我极大的自由度，而我也从中感受到了前所未有的喜悦与乐趣。最终我还是走上了管理岗位，这里面有很多个人无法左右的因素（包括大环境、家庭、经济等等）。但我仍然更乐意被大家称为程序员或者“老”程序员。就像在简书的自我介绍中，我总是把全栈工程师放在那些“头衔”的第一位，我也还在利用业余时间做自己喜欢的开源或个人项目。当我再一次问自己“为什么要编程”时，获得了与以往不一样的感悟：。公司里最近都在为一个老系统的升级问题发愁，这个系统已经运行了将近 20 年时间了，为了升级系统，大家不得不深入到这个系统的框架中，去读底层代码。我们读到了一位已经退休的美国同事Bill所实现的数据库连接池代码。在那个时候JAVA刚开始流行，还没有像 Spring 这样的框架，或是如 Hibernate 或 MyBatis 这样标准的持久层实现，这个系统中所有的数据库连接池及核心持久层代码都是由我的这位美国同事写的，这些代码让整个系统稳定运行了将近20年，大家都不禁为他高超的技术水平发出由衷的赞叹。我还认识一位从事证券交易软件研发的公司 CTO，看年纪应该已经接近 50 了，但他仍然在亲自写着那些证券交易的核心代码。当我问他到了这个年龄和职位，为什么还要坚持写代码时，他告诉我，当他看到自己所写的代码每天在支撑着千亿级的证券交易时，他感到非常兴奋和自豪，并不断地希望能够通过自己的努力将它做得更好。我的这个美国同事不会听到大家为他十几年前所代码发出的zan叹，股民们也不会知道这位 CTO 所写的代码正在支撑着他们的日常交易。，我们不能确定这些痕迹能够保留多久，或许几年，或许更短，但它们都曾经在我们的日常生活中产生了重要的价值，而新的未来也将构建在这些痕迹的基础之上，我想这可能才是编程的意义所在吧。我似乎理解了编程的意义，但我明白未来的某一天，我一定还会问自己同样的问题——为什么要编程，希望到那个时候自己还能是那个热爱编程，有着一颗匠心的“技匠”吧……\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/07/b82c41ce36630a47a22e10059671eb52.jpg"]}
{"title": "深入学习 Redis（2）：持久化 - 文章 - 伯乐在线", "tag": ["IT技术", "Redis", "数据库"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n前言在上一篇文章中，介绍了，从这篇文章开始，将依次介绍Redis高可用相关的知识——持久化、复制(及读写分离)、哨兵、以及集群。本文将先说明上述几种技术分别解决了Redis高可用的什么问题；然后详细介绍Redis的持久化技术，主要是RDB和AOF两种持久化方案；在介绍RDB和AOF方案时，不仅介绍其作用及操作方法，同时介绍持久化实现的一些原理细节及需要注意的问题。最后，介绍在实际使用中，持久化方案的选择，以及经常遇到的问题等。在介绍Redis高可用之前，先说明一下在Redis的语境中高可用的含义。我们知道，在web服务器中，高可用是指服务器可以正常访问的时间，衡量的标准是在多长时间内可以提供正常服务（99.9%、99.99%、99.999% 等等）。但是在Redis语境中，高可用的含义似乎要宽泛一些，除了保证提供正常服务(如主从分离、快速容灾技术)，还需要考虑数据容量的扩展、数据安全不会丢失等。在Redis中，实现高可用的技术主要包括持久化、复制、哨兵和集群，下面分别说明它们的作用，以及解决了什么样的问题。持久化：持久化是最简单的高可用方法(有时甚至不被归为高可用的手段)，主要作用是数据备份，即将数据存储在硬盘，保证数据不会因进程退出而丢失。复制：复制是高可用Redis的基础，哨兵和集群都是在复制基础上实现高可用的。复制主要实现了数据的多机备份，以及对于读操作的负载均衡和简单的故障恢复。缺陷：故障恢复无法自动化；写操作无法负载均衡；存储能力受到单机的限制。哨兵：在复制的基础上，哨兵实现了自动化的故障恢复。缺陷：写操作无法负载均衡；存储能力受到单机的限制。集群：通过集群，Redis解决了写操作无法负载均衡，以及存储能力受到单机限制的问题，实现了较为完善的高可用方案。持久化的功能：Redis是内存数据库，数据都是存储在内存中，为了避免进程退出导致数据的永久丢失，需要定期将Redis中的数据以某种形式(数据或命令)从内存保存到硬盘；当下次Redis重启时，利用持久化文件实现数据恢复。除此之外，为了进行灾难备份，可以将持久化文件拷贝到一个远程位置。Redis持久化分为RDB持久化和AOF持久化由于AOF持久化的实时性更好，即当进程意外退出时丢失的数据更少，因此AOF是目前主流的持久化方式，不过RDB持久化仍然有其用武之地。下面依次介绍RDB持久化和AOF持久化；由于Redis各个版本之间存在差异，如无特殊说明，以Redis3.0为准。RDB持久化是将当前进程中的数据生成快照保存到硬盘(因此也称作快照持久化)，保存的文件后缀是rdb；当Redis重新启动时，可以读取快照文件恢复数据。1. 触发条件RDB持久化的触发分为手动触发和自动触发两种。save命令和bgsave命令都可以生成RDB文件。save命令会阻塞Redis服务器进程，直到RDB文件创建完毕为止，在Redis服务器阻塞期间，服务器不能处理任何命令请求。而bgsave命令会创建一个子进程，由子进程来负责创建RDB文件，父进程(即Redis主进程)则继续处理请求。此时服务器执行日志如下：bgsave命令执行过程中，只有fork子进程时会阻塞服务器，而对于save命令，整个过程都会阻塞服务器，因此save已基本被废弃，线上环境要杜绝save的使用；后文中也将只介绍bgsave命令。此外，在自动触发RDB持久化时，Redis也会选择bgsave而不是save来进行持久化；下面介绍自动触发RDB持久化的条件。自动触发最常见的情况是在配置文件中通过save m n，指定当m秒内发生n次变化时，会触发bgsave。例如，查看redis的默认配置文件(Linux下为redis根目录下的redis.conf)，可以看到如下配置信息：其中save 900 1的含义是：当时间到900秒时，如果redis数据发生了至少1次变化，则执行bgsave；save 300 10和save 60 10000同理。当三个save条件满足任意一个时，都会引起bgsave的调用。Redis的save m n，是通过serverCron函数、dirty计数器、和lastsave时间戳来实现的。serverCron是Redis服务器的周期性操作函数，默认每隔100ms执行一次；该函数对服务器的状态进行维护，其中一项工作就是检查 save m n 配置的条件是否满足，如果满足就执行bgsave。dirty计数器是Redis服务器维持的一个状态，记录了上一次执行bgsave/save命令后，服务器状态进行了多少次修改(包括增删改)；而当save/bgsave执行完成后，会将dirty重新置为0。例如，如果Redis执行了set mykey helloworld，则dirty值会+1；如果执行了sadd myset v1 v2 v3，则dirty值会+3；注意dirty记录的是服务器进行了多少次修改，而不是客户端执行了多少修改数据的命令。lastsave时间戳也是Redis服务器维持的一个状态，记录的是上一次成功执行save/bgsave的时间。save m n的原理如下：每隔100ms，执行serverCron函数；在serverCron函数中，遍历save m n配置的保存条件，只要有一个条件满足，就进行bgsave。对于每一个save m n条件，只有下面两条同时满足时才算满足：（1）当前时间-lastsave > m（2）dirty >= n下图是save m n触发bgsave执行时，服务器打印日志的情况：除了save m n 以外，还有一些其他情况会触发bgsave：在主从复制场景下，如果从节点执行全量复制操作，则主节点会执行bgsave命令，并将rdb文件发送给从节点执行shutdown命令时，自动执行rdb持久化，如下图所示：2. 执行流程前面介绍了触发bgsave的条件，下面将说明bgsave命令的执行流程，如下图所示(图片来源：https://blog.csdn.net/a1007720052/article/details/79126253)：图片中的5个步骤所进行的操作如下：1)  Redis父进程首先判断：当前是否在执行save，或bgsave/bgrewriteaof（后面会详细介绍该命令）的子进程，如果在执行则bgsave命令直接返回。bgsave/bgrewriteaof 的子进程不能同时执行，主要是基于性能方面的考虑：两个并发的子进程同时执行大量的磁盘写操作，可能引起严重的性能问题。2)  父进程执行fork操作创建子进程，这个过程中父进程是阻塞的，Redis不能执行来自客户端的任何命令3)  父进程fork后，bgsave命令返回”Background saving started”信息并不再阻塞父进程，并可以响应其他命令4)  子进程创建RDB文件，根据父进程内存快照生成临时快照文件，完成后对原有文件进行原子替换5)  子进程发送信号给父进程表示完成，父进程更新统计信息3. RDB文件RDB文件是经过压缩的二进制文件，下面介绍关于RDB文件的一些细节。RDB文件的存储路径既可以在启动前配置，也可以通过命令动态设定。配置：dir配置指定目录，dbfilename指定文件名。默认是Redis根目录下的dump.rdb文件。动态设定：Redis启动后也可以动态修改RDB存储路径，在磁盘损害或空间不足时非常有用；执行命令为config set dir {newdir}和config set dbfilename {newFileName}。如下所示(Windows环境)：RDB文件格式如下图所示（图片来源：《Redis设计与实现》）：其中各个字段的含义说明如下：1)  REDIS：常量，保存着”REDIS”5个字符。2)  db_version：RDB文件的版本号，注意不是Redis的版本号。3)  SELECTDB 0 pairs：表示一个完整的数据库(0号数据库)，同理SELECTDB 3 pairs表示完整的3号数据库；只有当数据库中有键值对时，RDB文件中才会有该数据库的信息(上图所示的Redis中只有0号和3号数据库有键值对)；如果Redis中所有的数据库都没有键值对，则这一部分直接省略。其中：SELECTDB是一个常量，代表后面跟着的是数据库号码；0和3是数据库号码；pairs则存储了具体的键值对信息，包括key、value值，及其数据类型、内部编码、过期时间、压缩信息等等。4)  EOF：常量，标志RDB文件正文内容结束。5)  check_sum：前面所有内容的校验和；Redis在载入RBD文件时，会计算前面的校验和并与check_sum值比较，判断文件是否损坏。Redis默认采用LZF算法对RDB文件进行压缩。虽然压缩耗时，但是可以大大减小RDB文件的体积，因此压缩默认开启；可以通过命令关闭：需要注意的是，RDB文件的压缩并不是针对整个文件进行的，而是对数据库中的字符串进行的，且只有在字符串达到一定长度(20字节)时才会进行。4. 启动时加载RDB文件的载入工作是在服务器启动时自动执行的，并没有专门的命令。但是由于AOF的优先级更高，因此当AOF开启时，Redis会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会在Redis服务器启动时检测RDB文件，并自动载入。服务器载入RDB文件期间处于阻塞状态，直到载入完成为止。Redis启动日志中可以看到自动载入的执行：Redis载入RDB文件时，会对RDB文件进行校验，如果文件损坏，则日志中会打印错误，Redis启动失败。5. RDB常用配置总结下面是RDB常用的配置项，以及默认值；前面介绍过的这里不再详细介绍。save m n：bgsave自动触发的条件；如果没有save m n配置，相当于自动的RDB持久化关闭，不过此时仍可以通过其他方式触发stop-writes-on-bgsave-error yes：当bgsave出现错误时，Redis是否停止执行写命令；设置为yes，则当硬盘出现问题时，可以及时发现，避免数据的大量丢失；设置为no，则Redis无视bgsave的错误继续执行写命令，当对Redis服务器的系统(尤其是硬盘)使用了监控时，该选项考虑设置为nordbcompression yes：是否开启RDB文件压缩rdbchecksum yes：是否开启RDB文件的校验，在写入文件和读取文件时都起作用；关闭checksum在写入文件和启动文件时大约能带来10%的性能提升，但是数据损坏时无法发现dbfilename dump.rdb：RDB文件名dir ./：RDB文件和AOF文件所在目录RDB持久化是将进程数据写入文件，而AOF持久化(即Append Only File持久化)，则是将Redis执行的每次写命令记录到单独的日志文件中（有点像MySQL的binlog）；当Redis重启时再次执行AOF文件中的命令来恢复数据。与RDB相比，AOF的实时性更好，因此已成为主流的持久化方案。1. 开启AOFRedis服务器默认开启RDB，关闭AOF；要开启AOF，需要在配置文件中配置：appendonly yes2. 执行流程由于需要记录Redis的每条写命令，因此AOF不需要触发，下面介绍AOF的执行流程。AOF的执行流程包括：命令追加(append)：将Redis的写命令追加到缓冲区aof_buf；文件写入(write)和文件同步(sync)：根据不同的同步策略将aof_buf中的内容同步到硬盘；文件重写(rewrite)：定期重写AOF文件，达到压缩的目的。Redis先将写命令追加到缓冲区，而不是直接写入文件，主要是为了避免每次有写命令都直接写入硬盘，导致硬盘IO成为Redis负载的瓶颈。命令追加的格式是Redis命令请求的协议格式，它是一种纯文本格式，具有兼容性好、可读性强、容易处理、操作简单避免二次开销等优点；具体格式略。在AOF文件中，除了用于指定数据库的select命令（如select 0 为选中0号数据库）是由Redis添加的，其他都是客户端发送来的写命令。Redis提供了多种AOF缓存区的同步文件策略，策略涉及到操作系统的write函数和fsync函数，说明如下：为了提高文件写入效率，在现代操作系统中，当用户调用write函数将数据写入文件时，操作系统通常会将数据暂存到一个内存缓冲区里，当缓冲区被填满或超过了指定时限后，才真正将缓冲区的数据写入到硬盘里。这样的操作虽然提高了效率，但也带来了安全问题：如果计算机停机，内存缓冲区中的数据会丢失；因此系统同时提供了fsync、fdatasync等同步函数，可以强制操作系统立刻将缓冲区中的数据写入到硬盘里，从而确保数据的安全性。AOF缓存区的同步文件策略由参数appendfsync控制，各个值的含义如下：always：命令写入aof_buf后立即调用系统fsync操作同步到AOF文件，fsync完成后线程返回。这种情况下，每次有写命令都要同步到AOF文件，硬盘IO成为性能瓶颈，Redis只能支持大约几百TPS写入，严重降低了Redis的性能；即便是使用固态硬盘（SSD），每秒大约也只能处理几万个命令，而且会大大降低SSD的寿命。no：命令写入aof_buf后调用系统write操作，不对AOF文件做fsync同步；同步由操作系统负责，通常同步周期为30秒。这种情况下，文件同步的时间不可控，且缓冲区中堆积的数据会很多，数据安全性无法保证。everysec：命令写入aof_buf后调用系统write操作，write完成后线程返回；fsync同步文件操作由专门的线程每秒调用一次。随着时间流逝，Redis服务器执行的写命令越来越多，AOF文件也会越来越大；过大的AOF文件不仅会影响服务器的正常运行，也会导致数据恢复需要的时间过长。文件重写是指定期重写AOF文件，减小AOF文件的体积。需要注意的是，关于文件重写需要注意的另一点是：对于AOF持久化来说，文件重写虽然是强烈推荐的，但并不是必须的；即使没有文件重写，数据也可以被持久化并在Redis启动的时候导入；因此在一些实现中，会关闭自动的文件重写，然后通过定时任务在每天的某一时刻定时执行。文件重写之所以能够压缩AOF文件，原因在于：过期的数据不再写入文件无效的命令不再写入文件：如有些数据被重复设值(set mykey v1, set mykey v2)、有些数据被删除了(sadd myset v1, del myset)等等多条命令可以合并为一个：如sadd myset v1, sadd myset v2, sadd myset v3可以合并为sadd myset v1 v2 v3。不过为了防止单条命令过大造成客户端缓冲区溢出，对于list、set、hash、zset类型的key，并不一定只使用一条命令；而是以某个常量为界将命令拆分为多条。这个常量在redis.h/REDIS_AOF_REWRITE_ITEMS_PER_CMD中定义，不可更改，3.0版本中值是64。通过上述内容可以看出，由于重写后AOF执行的命令减少了，文件重写既可以减少文件占用的空间，也可以加快恢复速度。文件重写的触发，分为手动触发和自动触发：手动触发：直接调用bgrewriteaof命令，该命令的执行与bgsave有些类似：都是fork子进程进行具体的工作，且都只有在fork时阻塞。此时服务器执行日志如下：自动触发：根据auto-aof-rewrite-min-size和auto-aof-rewrite-percentage参数，以及aof_current_size和aof_base_size状态确定触发时机。auto-aof-rewrite-min-size：执行AOF重写时，文件的最小体积，默认值为64MB。auto-aof-rewrite-percentage：执行AOF重写时，当前AOF大小(即aof_current_size)和上一次重写时AOF大小(aof_base_size)的比值。其中，参数可以通过config get命令查看：状态可以通过info persistence查看：只有当auto-aof-rewrite-min-size和auto-aof-rewrite-percentage两个参数同时满足时，才会自动触发AOF重写，即bgrewriteaof操作。自动触发bgrewriteaof时，可以看到服务器日志如下：文件重写流程如下图所示(图片来源：http://www.cnblogs.com/yangmingxianshen/p/8373205.html)：关于文件重写的流程，有两点需要特别注意：(1)重写由父进程fork子进程进行；(2)重写期间Redis执行的写命令，需要追加到新的AOF文件中，为此Redis引入了aof_rewrite_buf缓存。对照上图，文件重写的流程如下：1) Redis父进程首先判断当前是否存在正在执行 bgsave/bgrewriteaof的子进程，如果存在则bgrewriteaof命令直接返回，如果存在bgsave命令则等bgsave执行完成后再执行。前面曾介绍过，这个主要是基于性能方面的考虑。2) 父进程执行fork操作创建子进程，这个过程中父进程是阻塞的。3.1) 父进程fork后，bgrewriteaof命令返回”Background append only file rewrite started”信息并不再阻塞父进程，并可以响应其他命令。3.2) 由于fork操作使用写时复制技术，子进程只能共享fork操作时的内存数据。4) 子进程根据内存快照，按照命令合并规则写入到新的AOF文件。5.1) 子进程写完新的AOF文件后，向父进程发信号，父进程更新统计信息，具体可以通过info persistence查看。5.2) 父进程把AOF重写缓冲区的数据写入到新的AOF文件，这样就保证了新AOF文件所保存的数据库状态和服务器当前状态一致。5.3) 使用新的AOF文件替换老文件，完成AOF重写。3. 启动时加载前面提到过，当AOF开启时，Redis启动时会优先载入AOF文件来恢复数据；只有当AOF关闭时，才会载入RDB文件恢复数据。当AOF开启，且AOF文件存在时，Redis启动日志：当AOF开启，但AOF文件不存在时，即使RDB文件存在也不会加载(更早的一些版本可能会加载，但3.0不会)，Redis启动日志如下：与载入RDB文件类似，Redis载入AOF文件时，会对AOF文件进行校验，如果文件损坏，则日志中会打印错误，Redis启动失败。但如果是AOF文件结尾不完整(机器突然宕机等容易导致文件尾部不完整)，且aof-load-truncated参数开启，则日志中会输出警告，Redis忽略掉AOF文件的尾部，启动成功。aof-load-truncated参数默认是开启的：因为Redis的命令只能在客户端上下文中执行，而载入AOF文件时命令是直接从文件中读取的，并不是由客户端发送；因此Redis服务器在载入AOF文件之前，会创建一个没有网络连接的客户端，之后用它来执行AOF文件中的命令，命令执行的效果与带网络连接的客户端完全一样。4. AOF常用配置总结下面是AOF常用的配置项，以及默认值；前面介绍过的这里不再详细介绍。appendonly no：是否开启AOFappendfilename “appendonly.aof”：AOF文件名dir ./：RDB文件和AOF文件所在目录appendfsync everysec：fsync持久化策略no-appendfsync-on-rewrite no：AOF重写期间是否禁止fsync；如果开启该选项，可以减轻文件重写时CPU和硬盘的负载（尤其是硬盘），但是可能会丢失AOF重写期间的数据；需要在负载和安全性之间进行平衡auto-aof-rewrite-percentage 100：文件重写触发条件之一auto-aof-rewrite-min-size 64mb：文件重写触发提交之一aof-load-truncated yes：如果AOF文件结尾损坏，Redis启动时是否仍载入AOF文件前面介绍了RDB和AOF两种持久化方案的细节，下面介绍RDB和AOF的特点、如何选择持久化方案，以及在持久化过程中常遇到的问题等。1. RDB和AOF的优缺点RDB和AOF各有优缺点：优点：RDB文件紧凑，体积小，网络传输快，适合全量复制；恢复速度比AOF快很多。当然，与AOF相比，RDB最重要的优点之一是对性能的影响相对较小。缺点：RDB文件的致命缺点在于其数据快照的持久化方式决定了必然做不到实时持久化，而在数据越来越重要的今天，数据的大量丢失很多时候是无法接受的，因此AOF持久化成为主流。此外，RDB文件需要满足特定格式，兼容性差（如老版本的Redis不兼容新版本的RDB文件）。与RDB持久化相对应，AOF的优点在于支持秒级持久化、兼容性好，缺点是文件大、恢复速度慢、对性能影响大。2. 持久化策略选择在介绍持久化策略之前，首先要明白无论是RDB还是AOF，持久化的开启都是要付出性能方面代价的：对于RDB持久化，一方面是bgsave在进行fork操作时Redis主进程会阻塞，另一方面，子进程向硬盘写数据也会带来IO压力；对于AOF持久化，向硬盘写数据的频率大大提高(everysec策略下为秒级)，IO压力更大，甚至可能造成AOF追加阻塞问题（后面会详细介绍这种阻塞），此外，AOF文件的重写与RDB的bgsave类似，会有fork时的阻塞和子进程的IO压力问题。相对来说，由于AOF向硬盘中写数据的频率更高，因此对Redis主进程性能的影响会更大。在实际生产环境中，根据数据量、应用对数据的安全要求、预算限制等不同情况，会有各种各样的持久化策略；如完全不使用任何持久化、使用RDB或AOF的一种，或同时开启RDB和AOF持久化等。此外，持久化的选择必须与Redis的主从策略一起考虑，因为主从复制与持久化同样具有数据备份的功能，而且主机master和从机slave可以独立的选择持久化方案。下面分场景来讨论持久化策略的选择，下面的讨论也只是作为参考，实际方案可能更复杂更具多样性。（1）如果Redis中的数据完全丢弃也没有关系（如Redis完全用作DB层数据的cache），那么无论是单机，还是主从架构，都可以不进行任何持久化。（2）在单机环境下（对于个人开发者，这种情况可能比较常见），如果可以接受十几分钟或更多的数据丢失，选择RDB对Redis的性能更加有利；如果只能接受秒级别的数据丢失，应该选择AOF。（3）但在多数情况下，我们都会配置主从环境，slave的存在既可以实现数据的热备，也可以进行读写分离分担Redis读请求，以及在master宕掉后继续提供服务。在这种情况下，一种可行的做法是：master：完全关闭持久化（包括RDB和AOF），这样可以让master的性能达到最好slave：关闭RDB，开启AOF（如果对数据安全要求不高，开启RDB关闭AOF也可以），并定时对持久化文件进行备份（如备份到其他文件夹，并标记好备份的时间）；然后关闭AOF的自动重写，然后添加定时任务，在每天Redis闲时（如凌晨12点）调用bgrewriteaof。这里需要解释一下，为什么开启了主从复制，可以实现数据的热备份，还需要设置持久化呢？因为在一些特殊情况下，主从复制仍然不足以保证数据的安全，例如：master和slave进程同时停止：考虑这样一种场景，如果master和slave在同一栋大楼或同一个机房，则一次停电事故就可能导致master和slave机器同时关机，Redis进程停止；如果没有持久化，则面临的是数据的完全丢失。master误重启：考虑这样一种场景，master服务因为故障宕掉了，如果系统中有自动拉起机制（即检测到服务停止后重启该服务）将master自动重启，由于没有持久化文件，那么master重启后数据是空的，slave同步数据也变成了空的；如果master和slave都没有持久化，同样会面临数据的完全丢失。需要注意的是，即便是使用了哨兵(关于哨兵后面会有文章介绍)进行自动的主从切换，也有可能在哨兵轮询到master之前，便被自动拉起机制重启了。因此，应尽量避免“自动拉起机制”和“不做持久化”同时出现。（4）异地灾备：上述讨论的几种持久化策略，针对的都是一般的系统故障，如进程异常退出、宕机、断电等，这些故障不会损坏硬盘。但是对于一些可能导致硬盘损坏的灾难情况，如火灾地震，就需要进行异地灾备。例如对于单机的情形，可以定时将RDB文件或重写后的AOF文件，通过scp拷贝到远程机器，如阿里云、AWS等；对于主从的情形，可以定时在master上执行bgsave，然后将RDB文件拷贝到远程机器，或者在slave上执行bgrewriteaof重写AOF文件后，将AOF文件拷贝到远程机器上。一般来说，由于RDB文件文件小、恢复快，因此灾难恢复常用RDB文件；异地备份的频率根据数据安全性的需要及其他条件来确定，但最好不要低于一天一次。3. fork阻塞：CPU的阻塞在Redis的实践中，众多因素限制了Redis单机的内存不能过大，例如：当面对请求的暴增，需要从库扩容时，Redis内存过大会导致扩容时间太长；当主机宕机时，切换主机后需要挂载从库，Redis内存过大导致挂载速度过慢；以及持久化过程中的fork操作，下面详细说明。首先说明一下fork操作：父进程通过fork操作可以创建子进程；子进程创建后，父子进程共享代码段，不共享进程的数据空间，但是子进程会获得父进程的数据空间的副本。在操作系统fork的实际实现中，基本都采用了写时复制技术，即在父/子进程试图修改数据空间之前，父子进程实际上共享数据空间；但是当父/子进程的任何一个试图修改数据空间时，操作系统会为修改的那一部分(内存的一页)制作一个副本。虽然fork时，子进程不会复制父进程的数据空间，但是会复制内存页表（页表相当于内存的索引、目录）；父进程的数据空间越大，内存页表越大，fork时复制耗时也会越多。在Redis中，无论是RDB持久化的bgsave，还是AOF重写的bgrewriteaof，都需要fork出子进程来进行操作。如果Redis内存过大，会导致fork操作时复制内存页表耗时过多；而Redis主进程在进行fork时，是完全阻塞的，也就意味着无法响应客户端的请求，会造成请求延迟过大。对于不同的硬件、不同的操作系统，fork操作的耗时会有所差别，一般来说，如果Redis单机内存达到了10GB，fork时耗时可能会达到百毫秒级别（如果使用Xen虚拟机，这个耗时可能达到秒级别）。因此，一般来说Redis单机内存一般要限制在10GB以内；不过这个数据并不是绝对的，可以通过观察线上环境fork的耗时来进行调整。观察的方法如下：执行命令info stats，查看latest_fork_usec的值，单位为微秒。为了减轻fork操作带来的阻塞问题，除了控制Redis单机内存的大小以外，还可以适度放宽AOF重写的触发条件、选用物理机或高效支持fork操作的虚拟化技术等，例如使用Vmware或KVM虚拟机，不要使用Xen虚拟机。4. AOF追加阻塞：硬盘的阻塞前面提到过，在AOF中，如果AOF缓冲区的文件同步策略为everysec，则：在主线程中，命令写入aof_buf后调用系统write操作，write完成后主线程返回；fsync同步文件操作由专门的文件同步线程每秒调用一次。这种做法的问题在于，如果硬盘负载过高，那么fsync操作可能会超过1s；如果Redis主线程持续高速向aof_buf写入命令，硬盘的负载可能会越来越大，IO资源消耗更快；如果此时Redis进程异常退出，丢失的数据也会越来越多，可能远超过1s。为此，Redis的处理策略是这样的：主线程每次进行AOF会对比上次fsync成功的时间；如果距上次不到2s，主线程直接返回；如果超过2s，则主线程阻塞直到fsync同步完成。因此，如果系统硬盘负载过大导致fsync速度太慢，会导致Redis主线程的阻塞；此外，使用everysec配置，AOF最多可能丢失2s的数据，而不是1s。AOF追加阻塞问题定位的方法：（1）监控info Persistence中的aof_delayed_fsync：当AOF追加阻塞发生时（即主线程等待fsync而阻塞），该指标累加。（2）AOF阻塞时的Redis日志：Asynchronous AOF fsync is taking too long (disk is busy?). Writing the AOF buffer without waiting for fsync to complete, this may slow down Redis.（3）如果AOF追加阻塞频繁发生，说明系统的硬盘负载太大；可以考虑更换IO速度更快的硬盘，或者通过IO监控分析工具对系统的IO负载进行分析，如iostat（系统级io）、iotop（io版的top）、pidstat等。5. info命令与持久化前面提到了一些通过info命令查看持久化相关状态的方法，下面来总结一下。（1）info Persistence执行结果如下：其中比较重要的包括：rdb_last_bgsave_status:上次bgsave 执行结果，可以用于发现bgsave错误rdb_last_bgsave_time_sec:上次bgsave执行时间（单位是s），可以用于发现bgsave是否耗时过长aof_enabled:AOF是否开启aof_last_rewrite_time_sec: 上次文件重写执行时间（单位是s），可以用于发现文件重写是否耗时过长aof_last_bgrewrite_status: 上次bgrewrite执行结果，可以用于发现bgrewrite错误aof_buffer_length和aof_rewrite_buffer_length:aof缓存区大小和aof重写缓冲区大小aof_delayed_fsync:AOF追加阻塞情况的统计（2）info stats其中与持久化关系较大的是：latest_fork_usec，代表上次fork耗时，可以参见前面的讨论。本文主要内容可以总结如下：1、持久化在Redis高可用中的作用：数据备份，与主从复制相比强调的是由内存到硬盘的备份。2、RDB持久化：将数据快照备份到硬盘；介绍了其触发条件（包括手动出发和自动触发）、执行流程、RDB文件等，特别需要注意的是文件保存操作由fork出的子进程来进行。3、AOF持久化：将执行的写命令备份到硬盘（类似于MySQL的binlog），介绍了其开启方法、执行流程等，特别需要注意的是文件同步策略的选择（everysec）、文件重写的流程。4、一些现实的问题：包括如何选择持久化策略，以及需要注意的fork阻塞、AOF追加阻塞等。《Redis开发与运维》《Redis设计与实现》《Redis实战》\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"]}
{"title": "详解 Linux 文档属性、拥有者、群组、权限、差异 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 4 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n写在前面我们都知道是一个支持的系统，这也是它最优秀的特性，即可能同时有很多人都在系统上进行工作，所以千万不要，同时，为了保护每个人的隐私和工作环境，针对某一个文档(文件、目录)，系统定义了三种身份，分别是，每一种身份又对应三种权限，分别是。文档属性使用命令，或者此命令的简写可以查看文件或者目录的所有属性。如下：\n\n从上面可以看到，每一行都有7列，分别是：\n共10位，第1位表示文档类型，表示目录，表示文件，表示链接文件，表示可随机存取的设备，如U盘等，表示一次性读取设备，如鼠标、键盘等。后9位，依次对应三种身份所拥有的权限，身份顺序为：owner、group、others，权限顺序为：readable、writable、excutable。如：的含义为。\n表示连结数\n表示拥有者\n表示所属群组\n表示文档容量大小，单位字节\n表示文档最后修改时间，注意不是文档的创建时间哦\n表示文档名称。以点(.)开头的是隐藏文档变更拥有者(owner)注意：必须是该位置下已存在的帐号。也就是在中有记录的拥有者才能改变。备注：此命令也可以顺便变更文档群组，但还是建议使用命令来变更文档群组。-R 递归变更，即连同次目录下的所有文件(夹)都要变更。 变更文件夹账号为。\n\n 变更文件夹群组为。\n 变更文件夹账号为，群组为\n\n 单独变更群组为\n备注：虽然也可以在拥有者与群组间加小数点()，但为了避免有的同学命名中带点，故还是建议使用冒号“:”来隔开拥有者与群组，避免误判。变更群组(group)备注：从这里可以查看到所有群组备注：关于，可以通过等命令查询详细用法。 改变文件夹及其所有子文件(夹)的群组为。\n注意：群组名称不在位置内，将会报错。变更权限Linux文档的基本权限就三个，分别是，加上身份也只有九个。权限变更的方式有2种，分别是和。分别使用u，g，o来代表三种身份，a表示全部身份；分别使用r、w、x表示三种权限；分别使用+、-、=表示操作行为变更目录test的权限为任何人都可读、写、执行。去掉目录test执行权限备注：执行权限(x)，对目录而已就是其他用户能否成为工作目录。增加目录test执行权限备注：很熟悉吧，如果我们编写完一个shell文件test.sh后，通过就添加了文件执行权限。顾名思义，就是使用数字来代表权限，r,w,x分别为4,2,1。三种权限累加就可以得出一种身份的权限。设置目录test的权限为任何人都可读、写、执行。\n设置目录test的权限为任何人都可读、写。赋予一个shell文件test.sh可执行权限，拥有者可读、写、执行，群组账号和其他人可读、执行。备注：有没有发现数字法更简单啊！！！文件和目录权限差异文档权限对于文件和目录有巨大的差异针对的是该文件内容readable 可读取该文件的实际内容writable 可以编辑、新增或者是修改该文件的内容executable 有可以被系统执行的权限备注：具有w权限不可以删除文件，删除文件是目录权限控制的范围！！！记住。针对的是该目录下的文件对象readable 具有读取目录结构清单的权限，即可以通过命令，查询该目录清单。writable 具有变动该目录结构清单的权限，即可以创建、迁移、删除、更名该目录下的文件。executable 具备进入该目录的权限，即可以通过命令，转到工作目录。备注：从上面可以得出，开放目录给任何人浏览时，至少需要赋予或权限。读取目录文件内容，至少需要目录权限和文件权限。总结的每个文档可以分别针对三种身份赋予权限；命令变更文件群组，命令变更文件权限，变更文件拥有者；那么以后记得使用。。\n。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "是什么让初级工程师走投无路？ - 文章 - 伯乐在线", "tag": ["职场", " 1 评论 ", "程序员", "职场"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n几个月前，我参加了一场针对技术领域女性的活动。很多参加者中是新的开发者，毕业于编程学校或者计算机科学课程。几乎所有人都告诉我，她们在获得第一份工作时遇到了麻烦。我很幸运。我在大学的第一份“真正”工作是 2010 年哥伦比亚大学的“初级应用程序开发人员”。现如今，甚至找不到一个招聘初级开发者岗位的招聘帖。发这些招聘帖的人说他们被淹没在了简历中。然而优秀的公司又抱怨找不到好的工程师。我想知道这是为什么？我不知道这样做，具体来说能够为我们节省多少成本，毕竟我不参与公司的运营。但是我知道很多公司对我说过：「我们不雇佣初级工程师的原因是，。」我已经了解高级工程师的价格，因为我就是其中之一，并且为了预估项目预算，项目经理曾让我给项目分配时间。我知道的价格区间是 190 ~ 300 美元每小时。这就是很多公司认为雇佣初级工程师是一笔损失的原因。我并不这么认为：没有高级工程师能够一直高效工作一整天。公司对人力成本的焦虑就像鳄鱼的眼泪，（至少以我的观点来说）他们刻意不去思考浪费在很多事物上的时间，比如开会。但让我们来做个假设，他们将初级开发者的职位重新加入到团队。另一个问题出现了：。当我第一次开始与初级工程师合作时，我不知道该如何去做。我感到迷茫和困惑。我所待的公司基本上就是这样的态度：“让他们有事可做，让他们可以从中学到东西。”但是，这样做真的不可持续。我寻找资源，但是并没有找到。如果你知道任何资源，请在留言中通知我。我最终拼凑了各种课程和不同作业。但令人惊叹的是，我在做这件事时学到了很多东西。直到我必须解释 Javascript 语言的特性，我才觉得我真的深入地理解了它们。我为教学开发的一些工具最终付诸于项目。现在，有一些时候令我感到沮丧。特别是当项目经理或其他经理不了解现实状况的时候。他们总觉得，这些人教了就马上能够进行开发，但这之间有个消化和理解的过程。我认为我想说的是：整个软件开发生态系统需要初级工程师以保持健康。培训他们有成本，但也有好处。我建议那些想要再次招聘初级工程师的公司，投入一些时间用来制定一个大纲，用来帮助高级工程师以及任何与他们合作的人员有效地辅导。并且说明下这个严峻的现实。就像。那样的话，你会做什么呢？抱怨辅导你的高级工程师？或者追逐那些奋斗于通往成功领域（如项目管理、销售工程师或者其他非开发的角色）的人。在这些领域，软件技能也是非常重要的。并且。很多杰出的工程师不具备这一特质。他们应该避免扮演这样的角色。对于那些必须担任导师这一角色的人，如果他们没做好，我们也不应该苛责他们。我曾在一个团队中给初级开发者提供大部分的指导。与其他工程师所做的工作相比，这被认为不是“真正”的工作，这后来也让我不太愿意担当这个角色。是的，我会将性别考虑进去，因为我是一位女性，并且当女性担任类似这种角色，受刻板印象的影响，她们总被认为是“训导员”。那意味着更低的声誉，更低的声誉意味着更少的工资。话虽这么说，但如果没有提及一些其他阻碍初级工程师的经济问题，我不足以写下这篇文章。最近，因为一个活动，我拜访了一家公司，他们大概的意思就是说，现在所有“容易”的工作都已外包给另一个国家。这些工作以前都是初级工程师做的。之后有了自动化。我还是初级工程师时许多需要亲自做的工作，现在都可以自动化处理了。对于那些初级工程师，找到你的第一份工作正变得越来越困难。你可能不得不做一些我不愿意推荐的事，比如免费给各种项目打工。。我。你也要寻找你自己的导师。现场见面会是最好的方式，虽然我明白并不是每个人都喜欢这样，因此你可以试试 Slack 和 Discord 聊天应用。不过就像很多约会一样，这也会变得糟糕。你将被多次的拒绝。你将做一些糟糕的、甚至完全失败的项目，因为和商业项目的人员相比，免费项目的工作人员一般有点更古里古怪。就像一个初级工程师告诉我的：他们不再去某个见面会，因为他们之前做的项目彻底地失败了。我不得不告诉他们应该继续寻找项目，但心中要明白大多数项目都不是完善的。对我而言，我很高兴为参加见面会的人提供辅导。在这些背景下，我也要努力地制定一份更正式的导师计划。我不确定整个行业的解决方案是什么。我不确定缺乏初级工程师的公司是不平衡的还是聪明的。实际情况是，大多数软件开发人员不会长时间呆在一个地方，所以也许投入大量资源来培训人员是没有意义的。或者说，这个行业也许应该问问自己，为什么人们不停地跳槽？也许是因为大多数公司都很糟糕，或者对我们很多人来说，这是提高薪水的唯一途径。我可以等待一个愚蠢的、毫无意义的年度“绩效评估”让我涨 1％ 的工资。或者投递简历，通过面试，拿到 10％ 或更多的工资涨幅。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/03/1fd843979d2a6757332bedd49c9c8d80.png"]}
{"title": "如何高效学习 - 文章 - 伯乐在线", "tag": ["职场", " 3 评论 ", "学习"], "goodNum": "2", "saveNum": " 9 收藏", "sayNum": " 3 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nIT 行业是一个变化非常快的行业，它需要我们持续去学习新的知识和技能。 但是，工作以后，我们经常会发现自己学习的东西很少了，倒不是没有时间去学习， 而是学习的效率太低了。久而久之，就演变成『一年的工作经验，重复用十年』。当然，有些人会说自己经常加班，没有时间学习，这只是表象，时间挤挤总是有的。 你想想你为了上王者，浪费了多少时间？为了刷今日头条，又消磨了多少光阴？另外，很多人推崇碎片化学习，但是有一些东西碎片化学习效率是很低的，比如数学。这篇文章是我学习完 coursera 上面的《Learning How to Learn》MOOC加上我自己多年来的学习经验积累整理而来。注：文中可能有一些内容思考没有很深入，另外一些观点可能还需要更多的时间去检验，读者请自行甄别。  一些学习的坏习惯通常编程新手在学习一个新东西的时候，喜欢买一本权威指南之类的书（大神或者同事推荐），比如「C++ Primer」和「Javascript 权威指南」。 而这样一本书，一般页数在700-1400页左右，要完整读完，在不求甚解的基础之上大概要花费好几个月甚至大半年时间。 别说是新手，就算是一个C++编程老手去读「Javascript 权威指南」这样的书也不可能在只阅读一遍之后就能理解。 这时，很多人会选择重复多次阅读。有人会从头开始重复阅读，也有人只挑不理解的章节来阅读。 我以前上大学那会儿就是这么干的，读了好多C++的书籍，其实自己编写的C++代码并不多，也没有做过大型的C++项目。 看了好多书，其实都是一知半解，效率很低。工作以后，这种学习方式更加不可取，因为你没有那么多时间这么干。很多人偏好纸质书，因为在看书的时候手感不错，另外，还可以在书上把喜欢的句子和重点的段落用彩色笔标注出来。 这样做除了给自己造成一种假象「书上的重点我都标出来了，所以我都掌握了」之外，其实并无多大益处。 我现在喜欢在电脑上面看PDF，可以边看边写代码。读书的时候，还有一个误区，就是大脑被动地跟着作者的思路在走，如果是一本经典的书，你会每每被作者的真知灼见所震惊， 一种「于我心有戚戚焉」的感觉由然而生。如果作者的书写枯燥乏味，估计看几页你就丢到一边去了。在看书的时候，头脑中要 有自我意识，要感觉自己在跟作者对话，对于作者的观点不能一味全盘吸收，可以看一会儿，停下来，问几个为什么。另外，我并不是说划重点是不好的，只是划重点的效率没有想像中的高。划重点有点像收集资料和网页链接，在你收集了一大堆PDF和视频教程之后， 你会得到一种满足，但是这并不代表你真正学到了东西，这个是要非常警惕的。这是新手学编程的大忌，不去动手写，不去跟编译器和开发环境做斗争，你永远不知道软件开发过程中的操蛋事情。这个问题最大，也是影响N多人不去学习的理由。解决的办法只有一个，马上去做！一旦你开始去做了，你的大脑就不会排斥了。 你的计划再完美，你选的书籍再经典，你挑的视频水平再高，如果你不马上去看，去学，去动手实践，那永远也只是停留在空想的阶段。 成功学习的典范就是成功战胜拖延症的典范。这个是什么意思呢？不是说你真的只会写「Hello World」，而是说要跳出自己的舒适区，去尝试一些自己不了解的领域，去做一些超过自己能力范围的事情 。这是国内技术圈的一大通病，可能刚开始会聊点技术，但是时间一长就水了。好好的技术群一秒钟就可能变成水群。 而且经常还有老司机冒然发车，此时马上有人冒出一句「留图不留种，菊花万人捅」。我强烈建议大家不要过渡依赖Q群和微信群来学习技术或者解决问题，技术论坛，Stackoverflow 和 Github issue是你更好的去处。实践证明，睡眠不足，啥事也干不成，只想睡觉。有人会说我晚上不到那个点睡不着，我这里有一招。 拿着一本 Kindle，挑一本英文书，躺在床上看，半小时保管睡着。虽然说看书的效果不一定佳，但是催眠也是极好的。遇到问题，不假思索「百度」和「Google」，虽然现在80%的问题都可以找到解决方案，但是这样做对于自己并无多大益处。 找到解决方案之后，还要花几分钟时间探寻问题根源。可以查找背景资料，以便自己下次遇到同类型的问题时可以举一反三。做事情不专注，注意力不能集中，这也是学习的大忌。可以利用番茄工作法，给自己一段时间专注于某件事情，这样可以极大地提高 自己的工作效率。认为看书效率太低，而且收益也不高，看书需要大量的时间，而且看完感觉也没太大的用，不如直接Google和Q群来得容易。 如果你真的这样想过，我只想说「小伙子，你思想很危险！」 一些学习的好习惯与其一遍又一遍地阅读重复的书籍，编写同样的「Hello World」，不如有意识地总结回顾看过的书，学过的知识。 只需要每晚趟在床上的时候，回想一下今天都学到了什么？今天自己有进步一点点吗？看技术书籍要多写书中的代码，在初学阶段哪怕对着书本敲也没有什么问题。认真完成书中留的习题，在自己没有尽最大努力的情况下面不要去看答案。 不要怕犯错，每一次犯错都是自己进步的机会。不断地测试自己是最好的学习方法，不管是「刻意练习」还是「10000小时定律」，都要求我们通过不断地 实践来巩固我们的所学，从而让自己成为大师。每天把工作中遇到问题的解决方案总结一下，想想为什么要这么做，是什么导致了这个BUG，导致BUG的根本原因是什么。 是自己的逻辑混乱，粗心大意，还是程序框架太复杂？做需求的时候，要尽量避免复制粘贴，不要让代码里面有重复代码。 Don’t Repeat Yourself! Don’t Repeat Yourself! Don’t Repeat Yourself! 「重要的事情说三遍！」我是一个非常爱学习的人，但是有时候还是感觉学习不够高效。经常会由于一些突发情况把原本的学习计划打乱，导致学习效果打折扣。 因为学习一个东西最怕三天打渔，如果能够持续地学习一个东西，我可以把它学习地很好。这时候，我就得结合我自身的情况，选择一段最佳的 学习时间，在这段学习时间里我可以不被打扰，保持高度专注。比如每天早上6.30起床看一个小时书。在遇到一个没有显而易见解决方案的问题时，你可能费了好大功夫想出一个方案，但是千万要记得，该方案不一定是最优的， 而且很大可能还存在一个更佳的方法。而这个方法只需要你退后一步，换个思路，或者与同事讨论一下就可以得出。 这也是我为什么非常喜欢别人 Review 我的代码的原因，因为别人能看到我代码中存在的不足。另外，有些时候，对现有的方案做一些 「微创新」也能使原本普通的方案变得不普通。另外，习惯了面向对象，何不尝尝函数式编程？每年学习一门新的不同范式的编程语言，可以极大地开拓你的眼界，给你一些不一样的解题思路。多参加体育锻炼，多去户外走走，运动能够增强人的记忆力，并且有时候还能产生灵感。 如果身体不好，比如颈椎不好，下了班你就只想葛优躺了，因为你的本能告诉你，我不能再写代码了，会挂的。。。 想要成为大神，身体好是前提条件。有人30岁成为大神，我资质不好，我35岁成为大神总可以吧。 切莫在30岁的时候就把身体弄跨了，然后35岁转行了，永远失去了成长为大神的机会。多写博客，多分享自己的所学所思，这些对于学习者自身也是非常有益的。通过用别人能够理解的语言来解释你学到的东西， 本身就要求你对该知识充分理解。另外，很多人经常感叹「跟你讨论一下，我马上变得有思路了」，这其实就是交流的作用。很多知识没有足够的专注力和足够多的时间是很难学好的，保持学习的专注尤其重要。 因为人的大脑在专注模式下面，神经细胞更活跃，你学的东西更容易从短期记忆变成中长期记忆。 而且在高度专注下面，你的解决问题的能力也会提高，原本看起来复杂的东西，在专注面前说不定就不是事了。发现并找到自己的不足相对来说是比较容易的，但是要补齐短板就非常不易了。 因为人总是有畏难思想的，拖延症是怎么来的，就是你的大脑出于本能去做一些让自己分泌更多多巴胺的事情。 如果自己英语不好，就要下决心把英语攻克。如果自己数学不行，就要下死力气掌握数学。 补齐短板就像渡劫，越早渡劫，越快升仙。比如学好了 3D 数学，就给自己买一台顶配 MacBookPro 之类的。为什么游戏可以让你上瘾，因为它有反馈，有奖励机制。 学习数学是非常枯燥的，如果有了这个奖励机制，也许自己就更容易坚持了呢。PS：这一点对于有家室的程序员有用，你想学好什么，要获得什么奖励，你可以当着你老婆的面立个FLAG 小结Coursera 的这门MOOC 《Learning How to Learn》 强烈推荐给每一伴热爱学习的小伙伴，也欢迎大家给我留言，分享你的学习感悟。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/09/cfb878cc788ffd38bb744dd98d83c4fb.jpg"]}
{"title": "分布式之延时任务方案解析 - 文章 - 伯乐在线", "tag": ["IT技术", "分布式", "数据库"], "goodNum": "2", "saveNum": " 5 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n引言在开发中，往往会遇到一些关于延时任务的需求。例如生成订单30分钟未支付，则自动取消生成订单60秒后,给用户发短信对上述的任务，我们给一个专业的名字来形容，那就是。那么这里就会产生一个问题，这个和的区别究竟在哪里呢？一共有如下几点区别定时任务有明确的触发时间，延时任务没有定时任务有执行周期，而延时任务在某事件触发后一段时间内执行，没有执行周期定时任务一般执行的是批处理操作是多个任务，而延时任务一般是单个任务下面，我们以判断订单是否超时为例，进行方案分析方案分析该方案通常是在小型项目中使用，即通过一个线程定时的去扫描数据库，通过订单时间来判断是否有超时的订单，然后进行update或delete等操作博主当年早期是用quartz来实现的(实习那会的事)，简单介绍一下\nmaven项目引入一个依赖如下所示调用Demo类MyJob如下所示运行代码，可发现每隔3秒，输出如下优点:简单易行，支持集群操作\n缺点:(1)对服务器内存消耗大\n(2)存在延迟，比如你每隔3分钟扫描一次，那最坏的延迟时间就是3分钟\n(3)假设你的订单有几千万条，每隔几分钟这样扫描一次，数据库损耗极大该方案是利用JDK自带的DelayQueue来实现，这是一个无界阻塞队列，该队列只有在延迟期满的时候才能从中获取元素，放入DelayQueue中的对象，是必须实现Delayed接口的。\nDelayedQueue实现工作流程如下图所示其中Poll():获取并移除队列的超时元素，没有则返回空\ntake():获取并移除队列的超时元素，如果没有则wait当前线程，直到有元素满足超时条件，返回结果。定义一个类OrderDelay实现Delayed，代码如下运行的测试Demo为，我们设定延迟时间为3秒输出如下可以看到都是延迟3秒，订单被删除优点:效率高,任务触发时间延迟低。\n缺点:(1)服务器重启后，数据全部消失，怕宕机\n(2)集群扩展相当麻烦\n(3)因为内存条件限制的原因，比如下单未付款的订单数太多，那么很容易就出现OOM异常\n(4)代码复杂度较高先上一张时间轮的图(这图到处都是啦)时间轮算法可以类比于时钟，如上图箭头（指针）按某一个方向按固定频率轮动，每一次跳动称为一个 tick。这样可以看出定时轮由个3个重要的属性参数，ticksPerWheel（一轮的tick数），tickDuration（一个tick的持续时间）以及 timeUnit（时间单位），例如当ticksPerWheel=60，tickDuration=1，timeUnit=秒，这就和现实中的始终的秒针走动完全类似了。如果当前指针指在1上面，我有一个任务需要4秒以后执行，那么这个执行的线程回调或者消息将会被放在5上。那如果需要在20秒之后执行怎么办，由于这个环形结构槽数只到8，如果要20秒，指针需要多转2圈。位置是在2圈之后的5上面（20 % 8 + 1）我们用Netty的HashedWheelTimer来实现\n给Pom加上下面的依赖测试代码HashedWheelTimerTest如下所示输出如下优点:效率高,任务触发时间延迟时间比delayQueue低，代码复杂度比delayQueue低。\n缺点:(1)服务器重启后，数据全部消失，怕宕机\n(2)集群扩展相当麻烦\n(3)因为内存条件限制的原因，比如下单未付款的订单数太多，那么很容易就出现OOM异常利用redis的zset,zset是一个有序集合，每一个元素(member)都关联了一个score,通过score排序来取集合中的值\n\n添加元素:\n按顺序查询元素:\n查询元素score:\n移除元素:\n测试如下那么如何实现呢？我们将订单超时时间戳与订单号分别设置为score和member,系统扫描第一个元素判断是否超时，具体如下图所示此时对应输出如下可以看到，几乎都是3秒之后，消费订单。然而，这一版存在一个致命的硬伤，在高并发条件下，多消费者会取到同一个订单号，我们上测试代码ThreadTest输出如下所示显然，出现了多个线程消费同一个资源的情况。(1)用分布式锁，但是用分布式锁，性能下降了，该方案不细说。\n(2)对ZREM的返回值进行判断，只有大于0的时候，才消费数据，于是将consumerDelayMessage()方法里的修改为在这种修改后，重新运行ThreadTest类，发现输出正常了该方案使用redis的Keyspace Notifications，中文翻译就是，就是利用该机制可以在key失效之后，提供一个回调，实际上是redis会给客户端发送一个消息。是需要redis版本2.8以上。在redis.conf中，加入一条配置运行代码如下输出如下可以明显看到3秒过后，订单取消了\nps:redis的机制存在一个硬伤，官网内容如下\n:Because Redis Pub/Sub is fire and forget currently there is no way to use this feature if your application demands reliable notification of events, that is, if your Pub/Sub client disconnects, and reconnects later, all the events delivered during the time the client was disconnected are lost.\n: Redis的发布/订阅目前是即发即弃(fire and forget)模式的，因此无法实现事件的可靠通知。也就是说，如果发布/订阅的客户端断链之后又重连，则在客户端断链期间的所有事件都丢失了。\n因此，方案二不是太推荐。当然，如果你对可靠性要求不高，可以使用。优点:(1)由于使用Redis作为消息通道，消息都存储在Redis中。如果发送程序或者任务处理程序挂了，重启之后，还有重新处理数据的可能性。\n(2)做集群扩展相当方便\n(3)时间准确度高\n缺点:(1)需要额外进行redis维护我们可以采用rabbitMQ的延时队列。RabbitMQ具有以下两个特性，可以实现延迟队列RabbitMQ可以针对Queue和Message设置 x-message-tt，来控制消息的生存时间，如果超时，则消息变为dead letterlRabbitMQ的Queue可以配置x-dead-letter-exchange 和x-dead-letter-routing-key（可选）两个参数，用来控制队列内出现了deadletter，则按照这两个参数重新路由。\n结合以上两个特性，就可以模拟出延迟消息的功能,具体的，我改天再写一篇文章，这里再讲下去，篇幅太长。优点: 高效,可以利用rabbitmq的分布式特性轻易的进行横向扩展,消息支持持久化增加了可靠性。\n缺点：本身的易用度要依赖于rabbitMq的运维.因为要引用rabbitMq,所以复杂度和成本变高总结本文总结了目前互联网中，绝大部分的延时任务的实现方案。希望大家在工作中能够有所收获。\n其实大家在工作中，百分九十的人还是以业务逻辑为主，很少有机会能够进行方案设计。所以博主不推荐在分布式这块，花太多时间，应该看看《》。不过，鉴于现在的面试造火箭，工作拧螺丝现象太过严重，所以博主开始写《》，最后来个小漫画娱乐一下。\n\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/03/4bae6998d00f180d42c7da716e3d0bb2.jpg"]}
{"title": "如何编译 Linux 内核 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "2", "saveNum": " 2 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n曾经有一段时间，升级 Linux 内核让很多用户打心里有所畏惧。在那个时候，升级内核包含了很多步骤，也需要很多时间。现在，内核的安装可以轻易地通过像  这样的包管理器来处理。通过添加特定的仓库，你能很轻易地安装实验版本的或者指定版本的内核（比如针对音频产品的实时内核）。考虑一下，既然升级内核如此容易，为什么你不愿意自行编译一个呢？这里列举一些可能的原因：你想要简单了解编译内核的过程你需要启用或者禁用内核中特定的选项，因为它们没有出现在标准选项里你想要启用标准内核中可能没有添加的硬件支持你使用的发行版需要你编译内核你是一个学生，而编译内核是你的任务不管出于什么原因，懂得如何编译内核是非常有用的，而且可以被视作一个通行权。当我第一次编译一个新的 Linux 内核（那是很久以前了），然后尝试从它启动，我从中（系统马上就崩溃了，然后不断地尝试和失败）感受到一种特定的兴奋。既然这样，让我们来实验一下编译内核的过程。我将使用 Ubuntu 16.04 Server 来进行演示。在运行了一次常规的  之后，当前安装的内核版本是 。我想要升级内核版本到 ， 让我们小心地开始吧。有一个警告：强烈建议你在虚拟机里实验这个过程。基于虚拟机，你总能创建一个快照，然后轻松地从任何问题中回退出来。不要在产品机器上使用这种方式升级内核，除非你知道你在做什么。我们要做的第一件事是下载内核源码。在  找到你要下载的所需内核的 URL。找到 URL 之后，使用如下命令（我以  内核为例） 来下载源码文件:在下载期间，有一些事需要去考虑。为了编译内核，我们首先得安装一些需要的环境。这可以通过一个命令来完成：务必注意：你将需要至少 128GB 的本地可用磁盘空间来完成内核的编译过程。因此你必须确保有足够的空间。在新下载的内核所在的文件夹下，使用该命令来解压内核：使用命令  进入新生成的文件夹。在正式编译内核之前，我们首先必须配置需要包含哪些模块。实际上，有一些非常简单的方式来配置。使用一个命令，你能拷贝当前内核的配置文件，然后使用可靠的  命令来做任何必要的更改。使用如下命令来完成：现在你有一个配置文件了，输入命令 。该命令将打开一个配置工具（图 1），它可以让你遍历每个可用模块，然后启用或者禁用你需要或者不需要的模块。很有可能你会禁用掉内核中的一个重要部分，所以在  期间小心地一步步进行。如果你对某个选项不确定，不要去管它。或者更好的方法是使用我们拷贝的当前运行的内核的配置文件（因为我们知道它可以工作）。一旦你已经遍历了整个配置列表（它非常长），你就准备好开始编译了。现在是时候去实际地编译内核了。第一步是使用  命令去编译。调用  命令然后回答必要的问题（图 2）。这些问题取决于你将升级的现有内核以及升级后的内核。相信我，将会有非常多的问题要回答，因此你得预留大量的时间。回答了长篇累牍的问题之后，你就可以用如下的命令安装那些之前启用的模块：又来了，这个命令将耗费一些时间，所以要么坐下来看着编译输出，或者去做些其他事（因为编译期间不需要你的输入）。可能的情况是，你想要去进行别的任务（除非你真的喜欢看着终端界面上飞舞而过的输出）。现在我们使用这个命令来安装内核：又一次，另一个将要耗费大量可观时间的命令。事实上， 命令将比  命令花费更多的时间。去享用午餐，配置一个路由器，将 Linux 安装在一些服务器上，或者小睡一会吧。一旦  命令完成了，就是时候将内核启用来作为引导。使用这个命令来实现：当然，你需要将上述内核版本号替换成你编译完的。当命令执行完毕后，使用如下命令来更新 grub：现在你可以重启系统并且选择新安装的内核了。你已经编译了一个 Linux 内核！它是一项耗费时间的活动；但是，最终你的 Linux 发行版将拥有一个定制的内核，同时你也将拥有一项被许多 Linux 管理员所倾向忽视的重要技能。从 Linux 基金会和 edX 提供的免费  课程来学习更多的 Linux 知识。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "分布式之 Redis 复习精讲 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "Redis", "分布式", "数据库"], "goodNum": "1", "saveNum": " 8 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n引言博主的得到了大家的好评，内心诚惶诚恐，想着再出一篇关于复习精讲的文章。但是还是要说明一下，复习精讲的文章偏面试准备，真正在开发过程中，还是脚踏实地，一步一个脚印，不要投机取巧。\n考虑到绝大部分写业务的程序员，在实际开发中使用redis的时候，只会setvalue和getvalue两个操作，对redis整体缺乏一个认知。又恰逢博主某个同事下周要去培训redis，所以博主斗胆以redis为题材，对redis常见问题做一个总结，希望能够弥补大家的知识盲点。本文围绕以下几点进行阐述\n1、为什么使用redis\n2、使用redis有什么缺点\n3、单线程的redis为什么这么快\n4、redis的数据类型，以及每种数据类型的使用场景\n5、redis的过期策略以及内存淘汰机制\n6、redis和数据库双写一致性问题\n7、如何应对缓存穿透和缓存雪崩问题\n8、如何解决redis的并发竞争问题正文:博主觉得在项目中使用redis，主要是从两个角度去考虑:和。当然，redis还具备可以做分布式锁等其他功能，但是如果只是为了分布式锁这些其他功能，完全还有其他中间件(如zookpeer等)代替，并不是非要使用redis。因此，这个问题主要从性能和并发两个角度去答。\n:如下所示，分为两点\n\n如下图所示，我们在碰到需要执行耗时特别久，且结果不频繁变动的SQL，就特别适合将运行结果放入缓存。这样，后面的请求就去缓存中读取，使得请求能够。\n\n忽然想聊一下这个的标准。其实根据交互效果的不同，这个响应时间没有固定标准。不过曾经有人这么告诉我:”在理想状态下，我们的页面跳转需要在解决，对于页内操作则需要在间解决。另外，超过的耗时操作要有进度提示，并且可以随时中止或取消，这样才能给用户最好的体验。”\n那么具体是多少时间呢？\n根据《摩诃僧祗律》记载那么，经过周密的计算，一为0.36 秒,一有 0.018 秒.一长达 7.2 秒。\n\n如下图所示，在大并发的情况下，所有的请求直接访问数据库，数据库会出现连接异常。这个时候，就需要使用redis做一个缓冲操作，让请求先访问到redis，而不是直接访问数据库。\n:大家用redis这么久，这个问题是必须要了解的，基本上使用redis都会碰到一些问题，常见的也就几个。\n:主要是四个问题\n(一)缓存和数据库双写一致性问题\n(二)缓存雪崩问题\n(三)缓存击穿问题\n(四)缓存的并发竞争问题\n这四个问题，我个人是觉得在项目中，比较常遇见的，具体解决方案，后文给出。:这个问题其实是对redis内部机制的一个考察。其实根据博主的面试经验，很多人其实都不知道redis是单线程工作模型。所以，这个问题还是应该要复习一下的。\n:主要是以下三点\n(一)纯内存操作\n(二)单线程操作，避免了频繁的上下文切换\n(三)采用了非阻塞我们现在要仔细的说一说I/O多路复用机制，因为这个说法实在是太通俗了，通俗到一般人都不懂是什么意思。博主打一个比方：小曲在S城开了一家快递店，负责同城快送服务。小曲因为资金限制，雇佣了快递员，然后小曲发现资金不够了，只够买车送快递。\n\n客户每送来一份快递，小曲就让一个快递员盯着，然后快递员开车去送快递。慢慢的小曲就发现了这种经营方式存在下述问题几十个快递员基本上时间都花在了抢车上了，大部分快递员都处在闲置状态，谁抢到了车，谁就能去送快递随着快递的增多，快递员也越来越多，小曲发现快递店里越来越挤，没办法雇佣新的快递员了快递员之间的协调很花时间综合上述缺点，小曲痛定思痛，提出了下面的经营方式\n\n小曲只雇佣一个快递员。然后呢，客户送来的快递，小曲按标注好，然后放在一个地方。最后，那个快递员的去取快递，一次拿一个，然后开着车去送快递，送好了就回来拿下一个快递。\n上述两种经营方式对比，是不是明显觉得第二种，效率更高，更好呢。在上述比喻中:每个快递员——————>每个线程每个快递——————–>每个socket(I/O流)快递的送达地点————–>socket的不同状态客户送快递请求————–>来自客户端的请求小曲的经营方式————–>服务端运行的代码一辆车———————->CPU的核数于是我们有如下结论\n1、经营方式一就是传统的并发模型，每个I/O流(快递)都有一个新的线程(快递员)管理。\n2、经营方式二就是I/O多路复用。只有单个线程(一个快递员)，通过跟踪每个I/O流的状态(每个快递的送达地点)，来管理多个I/O流。下面类比到真实的redis线程模型，如图所示\n\n参照上图，简单来说，就是。我们的redis-client在操作的时候，会产生具有不同事件类型的socket。在服务端，有一段I/0多路复用程序，将其置入队列之中。然后，文件事件分派器，依次去队列中取，转发到不同的事件处理器中。\n需要说明的是，这个I/O多路复用机制，redis还提供了select、epoll、evport、kqueue等多路复用函数库，大家可以自行去了解。：是不是觉得这个问题很基础，其实我也这么觉得。然而根据面试经验发现，至少百分八十的人答不上这个问题。建议，在项目中用到后，再类比记忆，体会更深，不要硬记。基本上，一个合格的程序员，五种类型都会用到。\n：一共五种\n(一)String\n这个其实没啥好说的，最常规的set/get操作，value可以是String也可以是数字。一般做\n(二)hash\n这里value存放的是结构化的对象，比较方便的就是操作其中的某个字段。博主在做的时候，就是用这种数据结构存储用户信息，以cookieId作为key，设置30分钟为缓存过期时间，能很好的模拟出类似session的效果。\n(三)list\n使用List的数据结构，可以。另外还有一个就是，可以利用lrange命令，，性能极佳，用户体验好。\n(四)set\n因为set堆放的是一堆不重复值的集合。所以可以做。为什么不用JVM自带的Set进行去重？因为我们的系统一般都是集群部署，使用JVM自带的Set，比较麻烦，难道为了一个做一个全局去重，再起一个公共服务，太麻烦了。\n另外，就是利用交集、并集、差集等操作，可以。\n(五)sorted set\nsorted set多了一个权重参数score,集合中的元素能够按score进行排列。可以做。另外，参照另一篇，该文指出了sorted set可以用来做。最后一个应用就是可以做。:这个问题其实相当重要，到底redis有没用到家，这个问题就可以看出来。比如你redis只能存5G数据，可是你写了10G，那会删5G的数据。怎么删的，这个问题思考过么？还有，你的数据已经设置了过期时间，但是时间到了，内存占用率还是比较高，有思考过原因么?\n:\nredis采用的是定期删除+惰性删除策略。\n\n定时删除,用一个定时器来负责监视key,过期则自动删除。虽然内存及时释放，但是十分消耗CPU资源。在大并发请求下，CPU要将时间应用在处理请求，而不是删除key,因此没有采用这一策略.\n\n定期删除，redis默认每个100ms检查，是否有过期的key,有过期key则删除。需要说明的是，redis不是每个100ms将所有的key检查一次，而是随机抽取进行检查(如果每隔100ms,全部key进行检查，redis岂不是卡死)。因此，如果只采用定期删除策略，会导致很多key到时间没有删除。\n于是，惰性删除派上用场。也就是说在你获取某个key的时候，redis会检查一下，这个key如果设置了过期时间那么是否过期了？如果过期了此时就会删除。\n\n不是的，如果定期删除没删除key。然后你也没即时去请求key，也就是说惰性删除也没生效。这样，redis的内存会越来越高。那么就应该采用。\n在redis.conf中有一行配置该配置就是配内存淘汰策略的(什么，你没配过？好好反省一下自己)\n1）noeviction：当内存不足以容纳新写入数据时，新写入操作会报错。\n2）allkeys-lru：当内存不足以容纳新写入数据时，在键空间中，移除最近最少使用的key。\n3）allkeys-random：当内存不足以容纳新写入数据时，在键空间中，随机移除某个key。\n4）volatile-lru：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，移除最近最少使用的key。\n5）volatile-random：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，随机移除某个key。\n6）volatile-ttl：当内存不足以容纳新写入数据时，在设置了过期时间的键空间中，有更早过期时间的key优先移除。\nps：如果没有设置 expire 的key, 不满足先决条件(prerequisites); 那么 volatile-lru, volatile-random 和 volatile-ttl 策略的行为, 和 noeviction(不删除) 基本上一致。:一致性问题是分布式常见问题，还可以再分为最终一致性和强一致性。数据库和缓存双写，就必然会存在不一致的问题。答这个问题，先明白一个前提。就是我们所做的一切，只能保证最终一致性。另外，我们所做的方案其实从根本上来说，只能说，无法完全避免。因此，有强一致性要求的数据，不能放缓存。\n:给出了详细的分析，在这里简单的说一说。首先，采取正确更新策略，先更新数据库，再删缓存。其次，因为可能存在删除缓存失败的问题，提供一个补偿措施即可，例如利用消息队列。:这两个问题，说句实在话，一般中小型传统软件企业，很难碰到这个问题。如果有大并发的项目，流量有几百万左右。这两个问题一定要深刻考虑。\n:如下所示\n，即黑客故意去请求缓存中不存在的数据，导致所有的请求都怼到数据库上，从而数据库连接异常。\n:\n(一)利用互斥锁，缓存失效的时候，先去获得锁，得到锁了，再去请求数据库。没得到锁，则休眠一段时间重试\n(二)采用异步更新策略，无论key是否取到值，都直接返回。value值中维护一个缓存失效时间，缓存如果过期，异步起一个线程去读数据库，更新缓存。需要做(项目启动前，先加载缓存)操作。\n(三)提供一个能迅速判断请求是否有效的拦截机制，比如，利用布隆过滤器，内部维护一系列合法有效的key。迅速判断出，请求所携带的Key是否合法有效。如果不合法，则直接返回。\n，即缓存同一时间大面积的失效，这个时候又来了一波请求，结果请求都怼到数据库上，从而导致数据库连接异常。\n:\n(一)给缓存的失效时间，加上一个随机值，避免集体失效。\n(二)使用互斥锁，但是该方案吞吐量明显下降了。\n(三)双缓存。我们有两个缓存，缓存A和缓存B。缓存A的失效时间为20分钟，缓存B不设失效时间。自己做缓存预热操作。然后细分以下几个小点I 从缓存A读数据库，有则直接返回II A没有数据，直接从B读数据，直接返回，并且异步启动一个更新线程。III 更新线程同时更新缓存A和缓存B。:这个问题大致就是，同时有多个子系统去set一个key。这个时候要注意什么呢？大家思考过么。需要说明一下，博主提前百度了一下，发现答案基本都是推荐用redis事务机制。博主因为我们的生产环境，基本都是redis集群环境，做了数据分片操作。你一个事务中有涉及到多个key操作的时候，这多个key不一定都存储在同一个redis-server上。因此，\n如下所示\n(1)如果对这个key操作，\n这种情况下，准备一个分布式锁，大家去抢锁，抢到锁就做set操作即可，比较简单。\n(2)如果对这个key操作，\n假设有一个key1,系统A需要将key1设置为valueA,系统B需要将key1设置为valueB,系统C需要将key1设置为valueC.\n期望按照key1的value值按照 valueA–>valueB–>valueC的顺序变化。这种时候我们在数据写入数据库的时候，需要保存一个时间戳。假设时间戳如下那么，假设这会系统B先抢到锁，将key1设置为{valueB 3:05}。接下来系统A抢到锁，发现自己的valueA的时间戳早于缓存中的时间戳，那就不做set操作了。以此类推。其他方法，比如利用队列，将set方法变成串行访问也可以。总之，灵活变通。总结本文对redis的常见问题做了一个总结。大部分是博主自己在工作中遇到，以及以前面试别人的时候，爱问的一些问题。另外，，真正碰到一些有经验的工程师，其实几下就能把你问懵。最后，希望大家有所收获吧。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"]}
{"title": "倾听程序员的心声真的很重要 - 文章 - 伯乐在线", "tag": ["职场", " 1 评论 ", "心声"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n说到开发产品，没有人比程序员更了解产品。程序员知道产品的优点、缺陷、用途和潜在用途。说起这些，程序员了如指掌，如数家珍。在这个似乎无所不在的数字时代，倾听程序员必须要说的内容非常重要，而且也许比以往任何时期都更加重要。计算机和网络行业日渐变得更加软件驱动。同时，物联网（IoT）产业正在迅速占领市场。Gartner 预测，到 2020 年，全球将有超过 208 亿个连接的物联网设备。从汽车到衣服到尚未可知的产品，我们将开发出数以亿计的物联网设备——从设备到收集并向最终用户显示数据的项目或 app 都需要编程。竞争将不可避免地出现在该领域的许多新老对手中。在像 IoT 这样的新兴行业中，开发者社区至关重要。那些具备了软件和工程技能的人员必须能够开发、探索并将创意引导到现实中，将现有产品开发并优化为更好的产品。在此过程中，开发人员的知识和投入非常重要。任何行业，无论是否是新兴行业，你都不能冒疏远开发者的风险。忽视他们的投入意味着对他们缺乏信任，而信任是管理者与开发者关系良好的基石。他们需要信任你的产品以及你告诉他们的有关你的产品的要点。你最不应该做的一件事是危及到维护和开发产品的知识库。你还需要保持开发人员的投入并对你要求他们做的事情感兴趣。你需要听取他们的意见。为此，你需要一个在线社区。社区促进倾听。良好的社区使开发人员可以轻松地与其他开发人员进行协作和合作，并且在征求和收集开发人员投入的过程中提供所急需的手续。请记住，收集反馈信息越容易，将信息提供给产品管理和工程团队的速度就越快。良好的社区不仅承认开发人员对产品和平台的贡献，而且还不断寻求改进开发人员体验的方法。改进过程不应该凭空进行；此过程应该由开发者自己来提供意见。例如，社区经理发布了一个简短的调查，询问开发人员开发特定平台的近期体验。这项调查不仅是为了听取开发者喜欢什么，而且还想知道他们不喜欢什么，什么让他们感到沮丧，他们希望能以怎样不同的方式改善体验。经理跟进几项调查回复，深入挖掘开发人员的关注点。然后，经理处理这些问题，在开发人员社区中进行以下改进：重新整理开发人员文档体系结构，以简化导航并更容易找到最流行的参考文档增加示例代码数量实施流程以确保 SDK 与最新的产品更新和 bug 修复同步社区改进的范围很广，并且没有一成不变的规则或准则。最主要的是让开发者有机会表达他们的好恶，并确保他们的努力不会被置之不理。开发人员的投入有助于确保你的产品满足客户的期望并解决他们的问题。开发者提出的意见可帮助你提供令人惊叹的客户体验，并提高客户粘性。开发者付出的努力是产品可靠性和寿命最宝贵的资源之一。你需要倾听开发人员的意见，并为他们提供一个社区，不但开发者可以在社区中贡献和协作，而且你也可以在社区里轻松地征求、收集和积极影响开发者的重要投入。\n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/06/98df4795d7c7f65c7ec89ddf1a1afd92.jpg"]}
{"title": "分支限界法 - 文章 - 伯乐在线", "tag": ["IT技术", "分支"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n（1）求解目标：回溯法的求解目标是找出解空间树中满足约束条件的所有解，而分支限界法的求解目标则是找出满足约束条件的一个解，或是在满足约束条件的解中找出在某种意义下的最优解。 （2）搜索方式的不同：回溯法以深度优先的方式搜索解空间树，而分支限界法则以广度优先或以最小耗费优先的方式搜索解空间树。分支限界法的基本思想分支限界法常以广度优先或以最小耗费（最大效益）优先的方式搜索问题的解空间树。在分支限界法中，每一个活结点只有一次机会成为扩展结点。活结点一旦成为扩展结点，就一次性产生其所有儿子结点。在这些儿子结点中，导致不可行解或导致非最优解的儿子结点被舍弃，其余儿子结点被加入活结点表中。 此后，从活结点表中取下一结点成为当前扩展结点，并重复上述结点扩展过程。这个过程一直持续到找到所需的解或活结点表为空时为止。常见的两种分支限界法（1）队列式(FIFO)分支限界法    按照队列先进先出（FIFO）原则选取下一个结点为扩展结点。 （2）优先队列式分支限界法    按照优先队列中规定的优先级选取优先级最高的结点成为当前扩展结点。1、问题描述在下图所给的有向图G中，每一边都有一个非负边权。要求图G的从源顶点s到目标顶点t之间的最短路径。下图是用优先队列式分支限界法解有向图的单源最短路径问题产生的解空间树。其中，每一个结点旁边的数字表示该结点所对应的当前路长。找到一条路径：目前的最短路径是8，一旦发现某个结点的下界不小于这个最短路进，则剪枝：同一个结点选择最短的到达路径：2.剪枝策略在算法扩展结点的过程中，一旦发现一个结点的下界不小于当前找到的最短路长，则算法剪去以该结点为根的子树。在算法中，利用结点间的控制关系进行剪枝。从源顶点s出发，2条不同路径到达图G的同一顶点。由于两条路径的路长不同，因此可以将路长长的路径所对应的树中的结点为根的子树剪去。3.算法思想解单源最短路径问题的优先队列式分支限界法用一极小堆来存储活结点表。其优先级是结点所对应的当前路长。算法从图G的源顶点s和空优先队列开始。结点s被扩展后，它的儿子结点被依次插入堆中。此后，算法从堆中取出具有最小当前路长的结点作为当前扩展结点，并依次检查与当前扩展结点相邻的所有顶点。如果从当前扩展结点i到顶点j有边可达，且从源出发，途经顶点i再到顶点j的所相应的路径的长度小于当前最优路径长度，则将该顶点作为活结点插入到活结点优先队列中。这个结点的扩展过程一直继续到活结点优先队列为空时为止。\n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/06/6093f32a122633db22eb695f0d6cb461.jpg"]}
{"title": "我必须得告诉大家的MySQL优化原理 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "B+Tree", "B-Tree", "优化", "索引"], "goodNum": "4", "saveNum": " 12 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n说起MySQL的查询优化，相信大家收藏了一堆奇技淫巧：不能使用、不使用NULL字段、合理创建索引、为字段选择合适的数据类型….. 你是否真的理解这些优化技巧？是否理解其背后的工作原理？在实际场景下性能真有提升吗？我想未必。因而理解这些优化建议背后的原理就尤为重要，希望本文能让你重新审视这些优化建议，并在实际业务场景下合理的运用。如果能在头脑中构建一幅MySQL各组件之间如何协同工作的架构图，有助于深入理解MySQL服务器。下图展示了MySQL的逻辑架构图。MySQL逻辑架构整体分为三层，最上层为客户端层，并非MySQL所独有，诸如：连接处理、授权认证、安全等功能均在这一层处理。MySQL大多数核心服务均在中间这一层，包括查询解析、分析、优化、缓存、内置函数(比如：时间、数学、加密等函数)。所有的跨存储引擎的功能也在这一层实现：存储过程、触发器、视图等。最下层为存储引擎，其负责MySQL中的数据存储和提取。和Linux下的文件系统类似，每种存储引擎都有其优势和劣势。中间的服务层通过API与存储引擎通信，这些API接口屏蔽了不同存储引擎间的差异。我们总是希望MySQL能够获得更高的查询性能，最好的办法是弄清楚MySQL是如何优化和执行查询的。一旦理解了这一点，就会发现：当向MySQL发送一个请求的时候，MySQL到底做了些什么呢？MySQL客户端/服务端通信协议是“半双工”的：在任一时刻，要么是服务器向客户端发送数据，要么是客户端向服务器发送数据，这两个动作不能同时发生。一旦一端开始发送消息，另一端要接收完整个消息才能响应它，所以我们无法也无须将一个消息切成小块独立发送，也没有办法进行流量控制。客户端用一个单独的数据包将查询请求发送给服务器，所以当查询语句很长的时候，需要设置参数。但是需要注意的是，如果查询实在是太大，服务端会拒绝接收更多数据并抛出异常。与之相反的是，服务器响应给用户的数据通常会很多，由多个数据包组成。但是当服务器响应客户端请求时，客户端必须完整的接收整个返回结果，而不能简单的只取前面几条结果，然后让服务器停止发送。因而在实际开发中，尽量保持查询简单且只返回必需的数据，减小通信间数据包的大小和数量是一个非常好的习惯，这也是查询中尽量避免使用以及加上限制的原因之一。在解析一个查询语句前，如果查询缓存是打开的，那么MySQL会检查这个查询语句是否命中查询缓存中的数据。如果当前查询恰好命中查询缓存，在检查一次用户权限后直接返回缓存中的结果。这种情况下，查询不会被解析，也不会生成执行计划，更不会执行。MySQL将缓存存放在一个引用表（不要理解成，可以认为是类似于的数据结构），通过一个哈希值索引，这个哈希值通过查询本身、当前要查询的数据库、客户端协议版本号等一些可能影响结果的信息计算得来。所以两个查询在任何字符上的不同（例如：空格、注释），都会导致缓存不会命中。如果查询中包含任何用户自定义函数、存储函数、用户变量、临时表、mysql库中的系统表，其查询结果\n都不会被缓存。比如函数或者会因为不同的查询时间，返回不同的查询结果，再比如包含或者的查询语句会因为不同的用户而返回不同的结果，将这样的查询结果缓存起来没有任何的意义。既然是缓存，就会失效，那查询缓存何时失效呢？MySQL的查询缓存系统会跟踪查询中涉及的每个表，如果这些表（数据或结构）发生变化，那么和这张表相关的所有缓存数据都将失效。正因为如此，在任何的写操作时，MySQL必须将对应表的所有缓存都设置为失效。如果查询缓存非常大或者碎片很多，这个操作就可能带来很大的系统消耗，甚至导致系统僵死一会儿。而且查询缓存对系统的额外消耗也不仅仅在写操作，读操作也不例外：任何的查询语句在开始之前都必须经过检查，即使这条SQL语句永远不会命中缓存如果查询结果可以被缓存，那么执行完成后，会将结果存入缓存，也会带来额外的系统消耗基于此，我们要知道并不是什么情况下查询缓存都会提高系统性能，缓存和失效都会带来额外消耗，只有当缓存带来的资源节约大于其本身消耗的资源时，才会给系统带来性能提升。但要如何评估打开缓存是否能够带来性能提升是一件非常困难的事情，也不在本文讨论的范畴内。如果系统确实存在一些性能问题，可以尝试打开查询缓存，并在数据库设计上做一些优化，比如：用多个小表代替一个大表，注意不要过度设计批量插入代替循环单条插入合理控制缓存空间大小，一般来说其大小设置为几十兆比较合适可以通过和来控制某个查询语句是否需要进行缓存最后的忠告是不要轻易打开查询缓存，特别是写密集型应用。如果你实在是忍不住，可以将设置为，这时只有加入的查询才会走缓存，其他查询则不会，这样可以非常自由地控制哪些查询需要被缓存。当然查询缓存系统本身是非常复杂的，这里讨论的也只是很小的一部分，其他更深入的话题，比如：缓存是如何使用内存的？如何控制内存的碎片化？事务对查询缓存有何影响等等，读者可以自行阅读相关资料，这里权当抛砖引玉吧。MySQL通过关键字将SQL语句进行解析，并生成一颗对应的解析树。这个过程解析器主要通过语法规则来验证和解析。比如SQL中是否使用了错误的关键字或者关键字的顺序是否正确等等。预处理则会根据MySQL规则进一步检查解析树是否合法。比如检查要查询的数据表和数据列是否存在等等。经过前面的步骤生成的语法树被认为是合法的了，并且由优化器将其转化成查询计划。多数情况下，一条查询可以有很多种执行方式，最后都返回相应的结果。优化器的作用就是找到这其中最好的执行计划。MySQL使用基于成本的优化器，它尝试预测一个查询使用某种执行计划时的成本，并选择其中成本最小的一个。在MySQL可以通过查询当前会话的的值来得到其计算当前查询的成本。示例中的结果表示优化器认为大概需要做6391个数据页的随机查找才能完成上面的查询。这个结果是根据一些列的统计信息计算得来的，这些统计信息包括：每张表或者索引的页面个数、索引的基数、索引和数据行的长度、索引的分布情况等等。有非常多的原因会导致MySQL选择错误的执行计划，比如统计信息不准确、不会考虑不受其控制的操作成本（用户自定义函数、存储过程）、MySQL认为的最优跟我们想的不一样（我们希望执行时间尽可能短，但MySQL值选择它认为成本小的，但成本小并不意味着执行时间短）等等。MySQL的查询优化器是一个非常复杂的部件，它使用了非常多的优化策略来生成一个最优的执行计划：重新定义表的关联顺序（多张表关联查询时，并不一定按照SQL中指定的顺序进行，但有一些技巧可以指定关联顺序）优化和函数（找某列的最小值，如果该列有索引，只需要查找B+Tree索引最左端，反之则可以找到最大值，具体原理见下文）提前终止查询（比如：使用Limit时，查找到满足数量的结果集后会立即终止查询）优化排序（在老版本MySQL会使用两次传输排序，即先读取行指针和需要排序的字段在内存中对其排序，然后再根据排序结果去读取数据行，而新版本采用的是单次传输排序，也就是一次读取所有的数据行，然后根据给定的列排序。对于I/O密集型应用，效率会高很多）随着MySQL的不断发展，优化器使用的优化策略也在不断的进化，这里仅仅介绍几个非常常用且容易理解的优化策略，其他的优化策略，大家自行查阅吧。在完成解析和优化阶段以后，MySQL会生成对应的执行计划，查询执行引擎根据执行计划给出的指令逐步执行得出结果。整个执行过程的大部分操作均是通过调用存储引擎实现的接口来完成，这些接口被称为。查询过程中的每一张表由一个实例表示。实际上，MySQL在查询优化阶段就为每一张表创建了一个实例，优化器可以根据这些实例的接口来获取表的相关信息，包括表的所有列名、索引统计信息等。存储引擎接口提供了非常丰富的功能，但其底层仅有几十个接口，这些接口像搭积木一样完成了一次查询的大部分操作。查询执行的最后一个阶段就是将结果返回给客户端。即使查询不到数据，MySQL仍然会返回这个查询的相关信息，比如该查询影响到的行数以及执行时间等等。如果查询缓存被打开且这个查询可以被缓存，MySQL也会将结果存放到缓存中。结果集返回客户端是一个增量且逐步返回的过程。有可能MySQL在生成第一条结果时，就开始向客户端逐步返回结果集了。这样服务端就无须存储太多结果而消耗过多内存，也可以让客户端第一时间获得返回结果。需要注意的是，结果集中的每一行都会以一个满足①中所描述的通信协议的数据包发送，再通过TCP协议进行传输，在传输过程中，可能对MySQL的数据包进行缓存然后批量发送。回头总结一下MySQL整个查询执行过程，总的来说分为6个步骤：客户端向MySQL服务器发送一条查询请求服务器首先检查查询缓存，如果命中缓存，则立刻返回存储在缓存中的结果。否则进入下一阶段服务器进行SQL解析、预处理、再由优化器生成对应的执行计划MySQL根据执行计划，调用存储引擎的API来执行查询将结果返回给客户端，同时缓存查询结果看了这么多，你可能会期待给出一些优化手段，是的，下面会从3个不同方面给出一些优化建议。但请等等，还有一句忠告要先送给你：。选择数据类型只要遵循的原则就好，越小的数据类型通常会更快，占用更少的磁盘、内存，处理时需要的CPU周期也更少。越简单的数据类型在计算时需要更少的CPU周期，比如，整型就比字符操作代价低，因而会使用整型来存储ip地址，使用来存储时间，而不是使用字符串。这里总结几个可能容易理解错误的技巧：通常来说把可为的列改为不会对性能提升有多少帮助，只是如果计划在列上创建索引，就应该将该列设置为。对整数类型指定宽度，比如，没有任何卵用。使用32位（4个字节）存储空间，那么它的表示范围已经确定，所以和对于存储和计算是相同的。表示不允许负值，大致可以使正数的上限提高一倍。比如存储范围是-128 ~ 127，而存储的范围却是0 – 255。通常来讲，没有太大的必要使用数据类型。即使是在需要存储财务数据时，仍然可以使用。比如需要精确到万分之一，那么可以将数据乘以一百万然后使用存储。这样可以避免浮点数计算不准确和精确计算代价高的问题。使用4个字节存储空间，使用8个字节存储空间。因而，只能表示1970 – 2038年，比表示的范围小得多，而且的值因时区不同而不同。大多数情况下没有使用枚举类型的必要，其中一个缺点是枚举的字符串列表是固定的，添加和删除字符串（枚举选项）必须使用（如果只只是在列表末尾追加元素，不需要重建表）。schema的列不要太多。原因是存储引擎的API工作时需要在服务器层和存储引擎层之间通过行缓冲格式拷贝数据，然后在服务器层将缓冲内容解码成各个列，这个转换过程的代价是非常高的。如果列太多而实际使用的列又很少的话，有可能会导致CPU占用过高。大表非常耗时，MySQL执行大部分修改表结果操作的方法是用新的结构创建一个张空表，从旧表中查出所有的数据插入新表，然后再删除旧表。尤其当内存不足而表又很大，而且还有很大索引的情况下，耗时更久。当然有一些奇技淫巧可以解决这个问题，有兴趣可自行查阅。索引是提高MySQL查询性能的一个重要途径，但过多的索引可能会导致过高的磁盘使用率以及过高的内存占用，从而影响应用程序的整体性能。应当尽量避免事后才想起添加索引，因为事后可能需要监控大量的SQL才能定位到问题所在，而且添加索引的时间肯定是远大于初始添加索引所需要的时间，可见索引的添加也是非常有技术含量的。接下来将向你展示一系列创建高性能索引的策略，以及每条策略其背后的工作原理。但在此之前，先了解与索引相关的一些算法和数据结构，将有助于更好的理解后文的内容。通常我们所说的索引是指索引，它是目前关系型数据库中查找数据最为常用和有效的索引，大多数存储引擎都支持这种索引。使用这个术语，是因为MySQL在或其它语句中使用了这个关键字，但实际上不同的存储引擎可能使用不同的数据结构，比如InnoDB就是使用的。中的B是指，意为平衡。需要注意的是，B+树索引并不能找到一个给定键值的具体行，它找到的只是被查找数据行所在的页，接着数据库会把页读入到内存，再在内存中进行查找，最后得到要查找的数据。在介绍前，先了解一下二叉查找树，它是一种经典的数据结构，其左子树的值总是小于根的值，右子树的值总是大于根的值，如下图①。如果要在这课树中查找值为5的记录，其大致流程：先找到根，其值为6，大于5，所以查找左子树，找到3，而5大于3，接着找3的右子树，总共找了3次。同样的方法，如果查找值为8的记录，也需要查找3次。所以二叉查找树的平均查找次数为(3 + 3 + 3 + 2 + 2 + 1) / 6 = 2.3次，而顺序查找的话，查找值为2的记录，仅需要1次，但查找值为8的记录则需要6次，所以顺序查找的平均查找次数为：(1 + 2 + 3 + 4 + 5 + 6) / 6 = 3.3次，因此大多数情况下二叉查找树的平均查找速度比顺序查找要快。由于二叉查找树可以任意构造，同样的值，可以构造出如图②的二叉查找树，显然这棵二叉树的查询效率和顺序查找差不多。若想二叉查找数的查询性能最高，需要这棵二叉查找树是平衡的，也即平衡二叉树（AVL树）。平衡二叉树首先需要符合二叉查找树的定义，其次必须满足任何节点的两个子树的高度差不能大于1。显然图②不满足平衡二叉树的定义，而图①是一课平衡二叉树。平衡二叉树的查找性能是比较高的（性能最好的是最优二叉树），查询性能越好，维护的成本就越大。比如图①的平衡二叉树，当用户需要插入一个新的值9的节点时，就需要做出如下变动。通过一次左旋操作就将插入后的树重新变为平衡二叉树是最简单的情况了，实际应用场景中可能需要旋转多次。至此我们可以考虑一个问题，平衡二叉树的查找效率还不错，实现也非常简单，相应的维护成本还能接受，为什么MySQL索引不直接使用平衡二叉树？随着数据库中数据的增加，索引本身大小随之增加，不可能全部存储在内存中，因此索引往往以索引文件的形式存储的磁盘上。这样的话，索引查找过程中就要产生磁盘I/O消耗，相对于内存存取，I/O存取的消耗要高几个数量级。可以想象一下一棵几百万节点的二叉树的深度是多少？如果将这么大深度的一颗二叉树放磁盘上，每读取一个节点，需要一次磁盘的I/O读取，整个查找的耗时显然是不能够接受的。那么如何减少查找过程中的I/O存取次数？一种行之有效的解决方法是减少树的深度，将二叉树变为m叉树（多路搜索树），而就是一种多路搜索树。理解时，只需要理解其最重要的两个特征即可：第一，所有的关键字（可以理解为数据）都存储在叶子节点（），非叶子节点（）并不存储真正的数据，所有记录节点都是按键值大小顺序存放在同一层叶子节点上。其次，所有的叶子节点由指针连接。如下图为高度为2的简化了的。怎么理解这两个特征？MySQL将每个节点的大小设置为一个页的整数倍（原因下文会介绍），也就是在节点空间大小一定的情况下，每个节点可以存储更多的内结点，这样每个结点能索引的范围更大更精确。所有的叶子节点使用指针链接的好处是可以进行区间访问，比如上图中，如果查找大于20而小于30的记录，只需要找到节点20，就可以遍历指针依次找到25、30。如果没有链接指针的话，就无法进行区间查找。这也是MySQL使用作为索引存储结构的重要原因。MySQL为何将节点大小设置为页的整数倍，这就需要理解磁盘的存储原理。磁盘本身存取就比主存慢很多，在加上机械运动损耗（特别是普通的机械硬盘），磁盘的存取速度往往是主存的几百万分之一，为了尽量减少磁盘I/O，磁盘往往不是严格按需读取，而是每次都会预读，即使只需要一个字节，磁盘也会从这个位置开始，顺序向后读取一定长度的数据放入内存，预读的长度一般为页的整数倍。页是计算机管理存储器的逻辑块，硬件及OS往往将主存和磁盘存储区分割为连续的大小相等的块，每个存储块称为一页（许多OS中，页的大小通常为4K）。主存和磁盘以页为单位交换数据。当程序要读取的数据不在主存中时，会触发一个缺页异常，此时系统会向磁盘发出读盘信号，磁盘会找到数据的起始位置并向后连续读取一页或几页载入内存中，然后一起返回，程序继续运行。MySQL巧妙利用了磁盘预读原理，将一个节点的大小设为等于一个页，这样每个节点只需要一次I/O就可以完全载入。为了达到这个目的，每次新建节点时，直接申请一个页的空间，这样就保证一个节点物理上也存储在一个页里，加之计算机存储分配都是按页对齐的，就实现了读取一个节点只需一次I/O。假设的高度为h，一次检索最多需要次I/O（根节点常驻内存），复杂度O(h) = O(logmN)。实际应用场景中，M通常较大，常常超过100，因此树的高度一般都比较小，通常不超过3。最后简单了解下节点的操作，在整体上对索引的维护有一个大概的了解，虽然索引可以大大提高查询效率，但维护索引仍要花费很大的代价，因此合理的创建索引也就尤为重要。仍以上面的树为例，我们假设每个节点只能存储4个内节点。首先要插入第一个节点28，如下图所示。接着插入下一个节点70，在Index Page中查询后得知应该插入到50 – 70之间的叶子节点，但叶子节点已满，这时候就需要进行也分裂的操作，当前的叶子节点起点为50，所以根据中间值来拆分叶子节点，如下图所示。最后插入一个节点95，这时候Index Page和Leaf Page都满了，就需要做两次拆分，如下图所示。拆分后最终形成了这样一颗树。为了保持平衡，对于新插入的值需要做大量的拆分页操作，而页的拆分需要I/O操作，为了尽可能的减少页的拆分操作，也提供了类似于平衡二叉树的旋转功能。当Leaf Page已满但其左右兄弟节点没有满的情况下，并不急于去做拆分操作，而是将记录移到当前所在页的兄弟节点上。通常情况下，左兄弟会被先检查用来做旋转操作。就比如上面第二个示例，当插入70的时候，并不会去做页拆分，而是左旋操作。通过旋转操作可以最大限度的减少页分裂，从而减少索引维护过程中的磁盘的I/O操作，也提高索引维护效率。需要注意的是，删除节点跟插入节点类似，仍然需要旋转和拆分操作，这里就不再说明。通过上文，相信你对的数据结构已经有了大致的了解，但MySQL中索引是如何组织数据的存储呢？以一个简单的示例来说明，假如有如下数据表：对于表中每一行数据，索引中包含了last_name、first_name、dob列的值，下图展示了索引是如何组织数据存储的。可以看到，索引首先根据第一个字段来排列顺序，当名字相同时，则根据第三个字段，即出生日期来排序，正是因为这个原因，才有了索引的“最左原则”。“独立的列”是指索引列不能是表达式的一部分，也不能是函数的参数。比如：我们很容易看出其等价于 id = 4，但是MySQL无法自动解析这个表达式，使用函数是同样的道理。如果列很长，通常可以索引开始的部分字符，这样可以有效节约索引空间，从而提高索引效率。在多数情况下，在多个列上建立独立的索引并不能提高查询性能。理由非常简单，MySQL不知道选择哪个索引的查询效率更好，所以在老版本，比如MySQL5.0之前就会随便选择一个列的索引，而新的版本会采用合并索引的策略。举个简单的例子，在一张电影演员表中，在actor_id和film_id两个列上都建立了独立的索引，然后有如下查询：老版本的MySQL会随机选择一个索引，但新版本做如下的优化：当出现多个索引做相交操作时（多个AND条件），通常来说一个包含所有相关列的索引要优于多个独立索引。当出现多个索引做联合操作时（多个OR条件），对结果集的合并、排序等操作需要耗费大量的CPU和内存资源，特别是当其中的某些索引的选择性不高，需要返回合并大量数据时，查询成本更高。所以这种情况下还不如走全表扫描。因此时如果发现有索引合并（Extra字段出现），应该好好检查一下查询和表结构是不是已经是最优的，如果查询和表都没有问题，那只能说明索引建的非常糟糕，应当慎重考虑索引是否合适，有可能一个包含所有相关列的多列索引更适合。前面我们提到过索引如何组织数据存储的，从图中可以看到多列索引时，索引的顺序对于查询是至关重要的，很明显应该把选择性更高的字段放到索引的前面，这样通过第一个字段就可以过滤掉大多数不符合条件的数据。是指不重复的索引值和数据表的总记录数的比值，选择性越高查询效率越高，因为选择性越高的索引可以让MySQL在查询时过滤掉更多的行。唯一索引的选择性是1，这是最好的索引选择性，性能也是最好的。理解索引选择性的概念后，就不难确定哪个字段的选择性较高了，查一下就知道了，比如：是应该创建的索引还是应该颠倒一下顺序？执行下面的查询，哪个字段的选择性更接近1就把哪个字段索引前面就好。多数情况下使用这个原则没有任何问题，但仍然注意你的数据中是否存在一些特殊情况。举个简单的例子，比如要查询某个用户组下有过交易的用户信息：MySQL为这个查询选择了索引，如果不考虑特殊情况，这看起来没有任何问题，但实际情况是这张表的大多数数据都是从老系统中迁移过来的，由于新老系统的数据不兼容，所以就给老系统迁移过来的数据赋予了一个默认的用户组。这种情况下，通过索引扫描的行数跟全表扫描基本没什么区别，索引也就起不到任何作用。推广开来说，经验法则和推论在多数情况下是有用的，可以指导我们开发和设计，但实际情况往往会更复杂，实际业务场景下的某些特殊情况可能会摧毁你的整个设计。实际开发中，我们会经常使用多个范围条件，比如想查询某个时间段内登录过的用户：这个查询有一个问题：它有两个范围条件，login_time列和age列，MySQL可以使用login_time列的索引或者age列的索引，但无法同时使用它们。如果一个索引包含或者说覆盖所有需要查询的字段的值，那么就没有必要再回表查询，这就称为覆盖索引。覆盖索引是非常有用的工具，可以极大的提高性能，因为查询只需要扫描索引会带来许多好处：索引条目远小于数据行大小，如果只读取索引，极大减少数据访问量索引是有按照列值顺序存储的，对于I/O密集型的范围查询要比随机从磁盘读取每一行数据的IO要少的多MySQL有两种方式可以生产有序的结果集，其一是对结果集进行排序的操作，其二是按照索引顺序扫描得出的结果自然是有序的。如果explain的结果中列的值为表示使用了索引扫描来做排序。扫描索引本身很快，因为只需要从一条索引记录移动到相邻的下一条记录。但如果索引本身不能覆盖所有需要查询的列，那么就不得不每扫描一条索引记录就回表查询一次对应的行。这个读取操作基本上是随机I/O，因此按照索引顺序读取数据的速度通常要比顺序地全表扫描要慢。在设计索引时，如果一个索引既能够满足排序，又满足查询，是最好的。只有当索引的列顺序和子句的顺序完全一致，并且所有列的排序方向也一样时，才能够使用索引来对结果做排序。如果查询需要关联多张表，则只有子句引用的字段全部为第一张表时，才能使用索引做排序。子句和查询的限制是一样的，都要满足最左前缀的要求（有一种情况例外，就是最左的列被指定为常数，下面是一个简单的示例），其他情况下都需要执行排序操作，而无法利用索引排序。\n\n冗余索引是指在相同的列上按照相同的顺序创建的相同类型的索引，应当尽量避免这种索引，发现后立即删除。比如有一个索引，再创建索引就是冗余索引。冗余索引经常发生在为表添加新索引时，比如有人新建了索引，但这个索引不是扩展已有的索引。大多数情况下都应该尽量扩展已有的索引而不是创建新索引。但有极少情况下出现性能方面的考虑需要冗余索引，比如扩展已有索引而导致其变得过大，从而影响到其他使用该索引的查询。定期删除一些长时间未使用过的索引是一个非常好的习惯。关于索引这个话题打算就此打住，最后要说一句，索引并不总是最好的工具，只有当索引帮助提高查询速度带来的好处大于其带来的额外工作时，索引才是有效的。对于非常小的表，简单的全表扫描更高效。对于中到大型的表，索引就非常有效。对于超大型的表，建立和维护索引的代价随之增长，这时候其他技术也许更有效，比如分区表。最后的最后，。可能是被大家误解最多的函数了，它有两种不同的作用，其一是统计某个列值的数量，其二是统计行数。统计列值时，要求列值是非空的，它不会统计NULL。如果确认括号中的表达式不可能为空时，实际上就是在统计行数。最简单的就是当使用时，并不是我们所想象的那样扩展成所有的列，实际上，它会忽略所有的列而直接统计行数。我们最常见的误解也就在这儿，在括号内指定了一列却希望统计结果是行数，而且还常常误以为前者的性能会更好。但实际并非这样，如果要统计行数，直接使用，意义清晰，且性能更好。有时候某些业务场景并不需要完全精确的值，可以用近似值来代替，EXPLAIN出来的行数就是一个不错的近似值，而且执行EXPLAIN并不需要真正地去执行查询，所以成本非常低。通常来说，执行都需要扫描大量的行才能获取到精确的数据，因此很难优化，MySQL层面还能做得也就只有覆盖索引了。如果不还能解决问题，只有从架构层面解决了，比如添加汇总表，或者使用redis这样的外部缓存系统。在大数据场景下，表与表之间通过一个冗余字段来关联，要比直接使用有更好的性能。如果确实需要使用关联查询的情况下，需要特别注意的是：确保和字句中的列上有索引。在创建索引的时候就要考虑到关联的顺序。当表A和表B用列c关联的时候，如果优化器关联的顺序是A、B，那么就不需要在A表的对应列上创建索引。没有用到的索引会带来额外的负担，一般来说，除非有其他理由，只需要在关联顺序中的第二张表的相应列上创建索引（具体原因下文分析）。确保任何的和中的表达式只涉及到一个表中的列，这样MySQL才有可能使用索引来优化。要理解优化关联查询的第一个技巧，就需要理解MySQL是如何执行关联查询的。当前MySQL关联执行的策略非常简单，它对任何的关联都执行操作，即先在一个表中循环取出单条数据，然后在嵌套循环到下一个表中寻找匹配的行，依次下去，直到找到所有表中匹配的行为为止。然后根据各个表匹配的行，返回查询中需要的各个列。太抽象了？以上面的示例来说明，比如有这样的一个查询：假设MySQL按照查询中的关联顺序A、B来进行关联操作，那么可以用下面的伪代码表示MySQL如何完成这个查询：可以看到，最外层的查询是根据列来查询的，上如果有索引的话，整个关联查询也不会使用。再看内层的查询，很明显上如果有索引的话，能够加速查询，因此只需要在关联顺序中的第二张表的相应列上创建索引即可。当需要分页操作时，通常会使用加上偏移量的办法实现，同时加上合适的字句。如果有对应的索引，通常效率会不错，否则，MySQL需要做大量的文件排序操作。一个常见的问题是当偏移量非常大的时候，比如：这样的查询，MySQL需要查询10020条记录然后只返回20条记录，前面的10000条都将被抛弃，这样的代价非常高。优化这种查询一个最简单的办法就是尽可能的使用覆盖索引扫描，而不是查询所有的列。然后根据需要做一次关联查询再返回所有的列。对于偏移量很大时，这样做的效率会提升非常大。考虑下面的查询：如果这张表非常大，那么这个查询最好改成下面的样子：这里的延迟关联将大大提升查询效率，让MySQL扫描尽可能少的页面，获取需要访问的记录后在根据关联列回原表查询所需要的列。有时候如果可以使用书签记录上次取数据的位置，那么下次就可以直接从该书签记录的位置开始扫描，这样就可以避免使用，比如下面的查询：其他优化的办法还包括使用预先计算的汇总表，或者关联到一个冗余表，冗余表中只包含主键列和需要做排序的列。MySQL处理的策略是先创建临时表，然后再把各个查询结果插入到临时表中，最后再来做查询。因此很多优化策略在查询中都没有办法很好的时候。经常需要手动将、、等字句“下推”到各个子查询中，以便优化器可以充分利用这些条件先优化。除非确实需要服务器去重，否则就一定要使用，如果没有关键字，MySQL会给临时表加上选项，这会导致整个临时表的数据做唯一性检查，这样做的代价非常高。当然即使使用ALL关键字，MySQL总是将结果放入临时表，然后再读出，再返回给客户端。虽然很多时候没有这个必要，比如有时候可以直接把每个子查询的结果返回给客户端。理解查询是如何执行以及时间都消耗在哪些地方，再加上一些优化过程的知识，可以帮助大家更好的理解MySQL，理解常见优化技巧背后的原理。希望本文中的原理、示例能够帮助大家更好的将理论和实践联系起来，更多的将理论知识运用到实践中。其他也没啥说的了，给大家留两个思考题吧，可以在脑袋里想想答案，这也是大家经常挂在嘴边的，但很少有人会思考为什么？有非常多的程序员在分享时都会抛出这样一个观点：尽可能不要使用存储过程，存储过程非常不容易维护，也会增加使用成本，应该把业务逻辑放到客户端。既然客户端都能干这些事，那为什么还要存储过程？本身也挺方便的，直接查询就好了，为什么还需要视图呢？[1] \n[2] \n[3] 备注：水平有限，难免疏漏，如果问题请留言\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://wx4.sinaimg.cn/mw690/63918611gy1frnqlou40xj207p07dq32.jpg"]}
{"title": "如何编写 C++ 游戏引擎 - 文章 - 伯乐在线", "tag": ["C/C++", "游戏", "游戏引擎"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n最近我在用 C++ 写游戏引擎，再用这个引擎做了一个移动端小游戏跳一跳（Hop Out）。下面是截自我的 iPhone6 的一个小片段。视频地址：http://preshing.com/images/hopoutclip.mp4跳一跳是我想玩的游戏类型：3D卡通外观的复古街机游戏。目标是改变每个填充块的颜色，就像Q * Bert一样。Hop Out仍在开发中，但引擎的功能已经很完善了，所以我想在这里分享一些关于引擎开发的技巧。你为什么想要写一个游戏引擎？可能有很多原因：你是个修理工，喜欢从头开始建立系统，直到系统完成。关于游戏开发你想了解更多。我在游戏行业工作了14年，现在我仍然在不停的琢磨。我甚至不确定我是否可以从头开始编写一个引擎，因为它与大型工作室的编程工作的日常职责大不相同。我想知道答案。你喜欢控制。对完全按照你想要的方式组织代码，知道一切都在哪里，感到满意。你可以从（1984），（1993），（1995）等经典游戏引擎以及Unity和Unreal等行业巨头那里获得灵感。你相信我们这个游戏产业应该试着去揭开引擎发展的序幕。我们并没有掌握制作游戏的艺术。还离得很远！我们对这个过程的研究越多，改进的机会就越大。2017年的游戏平台 – 手机，游戏机和电脑 – 非常强大，而且在很多方面都非常相似。游戏引擎的开发并不是像过去一样，在脆弱和怪异的硬件上挣扎。在我看来，更多是关于自己制造出来的复杂性的斗争。创造一个怪物很容易！这就是为什么本文建议围绕着保持事情可控的原因。我把它分成三部分：使用迭代方法在统一事物前要三思请注意，序列化是一个很大的课题这个建议适用于任何类型的游戏引擎。我不会告诉你如何编写着色器，八叉树是什么，或者如何添加物体。这些事儿，都是我假设你已经知道而且应该知道 – 这很大程度上取决于你想要制作的游戏类型。相反，我故意选择了一些似乎没有被广泛承认或提及的观点 – 这些是我在试图揭开一个主题神秘面纱时最感兴趣的一些观点。使用迭代方法我的第一条建议是使一些东西（任何东西），快速运行起来，然后迭代。如果可能的话，从一个示例应用程序开始，初始化设备并在屏幕上绘制一些东西。就我而言，我下载了，打开了Xcode-iOS / Test / TestiPhoneOS.xcodeproj，然后在我的iPhone上运行了testgles2示例。瞧！我使用OpenGL ES 2.0，生成了一个可爱的旋转立方体。下一步，是下载一个其他人制作的马里奥3D 模型。我写了一个快速和粗糙的OBJ文件加载器 – 文件格式并不太复杂 – 并且修改了例程，来呈现Mario，而不是一个立方体。我还集成了来帮助加载纹理。然后我实现了一个双摇杆控制器用来操控马里奥（我本来想要创建的是一个双摇杆设计游戏，并不是马里奥。）接下来，我想探索骨骼动画，所以我打开了，做了一个触手模型，并且用一个前后摆动的双骨架来操纵它。此时，我放弃了OBJ文件格式，编写了一个Python脚本来从Blender导出自定义的JSON文件。这些JSON文件描述了皮肤网格，骨架和动画数据。在的帮助下将这些文件加载到游戏中。一旦这个完成，我回到了Blender，并做了更详细的角色设计。 （这是我创造的第一个被操纵的3D人，我为他感到骄傲。）在接下来的几个月里，我采取了以下几个步骤：开始将向量和矩阵函数分解成我自己的3D数学库。用CMake项目替换.xcodeproj。在Windows和iOS上运行引擎，因为我喜欢在Visual Studio下工作。开始将代码移动到单独的“引擎”和“游戏”库中。随着时间的推移，我把它们分成更细粒度的库。写了一个单独的应用程序将我的JSON文件转换为游戏可以直接加载的二进制数据。最终从iOS版本中删除所有SDL库。 （Windows版本仍然使用SDL。）重点是：在开始编程之前，我没有对引擎架构进行设计。这是一个经过深思熟虑的选择。相反，我只是写了实现下一个特性的最简单的代码，然后我会查看代码，看看会出现什么自然生成的架构。我说的“引擎架构”是指组成游戏引擎的模块集，这些模块之间的依赖关系，以及用于与每个模块交互的 。这是一个的方法，因为它关注于较小的可交付成果。它在编写游戏引擎时效果非常好，因为在每个步骤中，你都有一个正在运行的程序。如果在将代码合成到新模块中时出现问题，可以随时将做的更改与以前工作的代码进行比较。显然，我假设你在使用。你可能会认为这种方法浪费了很多时间，因为总是在编写糟糕的代码，之后需要清理。但是大部分的清理操作都是将代码从一个.cpp文件移动到另一个，将函数声明提取到.h文件中，或者直接进行简单的修改。决定事情应该去哪是难点，但是这在已经有代码的时候会更容易决定。我认为用相反的方法：试图设计出一个能够提前完成所有需求的架构，会浪费更多的时间。我最喜欢的两篇关于系统过度设计风险的文章是 和 。我并不是说在用代码处理问题之前，不应该在纸上进行设计。我也不是说你不应该事先决定你想要的功能。比如，我从一开始就知道我想让我的引擎在后台线程中加载所有资源。我只是没有尝试设计或实现该功能，直到我的引擎首先加载一些资源。迭代的方法给了我一个比我以前盯着一张白纸冥思苦想更优雅的架构。我的引擎的iOS版本现在是 100％ 原始代码，包括自定义数学库，容器模板，反射/序列化系统，渲染框架，物理模块和音频混合器。我可以编写每一个模块，但是你可能没有必要自己写所有这些东西。你可能会发现适合自己引擎的许多优秀的开源代码库。 、 和 只是一些有趣的例子。在整合事物太多之前要三思作为程序员，我们尽量避免代码重复，喜欢代码遵循统一的风格。不过，我认为不要让这些本能凌驾于每一个决定之上。举个例子，我的引擎包含了几个“智能指针”模板类，与 std :: shared_ptr 类似。每一个指针作为一个原始指针的包装，有助于防止内存泄漏。<> 是用于具有单个所有者的动态分配的对象。Reference<> 使用引用计数来允许一个对象拥有多个所有者。audio :: AppOwned <> 被音频混音器以外的代码调用，允许游戏系统拥有音频混音器使用的对象，例如当前播放的语音。audio :: AudioHandle <> 使用音频混音器内部的引用计数系统。这样可能看起来像其中一些类复制了其它的功能，违反 的原则。事实上，在开发早期，我尽可能地重用现有的Reference <>类。但是，我发现音频对象的生命周期是由特殊规则来管理的：如果一个音频语音已经完成了一个样本的播放，并且游戏没有指向该语音的指针，那么该语音会被立即到删除排队等待。如果游戏持有指针，则不应删除这个语音对象。如果游戏持有一个指针，但指针的所有者在语音结束之前被销毁，这段语音应该被取消，而不是增加Reference <>的复杂性，我决定引入单独的模板类，这样更为实用。95％ 的时间都在重用现有的代码。但是，如果你开始感到麻痹，或者发现自己增加了一件简单的事情的复杂性，那就问自己，代码库中的东西是否应该是两件事。我不喜欢Java的一件事是，它强迫你在一个类中定义每个函数。在我看来，这是无稽之谈。这可能会使你的代码看起来更加一致，但是它也鼓励过度工程，并且不适合我前面描述的迭代方法。在我的 C++ 引擎中，一些函数属于类，有些则不属于类。例如，游戏中的每个敌人都是一个类，可能就像你预料的那样，大部分敌人的行为都是在这个类内部实现的。另一方面，在我的引擎中投射的球体是通过调用 ) 函数来执行的，这是物理命名空间中的一个函数。 sphereCast() 不属于任何类 – 它只是物理模块的一部分。我构建了一个系统来管理模块之间的依赖关系，这使得我的代码组织得很好。将这个函数包装在一个任意的类中不会以任何有意义的方式改善代码的组织。然后是，这是一种。我们经常需要为一个对象调用一个函数，而不知道该对象的确切类型。 C ++程序员的第一本能是用虚函数定义抽象基类，然后在派生类中重写这些函数。这是有效的，但这只是一种技术。还有其他动态调度技术，不会引入额外的代码，或带来其他好处： C ++ 11引入了std :: function，这是存储回调函数的一个简便方法。也可以编写自己的std :: function版本，这样在调试中不会那么痛苦。许多回调函数可以用一对指针来实现：一个函数指针和一个类型不确定的参数。它只需要在回调函数中进行明确的转换。你在纯C语言库中经常看到。有时候，底层类型实际上是在编译时已知的，你可以绑定这个函数调用而不用额外的运行开销。 是我在游戏引擎中使用的一个库，它非常依赖这种技术。例如看到turf:: Mutex,这只是针对特定平台类的定义。有时，最直接的方法是自己构建和维护一个原始函数指针表。我在我的音频混音器和序列化系统中使用了这种方法。Python解释器也大量使用这种技术，如下所述。你甚至可以将函数指针存储在散列表中，使用函数名称作为关键字。我使用这种技术来调度输入事件，如多点触控事件。这是记录游戏输入并用重放系统回放的策略的一部分。动态调度是一个很大的课题。我只是想表明，有很多方法来实现它。你编写的可扩展底层代码越多（这在游戏引擎中很常见），越会发现替代方法越多。如果你不习惯这种编程，C语言编写的Python解释器是一个很好的学习资源。它实现了一个强大的对象模型：每个PyObject都指向一个PyTypeObject，每个PyTypeObject都包含一个用于动态分配的函数指针表。如果你想直接跳转到其中的话，的文档是一个很好的起点。注意序列化是一个大问题是将运行时对象转换为字节序列的操作。换句话说，就是保存和加载数据。对于许多游戏引擎来说，游戏内容以各种可编辑的格式创建，例如.png，.json，.blend或专有格式，然后最终转换为特定于平台的可以快速加载到引擎的游戏格式。流水线中的最后一个应用通常被称为“炊具”。炊具可能被集成到另一个工具，甚至分布在几台机器上。通常，炊具和一些工具是与游戏引擎本身一起开发和维护的。在建立这样的流水线时，每个阶段的文件格式的选择取决于你。你可以定义自己的一些文件格式，这些格式可能会随着添加引擎功能而变化。渐渐地可能会发现有必要保持某些程序与以前保存的文件兼容。不管什么格式，你最终都需要用C++来序列化它。用C ++实现序列化有无数种方法。一个相当明显的方式是将加载和保存函数添加到要序列化的C ++类。可以通过在文件头中存储版本号来实现向后兼容，然后将这个数字传递给每个加载函数。这是可行的，尽管这样代码可能维护起来比较繁琐。通过（特别是通过创建描述C ++类型布局的运行时数据），可以编写更灵活，不容易出错的序列化代码。想要快速了解反射如何进行序列化，请看一下开源项目是如何实现的。 从源代码构建Blender时，有许多步骤。首先，编译并运行一个名为makesdna的自定义实用程序。该实用程序解析Blender源代码树中的一组C语言头文件，然后以的自定义格式输出所有C定义类型的汇总。这个SDNA数据作为反射数据，链接到Blender本身，并保存在Blender写入的每个.blend文件中。从这一刻开始，每当Blender加载一个.blend文件，就会将.blend文件的SDNA与链接到当前版本的SDNA进行比较，并使用通用序列化代码来处理差异。这个策略使Blender具有令人印象深刻的向前和向后兼容性。你仍然可以在最新版本的Blender中加载的文件，也可以在旧版本中加载新的.blend文件。像Blender一样，许多游戏引擎及其相关工具都会生成并使用自己的反射数据。有很多方法可以做到这一点：可以像Blender一样解析自己的C / C ++源代码来提取类型信息。你可以创建一个单独的数据描述语言，并编写一个工具来从该语言生成C ++类型定义和反射数据。可以使用预处理器宏和C ++模板在运行时生成反射数据。一旦你有反射数据可用，有无数的方法来编写一个通用的序列化器。显然，我省略了很多细节。在这篇文章中，我只想表明有很多不同的方法来序列化数据，其中一些非常复杂。程序员不会像其他引擎系统那样讨论序列化，尽管大多数其他系统依赖于它。例如，在给出的96个程序设计讲座中，我数了一下，共有31次关于图形，11次关于在线，10次关于工具，4次关于AI，3关于物理模块，2关于音频的 – 但只有一个。至少，试着想一想你的需求会有多复杂。如果你正在制作一个像Flappy Bird这样的小游戏，只有少数资源.，那么你可能不需要想太多的序列化。你可以直接从PNG加载纹理，这样很好处理。如果你需要一个向后兼容的紧凑的二进制格式，但不想自己开发，可以看看第三方库，比如或者。我不认为是序列化游戏资产的理想选择，但是值得研究。编写一个游戏引擎，即使是一个小游戏引擎，也是一个很大的任务。关于这个我可以说的还有很多，但是对于这个长度的帖子来说，这真的是我认为最有用的建议：迭代地工作，抵制统一代码的冲动，并且知道序列化是一个大问题，你需要选择一个合适的策略。根据我的经验，如果忽视这些事情，每一件事情都可能成为一个绊脚石。我喜欢比较这些东西，真的很想听到其他开发人员的意见。如果你已经写了一个引擎，你的经验是否让你有什么相同的结论吗？如果你没有写，或者只是在构思，我也对你的想法也很感兴趣。你认为什么是好的学习资源？哪些部分对你来说看起来很神秘？你可以在下面评论或在上给我留言！\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://wx2.sinaimg.cn/mw690/63918611gy1fre7k2nnx5j20c806wgli.jpg"]}
{"title": "如何做人性化的代码审查？ - 文章 - 伯乐在线", "tag": ["IT技术", " 2 评论 ", "Code Review", "代码审查"], "goodNum": "1", "saveNum": " 4 收藏", "sayNum": " 2 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n最近，我一直在读有关代码审查最佳范例的文章。我注意到这些文章的关注点是找到 bug，而忽略了代码审查其他的部分。用建设性、专业的问题沟通方式？不相关！只要识别出所有的 bug，剩下的部分会水到渠成。我只能假设我读过的这些文章都来自未来，那时候所有的开发人员都是机器人。在那个世界，你的队友欢迎对其代码未经过推敲措辞的批评，因为处理这样的信息能温暖他们冰冷的机器人之心。我要做一个大胆的假设，你想要在当前世界改进代码审查，此时你的队友都是人类。我还要做一个更大胆的假设，你与同事之间积极的关系本身就是一个目的，而不仅仅是一个可调整的变量来最小化缺陷的平均成本。在这些情况下，你的审查实践会发生怎样的变化呢？在这篇文章中，我讨论了一些技巧，把代码审查既看作是技术过程，也看作是社会过程。什么是代码审查?“代码审查（code review）”这一术语可以指一系列活动，从简单地站在队友身后读读代码，到 20 人与会的单行代码分析。我用这一术语指正式的、书面的过程，但也不像一系列现场代码审查会议那么重大。代码审查的参与者包括以及：作者写代码并把代码送去审查，审查者读代码并决定代码什么时候就绪并入团队的代码库。一次审查可以由多个审查者完成，但是我做了简化的假设——你是唯一的审查者。在代码审查开始之前，作者必须创建一个。作者想要将源代码并入团队代码库，变更表包括一系列源代码的变更。当作者把变更表发给审查者时，审查就开始了。代码审查是发生的。每个循环都是作者与审查者之间完整的往返：作者发送变更，审查者给予变更的书面反馈。每次代码审查都包括一次或者更多的循环。当审查者了这些变更，审查结束。这通常指的是给出 LGTM，“我觉得不错（looks good to me）”的简写。这为什么很难？如果程序员给你发了一份变更表，他们觉得这个变更表棒极了。你又给他们写了一份详细的清单，解释为什么这个变更表并不好。这是需要小心处理的信息。这是我不想念 IT 的一个原因，因为程序员是非常不可爱的人……比如，在航空业，那些过分高估了自己技术水平的人都死了。Philip Greenspun，ArsDigita 的联合创始人，引自《》。作者容易把对其代码的批评解读为暗示他们不是合格的程序员。代码审查是一个分享知识和做工程决定的机会。但是如果作者把讨论理解为个人攻击，这个目标无法达成。除此之外，你还面临着书面传达想法的挑战，词不达意的风险会更高。作者听不到你的语气，也看不到你的肢体语言，所以清晰地、小心地传达你的反馈更为重要。对一个有戒备心的作者来说，一句无冒犯意味的批注，比如“你忘了关闭文件句柄”，可以被理解成“真不敢相信你忘了关闭文件句柄！你真是个傻子。”技巧让电脑做无聊的部分用风格指南平息风格争论马上开始审查从高级别开始，逐步向下慷慨地使用代码示例永远别说“你把反馈表达成请求，而不是指令把批注与原则联系在一起，而不是观点在会议和邮件的干扰下，可用来专注于代码的时间很少。你的精神毅力更是短缺。读队友的代码是认知上的负担，要求高强度的专注。别把这些资源浪费在电脑能做的任务上，尤其是当电脑能做得更好的时候。空白错误是一个显著的例子。比较一下人类审查者找到缩进错误并与作者一起改正所花费的精力，和仅仅使用一个自动排版工具所花费的精力：2.审查者写批注，指出错误缩进3.审查者重新读批注，确保措辞清晰，不含指责意味4.作者读批注5.作者改正代码缩进6.审查者核实作者适当地处理了批注右边是空的，因为作者用了一个代码编辑器，每次他们点击“保存”时，该代码编辑器会自动规定空白的格式。在最糟的情况下，作者把代码发出去以供审查，解决方法报告说空格错误。作者在不需要审查者顾虑的情况下，修正这个问题。在代码审查中寻找可以被自动解决的机械性任务。以下是常见的例子：自动化使你作为审查者能做出更多有意义的贡献。当你能忽略一整个类别的问题，比如输入的排序或者源文件命名的约定，你能够关注更有趣的事情，比如函数错误或者可读性缺陷。自动化也能给作者带来好处。自动化使作者用几秒钟发现粗心的错误，而不是几小时。即时反馈使得从错误中学习更容易，修正错误的代价也更小，因为作者脑海中还有相关的背景。另外，如果他们不得不听到自己犯下的愚蠢错误，对自尊心来说，从电脑那听到要比从你那听到更容易被接受。和你的团队一起将这些自动检查加入代码审查的工作流程中（例如，在 Git 中的  或者 Github 中的 ）。如果审查过程要求作者手动运行这些检查，你会损失大部分好处。作者总是会忘记一些情况，迫使你继续审查简单的问题，而这些问题本来就能被自动处理。关于风格的争论浪费了审查的时间。一致的风格确实重要，但是代码审查不是争论花括号位置的时候。在审查中消除风格争论的最佳办法是，遵守一个风格指南。好的风格指南不仅定义了像命名习惯或者空白规则这样的表面元素，而且定义了怎样使用给定编程语言的特征。比如，JavaScript 和 Perl 都包含了一些功能——他们提供了许多实现相同逻辑的方法。风格指南定义了做事的唯一方法，这样不会以一半队员用了一组语言特征而另一半队员用了完全不同的一组特征收尾。一旦有了一个风格指南，你就不需要浪费审查循环，来跟作者争论到底谁的命名习惯最好。只要遵从风格指南然后继续就行。如果你的风格指南没有指定某个特定问题的约定，那它一般都不值得争论。如果你遇到一个风格指南未涉及的问题，它又重要到需要讨论，和团队一起推敲。然后把决定加到风格指南，这样你们永远不需要再进行一次这个讨论。如果从网上搜索，你能找到已发布的风格指南可供使用。是最知名的，但是如果它的风格不适合你，你可以找到其他的指南。通过采纳一个现存的指南，不需要从头创造一个风格指南的大量花费就能继承其好处。坏处是组织为他们自己特别的需要优化其风格指南。比如，Google 的风格指南在上比较保守，因为他们有一个巨大的代码库，其中的代码要在所有东西上运行，从家用路由器到最新的 iPhone。如果你们是一个只有一个产品的四人小组，你可能选择在使用前沿语言特征或者扩展时更大胆。如果你不想采纳现存的指南，你可以自己创造一个。在代码审查中每产生一次风格争论，向整个团队提问来决定官方约定应该是什么。当你们达成共识，把决定编进风格指南中。我倾向于将团队的风格指南作为源控制下的 Markdown（例如 ）。这样，对风格指南的任何改动都需要通过普通的审查过程——某人得明确批准改动，而且团队中的每个人都有提出疑虑的机会。Wikis 和 Google 文件都是可接受的选择。合并选择 1 和选择 2，你可以采纳现存的风格指南作为基础，然后用本地风格指南来扩展或者覆盖这个基础。一个好例子是 。它用 作为基础，但是在其上添上自己的改动和附加。将代码审查视为高优先级。当你真正阅读代码并反馈时，慢点来，但是要马上审查——最好在几分钟内开始。如果队员发给你一个变更表，这可能意味着直到你完成审查前，他们会卡在其他工作上。理论上，源控制系统使作者能建起新的分支，继续工作，然后从审查中把变动合并进新分支。实际上，一共有大约四个开发者能够高效地做这件事。其他人要花很长时间来清理三方差异，以致于抵消掉了等待审查完成这段时间里的进步。你马上开始审查，就创造了一个良性循环。你的审查时间完全变成了一个与作者的变更表大小和复杂度相关的函数。这激励作者发送短小、范围狭窄的变更表。对你来说这样的变更表审查起来更容易，也更愉悦，所以你能更快地审查，循环继续。想象一下你的队员要执行一个新特征，这个特征要求 1000 行代码变更。如果他们知道你能在大概 2 小时内完成一个 200 行的变更表的审查，他们可以把特征拆分成各包含 200 行的变更表，然后在一两天内检查完整个特征。但是，如果无论大小你都要花一天来完成所有的代码审查，现在就要花一周时间才能检查完整个特征。你的队员不想傻坐一周，所以他们被激励着去发送更大的代码审查，比如每个包含 500 到 600 行。这样审查起来花销更大，反馈也更差，因为记 600 行变更表的背景要比 200 行变更表难。一个审查循环的最大周期应该是一个工作日。如果你正在处理一个更高优先级的问题，不能在一天内完成一个审查循环，让你的队员知悉并给予他们把审查交给别人的机会。如果你一个月被强制回绝审查超过一次，可能意味着你的团队需要放慢脚步，这样你能保持理智的开发实践。在一个既定的审查循环中，你写的批注越多，让作者感觉受打压的风险越大。准确的界限随开发者的不同而不同，但是一个审查循环中 20 到 50 个批注一般是危险区的开始。如果你担心把作者淹没在批注的海洋里，约束你自己在早期循环中反馈高级别的问题。注意重新设计类接口或者拆分复杂函数这样的问题。等到这些问题都解决了再去处理低级别的问题，比如变量命名或者代码评论的清晰度。一旦作者整合了你高级别的批注，低级别的批注可能会变得无意义。把低级别的批注推迟到后期的循环中，你可以把自己从小心措辞的工作中解救出来，也免得作者处理不必要的批注。这个技巧也细分了审查过程中你所关注的抽象层，帮助你和作者用清晰、系统的方法完成变更表。在一个理想的世界里，代码作者会感谢收到的每一次审查。这是他们学习的一个机会，也能防止他们犯错。事实上，有许多外部因素能导致作者负面地解读审查，怨恨你给他们批注。可能他们正面临着截止日期的压力，所以除了立刻不经审查的批准以外的东西都感觉像阻碍。可能你们没怎么在一起工作过，所以他们不相信你的反馈是好意的。一个让作者对审查过程感觉良好的方法是，在审查中找机会送他们礼物。所有开发者都爱收到的礼物是什么呢？当然是代码示例啦。如果通过写一些建议的改动来减轻作者的负担，就证明了作为审查者，你对时间很慷慨。比如，想象一下你的一个同事不熟悉 Python 的特征。他们给你发送了包含以下代码的审查：回复“能用列表推导（list comprehension）简化这个吗？”会使他们苦恼，因为现在他们得花 20 分钟搜索他们之前从没用过的东西。收到像以下这样的批注他们会更开心：\n这个技巧并不局限于单命令程序。我会经常建立我自己的代码分支，向作者展示概念的一个大型证明，比如拆分一个大型函数或者增加一个单元测试来覆盖一个附加边界情况。为清晰、无争议的改进保留此技巧。在上面列表推导（list comprehension）示例中，极少有开发者会拒绝减少 83% 的代码行数。相反，如果你写了一个冗长的示例来演示某个变动“更好”，而这个变动是基于你自己的个人品味（比如，风格变动），代码示例让你看起来固执己见，而不是慷慨大方。限制你自己在每个审查循环中只写两到三个代码示例。如果你开始为作者写整个变更表，这标志着你觉得作者没能力写自己的代码。这听起来挺怪异的，但是听我说：永远别在代码审查中使用“你”这个字。在审查中做的决定应该是基于什么能让代码更好，而不是谁出的主意。你的队员在他们的变更表中倾注了大量心血，而且很可能为自己的工作感到骄傲。他们听到对其工作的批评，自然反应是摆出防御和保护的姿态。组织反馈所使用的措辞，以最小化激起队员戒备心的风险。讲清楚你是在批评代码，而不是程序员。当作者在评论中看到“你”这个字，会将他们的注意力从代码转移到自己身上。这增加了他们把批评私人化的风险。考虑一下这个无害的评论：作者可以把这个批注理解成两种不同的意思：：嗨，好家伙！你拼错了“successfully”。但是我还是觉得你聪明！那可能就是个笔误。：你拼错了“successfully”，笨蛋。把这个跟省略了“你”的批注比较一下：后者是一个简单的修正而不是对作者的审判。幸运地是，在重新写反馈时避免使用“你”并不难。变成：“我们”加强了团队对代码的集体责任。作者可能跳槽到一个不同的公司去，你也可能，但是拥有这个代码的团队会一直以不同的形式存在。当你明显期望作者自己做某些事的时候，说“我们”听起来会比较傻，但是傻要比指责好。另一个避免使用“你”的方法是用省略句子主语的简化句子：你可以用实现相似的效果。我在技术写作中一般会避免像瘟疫一样使用被动语态，但是它是个有用的方法来避免使用“你”。另一个选择是把它表述为一个问题，用“……如何”或者“……怎么样”开头：代码审查相对平常的交流来说，要求更多的机智和谨慎，因为存在高风险把讨论转变成私人争论。你会期望审查者在审查中表示出礼貌，但是奇怪地是，我发现他们走向了另一个方向。多数人永远不会对同事说“给我订书机，再给我拿瓶汽水。”但是我看到过无数审查者用类似的指令来表达反馈，比如，“把这个类移到一个单独的文件里。”宁可在反馈中恼人地绅士。把批注表达成请求或者建议那样，而不是指令。比较用两种不同方式表达的同一个批注：人们喜欢掌控自己的工作。向作者提出请求给他们带来自主意识。请求也让作者礼貌地反馈更容易。可能他们的选择是有合理的。如果把反馈表达成指令，来自作者的任何反馈都像违反指令。如果你把反馈表达成请求或者问题，作者能简单地回答你。比较对话的好斗程度，取决于审查者怎么表达他们的初始批注：看看当你把批注表达成请求而非指令的时候，对话变得多么有礼貌。当你给作者写批注时，既要给出变更建议，也要给出变更的。“现在，这个类既负责下载文件，也负责解析文件。我们应该依照，把它拆分成一个下载类和一个解析类。”这么说会更好，而不是说“我们应该把这个类分成两个。”让你的批注有原则性的立足点，这样能让讨论走向更积极的方向更有建设性。但你有一个具体的原因，比如“我们应该把这个函数写成私有函数，来最小化 public 借口类”，作者就不能简单地回复“不，我倾向于我的方法。”更确切地说，他们，但是因为你演示了改动如何满足目标，而他们只陈述了一个偏好，他们会看起来很傻。软件开发既是艺术也是科学。你不可能永远都能用确定的原则来明确表达代码到底哪里出了问题。有时候代码只是难看或者不符合直觉，不容易确定为什么。在这些情况下，解释你能怎么做，但是保持客观性。如果你说“发现这不容易理解”，这至少是个客观的陈述；相反，“莫名其妙”是一个价值判断，不一定适用于所有人。尽可能以链接的形式提供支持证据。团队风格指南的相关部分是你能提供的最佳链接。你也可以链接到语言或者库的文件。高票  回答也行，但是离权威文件越远，你的证据变得越不稳固。第二部分：即将上线敬请期待其他小技巧，包括：处理特别大的代码审查识别给予表扬的机会尊重审核的，以及化解僵局\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    ", "img": ["http://wx1.sinaimg.cn/mw690/7cc829d3gy1frr57nj93bj20lc0oe0xi.jpg"]}
{"title": "如何识别人的技术能力和水平？ - 文章 - 伯乐在线", "tag": ["职场", "技术", "能力"], "goodNum": "1", "saveNum": " 4 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n这个题目是比较复杂的，它包含的东西比较多，认真讨论估计能写几万字。如果是专业研究，我看能写一本书了。这里打算根据自己的学习过程和工作经验，谈一下要点问题，均属个人看法，欢迎讨论。写这篇文章的初衷，跟前段时间跟朋友们聊招聘有关。因为技术招聘除了考察人的协作精神和工作态度，一大目标便是判断人的技术能力和实际水平。在这件事情上多做观察、思考是很有意义的。对于考察人的技术等级，学界是有认真的研究的。参见：。德雷福斯模型把人的技能水平，分成5级：对不同技能等级的认定是这样的：就是必须给出详细而具体的操作规则，才能工作。比如你做一道从未做过的菜，需要看菜谱的说明，第一步做什么，第二步做什么等等，直到最后烹饪结束。这是小工的水平。比如他能跟着师傅干点活，打打下手。可以靠着反复检索搜索引擎、StackOverflow解决具体的小问题。这是一般的企业招聘，比较希望招到的等级，招进来稍作适应就能干活了，省心省力。这类等级的人，思考可以指向内在，通过反省、反馈改善技能。这种在企业可以算上高手、大拿了，培养不易。实际你让他解释，他可能也说不出个所以然，就是直觉给出答案，然后还是对的。专家人数稀少，需要很长时间训练、实践。通常的说法是10年出专家，10000小时定律。这个是理论上的研究，实践中比较缺乏操作性，难以迅速的判定应聘者的实际情况。不信你打开收进来的大把简历，刚毕业的学生，每个技能名词上面都是一堆堆的“” – 你相信么？但它可以当成一个职业技能等级判定的参照标准。于是乎，各家企业开启了各种“笔试”、“机试”，多轮面试，并且严格要求学历以及出身院校，试图以此过滤掉不合意的应征者，留下合格的人选。不然也不会催生出各类“推荐式”的招聘。看重学历、学校当然也有其优点：它是快速过滤的手段，毕竟能考上好学校的人智商不会太差吧。但在大数字公司的一朋友说，公司里面还有初中毕业，一直精研安全领域的人，技术能力也是十分出色。如果严苛对待背景，这些人就会错过了。因为人的生活多种多样，有各种历史的背景因素影响经历。而部分人的经历，就是跟一些人不同的，可是不妨碍他们同样可以变得优秀。招聘，实际上是建立信任关系。如果有充足的信息证明，应聘者足够优秀，这就够了。条条框框只是辅助手段，并不是目的。任正非的洞察力一流推荐式的招聘实际要靠谱的多，因为人很容易了解熟悉的人的水平。人平时沟通时说什么话，日常看什么书，关注哪些领域，琢磨过啥问题，哪些东西很熟，这个经常聊的熟人往往都知道。可是，这类招聘局限性也很大：。靠推荐能招几个好手啊？好手往往是各家争抢的对象，窗口期有限，基本不会缺工作的。说了一圈，还是要在技能水准判定上有更高效率的办法，招进合适的人来。回到开头的德雷福斯模型，既然人的技能是分级的，那么如果千篇一律的走招聘流程，就容易出问题了。比如你明明要找的是“”，可上来就让人一堆笔试、机试，这是不合适的。对方会十分的厌烦。体现高水平技术能力的并不在默写什么“字符串算法”那里。这反倒是刚毕业的人占便宜，因为才学过不久，印象深。不信你让工作10年的人跟计算机专业应届生比比写排序算法，真未必能赢。但是这并不重要 – 你干活不看手册不查文档吗？聪明人从不死记硬背。对待初阶新人，某类人要说起技术来，滔滔不绝，两眼放光，充满热情，对未知的、新生的各类概念、技术非常好奇，这种人想差都难。因为他会自我驱动，不用督促，自己就钻研前进。反之，觉得这个职业待遇高，只是想混饭吃的人，很少走得长远。这类初阶新人以毕业生、工作年限少者为多。测试考核，可以笔试查看其对基础概念的理解是否准确，知识领域的大致范围。甚至，布置一个有点挑战性的小任务，让他尝试解决，说明思路。。笔试做题没啥用，原因前面说了。这类招聘是重头戏，企业都喜欢找这样的，能干活。所以考核评估的地方也较多。我觉得可以分成几个方面去看。业界的开发思想也是在不断变化，工具链一直在革新。聪明的人不用蛮力，而爱用工具提升效率，喜欢自动化操作解放人力。好的开发者会及时注意新出现的工具，挖掘它能解决什么问题，并尝试吸收，解决自己的需求。如果没有这个思想意识，工作效率就会打折扣了。因为你会落后行业发展水平。人善于自我反省，则会催动自我纠正，这正是精通者的特征。参考：解决问题的能力是重头戏，也是企业招聘人的主因。人要善于解决实际问题，而且，要学会聪明的解决问题。解决问题要看思路，看手段，看是否有创造性，这是真正考验人能力的地方。好的开发者，会考虑很多可能选项，预估各种优劣，给出一个较优的方案。 遇到难题，会用各种方法尝试。经验丰富的人，常常会使用技术的组合手段来处理难题，而不是一个语言一个工具到处用。所以，一些公司据说不招聘不会用谷歌的工程师。谷歌打不开？嘿嘿，这就是你要克服的困难啊。这你都解决不了，还做什么研发。谷歌是人类最全、最新知识的总索引，充分利用事半功倍。问问他看过什么书，研究过什么东西。说白了，知道的东西是否多。一些公司很喜欢用CheckList模式来考核，列一堆领域的知识点、概念，问人懂不懂，知道就是水平好，不懂就是水平差。实际情况并非如此。人的工作过程是独立的，一些事情如果没有工作机会去接触并解决，那么一些冷僻的问题就永远都碰不上。当然也就不知道。但你能说没做过就一定做不好么？另外，人的技能树，其实也是“犬牙交错、参差不齐”的。什么意思？技术领域非常的广阔，你真的没办法每个领域都很精通，实际上是这个做的多，懂的多，那个用的少，知道的少。这个时候，应看具体知识领域，是哪一类。它是否需要复杂的、难度较高的背景。门槛高的技术，需要的配套技能多得多，比如。而一般产品应用领域则不然，了解核心概念、设计意图，看着手册、最佳实践，也就能上手了。这个暂时不会，实际无关紧要的，工作一段学的认真点就会了。但是门槛高的领域，就需要很长时间的学习了。这是本质的差别。我曾看见某公司放出的职员技能树，包罗万象，几乎一切IT领域的知识技能都在里面了，还声称要求“全部精通”。我不知道它如何定义的“精通”，如果按德雷福斯模型的定义，能做到的那是神，不是人类。这个纯属吹牛皮，我压根就不信。如果真有这样的人，出来让我膜拜下。因为每个稍大点的领域，都足够让你钻研一辈子，因为它们也在迅速发展呀。业内流传“”的说法，鼓吹自己是全栈的人经常是前端工程师。而研究后端工作领域的技术高手经常鄙视这类人：真以为会点Node.js就能解决一堆后端的事务了么？我也懂一些前端，也能号称“全栈”，但在不同领域的专业性是什么水准，自己明白的很。前端要解决的事情也有很多复杂性。全栈实际是反专业化的，是人力资源稀缺时候的低成本选择。更高一层，则是考察人本身了。人的视野够广阔么？其它领域的知识有了解吗？一些问题的解答并不在问题域本身，而是在外面的领域。所谓“”。公司讲求团队协作，总要面临不同的分工合作问题。比如产品、运营的人提需求，可以换位思考吗？合作意识强么？谁也不想招个刺头进来吧？把团队的气氛和人际关系搞的一团糟，大家做事都不痛快、不顺心，又如何安心做好工作？最终只能让团队工作效率下降，甚至瓦解。要说专家，实际上有研究者认为是需要刻意练习+充分实践才能功成。并不是每个人经过足够的工作年限，都自动成为专家。有的人工作10年，可能后面9年都在重复第一年的工作任务，毫无改进。而职业上的训练机会，又跟大环境乃至运气息息相关，并不是每个人都有机缘的。但是把个人的职业技能做到胜任乃至精通，则是完全可行的，这只需要认真和勤奋，工作态度问题。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/04/e268c18430b4378f4b65054379484b31.png"]}
{"title": "Linux 目录结构：/lib 分析 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "Linux"], "goodNum": "1", "saveNum": " 5 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n我们在之前的文章中已经分析了其他重要系统目录，比如 、、、  等。可以根据自己的兴趣进入下列链接了解更多信息。本文中，让我们来看看  目录都有些什么。 文件夹是  ，包含了所有对系统有用的库文件。简单来说，它是应用程序、命令或进程正确执行所需要的文件。在  或  目录中的命令的动态库文件正是在此目录中。内核模块同样也在这里。以  命令执行为例。执行它需要调用一些库文件。让我们来探索一下  命令执行时都发生了什么。我们需要使用  找出调用的库文件。示例：如果你注意到的话，会发现我们使用的  命令的执行需要调用两个库文件。正如之前所说，这个文件夹包含了目标文件和一些库文件，如果能了解这个文件夹的一些重要子文件，想必是极好的。下面列举的内容是基于我自己的系统，对于你的来说，可能会有所不同。 – 这个文件夹包含了一些硬件、固件Firmware代码。为了使硬件正常运行，很多设备软件由两部分软件组成。加载到实际硬件的代码部分就是固件，用于在固件和内核之间通讯的软件被称为驱动程序。这样一来，内核就可以直接与硬件通讯，并确保硬件完成内核指派的工作。 – modprobe 命令的配置目录。 – 所有的可加载内核模块都存储在这个目录下。如果你有多个内核，你会在这个目录下看到代表美国内核的目录。 – 包含 SATA/IDE 硬盘正确运行的参数。 – 用户空间 /dev 是 Linux 内核设备管理器。这个文件夹包含了所有的 udev 相关的文件和文件夹，例如  包含了 udev 规范文件。这两个文件夹包含了特殊结构的库文件。它们几乎和  文件夹一样，除了架构级别的差异。 – 所有软件的库都安装在这里。但是不包含系统默认库文件和内核库文件。 – 放置额外的系统文件。这些库能够用于各种应用。 – 存储动态数据的库和文件，例如 rpm/dpkg 数据和游戏记录。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "比起 Windows，怎样解读 Linux 的文件系统与目录结构？ - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 4 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nLinux 和Windows的文件系统有些不同，在学习使用 Linux 之前，若能够了解这些不同，会有助于后续学习。本文先对Windows和 Linux 上面文件系统原理、组织概念进行区分，并给出例子、列举两者的优缺点以具体说明，最后较为详细地介绍了 Linux 系统的目录结构。Windows 和 Linux 文件系统下面将介绍启动Windows和 Linux 后，在文件系统的角度上，它们分别是怎样看待自己世界的。在Windows系统中， 一切东西都是存放在硬盘上的。启动系统后，先确定硬盘，再确定硬盘上的分区以及每个分区所对应文件系统，最后是存放在某个分区特定的文件系统中的文件。 也就是说，Windows是通过  这样的顺序来访问到一个文件的。但是与Windows不同, Linux 系统中的一切都是存放在唯一的 虚拟文件系统中的，这个 虚拟文件系统是树状的结构以一个根目录开始。启动系统后，先有这个 虚拟文件系统，再识别出各个硬盘， 再把某个硬盘的某个分区挂载到这个 虚拟文件系统的某个子树上（即分区用某个子目录来表示），再确定分区对应的子目录文件系统，最后的文件就存放在这个特定的文件系统中。 也就是说， Linux 系统是通过  这样的顺序来访问一个文件的。可能对习惯了使用Windows的用户来说， Linux 的方式有些不适应，它的 虚拟文件系统，实质就是一颗目录树，最开始的目录叫做根目录，根目录中又有每一级子目录，或者文件，子目录又有子子目录和文件，其中每个子目录都特定的功能这个功能（这些是约定俗成了的，在后面 常用的重要目录 (See section 1.2.1) 中会详细说明）。也许有人会问，没有这个虚拟文件系统就无法使用硬盘，可是最开始没有硬盘，那么这个 虚拟文件系统以及相应的组织结构是怎么存放起来的呢？这个问题，就像先有鸡还是先有蛋这个问题一样看似简单实则……但是，在 Linux 中，很轻易地跳出了这个思维循环，问题的答案并没在 虚拟文件系统 和 硬盘 这两者之间徘徊，而是第三者—— 内存 ，Linux系统启动起来之后，整个 虚拟文件系统的组织结构，都是随着每次内核系统的启动自动在内存中建立好了的，根本就不需要硬盘。另外还要注意，就是在我们用户的角度上，无论在Windows还是 Linux 上面，都是使用路径来访问一个文件的。表示文件的路径由  三个部分组成，这个策略在两者之间是一样的，所不同的是，Windows下面目录分隔符是 \\ ， Linux 下面是 / ，也许这也是两者之间为了表示其各自立场不同的一个原因吧？^_^在Windows系统中，我们可以把文件大体分为两种：  。一般来说系统文件（例如Windows操作系统本身，一些系统程序，程序运行所需的库文件，以及一些系统配置文件等）存放的默认位置在 C 盘，当然也可以在安装时候指定在其他盘；其它用户文件，包含用户后来安装的程序以及一些数据文件等，用户可以把它们随意存放在任意的分区。在 Linux 系统中，主要有两个概念： 虚拟文件系统中的文件和 Linux操作系统内核 本身。逻辑上可以认为前者属于上层，后者在下层，前者基于后者，后者依赖前者而存在。 Linux 把除了它本身（ Linux操作系统内核 ）以外的一切事物都看作是在 虚拟文件系统中的文件了。无论是键盘，鼠标，数据，程序，CPU，内存，网卡……无论是硬件、软件、数据还是内存中的东西，我们都可以在 虚拟文件系统中的相应子目录对他们进行访问和操作，操作统一。而实现这些管理的幕后就是 Linux操作系统内核 本身：启动 Linux 系统的时候，首先电脑把 Linux操作系统内核 加载到内存中，内核本身提供了文件管理，设备管理，内存管理，CPU进程调度管理，网络管理等功能，等内核运行起来之后，就在内存中建立起相应的 虚拟文件系统，最后就是内核利用它提供的那些功能，通过管理文件的方式，来管理 虚拟文件系统中的硬件软件等各种资源了。Linux 把提供操作系统本身功能（管理计算机软硬件资源）的那些部分划给了 Linux操作系统内核 ，使得Linux操作系统内核 成为一个独立的部分，有它自己独立的开源代码；而其它的一切（软件应用，硬件驱动，数据）都根据其特性有自己的开源代码、或者自由地组织并且存放在那个 虚拟文件系统中由 Linux操作系统内核 来管理。这样，将系统本身和系统所管理的资源分开，并开放源代码，有助于对系统或者系统所管理的资源进行灵活的定制和扩展，还能按需快速建立起只适合自己使用的操作系统，也利于操作系统本身的发展。实际 Ubuntu ， Fedora ， RedHat 等各种不同的 Linux 操作系统发行版，简单来说就是不同厂商对其文件系统和内核进行了不同的配置而产生的  的操作系统。相比之下，Windows就显得非常地零乱复杂，将系统、软件、硬件、数据都混在了一起，其不同版本只能由Microsoft 一家公司发行。下面用直观的例子，来说明两者的不同，以加深理解。假设我们的机器上面有一个硬盘，硬盘分为三个区。在Windows系统中， 我们启动系统之后就会看到 C, D, E, 盘符，它们分别对应硬盘上的三个分区，增加硬盘，或者分区，会导致盘符的增加（注意由于历史原因， A, B 用于表示软驱，硬盘分区盘符从 C 开始按字母递增），这里的每个分区都各自可以被格式化为不同的文件系统（这里的文件系统，包括例如 NTFS 格式， FAT32 格式等)，文件系统的基本功能就是为了存放文件的，不同文件系统区别一般在于管理其中存放的文件的功能的强弱，所以分区被格式化成指定格式的文件系统之后，就可以存放任何文件和目录了，我们看到的 C, D, E 内容也就对应了硬盘中相应分区的数据内容。但是，与Windows中把硬盘分区看成 C, D, E 盘符不同， Linux 中最开始根本就没有硬盘的概念，就只有一个纯粹的 虚拟文件系统。如果想要使用哪个硬盘的某个分区，就把那个分区  到某个子目录之下，这样硬盘中的分区，文件系统，目录等内容就呈现到了那个子目录里面。也就是说，在 Linux 中，我们使用硬盘中的数据，实际是先把硬盘的某个分区  到某个子目录下，然后通过那个子目录来访问的。这个例子中， 通常硬盘会对应 虚拟文件系统中的/dev/sda （如有多个硬盘，则为 /dev/sda, /dev/sdb, ……， 按字母递增）, 其三个分区对应 /dev/sda1, /dev/sda2,/dev/sda3 （多个分区按数字递增，不同硬盘的分区，对应为 /dev/sdb1, /dev/sdb2 等等）, 默认硬盘各个分区会被挂载到 虚拟文件系统系统中类似 /mnt/sda1/, /mnt/sda2/, /mnt/sda3/ 的目录（在 Linux 又叫挂载点）中，在/etc/fstab 文件中，我们可以找到分区文件和挂载点的对应关系描述。这样，硬盘相应的分区就做为整个 虚拟文件系统根目录下的一颗子树，反映到了子目录（挂载点）上，子目录中的内容就对应分区中的数据。假设访问上述硬盘第三个分区 dir1 目录中的文件 test.file再有，假设用户安装和卸载一个程序 firefox ：Windows系统中指定或不指定安装路径类似，程序的安装目录会在 C:\\Program Files\\Firefox 类似的目录中，或指定的安装路径中； 可执行文件一般在程序的安装路径；依赖的内部库、第三方库、和系统库可能在安装路径中，也可能在C:\\Windows\\System32, 或 C:\\Windows\\system 等类似的路径；而程序访问期间的系统和用户配置文件和产生的输入输出文件，可能会在安装路径配置中，或者在 C:\\Windows\\ 下的某些文件中（比如注册表数据库文件、用户目录等），这就不一定了。而且不同的系统版本，应用程序版本下，这些目录的具体名称和路径可能会有所不同。卸载的时候由于不确定哪些地方安装了什么内容，很容易造成文件删除补全，遗留系统垃圾等现象，造成系统越来越瘫肿。Linux 系统中如果不指定安装路径，所有程序的可执行文件在 /usr/bin 中， 全局配置文件在 /etc/firefox 类似的目录， 用户配置文件一般在用户主目录的 .firefox 的路径下(用户主目录路径名称统一格式为 /home/<username>) ，依赖的内部库和第三方库在 /usr/lib, 系统库在 /lib 下， 数据文件一般就在用户主目录下。 如果指定安装目录，那么所有内部库和可执行程序，全局配置文件，会在 <安装路径> 下的 bin, lib, etc 子目录下，其它文件一般和默认情况相同。卸载程序之时，只需在对应目录中，将可执行文件、内部库、配置文件、数据文件删除即可，基本没有不确定是否遗留垃圾文件的问题。这些都是大多数应用程序安装的和访问的默认策略，就像是不成文的业界标准，不排除有个别程序不安装这种策略部署应用，但是 Linux 用户带来 “麻烦“ 的应用，早晚也会被淘汰，不可能会流行在 Linux 系统中，这样，自然的，好的应用都保存在 Linux 系统中并逐渐流行起来，还不会破坏系统结构。可见， Linux 文件的存放和组织明显方式更高效，层次更分明。基于上述内容，Windows和 Linux 文件系统的各有优缺点分别如下。Windows系统优点优点主要是用户存放东西的位置比较自由，系统结构简单便于新用户上手。Windows系统缺点缺点较多主要有：\n目录组织缺乏标准由于对“系统文件”和“用户文件”存放位置缺乏细致的规定，数据组织的方式显得比较凌乱，并且两种文件之间很容易相互干扰（例如数据文件可能存放在系统区域给系统带来垃圾文件等）。用户的使用经验对系统的使用效率影响很大一般来说，我们使用Windows时候合理使用分区会提升的系统效率。例如根据需要设置合理的系统分区（假设为C 分区），尽量少往 C 盘存放数据文件，根据具体情况可以将一些  程序安装在 C 分区，随时保持系统目录的清洁和大小助于提升系统的运行速度，用户安装的一般软件尽量不要安装在 C 盘，安装软件时候指定的位置最好采用默认标准目录名称（例如 X:\\Program Files 目录，这里 X 表示盘符而不要自己定义一些奇怪名字的目录，这样便于软件的维护等等。共享不便Windows上有经验的用户们会将自己的目录结构组织好，但是每个用户组织自己内容的方式是不一样的，所以他的机器上哪里存放了什么内容，别人很难知道，为共享带来了麻烦。\nLinux 系统缺点最开始 虚拟文件系统中的每个子目录的功能是事先规定好了的，我们需要事先知道那些目录存放哪些文件，然后在相应的位置中创建自己的内容，这也是 Linux 系统入门门槛高的一个原因。当然，最开始的新手，也完全可以无视这一点，可以像Windows那样随意地创建目录和文件（尽管不推荐这么做）。\n实际上最开始的目录也不多，主要就那么几个，花不了多长时间就会明白它们的作用的，而明白这些作用之后带来的好处，远不止付出那么多（本文后面 常用的重要目录 (See section 1.2.1) 会着重对此进行介绍）。Linux 系统优点这里只说几个优点：\n目录结构反映系统运行机理当我们了解了这些目录的功能之后，我们对整个 Linux 操作系统的运行机理也会有一个大致的了解。结构清晰避免逻辑混乱这样的目录结构，有助于我们以一种高效的方式组织自己的数据，分类清晰并且不会对系统运行有任何影响，规定了最开始每个目录的功能，并没有限制我们的自由，因为我们知道我们可以在哪里创建自己的子目录并且在子目录中任意创建自己的文件。组织规范便于共享由于目录具有统一的组织结构，所以 Linux 上面的用户在共享数据的时候，能够很容易地猜测出他所需要的数据大致存放在什么位置，同时也不会影响到私有数据的保密性，毕竟具体来说，怎么存放自己的私有数据，那是用户自己决定的。\nLinux 上面的虚拟文件系统目录组织实质上，我们启动系统所看到的  ，逻辑上是 Linux 虚拟文件系统的根目录中的一个子目录，我们看不到除了这个  以外的其他的目录，那些目录和操作系统的具体实现相关是被操作系统内核隐藏起来了的，所以这里就介绍我们所能看到的文件系统中的  的各个子目录中的作用吧。在 Linux 文件系统中的每一个子目录都有特定的目的和用途。一般都是根据 FHS 标准定义一个正式的文件系统结构的，这个标准规定了哪些目录应该哪些作用。这里我们先介绍一些日常经常用到的目录，然后给出 FHS 相关的内容。这里，根据本人的使用经验，给出比较常见重要的一些目录，最开始我们对它们有所了解就可以了。随着对 Linux 使用的经验的加深，我们会了解越来越多的目录。对目录的功能知道得越多，我们对 Linux 系统的工p作原理就理解的越深刻，理解操作系统的工作原理，更助于我们更为规范地使用和理解系统中每个目录存在的意义，直至最后几乎知道系统中的每个文件……/ 根目录包含了几乎所的文件目录。相当于中央系统。进入的最简单方法是：cd /。/boot 引导程序，内核等存放的目录这个目录，包括了在引导过程中所必需的文件，引导程序的相关文件（例如 grub ， lilo 以及相应的配置文件）以及 Linux 操作系统内核相关文件（例如 vmlinuz 等）一般都存放在这里。在最开始的启动阶段，通过引导程序将内核加载到内存，完成内核的启动（这个时候， 虚拟文件系统还不存在，加载的内核虽然是从硬盘读取的，但是没经过 Linux 的 虚拟文件系统，这是比较底层的东西来实现的）。然后内核自己创建好 虚拟文件系统，并且从 虚拟文件系统的其他子目录中（例如 /sbin 和 /etc ）加载需要在开机启动的其他程序或者服务或者特定的动作（部分可以由用户自己在相应的目录中修改相应的文件来配制）。如果我们的机器中包含多个操作系统，那么可以通过修改这个目录中的某个配置文件（例如 grub.conf ）来调整启动的默认操作系统，系统启动的择菜单，以及启动延迟等参数。/sbin 超级用户可以使用的命令的存放目录存放大多涉及系统管理的命令（例如引导系统的 init 程序），是超级权限用户 root 的可执行命令存放地，普通用户无权限执行这个目录下的命令（但是有时普通用户也可能会用到）。这个目录和 /usr/sbin ,/usr/X11R6/sbin或/usr/local/sbin 等目录是相似的，我们要记住，凡是目录 sbin 中包含的都是 root 权限才能执行的，这样就行了。后面会具体区分。/bin 普通用户可以使用的命令的存放目录系统所需要的那些命令位于此目录，比如 ls 、 cp 、 mkdir 等命令；类似的目录还 /usr/bin ， /usr/local/bin等等。这个目录中的文件都是可执行的、普通用户都可以使用的命令。作为基础系统所需要的最基础的命令就是放在这里。/lib 根目录下的所程序的共享库目录此目录下包含系统引导和在根用户执行命令时候所必需用到的共享库。做个不太好但是比较形象的比喻，点类似于Windows上面的 system32 目录。按理说，这里存放的文件应该是 /bin 目录下程序所需要的库文件的存放地，也不排除一些例外的情况。类似的目录还 /usr/lib ， /usr/local/lib 等等。/dev 设备文件目录在 Linux 中设备都是以文件形式出现，这里的设备可以是硬盘，键盘，鼠标，网卡，终端，等设备，通过访问这些文件可以访问到相应的设备。设备文件可以使用 mknod 命令来创建，具体参见相应的命令；而为了将对这些设备文件的访问转化为对设备的访问，需要向相应的设备提供设备驱动模块（一般将设备驱动编译之后，生成的结果是一个*.ko 类型的二进制文件），在内核启动之后，再通过 insmod 等命令加载相应的设备驱动之后，我们就可以通过设备文件来访问设备了。一般来说，想要 Linux 系统支持某个设备，只需要三个东西：相应的硬件设备，支持硬件的驱动模块，以及相应的设备文件。/home 普通用户的家目录（或 $HOME 目录、主目录）在 Linux 机器上，用户主目录通常直接或间接地置在此目录下。其结构通常由本地机的管理员来决定。通常而言，系统的每个用户都有自己的家目录，目录以用户名作为名字存放在 /home 下面（例如 quietheart 用户，其家目录的名字为 /home/quietheart ）。该目录中保存了绝大多数的用户文件(用户自己的配置文件，定制文件，文档，数据等)， root 用户除外（参见后面的 /root 目录）。由于这个目录包含了用户实际的数据，通常系统管理员为这个目录单独挂载一个独立的磁盘分区，这样这个目录的文件系统格式就可能和其他目录不一样了（尽管表面上看，这个目录还是属于根目录的一棵子树上），将系统文件和数据文件分开存放，有利于维护。/root 用户root的 $HOME 目录系统管理员(就是 root 用户或超级用户)的主目录比较特殊，不存放在 /home 中，而是直接放在 /root 目录下了。/etc 全局的配置文件存放目录系统和程序一般都可以通过修改相应的配置文件，来进行配置。例如，要配置系统开机的时候启动那些程序，配置某个程序启动的时候显示什么样的风格等等。通常这些配置文件都集中存放在 /etc 目录中，所以想要配置什么东西的话，可以在 /etc 下面寻找我们可能需要修改的文件。一些大型套件，如 X11 ，在 /etc 下它们自己的子目录。系统配置文件可以放在这里或在 /usr/etc 。 不过所有程序总是在 /etc 目录下查找所需的配置文件，你也可以将这些文件链接到目录 /usr/etc 。另外，还一个需要注意的常见现象就是，当某个程序在某个用户下运行的时候，可能会在该用户的家目录中生成一个配置文件（一般这个文件最开始就是 /etc 下相应配置文件的拷贝，存放相应于“当前用户”的配置），这样当前用户可以通过配置这个家目录的配置文件，来改变程序的行为，并且这个行为只是该用户特有的。原因就是：一般来说一个程序启动，如果需要读取一些配置文件的话，它会首先读取当前用户家目录的配置文件，如果存在就使用；如果不存在它就到 /etc 下读取全局的配置文件进而启动程序。就是这个配置文件不自动生成，我们手动在自己的家目录中创建一个文件的话，也有许多程序会首先读取到这个家目录的文件并且以它的配置作为启动的选项（例如我们可以在家目录中创建 vim 程序的配置文件 .vimrc ，来配置自己的 vim 程序）。/usr 这个目录中包含了命令库文件和在通常操作中不会修改的文件这个目录对于系统来说也是一个非常重要的目录，其地位类似Windows上面的 Program Files 目录（请原谅我可能这样做比较不太恰当^_^）。安装程序的时候，默认就是安装在此文件内部某个子文件夹内。输入命令后系统默认执行 /usr/bin 下的程序（当然，前提是这个目录的路径已经被添加到了系统的环境变量中）。此目录通常也会挂载一个独立的磁盘分区，它应保存共享只读类文件，这样它可以被运行 Linux 的不同主机挂载。/usr/lib 目标库文件，包括动态连接库加上一些通常不是直接调用的可执行文件的存放位置这个目录功能类似 /lib 目录，理说，这里存放的文件应该是 /bin 目录下程序所需要的库文件的存放地，也不排除一些例外的情况。/usr/bin 一般使用者使用并且不是系统自检等所必需可执行文件的目录此目录相当于根文件系统下的对应目录（ /bin ），非启动系统，非修复系统以及非本地安装的程序一般都放在此目录下。/usr/sbin 管理员使用的非系统必须的可执行文件存放目录此目录相当于根文件系统下的对应目录（ /sbin ），保存系统管理程序的二进制文件，并且这些文件不是系统启动或文件系统挂载 /usr 目录或修复系统所必需的。/usr/share 存放共享文件的目录在此目录下不同的子目录中保存了同一个操作系统在不同构架下工作时特定应用程序的共享数据(例如程序文档信息)。使用者可以找到通常放在 /usr/doc 或 /usr/lib 或 /usr/man 目录下的这些类似数据。/usr/include C程序语言编译使用的头文件Linux 下开发和编译应用程序所需要的头文件一般都存放在这里，通过头文件来使用某些库函数。默认来说这个路径被添加到了环境变量中，这样编译开发程序的时候编译器会自动搜索这个路径，从中找到你的程序中可能包含的头文件。/usr/local 安装本地程序的一般默认路径当我们下载一个程序源代码，编译并且安装的时候，如果不特别指定安装的程序路径，那么默认会将程序相关的文件安装到这个目录的对应目录下。例如，安装的程序可执行文件被安装（安装实质就是复制）到了 /usr/local/bin 下面，此程序（可执行文件）所需要依赖的库文件被安装到了 /usr/local/lib 目录下，被安装的软件如果是某个开发库（例如 Qt ， Gtk 等）那么相应的头文件可能就被安装到了 /usr/local/include 中等等。也就是说，这个目录存放的内容，一般都是我们后来自己安装的软件的默认路径，如果择了这个默认路径作为软件的安装路径，被安装的软件的所文件都限制在这个目录中，其中的子目录就相应于根目录的子目录。/proc 特殊文件目录这个目录采用一种特殊的文件系统格式（ proc 格式），内核支持这种格式。其中包含了全部虚拟文件。它们并不保存在磁盘中，也不占据磁盘空间(尽管命令 ls -c 会显示它们的大小)。当您查看它们时，您实际上看到的是内存里的信息，这些文件助于我们了解系统内部信息。例如：\n\r\n\r\n\t\t\r\n\r\n\n/opt 可择的文件目录这个目录表示的是可择的意思，些自定义软件包或者第方工具，就可以安装在这里。比如在 Fedora Core 5.0 中，OpenOffice 就是安装在这里。些我们自己编译的软件包，就可以安装在这个目录中；通过源码包安装的软件，可以把它们的安装路径设置成 /opt 这样来安装。这个目录的作用一点类似 /usr/local 。/mnt 临时挂载目录这个目录一般是用于存放挂载储存设备的挂载目录的，比如磁盘，光驱，网络文件系统等，当我们需要挂载某个磁盘设备的时候，可以把磁盘设备挂载到这个目录上去，这样我们可以直接通过访问这个目录来访问那个磁盘了。一般来说，我们最好在 /mnt 目录下面多建立几个子目录，挂载的时候挂载到这些子目录上面，因为通常我们可能不仅仅是挂载一个设备吧?/media 挂载的媒体设备目录挂载的媒体设备目录，一般外部设备挂载到这里，例如 cdrom 等。比如我们插入一个U盘，我们一般会发现， Linux 自动在这个目录下建立一个 disk 目录，然后把U盘挂载到这个 disk 目录上，通过访问这个 disk 来访问U盘。/var 内容经常变化的目录此目录下文件的大小可能会改变，如缓冲文件，日志文件，缓存文件，等一般都存放在这里。/tmp 临时文件目录该目录存放系统中的一些临时文件，文件可能会被系统自动清空。的系统直接把 tmpfs 类型的文件系统挂载到这个目录上， tmpfs 文件系统由 Linux 内核支持，在这个文件系统中的数据，实际上是内存中的，由于内存的数据断电易失，当系统重新启动的时候我们就会发现这个目录被清空了。/lost+found 恢复文件存放的位置当系统崩溃的时候，在系统修复过程中需要恢复的文件，可能就会在这里被找到了，这个目录一般为空。以上目录，是最常见的重要目录。其中，有些目录初学者容易混淆，这里简单区分一下：/bin , /sbin 与 /usr/bin , /usr/sbin\n/bin 一般存放对于用户和系统来说“必须”的程序（二进制文件）。/sbin 一般存放用于系统管理的“必需”的程序（二进制文件），一般普通用户不会使用，根用户使用。/usr/bin 一般存放的只是对用户和系统来说“不是必需的”程序（二进制文件）。/usr/sbin 一般存放用于系统管理的系统管理的不是必需的程序（二进制文件）。\n/lib 与 /usr/lib\n/lib 和 /usr/lib 的区别类似 /bin, /sbin 与 /usr/bin, /usr/sbin 。/lib 一般存放对于用户和系统来说“必须”的库（二进制文件）。/usr/lib 一般存放的只是对用户和系统来说“不是必需的”库（二进制文件）。\n其他还一些目录例如： /home/user/bin, /home/user/opt, /home/user/etc, /usr/local/etc 等等，其作用都是类似于 /etc, /bin 等目录的，可能只是层次概念不同了，使用 Linux 时间长了，会逐渐体会到其中的含义。当然，我们可以无视这些目录，像使用Windows那样自由的，不管啥文件，想往哪存就往哪存，还是那句话，使用 Linux 时间长了，会逐渐体会到其中的含义，到时候也许我们想要乱来都不行了呢。^_^在大多数 Linux 系统上面，我们可以使用一个命令： man hier ，通过这个命令的输出，就知道“根目录”中所子目录的作用了。这个命令含义我不多说了，总之这里的 hier 就是对 Linux 文件系统中各级目录的标准功能，是一个大家都约定俗成了的东西。想要了解每个目录更详细的信息，需要仔细参考 man hier 的输出。下面就是一个比较简短的中文描述的对文件系统目录分类的 FHS 标准，也就是对 man hier 的简单翻译。作者简介吕凯，TPV资深主任工程师，大连理工大学硕士。关注软件开发、系统运维、内容管理、行动管理等领域，喜欢计数写作及分享。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/11/59d49abe8909a122bc2c9aa43b71e3bb.png"]}
{"title": "假装很忙的三个命令行工具 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 5 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n有时候你很忙。而有时候你只是需要看起来很忙，就像电影中的黑客一样。有一些开源工具就是干这个的。如果在你在消磨时光时看过谍战片、动作片或犯罪片，那么你就会清晰地在脑海中勾勒出黑客的电脑屏幕的样子。就像是在《黑客帝国》电影中， 一样的十六进制数字流，又或是一排排快速移动的代码。也许电影中出现一幅世界地图，其中布满了闪烁的光点和一些快速更新的图表。不可或缺的，也可能有 3D 旋转的几何形状。甚至，这一切都会显示在一些完全不符合人类习惯的数量荒谬的显示屏上。 在《剑鱼行动》电影中黑客就使用了七个显示屏。当然，我们这些从事计算机行业的人一下子就明白这完全是胡说八道。虽然在我们中，许多人都有双显示器（或更多），但一个闪烁的数据仪表盘、刷新的数据通常和专注工作是相互矛盾的。编写代码、项目管理和系统管理与日常工作不同。我们遇到的大多数情况，为了解决问题，都需要大量的思考，与客户沟通所得到一些研究和组织的资料，然后才是少许的 。然而，这与我们想追求电影中的效果并不矛盾，也许，我们只是想要看起来“忙于工作”而已。如果您公司实际上是根据您繁忙程度来评估您的工作时，无论您是蓝领还是白领，都需要亟待解决这样的工作文化。假装工作很忙是一种有毒的文化，对公司和员工都有害无益。这就是说，让我们找些乐子，用一些老式的、毫无意义的数据和代码片段填充我们的屏幕。（当然，数据或许有意义，但不是在这种没有上下文的环境中。）当然有一些用于此用途的有趣的图形界面程序，如  或是  网站（LCTT 译注：是在线假装黑客操作的网站），为什么不使用标准的 Linux 终端程序呢？对于更老派的外观，可以考虑使用 ，这听起来确实如此：一个酷炫的复古终端程序。我将在下面的屏幕截图中使用酷炫复古终端，因为它看起来的确很酷。我们来看下第一个工具——Genact。Genact 的原理很简单，就是慢慢地无尽循环播放您选择的一个序列，让您的代码在您外出休息时“编译”。由您来决定播放顺序，但是其中默认包含数字货币挖矿模拟器、Composer PHP 依赖关系管理工具、内核编译器、下载器、内存转储等工具。其中我最喜欢的是其中类似《模拟城市》加载显示。所以只要没有人仔细检查，你可以花一整个下午等待您的电脑完成进度条。Genact  支持 Linux、OS X 和 Windows 的版本。并且其 Rust  在 GitHub 上开源（遵循 ）。Hollywood 采取更直接的方法。它本质上是在终端中创建一个随机的数量和配置的分屏，并启动那些看起来很繁忙的应用程序，如 htop、目录树、源代码文件等，并每隔几秒将其切换。它被组织成一个 shell 脚本，所以可以非常容易地根据需求进行修改。Hollywood的  在 GitHub 上开源（遵循 ）。Blessed-contrib 是我个人最喜欢的应用，实际上并不是为了这种表演而专门设计的应用。相反地，它是一个基于 Node.js 的终端仪表盘的构建库的演示文件。与其他两个不同，实际上我已经在工作中使用 Blessed-contrib 的库，而不是用于假装忙于工作。因为它是一个相当有用的库，并且可以使用一组在命令行显示信息的小部件。与此同时填充虚拟数据也很容易，所以可以很容易实现你在计算机上模拟《战争游戏》的想法。Blessed-contrib 的在 GitHub 上（遵循 ）。当然，尽管这些工具很容易使用，但也有很多其他的方式使你的屏幕丰富。在你看到电影中最常用的工具之一就是Nmap，这是一个开源的网络安全扫描工具。实际上，它被广泛用作展示好莱坞电影中，黑客电脑屏幕上的工具。因此 Nmap 的开发者创建了一个 ，列出了它出现在其中的一些电影，从《黑客帝国 2：重装上阵》到《谍影重重3》、《龙纹身的女孩》，甚至《虎胆龙威 4》。当然，您可以创建自己的组合，使用终端多路复用器（如  或 ）启动您希望使用的任何数据切分程序。那么，您是如何使用您的屏幕的呢？ \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/04/56513a8ab958df253f196a60a8424763.jpg"]}
{"title": "gdb 如何调用函数？ - 文章 - 伯乐在线", "tag": ["C/C++", "GDB"], "goodNum": "1", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n在这周，我发现我可以从 gdb 上调用 C 函数。这看起来很酷，因为在过去我认为 gdb 最多只是一个只读调试工具。我对 gdb 能够调用函数感到很吃惊。正如往常所做的那样，我在  上询问这是如何工作的。我得到了大量的有用答案。我最喜欢的答案是 ，它展示了 gdb 如何调用函数。代码能够运行，这很令人激动！我（通过一些跟踪和实验）认为那个示例 C 代码和 gdb 实际上如何调用函数不同。因此，在这篇文章中，我将会阐述 gdb 是如何调用函数的，以及我是如何知道的。关于 gdb 如何调用函数，还有许多我不知道的事情，并且，在这儿我写的内容有可能是错误的。在开始讲解这是如何工作之前，我先快速的谈论一下我是如何发现这件令人惊讶的事情的。假如，你已经在运行一个 C 程序（目标程序）。你可以运行程序中的一个函数，只需要像下面这样做：暂停程序（因为它已经在运行中）找到你想调用的函数的地址（使用符号表）使程序（目标程序）跳转到那个地址当函数返回时，恢复之前的指令指针和寄存器通过符号表来找到想要调用的函数的地址非常容易。下面是一段非常简单但能够工作的代码，我在 Linux 上使用这段代码作为例子来讲解如何找到地址。这段代码使用 。如果我想找到 PID 为 2345 的进程中的  函数的地址，那么我可以运行 。这并不能够真的发挥作用，你还需要找到文件的内存映射，并将符号偏移量加到文件映射的起始位置。找到内存映射并不困难，它位于  中。总之，找到想要调用的函数地址对我来说很直接，但是其余部分（改变指令指针，恢复寄存器等）看起来就不这么明显了。我已经说过，你不能够仅仅找到你想要运行的那个函数地址，然后跳转到那儿。我在 gdb 中尝试过那样做（），然后程序出现了段错误。毫无意义。首先，这是可能的。我写了一个非常简洁的 C 程序，它所做的事只有  1000 秒，把这个文件命名为  ：接下来，编译并运行它：最后，我们使用 gdb 来跟踪  这一程序：我运行  然后它运行了这个函数！这非常有趣。下面是一些可能的用途：它使得你可以把 gdb 当成一个 C 应答式程序（REPL），这很有趣，我想对开发也会有用在 gdb 中进行调试的时候展示/浏览复杂数据结构的功能函数（感谢 ）（我的同事  对此非常惊讶）可能还有许多我所不知道的用途当我在 Twitter 上询问从 gdb 中调用函数是如何工作的时，我得到了大量有用的回答。许多答案是“你从符号表中得到了函数的地址”，但这并不是完整的答案。有个人告诉了我两篇关于 gdb 如何工作的系列文章：，。第一部分讲述了 gdb 是如何调用函数的（指出了 gdb 实际上完成这件事并不简单，但是我将会尽力）。步骤列举如下：停止进程创建一个新的栈框（远离真实栈）保存所有寄存器设置你想要调用的函数的寄存器参数设置栈指针指向新的栈框stack frame在内存中某个位置放置一条陷阱指令为陷阱指令设置返回地址设置指令寄存器的值为你想要调用的函数地址再次运行进程！（LCTT 译注：如果将这个调用的函数看成一个单独的线程，gdb 实际上所做的事情就是一个简单的线程上下文切换）我不知道 gdb 是如何完成这些所有事情的，但是今天晚上，我学到了这些所有事情中的其中几件。创建一个栈框如果你想要运行一个 C 函数，那么你需要一个栈来存储变量。你肯定不想继续使用当前的栈。准确来说，在 gdb 调用函数之前（通过设置函数指针并跳转），它需要设置栈指针到某个地方。这儿是 Twitter 上一些关于它如何工作的猜测：我认为它在当前栈的栈顶上构造了一个新的栈框来进行调用！以及你确定是这样吗？它应该是分配一个伪栈，然后临时将 sp （栈指针寄存器）的值改为那个栈的地址。你可以试一试，你可以在那儿设置一个断点，然后看一看栈指针寄存器的值，它是否和当前程序寄存器的值相近？我通过 gdb 做了一个试验：这看起来符合“gdb 在当前栈的栈顶构造了一个新的栈框”这一理论。因为栈指针（）从  变成了  —— 栈指针从高地址往低地址长。所以  在  的后面。真是有趣！所以，看起来 gdb 只是在当前栈所在位置创建了一个新的栈框。这令我很惊讶！改变指令指针让我们来看一看 gdb 是如何改变指令指针的！的确是！指令指针从  变为了 （ 函数的地址）。我盯着输出看了很久，但仍然不理解它是如何改变指令指针的，但这并不影响什么。如何设置断点上面我写到  。我跟踪 gdb 运行程序的过程，但是没有任何发现。下面是 gdb 用来设置断点的一些系统调用。它们非常简单。它把一条指令用  代替了（这告诉我们  意味着  ），并且一旦程序被打断了，它就把指令恢复为原先的样子。我在函数  那儿设置了一个断点，地址为  。 展示了 gdb 如何改变正在运行的程序。在某处放置一条陷阱指令当 gdb 运行一个函数的时候，它也会在某个地方放置一条陷阱指令。这是其中一条。它基本上是用  来替换一条指令（）。 是什么？我查看了进程的内存映射，发现它位于  中的某个位置。这很奇怪，为什么 gdb 将陷阱指令放在 libc 中？让我们看一看里面的函数是什么，它是  。其他 gdb 放置陷阱指令的地方的函数是  、 、 和  。为什么？我不知道！也许出于某种原因，当函数  返回时，它调用  ，从而 gdb 能够进行返回控制。我不确定。我将要在这儿停止了（现在已经凌晨 1 点），但是我知道的多一些了！看起来“gdb 如何调用函数”这一问题的答案并不简单。我发现这很有趣并且努力找出其中一些答案，希望你也能够找到。我依旧有很多未回答的问题，关于 gdb 是如何完成这些所有事的，但是可以了。我不需要真的知道关于 gdb 是如何工作的所有细节，但是我很开心，我有了一些进一步的理解。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/04/099ab3d51f135a121ab1ae294f13298a.jpg"]}
{"title": "每个 Linux 新手都应该知道的 10 个命令 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n通过这 10 个基础命令开始掌握 Linux 命令行。你可能认为你是 Linux 新手，但实际上并不是。全球互联网用户有 ，他们都以某种方式使用 Linux，因为 Linux 服务器占据了互联网的 90%。大多数现代路由器运行 Linux 或 Unix， 也依赖于 Linux。如果你拥有一台 Android 智能手机，那么你的操作系统就是由 Linux 内核构建的。换句话说，Linux 无处不在。但是使用基于 Linux 的技术和使用 Linux 本身是有区别的。如果你对 Linux 感兴趣，但是一直在使用 PC 或者 Mac 桌面，你可能想知道你需要知道什么才能使用 Linux 命令行接口（CLI），那么你来到了正确的地方。下面是你需要知道的基本的 Linux 命令。每一个都很简单，也很容易记住。换句话说，你不必成为比尔盖茨就能理解它们。你可能会想：“这是（is）什么东西？”不，那不是一个印刷错误 —— 我真的打算输入一个小写的 l。，或者说 “list”， 是你需要知道的使用 Linux CLI 的第一个命令。这个 list 命令在 Linux 终端中运行，以显示在存放在相应文件系统下的所有主要目录。例如，这个命令：显示存储在  文件夹下的每个文件夹，你将使用它来查看文件、文件夹和目录。显示所有隐藏的文件都可以使用命令 。这个命令是你用来跳转（或“更改”）到一个目录的。它指导你如何从一个文件夹导航到另一个文件夹。假设你位于  文件夹中，但你想到名为  的文件夹中，简单地输入  将不起作用，因为 shell 不会识别它，并会报告你正在查找的文件夹不存在（LCTT 译注：这是因为目录名中有空格）。要跳转到那个文件夹，你需要包含一个反斜杠。改命令如下所示：要从当前文件夹返回到上一个文件夹，你可以在该文件夹输入 。把这两个点想象成一个后退按钮。该命令将文件从一个文件夹转移到另一个文件夹； 代表“移动”。你可以使用这个简单的命令，就像你把一个文件拖到 PC 上的一个文件夹一样。例如，如果我想创建一个名为  的文件来演示所有基本的 Linux 命令，并且我想将它移动到我的  文件夹中，我将输入这个命令：命令的第一部分（）说我想移动一个文件，第二部分（）表示我想移动的文件，第三部分（）表示我希望传输文件的位置。好吧，这不止一个命令，但我忍不住把它们都包括进来。为什么？因为它们能节省时间并避免经历头痛。 从光标处剪切文本直至本行结束 粘贴文本 将光标移到本行的末尾 将光标移动到本行的开头 跳转到下一个空格处 回到前一个空格处 删除前一个词 剪切光标前一个词 将文本粘贴到终端中 注销这些命令在许多方面都能派上用场。例如，假设你在命令行文本中拼错了一个单词：你可能注意到  拼写错了，因此该命令无法工作。但是快捷键可以让你很容易回去修复它。如果我的光标在这一行的末尾，我可以按下两次  来将光标移动到下面用  符号标记的地方：现在，我们可以快速地添加字母  来修复 ，十分简单！这是你用来在 Linux 环境下创建目录或文件夹的命令。例如，如果你像我一样喜欢 DIY，你可以输入  为你的 DIY 项目创建一个目录。如果你想在特定时间运行 Linux 命令，你可以将  添加到语句中。语法是  后面跟着你希望命令运行的日期和时间，然后命令提示符变为 ，这样你就可以输入在上面指定的时间运行的命令。例如：这将会在周六下午 4:08 运行  程序。这个命令允许你通过 Linux CLI 删除一个目录。例如：请记住，这个命令不会删除里面有文件的目录。这只在删除空目录时才起作用。如果你想删除文件， 命令就是你想要的。它可以删除文件和目录。要删除一个文件，键入 ，或者删除一个目录和里面的文件，键入 。 命令，也就是所谓的 “make file 的命令”，允许你使用 Linux CLI 创建新的、空的文件。很像  创建目录， 会创建文件。例如， 将会创建一个名为 testfile 的空文件。这个命令是你在 Linux 系统中用来查找文件的命令。就像在 Windows 中搜索一样，如果你忘了存储文件的位置或它的名字，这是非常有用的。例如，如果你有一个关于区块链用例的文档，但是你忘了标题，你可以输入  或者通过用星号分隔单词来查找 “blockchain use cases”，或者星号（）。例如：还有很多其他有用的 Linux CLI 命令，比如  命令，如果你开始关机但是你意识到你并不想这么做，那么这条命令很棒。但是这里描述的 10 个简单而有用的命令是你开始使用 Linux 命令行所需的基本知识。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/05/77d80105fd15f2465894827e23cc4842.jpeg"]}
{"title": "在 Linux 下 9 个有用的 touch 命令示例 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n 命令用于创建空文件，也可以更改 Unix 和 Linux 系统上现有文件时间戳。这里所说的更改时间戳意味着更新文件和目录的访问以及修改时间。让我们来看看  命令的语法和选项：： 命令中使用的选项：在这篇文章中，我们将介绍 Linux 中 9 个有用的  命令示例。要在 Linux 系统上使用  命令创建空文件，键入 ，然后输入文件名。如下所示：可能会出现一些情况，我们必须为某些测试创建大量空文件，这可以使用  命令轻松实现：在上面的例子中，我们创建了 20 个名为  到  的空文件，你可以根据需要更改名称和数字。假设我们想要改变名为  文件的访问时间，在  命令中使用  选项，然后输入文件名。如下所示：现在使用  命令验证文件的访问时间是否已更新：假设我们在  目录下有一个  文件夹，让我们用下面的命令改变这个文件夹的访问时间：在某些情况下，如果文件存在，我们希望更改文件的访问时间，并避免创建文件。在 touch 命令中使用  选项即可，如果文件存在，那么我们可以改变文件的访问时间，如果不存在，我们也可不会创建它。在  命令中使用  选项，我们可以更改文件和目录的修改时间。让我们更改名为  文件的更改时间：现在使用  命令来验证修改时间是否改变：同样的，我们可以改变一个目录的修改时间：使用  交叉验证访问和修改时间：每当我们使用  命令更改文件和目录的访问和修改时间时，它将当前时间设置为该文件或目录的访问和修改时间。假设我们想要将特定的日期和时间设置为文件的访问和修改时间，这可以使用  命令中的  和  选项来实现。日期和时间可以使用以下格式指定：其中： – 年份的前两位数字 – 年份的后两位数字 – 月份 (01-12) – 天 (01-31) – 小时 (00-23) – 分钟 (00-59)让我们将  文件的访问和修改时间设置为未来的一个时间（2025 年 10 月 19 日 18 时 20 分）。使用  命令查看更新访问和修改时间：根据日期字符串设置访问和修改时间，在  命令中使用  选项，然后指定日期字符串，后面跟文件名。如下所示：使用  命令验证文件的状态：在上述命令中，如果我们不指定 ，如果系统中不存在该文件那么  命令将创建一个新文件，并将时间戳设置为命令中给出的。在  命令中，我们可以使用参考文件来设置文件或目录的时间戳。假设我想在  文件上设置与文件  文件相同的时间戳， 命令中使用  选项可以轻松实现。默认情况下，每当我们尝试使用  命令更改符号链接文件的时间戳时，它只会更改原始文件的时间戳。如果你想更改符号链接文件的时间戳，则可以使用  命令中的  选项来实现。这就是本教程的全部了。我希望这些例子能帮助你理解  命令。请分享你的宝贵意见和评论。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/05/77d80105fd15f2465894827e23cc4842.jpeg"]}
{"title": "Pet：一个简单的命令行片段管理器 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n我们不可能记住所有的命令，对吧？是的。除了经常使用的命令之外，我们几乎不可能记住一些很少使用的长命令。这就是为什么需要一些外部工具来帮助我们在需要时找到命令。在过去，我们已经点评了两个有用的工具，名为 “Bashpast” 和 “Keep”。使用 Bashpast，我们可以轻松地为 Linux 命令添加书签，以便更轻松地重复调用。而 Keep 实用程序可以用来在终端中保留一些重要且冗长的命令，以便你可以随时使用它们。今天，我们将看到该系列中的另一个工具，以帮助你记住命令。现在让我们认识一下 “Pet”，这是一个用 Go 语言编写的简单的命令行代码管理器。使用 Pet，你可以：注册/添加你重要的、冗长和复杂的命令片段。以交互方式来搜索保存的命令片段。直接运行代码片段而无须一遍又一遍地输入。轻松编辑保存的代码片段。通过 Gist 同步片段。在片段中使用变量还有很多特性即将来临。由于它是用 Go 语言编写的，所以确保你在系统中已经安装了 Go。安装 Go 后，从  获取最新的二进制文件。对于 32 位计算机：解压下载的文件：对于 32 位：将  二进制文件复制到 PATH（即  之类的）。最后，让它可以执行：如果你使用的是基于 Arch 的系统，那么你可以使用任何 AUR 帮助工具从 AUR 安装它。使用 ：使用 ：使用 ：使用 ：此外，你需要安装  或  工具以启用交互式搜索。请参阅官方 GitHub 链接了解如何安装这些工具。运行没有任何参数的  来查看可用命令和常规选项的列表。要查看特定命令的帮助部分，运行：默认配置其实工作的挺好。但是，你可以更改保存片段的默认目录，选择要使用的选择器（fzf 或 peco），编辑片段的默认文本编辑器，添加 GIST id 详细信息等。要配置 Pet，运行：该命令将在默认的文本编辑器中打开默认配置（例如我是 vim），根据你的要求更改或编辑特定值。为了创建一个新的片段，运行：添加命令和描述，然后按下回车键保存它。这是一个简单的命令，用于从  命令输出中删除所有数字。你可以很轻松地记住它。但是，如果你很少使用它，几天后你可能会完全忘记它。当然，我们可以使用  搜索历史记录，但 Pet 会更容易。另外，Pet 可以帮助你添加任意数量的条目。另一个很酷的功能是我们可以轻松添加以前的命令。为此，在你的  或  文件中添加以下行。执行以下命令来使保存的更改生效。或者：现在，运行任何命令，例如：要添加上述命令，你不必使用  命令。只需要：将说明添加到该命令代码片段中，然后按下回车键保存。要查看保存的片段，运行：如果你想编辑代码片段的描述或命令，运行：这将在你的默认文本编辑器中打开所有保存的代码片段，你可以根据需要编辑或更改片段。要将标签用于判断，使用下面的  标志。要执行一个保存的片段，运行：从列表中选择你要运行的代码段，然后按回车键来运行它：记住你需要安装 fzf 或 peco 才能使用此功能。如果你有很多要保存的片段，你可以使用字符串或关键词如 below.qjz 轻松搜索它们。输入搜索字词或关键字以缩小搜索结果范围。首先，你需要获取访问令牌。转到此链接  并创建访问令牌（只需要 “gist” 范围）。使用以下命令来配置 Pet：将令牌设置到  字段中的 。设置完成后，你可以像下面一样将片段上传到 Gist。你也可以在其他 PC 上下载片段。为此，编辑配置文件并在  中将  设置为 GIST id。之后，使用以下命令下载片段：获取更多细节，参阅帮助选项：或者：这就是全部了。希望这可以帮助到你。正如你所看到的，Pet 使用相当简单易用！如果你很难记住冗长的命令，Pet 实用程序肯定会有用。干杯！\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/05/310d11635ef5716e4028f2035c080286.png"]}
{"title": "给初学者的 fc 示例教程 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "Linux"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n （ix ommands 的缩写）是个 shell 内置命令，用于在交互式 shell 里列出、编辑和执行最近输入的命令。你可以用你喜欢的编辑器编辑最近的命令并再次执行，而不用把它们整个重新输入一遍。除了可以避免重复输入又长又复杂的命令，它对修正拼写错误来说也很有用。因为是 shell 内置命令，大多 shell 都包含它，比如 Bash 、 Zsh 、 Ksh 等。在这篇短文中，我们来学一学在 Linux 中使用  命令。执行不带其它参数的  命令，它会列出最近 16 个命令。 选项用于将输出反向排序。 选项用于隐藏行号。这样行号就不再显示了。如果想以某个命令开始，只需在  选项后面加上行号即可。比如，要显示行号 520 至最近的命令，可以这样：要列出一段范围内的命令，将始、末行号作为  的参数即可，比如 520 至 525：除了使用行号，我们还可以使用字符。比如，要列出最近一个  至最近一个命令之间的所有命令，只需要像下面这样使用起始字母即可：要列出所有  和  之间的命令，你可以都使用起始字母，像这样：或者，使用开始命令的首字母以及结束命令的行号：或者都使用行号：这三个命令都显示一样的结果。我们经常敲错命令，这时你可以用默认编辑器修正拼写错误并执行而不用将命令重新再敲一遍。编辑并执行上一个命令：这会在默认编辑器里载入上一个命令。你可以看到，我上一个命令是 。你可以随意修改，它会在你保存退出编辑器时自动执行。这在命令或参数又长又复杂时很有用。需要注意的是，它同时也可能是的。比如，如果你的上一个命令是危险的 ，当它自动执行时你可能丢掉你的重要数据。所以，小心谨慎对待每一个命令。另一个有用的选项是  ，它可以用来为  命令选择不同的编辑器。比如，如果我们想用  来编辑上一个命令:这个命令会打开  编辑器（而不是默认编辑器）编辑上一个命令。如果你觉得用  选项太麻烦，你可以修改你的默认编辑器，只需要将环境变量  设为你想要让  使用的编辑器名称即可。比如，要把  设为默认编辑器，编辑你的  或其他初始化文件： （LCTT 译注：如果  不存在可自己创建；如果使用的是 bash ，可以编辑  ）添加下面一行：你也可以使用编辑器的完整路径：输入  保存退出。要使改动立即生效，运行以下命令：现在再输入  就可以使用  编辑器来编辑上一个命令了。我们现在知道  命令不带任何参数的话会将上一个命令载入编辑器。但有时你可能不想编辑，仅仅是想再次执行上一个命令。这很简单，在末尾加上连字符（）就可以了：如你所见， 带了  选项，但并没有编辑上一个命令（例中的 ）。需要注意的是，有些选项仅对指定 shell 有效。比如下面这些选项可以用在 zsh 中，但在 Bash 或 Ksh 中则不能用。想要知道命令是在什么时候执行的，可以用  选项：这样你就可以查看最近命令的具体执行时间了。使用选项  ，可以为每个命令显示完整的时间戳。当然，欧洲的老乡们还可以使用  选项来显示欧洲时间格式。当不带任何参数时， 将上一个命令载入默认编辑器。当带一个数字作为参数时， 将数字指定的命令载入默认编辑器。当带一个字符作为参数时， 将最近一个以指定字符开头的命令载入默认编辑器。当有两个参数时，它们分别指定需要列出的命令范围的开始和结束。更多细节，请参考 man 手册。好了，今天就这些。希望这篇文章能帮助到你。更多精彩内容，敬请期待！ \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/04/9d9a2ae51099793ebcb0c2af97dc331b.png"]}
{"title": "GitHub 工程师：我眼中的理想上司是这样子的 - 文章 - 伯乐在线", "tag": ["职场", "职场"], "goodNum": "1", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n我是 Github 的一名高级工程师。我不是要找工作，只是一直在思考领导能力的问题，思考在我多年共事过的诸多领导之中，我最欣赏的特质是什么。受到 Chad Fowler 的文章《》的启发，我也开始留意我想为什么样的领导工作，即——理想的领导是什么样。在分享我的看法之前，先让我简单介绍一下我自己的情况：我是一名经验丰富的工程师，做过很多基础架构的工作，同时在我的专业领域（API 及其生态环境）扮演着技术顾问的角色。我是个不太需要监督指导的人，我老板只要指出问题的大方向，就可以放手让我去完成了。我很乐意解决困难的工程问题，带领团队朝一个方向努力，或是帮助公司与公众就一个项目进行沟通。正如一个同事所言：我就是“擅长搞定麻烦事”。在工作中明显地表现出冷静和自在，了解你的态度和行为会对周围的人产生哪些影响，非常关注如何营造出一种相互支持的工作环境。工作是生活的一部分，拥有健康的工作时间，会休假。即使你自己选择在常规工作时间以外工作，也不期待别人和你一样，不干扰其他人的工作习惯。无论与谁谈话都在场。善于倾听。基于自己和团队的价值，会经过深思熟虑精心设计工作流程，因为你重视他人的参与和时间，因此不会为了走流程而增加流程。当你要提出批评性的建议的时候，会及时并且私下沟通。会提供具体的细节，并给出改进的建议和所需的支持。当你有积极的反馈意见时，也会提供具体的细节，并以别人喜欢被认可的方式分享出来。足够自信，乐于接受其他人对你工作和方法的反馈。足够谦虚，在你有不懂的时候、犯错的时候或是学到新东西的时候随时承认。享受从周围人身上学习新知识的过程。对公司的情况有深刻透彻的理解，利用已知的信息指导员工如何工作可以创造出最大的价值，为用户和公司带来最好的影响。不害怕质疑和否认自己的领导，或是挑战公司的现状。允许并支持你的员工在划定的范围内自己做决定，即使你可能不会做同样的决定。无论是大型还是小型的任务、新特性还是常规维护，重视他人的工作。经常强调这一点，让每个人都知道你重视他和他的工作成果。无论在何时何地都能培养一种信任的文化。能够意识到使没受重视的人群被边缘化的行为，即使这些行为是微不足道的，也可能是出于潜意识的。意识到这些事所造成的情感上的伤害。当这种情况出现时，能迅速采取行动解决问题。知道科技领域实际上并不是精英政治（根据个人才能和功绩分配权力），多留意在工作中谁创造了最多的价值，谁最积极主动，确保他们受到关注，拥有更多特权。同样，留意谁在工作中遇到了困难，努力纠正其中的不平等。观察大家在日常沟通和正式场合谈论事情有何不同。知道存在对女性和有色人种的系统性偏见，努力保证你的员工在相处和评估时不受到此类歧视。利用自己的特权帮助员工成长，积极赞助员工：使他们融入团队，看到他们的努力，让他们得到提拔。不只是期待员工做出最完美的工作，还要信任并赋予他们做好工作的权力。给予员工接受并完成新挑战所需的支持。不接受平庸。如果你尽了最大的努力，但是员工还是滥竽充数，那他们必须离开。尽管承担着很多责任和利益相关，仍然着眼于如何让员工更轻松地产出最佳工作成果。能注意到有人在工作中感到沮丧、无聊或是很吃力。无论他们主动告诉你的还是你感觉到的，抽出点时间关心他们，倾听其中的原因。从我的观点来看，以上这些都很重要。如果我描述的这些你都符合，我想你会成为一个好榜样，培养出一个互相支持，态度积极而又忠诚的团队。你能让员工的生活变得更好，理由很简单，你真正地关心着你的员工。\n                        \n            \n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2012/07/20120717_161512_1.jpg"]}
{"title": "MySQL 在并发场景下的问题及解决思路 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "数据库"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n1、背景对于数据库系统来说在多用户并发条件下提高并发性的同时又要保证数据的一致性一直是数据库系统追求的目标，既要满足大量并发访问的需求又必须保证在此条件下数据的安全，为了满足这一目标大多数数据库通过锁和事务机制来实现，MySQL数据库也不例外。尽管如此我们仍然会在业务开发过程中遇到各种各样的疑难问题，本文将以案例的方式演示常见的并发问题并分析解决思路。2、表锁导致的慢查询的问题首先我们看一个简单案例，根据ID查询一条用户信息：mysql> select * from user where id=6;这个表的记录总数为3条，但却执行了13秒。出现这种问题我们首先想到的是看看当前MySQL进程状态：从进程上可以看出select语句是在等待一个表锁，那么这个表锁又是什么查询产生的呢？这个结果中并没有显示直接的关联关系，但我们可以推测多半是那条update语句产生的（因为进程中没有其他可疑的SQL），为了印证我们的猜测，先检查一下user表结构：果然user表使用了MyISAM存储引擎，MyISAM在执行操作前会产生表锁，操作完成再自动解锁。如果操作是写操作，则表锁类型为写锁，如果操作是读操作则表锁类型为读锁。正如和你理解的一样写锁将阻塞其他操作(包括读和写)，这使得所有操作变为串行；而读锁情况下读-读操作可以并行，但读-写操作仍然是串行。以下示例演示了显式指定了表锁（读锁），读-读并行，读-写串行的情况。显式开启/关闭表锁，使用lock table user read/write; unlock tables;session1:session2：可以看到会话1启用表锁（读锁）执行读操作，这时会话2可以并行执行读操作，但写操作被阻塞。接着看：session1:session2:当session1执行解锁后，seesion2则立刻开始执行写操作，即读-写串行。总结：到此我们把问题的原因基本分析清楚，总结一下——MyISAM存储引擎执行操作时会产生表锁，将影响其他用户对该表的操作，如果表锁是写锁，则会导致其他用户操作串行，如果是读锁则其他用户的读操作可以并行。所以有时我们遇到某个简单的查询花了很长时间，看看是不是这种情况。解决办法：1）、尽量不用MyISAM存储引擎，在MySQL8.0版本中已经去掉了所有的MyISAM存储引擎的表，推荐使用InnoDB存储引擎。2）、如果一定要用MyISAM存储引擎，减少写操作的时间；3、线上修改表结构有哪些风险？如果有一天业务系统需要增大一个字段长度，能否在线上直接修改呢？在回答这个问题前，我们先来看一个案例：以上语句尝试修改user表的name字段长度，语句被阻塞。按照惯例，我们检查一下当前进程：从进程可以看出alter语句在等待一个元数据锁，而这个元数据锁很可能是上面这条select语句引起的，事实正是如此。在执行DML（select、update、delete、insert）操作时，会对表增加一个元数据锁，这个元数据锁是为了保证在查询期间表结构不会被修改，因此上面的alter语句会被阻塞。那么如果执行顺序相反，先执行alter语句，再执行DML语句呢？DML语句会被阻塞吗？例如我正在线上环境修改表结构，线上的DML语句会被阻塞吗？答案是：不确定。在MySQL5.6开始提供了online ddl功能，允许一些DDL语句和DML语句并发，在当前5.7版本对online ddl又有了增强，这使得大部分DDL操作可以在线进行。详见：所以对于特定场景执行DDL过程中，DML是否会被阻塞需要视场景而定。总结：通过这个例子我们对元数据锁和online ddl有了一个基本的认识，如果我们在业务开发过程中有在线修改表结构的需求，可以参考以下方案：1、尽量在业务量小的时间段进行；2、查看官方文档，确认要做的表修改可以和DML并发，不会阻塞线上业务；3、推荐使用percona公司的pt-online-schema-change工具，该工具被官方的online ddl更为强大，它的基本原理是：通过insert… select…语句进行一次全量拷贝，通过触发器记录表结构变更过程中产生的增量，从而达到表结构变更的目的。例如要对A表进行变更，主要步骤为：\n\n\n4、一个死锁问题的分析在线上环境下死锁的问题偶有发生，死锁是因为两个或多个事务相互等待对方释放锁，导致事务永远无法终止的情况。为了分析问题，我们下面将模拟一个简单死锁的情况，然后从中总结出一些分析思路。演示环境：MySQL5.7.20 事务隔离级别：RR表user：下面演示事务1、事务2工作的情况：Query OK, 0 rows affected (0.00 sec)Query OK, 0 rows affected (0.00 sec)+—-+——+——+\n| id | name | age |\n+—-+——+——+\n| 3 | sun | 20 |\n+—-+——+——+\n1 row in set (0.00 sec)+—-+——+——+\n| id | name | age |\n+—-+——+——+\n| 4 | zhou | 21 |\n+—-+——+——+\n1 row in set (0.00 sec)通过查询元数据库innodb事务表，监控到当前运行事务数为2，即事务1、事务2。因为id=4的记录已被事务2加上行锁，该语句将阻塞ERROR 1213 (40001): Deadlock found when trying to get lock; try restarting transactionid=3的记录已被事务1加上行锁，而本事务持有id=4的记录行锁，此时InnoDB存储引擎检查出死锁，本事务被回滚。Query OK, 0 rows affected (0.00 sec)这是一个简单的死锁场景，事务1、事务2彼此等待对方释放锁，InnoDB存储引擎检测到死锁发生，让事务2回滚，这使得事务1不再等待事务B的锁，从而能够继续执行。那么InnoDB存储引擎是如何检测到死锁的呢？为了弄明白这个问题，我们先检查此时InnoDB的状态：show engine innodb statusG————————\n\n————————\n2018-01-14 12:17:13 0x70000f1cc000\n*** (1) TRANSACTION:\nTRANSACTION 5120, ACTIVE 17 sec starting index read\nmysql tables in use 1, locked 1\nLOCK WAIT 3 lock struct(s), heap size 1136, 2 row lock(s)\nMySQL thread id 10, OS thread handle 123145556967424, query id 2764 localhost root updating\nupdate user set name=’haha’ where id=4\n*** (1) WAITING FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 94 page no 3 n bits 80 index PRIMARY of table . trx id 5120 lock_mode X locks rec but not gap waiting\nRecord lock, heap no 5 PHYSICAL RECORD: n_fields 5; compact format; info bits 0\n0: len 4; hex 80000004; asc ;;\n1: len 6; hex 0000000013fa; asc ;;\n2: len 7; hex 520000060129a6; asc R ) ;;\n3: len 4; hex 68616861; asc haha;;\n4: len 4; hex 80000015; asc ;;*** (2) TRANSACTION:\nTRANSACTION 5121, ACTIVE 12 sec starting index read\nmysql tables in use 1, locked 1\n3 lock struct(s), heap size 1136, 2 row lock(s)\nMySQL thread id 11, OS thread handle 123145555853312, query id 2765 localhost root updating\nupdate user set name=’hehe’ where id=3\n*** (2) HOLDS THE LOCK(S):\nRECORD LOCKS space id 94 page no 3 n bits 80 index PRIMARY of table . trx id 5121 lock_mode X locks rec but not gap\nRecord lock, heap no 5 PHYSICAL RECORD: n_fields 5; compact format; info bits 0\n0: len 4; hex 80000004; asc ;;\n1: len 6; hex 0000000013fa; asc ;;\n2: len 7; hex 520000060129a6; asc R ) ;;\n3: len 4; hex 68616861; asc haha;;\n4: len 4; hex 80000015; asc ;;*** (2) WAITING FOR THIS LOCK TO BE GRANTED:\nRECORD LOCKS space id 94 page no 3 n bits 80 index PRIMARY of table . trx id 5121 lock_mode X locks rec but not gap waiting\nRecord lock, heap no 7 PHYSICAL RECORD: n_fields 5; compact format; info bits 0\n0: len 4; hex 80000003; asc ;;\n1: len 6; hex 0000000013fe; asc ;;\n2: len 7; hex 5500000156012f; asc U V /;;\n3: len 4; hex 68656865; asc hehe;;\n4: len 4; hex 80000014; asc ;;InnoDB状态有很多指标，这里我们截取死锁相关的信息，可以看出InnoDB可以输出最近出现的死锁信息，其实很多死锁监控工具也是基于此功能开发的。在死锁信息中，显示了两个事务等待锁的相关信息（蓝色代表事务1、绿色代表事务2），重点关注：WAITING FOR THIS LOCK TO BE GRANTED和HOLDS THE LOCK(S)。WAITING FOR THIS LOCK TO BE GRANTED表示当前事务正在等待的锁信息，从输出结果看出事务1正在等待heap no为5的行锁，事务2正在等待 heap no为7的行锁；HOLDS THE LOCK(S)：表示当前事务持有的锁信息，从输出结果看出事务2持有heap no为5行锁。从输出结果看出，最后InnoDB回滚了事务2。那么InnoDB是如何检查出死锁的呢？我们想到最简单方法是假如一个事务正在等待一个锁，如果等待时间超过了设定的阈值，那么该事务操作失败，这就避免了多个事务彼此长等待的情况。参数innodb_lock_wait_timeout正是用来设置这个锁等待时间的。如果按照这个方法，解决死锁是需要时间的（即等待超过innodb_lock_wait_timeout设定的阈值），这种方法稍显被动而且影响系统性能，InnoDB存储引擎提供一个更好的算法来解决死锁问题，wait-for graph算法。简单的说，当出现多个事务开始彼此等待时，启用wait-for graph算法，该算法判定为死锁后立即回滚其中一个事务，死锁被解除。该方法的好处是：检查更为主动，等待时间短。下面是wait-for graph算法的基本原理：为了便于理解，我们把死锁看做4辆车彼此阻塞的场景：4辆车看做4个事务，彼此等待对方的锁，造成死锁。wait-for graph算法原理是把事务作为节点，事务之间的锁等待关系，用有向边表示，例如事务A等待事务B的锁，就从节点A画一条有向边到节点B，这样如果A、B、C、D构成的有向图，形成了环，则判断为死锁。这就是wait-for graph算法的基本原理。总结：1、如果我们业务开发中出现死锁如何检查出？刚才已经介绍了通过监控InnoDB状态可以得出，你可以做一个小工具把死锁的记录收集起来，便于事后查看。2、如果出现死锁，业务系统应该如何应对？从上文我们可以看到当InnoDB检查出死锁后，对客户端报出一个Deadlock found when trying to get lock; try restarting transaction信息，并且回滚该事务，应用端需要针对该信息，做事务重启的工作，并保存现场日志事后做进一步分析，避免下次死锁的产生。5、锁等待问题的分析在业务开发中死锁的出现概率较小，但锁等待出现的概率较大，锁等待是因为一个事务长时间占用锁资源，而其他事务一直等待前个事务释放锁。Query OK, 0 rows affected (0.00 sec)Query OK, 0 rows affected (0.00 sec)+—-+——+——+\n| id | name | age |\n+—-+——+——+\n| 3 | sun | 20 |\n+—-+——+——+\n1 row in set (0.00 sec)通过查询元数据库innodb事务表，监控到当前运行事务数为2，即事务1、事务2。因为id=3的记录被事务1加上行锁，所以该语句将阻塞（即锁等待）锁等待时间超过阈值，操作失败。注意：此时事务2并没有回滚。从上述可知事务1长时间持有id=3的行锁，事务2产生锁等待，等待时间超过innodb_lock_wait_timeout后操作中断，但事务并没有回滚。如果我们业务开发中遇到锁等待，不仅会影响性能，还会给你的业务流程提出挑战，因为你的业务端需要对锁等待的情况做适应的逻辑处理，是重试操作还是回滚事务。在MySQL元数据表中有对事务、锁等待的信息进行收集，例如information_schema数据库下的INNODB_LOCKS、INNODB_TRX、INNODB_LOCK_WAITS，你可以通过这些表观察你的业务系统锁等待的情况。你也可以用一下语句方便的查询事务和锁等待的关联关系：结果：waiting_trx_id: 5132\nwaiting_thread: 11\nwating_query: update user set name=’hehe’ where id=3\nblocking_trx_id: 5133\nblocking_thread: 10\nblocking_query: NULL总结：1、请对你的业务系统做锁等待的监控，这有助于你了解当前数据库锁情况，以及为你优化业务程序提供帮助；2、业务系统中应该对锁等待超时的情况做合适的逻辑判断。6、小结本文通过几个简单的示例介绍了我们常用的几种MySQL并发问题，并尝试得出针对这些问题我们排查的思路。文中涉及事务、表锁、元数据锁、行锁，但引起并发问题的远远不止这些，例如还有事务隔离级别、GAP锁等。真实的并发问题可能多而复杂，但排查思路和方法却是可以复用，在本文中我们使用了show processlist;show engine innodb status;以及查询元数据表的方法来排查发现问题，如果问题涉及到了复制，还需要借助master/slave监控来协助。参考资料：姜承尧《InnoDB存储引擎》李宏哲 杨挺 《MySQL排查指南》何登成  \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2015/11/e78e36715813f49e9e62fe0c6050075c.png"]}
{"title": "创建订单实现幂等的一点思考 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "分布式", "架构设计"], "goodNum": "1", "saveNum": "  收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n大部分文章都会说，同一个操作，进行多次操作后，结果是一样的，就可以说这个操作是支持幂等的。感觉不太准确，比如一个http get操作，可能每次的结果都不一样，但是其实是幂等的。看了很多文章，感觉下面的定义比较准确：一个操作如果多次任意执行所产生的影响（或者叫副作用），都是相同的。如果一个用户分两次下单，购买的商品都是一样的。第一次请求：user1：购买一个商品product1；\n第二次请求：user1：还是购买一个商品product1；这种场景也很常见，是需要生成两个订单的。这样子看起来貌似创建订单的接口做不了幂等，因为业务数据一样的情况下，还是需要生成多个订单。但是这样子设计还是有个坑，万一创建订单的接口超时了呢？并且调用方进行了重试的话，那就可能变成用户其实想下一个单，但是订单系统其实生成了多个订单。比如说：调用方发起创建订单的请求，订单系统收到了，并成功创建订单了。但是由于系统原因或者网络原因等，没有及时告知调用方订单已经创建成功，调用方一直等待回复，直到超时了。调用方再次发起了创建订单的请求，这个时候就可能会生成多个订单。如果订单接口不支持幂等的情况下，如何应付这种情况呢？有两种方法第一种:当调用方调用订单接口超时了，是会收到异常的，这个时候调用方捕获到这个异常后，虽然看起来很low，但是还是有人这么做的。第二种：让订单系统提供一个订单是否创建成功的查询接口，根据一些关键业务字段去查询，如果查询到已经创建成功了，则调用方不要重试了。上面两种方案都有人用过，但是都没实现幂等。其实针对上面的场景，用幂等来设计也不是很难。可以使用一个唯一的流水号ID，用来标识是不是同一个请求或者交易。这种ID通常都需要具备。假设让客户端来生成这个ID，每个创建订单的请求生成一个唯一的ID。那么订单系统如何根据来实现幂等呢？通常有两种。第一种：先将这个ID保存到一个流水表里面，并且流水表中将这个ID设置为,如果插入出现冲突了，则说明这个创建订单的请求已经处理过了，直接返回之前的操作结果。第二种：根据ID读取流水表，如果没有读取到，则创建订单和插入流水表。如果读取到了，则返回之前的操作结果。不建议使用第二种方式，因为大部分情况下的请求都不是重试来的，让100%的请求都要去读取流水表，实在是不应该。另外，读取流水表的操作也是有潜在风险的，因为用数据库的读检查来确保数据存在性可能因为竞争而不生效，存在竞态条件。建议用第一种方案，因为本来流水表就是要插入，顺便利用的冲突特性来判断。现在我们用第一种方案完整描述一下整个处理过程。当调用方携带流水号ID调用创建订单的接口，如果出现超时了，调用方不知道订单到底创建成功还是失败，这个时候，用流水号进行重试，订单系统虽然收到了两个请求，但是由于流水号ID是同一个，可以根据流水表来做幂等操作。并告知对方订单创建成功与否。这里又有一个坑，万一调用方进行重试的时候，重新生成一个流水号，那就没得救了，会生成多个订单了。这个只能让客户端来保证了。假设创建订单的接口在创建订单的时候，还需要依赖一些外部系统，如果订单创建接口实现了幂等，但是外部接口没有实现幂等的话，还是可能出现。属于整个链路幂等的问题了。好复杂。目前还没想好如何处理这种情况呢。调用方创建唯一ID，服务端用流水表这种方式实现幂等，非常依赖这个唯一ID。万一这个ID丢失了呢？咋破？目前我也在思考这个问题。\n                        \n            \n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2015/07/8266f93c2d45d97e0d52e71428ca372e.png"]}
{"title": "常用排序算法总结（1） - 文章 - 伯乐在线", "tag": ["IT技术", "排序算法", "算法"], "goodNum": "2", "saveNum": " 19 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n我们通常所说的排序算法往往指的是，即数据记录在内存中进行排序。排序算法大体可分为两种：一种是，时间复杂度O(nlogn) ~ O(n^2)，主要有：，，，，，等。另一种是，时间复杂度可以达到O(n)，主要有：，，等。这里我们来探讨一下常用的比较排序算法，非比较排序算法将在下一篇文章中介绍。下表给出了常见比较排序算法的性能：有一点我们很容易忽略的是(腾讯校招2016笔试题曾考过)。排序算法稳定性的简单形式化定义为：通俗地讲就是保证排序前后两个相等的数的相对顺序不变。对于不稳定的排序算法，只要举出一个实例，即可说明它的不稳定性；而对于稳定的排序算法，必须对算法进行分析从而得到稳定的特性。需要注意的是，排序算法是否为稳定的是由具体算法决定的，不稳定的算法在某种条件下可以变为稳定的算法，而稳定的算法在某种条件下也可以变为不稳定的算法。例如，对于冒泡排序，原本是稳定的排序算法，如果将记录交换的条件改成A[i] >= A[i + 1]，则两个相等的记录就会交换位置，从而变成不稳定的排序算法。其次，说一下排序算法稳定性的好处。基数排序就是这样，先按低位排序，逐次按高位排序，低位排序后元素的顺序在高位也相同时是不会改变的。冒泡排序(Bubble Sort)冒泡排序是一种极其简单的排序算法，也是我所学的第一个排序算法。它重复地走访过要排序的元素，依次比较相邻两个元素，如果他们的顺序错误就把他们调换过来，直到没有元素再需要交换，排序完成。这个算法的名字由来是因为越小(或越大)的元素会经由交换慢慢“浮”到数列的顶端。冒泡排序算法的运作如下：比较相邻的元素，如果前一个比后一个大，就把它们两个调换位置。对每一对相邻元素作同样的工作，从开始第一对到结尾的最后一对。这步做完后，最后的元素会是最大的数。针对所有的元素重复以上的步骤，除了最后一个。持续每次对越来越少的元素重复上面的步骤，直到没有任何一对数字需要比较。由于它的简洁，冒泡排序通常被用来对于程序设计入门的学生介绍算法的概念。冒泡排序的代码如下：上述代码对序列{ 6, 5, 3, 1, 8, 7, 2, 4 }进行冒泡排序的实现过程如下使用冒泡排序为一列数字进行排序的过程如右图所示：尽管冒泡排序是最容易了解和实现的排序算法之一，但它对于少数元素之外的数列排序是很没有效率的。冒泡排序的改进：鸡尾酒排序，也叫，是冒泡排序的一种改进。此算法与冒泡排序的不同处在于，而冒泡排序则仅从低到高去比较序列里的每个元素。他可以得到比冒泡排序稍微好一点的效能。鸡尾酒排序的代码如下：使用鸡尾酒排序为一列数字进行排序的过程如右图所示：以序列(2,3,4,5,1)为例，鸡尾酒排序只需要访问一次序列就可以完成排序，但如果使用冒泡排序则需要四次。但是在乱数序列的状态下，鸡尾酒排序与冒泡排序的效率都很差劲。选择排序(Selection Sort)选择排序也是一种简单直观的排序算法。它的工作原理很容易理解：初始时在序列中找到最小（大）元素，放到序列的起始位置作为已排序序列；然后，再从剩余未排序元素中继续寻找最小（大）元素，放到已排序序列的末尾。以此类推，直到所有元素均排序完毕。注意选择排序与冒泡排序的区别：冒泡排序通过依次交换相邻两个顺序不合法的元素位置，从而将当前最小（大）元素放到合适的位置；而选择排序每遍历一次都记住了当前最小（大）元素的位置，最后仅需一次交换操作即可将其放到合适的位置。选择排序的代码如下：上述代码对序列{ 8, 5, 2, 6, 9, 3, 1, 4, 0, 7 }进行选择排序的实现过程如右图：使用选择排序为一列数字进行排序的宏观过程：比如序列：{ 5, 8, 5, 2, 9 }，一次选择的最小元素是2，然后把2和第一个5进行交换，从而改变了两个元素5的相对次序。插入排序(Insertion Sort)插入排序是一种简单直观的排序算法。它的工作原理非常类似于我们抓扑克牌对于未排序数据(右手抓到的牌)，在已排序序列(左手已经排好序的手牌)中从后向前扫描，找到相应位置并插入。插入排序在实现上，通常采用in-place排序（即只需用到O(1)的额外空间的排序），因而在从后向前扫描过程中，需要反复把已排序元素逐步向后挪位，为最新元素提供插入空间。具体算法描述如下：从第一个元素开始，该元素可以认为已经被排序取出下一个元素，在已经排序的元素序列中从后向前扫描如果该元素（已排序）大于新元素，将该元素移到下一位置重复步骤3，直到找到已排序的元素小于或者等于新元素的位置将新元素插入到该位置后重复步骤2~5插入排序的代码如下：上述代码对序列{ 6, 5, 3, 1, 8, 7, 2, 4 }进行插入排序的实现过程如下使用插入排序为一列数字进行排序的宏观过程：插入排序不适合对于数据量比较大的排序应用。但是，如果需要排序的数据量很小，比如量级小于千，那么插入排序还是一个不错的选择。 插入排序在工业级库中也有着广泛的应用，在STL的sort算法和stdlib的qsort算法中，都将插入排序作为快速排序的补充，用于少量元素的排序（通常为8个或以下）。插入排序的改进：二分插入排序对于插入排序，如果比较操作的代价比交换操作大的话，可以采用来减少比较操作的次数，我们称为，代码如下：当n较大时，二分插入排序的比较次数比直接插入排序的最差情况好得多，但比直接插入排序的最好情况要差，所当以元素初始序列已经接近升序时，直接插入排序比二分插入排序比较次数少。二分插入排序元素移动次数与直接插入排序相同，依赖于元素初始序列。插入排序的更高效改进：希尔排序(Shell Sort)希尔排序，也叫，是插入排序的一种更高效的改进版本。希尔排序是的排序算法。希尔排序是基于插入排序的以下两点性质而提出改进方法的：插入排序在对几乎已经排好序的数据操作时，效率高，即可以达到线性排序的效率但插入排序一般来说是低效的，因为插入排序每次只能将数据移动一位希尔排序通过将比较的全部元素分为几个区域来提升插入排序的性能。这样可以让一个元素可以一次性地朝最终位置前进一大步。然后算法再取越来越小的步长进行排序，算法的最后一步就是普通的插入排序，但是到了这步，需排序的数据几乎是已排好的了（此时插入排序较快）。\n假设有一个很小的数据在一个已按升序排好序的数组的末端。如果用复杂度为O(n^2)的排序（冒泡排序或直接插入排序），可能会进行n次的比较和交换才能将该数据移至正确位置。而希尔排序会用较大的步长移动数据，所以小数据只需进行少数比较和交换即可到正确位置。希尔排序的代码如下：以23, 10, 4, 1的步长序列进行希尔排序：虽然一次插入排序是稳定的，不会改变相同元素的相对顺序，但在不同的插入排序过程中，相同的元素可能在各自的插入排序中移动，最后其稳定性就会被打乱。比如序列：{ 3, 5, 10, 8, 7, 2, 8, 1, 20, 6 }，h=2时分成两个子序列 { 3, 10, 7, 8, 20 } 和  { 5, 8, 2, 1, 6 } ，未排序之前第二个子序列中的8在前面，现在对两个子序列进行插入排序，得到 { 3, 7, 8, 10, 20 } 和 { 1, 2, 5, 6, 8 } ，即 { 3, 1, 7, 2, 8, 5, 10, 6, 20, 8 } ，两个8的相对次序发生了改变。归并排序(Merge Sort)归并排序是创建在归并操作上的一种有效的排序算法，效率为O(nlogn)，1945年由冯·诺伊曼首次提出。归并排序的实现分为与。递归实现的归并排序是算法设计中分治策略的典型应用，我们将一个大问题分割成小问题分别解决，然后用所有小问题的答案来解决整个大问题。非递归(迭代)实现的归并排序首先进行是两两归并，然后四四归并，然后是八八归并，一直下去直到归并了整个数组。归并排序算法主要依赖归并(Merge)操作。归并操作指的是将两个已经排序的序列合并成一个序列的操作，步骤如下：，使其大小为两个已经排序序列之和，该空间用来存放合并后的序列设定两个指针，最初位置分别为两个已经排序序列的起始位置比较两个指针所指向的元素，选择相对小的元素放入到合并空间，并移动指针到下一位置重复步骤3直到某一指针到达序列尾将另一序列剩下的所有元素直接复制到合并序列尾归并排序的代码如下：上述代码对序列{ 6, 5, 3, 1, 8, 7, 2, 4 }进行归并排序的实例如下使用归并排序为一列数字进行排序的宏观过程：归并排序除了可以对数组进行排序，还可以高效的求出数组小和（即单调和）以及数组中的逆序对，详见这篇。堆排序(Heap Sort)堆排序是指利用堆这种数据结构所设计的一种选择排序算法。堆是一种近似完全二叉树的结构（通常堆是通过一维数组来实现的），并满足性质：以最大堆（也叫大根堆、大顶堆）为例，其中父结点的值总是大于它的孩子节点。我们可以很容易的定义堆排序的过程：由输入的无序数组构造一个最大堆，作为初始的无序区把堆顶元素（最大值）和堆尾元素互换把堆（无序区）的尺寸缩小1，并调用heapify(A, 0)从新的堆顶元素开始进行堆调整重复步骤2，直到堆的尺寸为1堆排序的代码如下：堆排序算法的演示：动画中在排序过程之前简单的表现了创建堆的过程以及堆的逻辑结构。比如序列：{ 9, 5, 7, 5 }，堆顶元素是9，堆排序下一步将9和第二个5进行交换，得到序列 { 5, 5, 7, 9 }，再进行堆调整得到{ 7, 5, 5, 9 }，重复之前的操作最后得到{ 5, 5, 7, 9 }从而改变了两个5的相对次序。快速排序(Quick Sort)快速排序是由东尼·霍尔所发展的一种排序算法。在平均状况下，排序n个元素要O(nlogn)次比较。在最坏状况下则需要O(n^2)次比较，但这种状况并不常见。事实上，快速排序通常明显比其他O(nlogn)算法更快，因为它的内部循环可以在大部分的架构上很有效率地被实现出来。快速排序使用分治策略(Divide and Conquer)来把一个序列分为两个子序列。步骤为：从序列中挑出一个元素，作为”基准”(pivot).把所有比基准值小的元素放在基准前面，所有比基准值大的元素放在基准的后面（相同的数可以到任一边），这个称为分区(partition)操作。对每个分区递归地进行步骤1~2，递归的结束条件是序列的大小是0或1，这时整体已经被排好序了。快速排序的代码如下：使用快速排序法对一列数字进行排序的过程：比如序列：{ 1, 3, 4, 2, 8, 9, 8, 7, 5 }，基准元素是5，一次划分操作后5要和第一个8进行交换，从而改变了两个元素8的相对次序。Java系统提供的Arrays.sort函数。对于基础类型，底层使用快速排序。对于非基础类型，底层使用归并排序。请问是为什么？答：这是考虑到排序算法的稳定性。对于基础类型，相同值是无差别的，排序前后相同值的相对位置并不重要，所以选择更为高效的快速排序，尽管它是不稳定的排序算法；而对于非基础类型，排序前后相等实例的相对位置不宜改变，所以选择稳定的归并排序。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2014/10/a1a4de99de0c75eab712542a7dac876f.png"]}
{"title": "2017 年，我发布了 6 个副项目 - 文章 - 伯乐在线", "tag": ["职场", "副项目"], "goodNum": "1", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n2016 年我曾定了一个目标——每个月都要学点新东西。最终，我发布了 6 个新项目。下面我要对这些项目以及我学到的东西做个总结。回望这一年，我成功发布了尽可能多的副项目，同时有一份超过了全职工作的工作、和家人度过了高质量的时光（我有两个孩子和一位非常有耐心的妻子）、作为兼职教授教书、还兼职提供咨询服务。这些对我来说似乎有点疯狂。人们容易把缺乏时间视为阻碍自己做副项目的原因。我们常给自己找的借口是“只要有更多时间……”。我们还寻找花里胡哨的 App 或者任务管理技巧，来尝试在时间表中空出些时间来。但是，去年我学到的主要的一点就是，好消息是，我们“应付得了”动力。在 2017 年我学到了几种应付动力的方法，我想跟你们分享一下。你只是不能对你不关心的事物保持热情，所以选一些你激情所在的事情来做。当你灵光一闪时，别让它溜走，用上它。即使这意味着你要在工作会议上草草记下些笔记。重要的是紧紧抓住这些灵感时刻，以求知若饥并保持对工作的好奇心。对我来说，这意味着每个月发布些东西。一旦我开始工作，我往往会搞砸。所以 30 天的限制确实能帮助我控制好这个趋势，有效利用我的动力。如果结果发现某个月的想法不中用，这也能给你一个机会去尝试新想法。至少你不会把一整年的时间浪费在它上面。这是重要的一点。在项目尾声时你会耗尽“动力库”。（最后 10% 是致命的。）唯一能助你度过动力低迷期的是，知道在另一头还有人等着看你的成果。分享工作成果的另一个好处是，给你一个为副项目收集支持性反馈的机会。我工作的地方  会在每月第一个周五举办全办公室范围的活动。我利用这项活动展示我前一个月的项目，而且总能收到在场的这些慷慨的伙伴的鼓励和支持。站出来分享你的成果，你会对你收到了多少支持而感到震惊的。. . .这项实验中最让我惊讶的部分大概就是，我对在 2018 年发布更多工作更加充满动力，远不是在最后筋疲力尽。我会鼓励你在新的一年里应付动力问题，并发布一些你已经考虑了一段时间的想法。如果你尝试了，那我很乐意洗耳恭听。如果你对我在 2017 年的工作成果的细节感兴趣，请继续阅读！. . .一月项目：我已经入 的坑一段时间了。尽管我不把它看成是规范，也不认为它有那么科学，它仍是一个理解与我不同的人的有用框架。很多痴迷于个性的人没有意识到的是，MBTI 系统是基于的。认知功能是由现代心理学之父 Carl Jung 在上世纪 20 年代创造的。我想深挖一下，并进一步学习它。同时，我看了 HBO 的《西部世界》，看到了下面这一幕：我超爱这类科幻用户界面，它马上吸引了我的注意力。我想，如果我能基于人们的 MBTI 特征，建他们各自的“角色档案”会怎么样呢？为什么不呢？为了该项目做准备，我读了 “MBTI 圣经”， 》，并着手构建一个系统，该系统可以根据 MBTI 系统的基础——来生成雷达图。最后，我以《西部世界》的用户界面为核心，因为我（和其他 beta 测试者）发现，将多人重叠在同一张雷达图上以获得一群人之间的关系的能力更为实用。如果我自己也这么说的话，结果确实很有趣。试试输入团队成员的个性类型或者你和你伴侣的个性类型： Sheetcake 登陆页面我已经着手于 Sheetcake 几年了。它拥有非常小的一部分忠实用户（他们中的大多数都认识我或者与我关系亲密的人）。SheetCake 趣事：2012 年，我在 48 小时内完成了第一个版本。这是年轻一点的我演示这个 48 小时版本的我已经重新写了 4 次！第一版是用了 Backbone.js + Node.js。第二版是用了 Backbone + Marionette + Firebase。第三版是用了 React + Firebase（全都用了 CoffeeScript）。第四版，也是最终版，是用了 ES6、React 和 Firebase。使用 Sheetcake 的人往往连着用了好几年；然而还没有商业模型。Sheetcake 在某几方面的确做得很好（比如 Zero Day 注册），所以我想为它制作一个登录页面，以推销这些优点。我从一个模版开始，这是它的最终版本。 NeTi 聊天机器人去年早些时候，聊天机器人大火。尽管我从来不对聊天机器人能自己去某地抱什么希望，但是它们的对话 A.I. 属性还是吸引了我，我想进一步了解它。我是个内向的人，一般十分不擅长分享自己的事情。所以我想创造一个外向的机器人，它可以回答一些关于我的简单问题，这可能很有趣。如果我是个外向的人，我会拥有某些认知功能，NeTi 就得名于此。给提问意图分类的 A.I. 部分是用 Wit.ai 构建的，Wit.ai 使得构建 A.I. 容易多了。别让 NeTi 太生气，否则它可能会猛烈抨击你。 添加了移轴效果的代码截图——为什么不呢？在偶然间看到后，我被一个游戏背景中描述的  深深吸引。这个游戏叫 ，对我来说有些怀旧气息。过去我参与过一些有基础 A.I. 的游戏的工作，从来没有遇到这项技术。我记得那时我觉得 F.E.A.R 的 A.I. 特别令人印象深刻、栩栩如生。在进一步研究后，这个方法最吸引人的地方不是结果多么令人信服，而是解决方法多简单优雅（尤其是跟更标准的 A.I. 方法比较，比如有限状态机（Finite State Machine））。所以我为四月份的项目写了一个 JavaScript 库来探索 GOAP。一个基础执行简单得出乎意料（只要 58 行代码！）。 内嵌责任的目标合同五月我也开始了。我对我的饮食习惯变得满意，它也必然会影响我的能量级。整整 30 天节食（Whole30）对我来说进行得很顺利（节食期间我减了 18 磅，在接下来的几个月总共又减了 35 磅）。最重要的是，它确实均衡了我白天的能量，我感到更有动力了，也更专注了。看到了公开承诺和动力的相似之处，我决定将探索“目标合同”这个想法作为五月的副项目。. . .TiltMaps 主页这是一切的核心。我六月份的目标是做一个大家真正想买的产品。我最大的短板之一就是销售和营销，所以我想做一个可以帮助我练习的产品来进一步学习。我一直都对地图和生成艺术感兴趣，所以我有个吸引人的主意——创造一个工具，你可以用它来创造并购买你所喜爱的地点的海报。这个项目太过有野心，不能在一个月内作为副项目完成。所以我决定用 2017 年剩余的几个月来完成 TiltMaps，并在发布前每个月都研究该产品的不同角度。我发现把一个较大的项目的不同部分分成月度项目能有效完成项目。 为了弄清楚是否有可能生成高分辨率 3D 地图，我第一个月大部分时间都用来做 R&D 了。生成世界上任意地点的一张 300dpi 的 3D 地图不是任意 API 或者我找到的平台能开箱即用地支持的事情，所以我不得不发明我自己的方法来完成这件事。弄清它花掉了我这个月大部分的时间，但是当我找到了答案就变得出乎意料地简单了。之后，我构建了一个基础编辑器来开始制作真正的海报，并订购了几次打印测试。 接下来几个月我构建了该产品有更多消费者的 MVP。设计并不好，但是我还是让事情运转起来了，并且可以开始海报制作和打印的用户测试了。 接下来的几个月，我专注于让该项目准备好发布。尽管编辑器基本完成了，但是我还没有主页，而且市场营销方面还差得远。最终，通过在 Zero Day 和我参加的一个研讨会上展示 TiltMaps， 我在项目发布前的一个月卖出了几张海报。这非常鼓舞人心，因为这是我第一次从副项目中卖出了东西。 在  上的发布比我预想中进行得顺利。我预计会卖出 10 张左右，但最终卖出了 37 张，而且仍然有订单进来。制作人们想买的东西感觉很好，而且它是一个很好的测试平台，可以尝试那些可能会在我的全职工作中发挥作用的、不同的广告和销售策略。我计划 2018 年继续致力于 TiltMaps。但愿我能从其中获得体面的、有趣的收入。. . .总结完毕。感谢您读完全文。有任何想法或者反馈？我将洗耳恭听。在下面评论或者在  上与我联络。\r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://wx1.sinaimg.cn/large/63918611gy1frenpxw9krj20rs0j6q9i.jpg"]}
{"title": "15 分钟参透比特币和区块链 - 文章 - 伯乐在线", "tag": ["IT技术", " 2 评论 ", "区块链", "比特币"], "goodNum": "4", "saveNum": " 3 收藏", "sayNum": " 2 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n区块链就是比特币世界这个村子的账本，谁挖到矿，谁就有权在这个账本翻开新的一页，并在新的一页记下“X年X日，本村某某挖矿得到比特币一枚，并得到奖励的手续费若干”。比特币又火了。为什么要说又呢？因为比特币在 2013 年已经火过一次了。这次与 2013 年相同的是，比特币的价格一路飙升，让人咂舌。与 2013 年不同的是，这次人们不仅仅关注比特币的价格，也开始关注比特币背后的技术——。一夜之间，区块链从舞台背后站到了聚光灯下，成为了人们追捧的热点。物流、医药、版权…好像哪都可以凭借区块链脱胎换骨。那么，这么神奇的技术，到底是怎么回事？本文就以最通俗的语言，不涉及任何高等数学和计算机知识，来介绍一下比特币和区块链系统。说到区块链就不得不说比特币，比特币是区块链技术最好的载体，所以本文就以比特币为例来介绍区块链。比特币很牛，牛在两个特点：。别小瞧这两点，这两点同时存在可不是一件容易事儿。首先来说说去中心化，通常去中心化的货币一般都要追溯到很久以前了，远古时代人们自发地使用贝壳、石子做为雏形货币进行交易，这时候的货币可以看作是去中心化的货币——无需中央银行来组织发行、确认交易合法性。但是使用这类货币的弊端也不必我多说，货币供给不稳定，取决于每年的贝类产量；货币质量不一，有的大有的小，有的是花蛤有的是文蛤；交易很繁琐，大宗交易动不动就要好几车的贝壳，这么多货币运来运去还容易被抢劫。于是货币进化，信用货币时代到来，货币成了银行账户里的数字，上面的问题都解决了，但是我们必须需要银行来控制货币的发行、防伪，来进行交易结算，我们的财产权全掌握在了银行的手中。银行喜欢动不动搞点QE放点水，我们银行卡里的钱越来越贬值。比特币的基本原理做为一种货币，通常就要满足几个特点：得有人它，得能它，人与人之间可以互相它。持有比特币非常简单，只要有一个，就可以持有比特币并接受比特币。所持有的比特币数量只是这个地址下的一个数字。有人会问，这不跟银行账户一样么，确实很像，但实质又很不一样。银行系统是一个中心化的系统，账户的余额是由银行说了算的，哪天银行系统出错余额变成0，那你就真的从ATM机里取不出钱。比特币不使用这种权威的中心机构，又需要一个稳定的记账系统，所以解决办法是每一个“矿工”都把比特币世界发生过的所有交易记录存在自己的硬盘上。有了全部的交易记录，推算每个人有多少余额也就很容易了。这个被保存在所有人电脑里的交易记录，学名就是。黑客可以黑掉一些人保存的区块链，但是他做不到黑掉全世界大部分人，只要有大部分仍保存着正确的区块链，那么整个系统就可以通过纠错重新恢复正常。就像打麻将时，我们有时候用记账方式来记录每回合的应收应付，比特币世界也通过记账来交易，每发生一笔交易都会公之于众，然后大家把这笔交易记录在自己的小账本上，这样每家有多少钱，大家在自己的小账本上都能查清楚。只不过当记账由4个人变成全比特币世界的村民时，这就需要一个稍微复杂点的系统了。再来看看发行。我们先看纸币是怎么发行的，很简单，央行开动印刷机，一瞬间出现大把“毛爷爷”。而做为一种去中心化的电子货币，比特币是没有央行的，那怎么发行呢？比特币规定，人们可以去解答一个困难的问题，谁最先答出来，谁就可以发行一块比特币，也就是我们所谓的“挖矿”。这个困难的问题是什么呢？是哈希(hashing)的问题。哈希是一个函数，对输入进行一些运算来得到。就是咱们高中学过的。比特币让你解答的问题就是，告诉你哈希值和，求。这时候你会说了，这不就是个反函数的事么。抱歉，哈希函数这个函数比较特殊，找不到合适的反函数，要想求出，唯一的方法就是一个一个数来试，把每一个数都代入到里，看看结果是不是，如果恰好蒙对了，那也就把这个问题解答出来了。所以说所谓的货币发行、挖矿，实际上就是一帮人在用最好的计算机来撞大运蒙这个数。当一名矿工蒙对后，也就是挖到矿后，他就获得了在原有的区块链末端创造一个新的的权利，在这个新创建的交易区块上，这位矿工可以附带一个由作为付款人，收款人是任何人交易，这样，他就通过这个交易，创造并发行了一枚比特币。区块链就是由一串交易区块组成的。我们来看看交易区块上包含什么。一个交易区块会显示谁是它的父区块，包含本区块上的交易记录，以及本区块的哈希值。 这样，随着矿工们不断挖矿创建新的交易区块，一个接一个的区块就串成了一串，成为了名副其实的区块链！在比特币世界中，由于某些原因，区块链会发生分叉（为什么会分叉下文会提到），因而比特币世界规定：唯一合法的区块链是当前最长的区块链。区块链就是比特币世界这个村子的账本，谁挖到矿，谁就有权在这个账本翻开新的一页，并在新的一页记下“X年X日，本村某某挖矿得到比特币一枚，并得到奖励的手续费若干”。这个账本很特殊，并不是由村支书管理，而是所有的村民人手一本，谁挖到矿以后，都可以自己翻页记账，并让全村人按照同样的方式做，以保证全村所有人的账本一致。当全村人的账本出现不一致时，规定谁家的账本最长就听谁的。比特币的关键点在于交易。对于一个去中心化的电子货币系统，交易是很有风险的。想象一下，你和另一个人的电子货币交易就类似于打欠条，而且这个欠条没有第三方公证人。如果其中一方突然翻脸，欠条的有效性是很难保障的。由于不能使用类似银行结算中心的第三方公证人（使用了就是中心化系统了），所以比特币干脆就让全世界人做为公证人。所有比特币的交易都不能偷偷摸摸进行，都需要将这笔交易通过互联网广播到全世界。如果C想给B 0.5个比特币，会向全世界广播“C给了B 0.5个比特币！”，这时所有挖矿的矿工们，会把这条交易记录加到他们正在挖的这个交易区块中。他们为什么要加呢？因为当矿工挖出矿时，除了规定奖励的一枚比特币外，每加多一条交易记录，还会额外再多给一点点手续费。蚊子肉也是肉，辛勤的矿工们没有不喜欢的。在把交易记录加到区块的过程中，矿工们首先会验证一下这笔交易合不合法，也就是查查村里的账本，当C名下货币不足0.5个时，这条交易记录就会被拒绝加入到区块中。加入到区块中并不代表交易已经成功，只有当包含这个交易记录的区块的随机数X被某位矿工发现，并创造了新的交易区块链接在当前区块后，才能被认为是合法交易，这条交易记录也就成为被验证的交易。B可能会问了，那也就是说C发了给我钱的广播后，我还不能马上确定我是不是收到钱了啊？没错，C发广播，只相当于C站在村口朝全村人喊了一句 “我给B 五毛钱！”，只有当全村的人都听见，把这件事都记在了个自账本上，并且记下这件事的那页被矿工翻过去以后，B的户头上多了五毛钱这件事才真正得到了全村村民的认可。由于参与比特币挖矿的矿工众多，通常每笔交易所需的验证时间是非常短的，不会给交易带来延迟感。由此比特币的发行和交易首尾相连扣在了一起。交易通过发布广播的形式进行，矿工们听到广播后把交易写在交易区块中；矿工们通过挖矿来确认历史交易的完成，并由此创建新的区块，延长区块链，发行新的比特币。区块链的分叉之前提到了。为什么区块链会发生分叉呢？原因就在于。没有中心，大家都各自维护账本，因此受困于网络的延时、交流的不充分，难免有出现分歧的时候。举两个例子，一个是在挖矿时容易出现的问题：矿工B蒙对了随机数，挖矿成功，延长了区块链，注意，此时矿工B延长的区块链仅仅是自己的，其他人还都不知道这件事。当然，矿工B马上向全世界发布挖矿成功的消息，让大家按照他的方式延长区块链。但是这时，另一位矿工C也蒙对了随机数，他或者因为网速延迟还没听到B的广播，或者听到广播但不甘心，存心想破坏规则，于是他也把自己的区块链延长了，并开始向全世界发广播。因为网速的延迟，并不是所有人都先听到B的广播，此时就会出现一部分人按照B的指示更新区块链，一部分人按照C的指示更新区块链，而且因为网速的延迟，大家没办法确定到底是B还是C先发布的广播，从而引起区块链分叉。就好比村里两位矿工B和C分别住在村东和村西，B和C差不多在同一时间挖矿成功，把自家账本翻页，在新的一页写下属于自己的宣言“X年X月，本村B(C)挖矿得到比特币一枚”，并开始向全村大喊让全村人翻页并写下这句话。由于他们分别住在村子的两头，结果村东头的人先听到B大喊于是按找B的话记账，村西头的人先听到C大喊于是按照C的话记账，导致全村的账本此时出现了两个版本。第二种情况是，B与C进行交易，发布广播宣布付给C一枚比特币，但是B同时还跟D勾搭，几乎同时又发布广播宣布付给D一枚比特币，更糟糕的是，B宣布付出的是同一枚。跟第一种情况一样，由于网速问题，一部分矿工先听到B与C交易的广播，并将这条交易记录计入到当前交易区块中，后听到B与D的交易，并判定不合法，拒不添加到交易区块。而另一部分矿工正相反，只把B与D的交易添加到交易区块中。这两种情况并不是罕见的，由于比特币世界由全世界各地的人参与，有的地区用的是100M光宽带，有的地方用的是56K拨号上网，网速千差万别，而且又有很多人心怀不轨，存心作恶，因此区块链分叉几乎时时刻刻都在发生。此时，比特币世界的最高原则就起作用了：可是就上面两种分叉的情况来看，此时分叉的两个区块链一样长啊？没关系，这两条都合法，也都不合法，咱们搁置争议，继续开挖，看谁挖得快，谁先再蒙对新的X，让自己的区块链再进一步，谁的区块链就变成最长，也就成了唯一合法的了。这么一听，怎么感觉这个区块链系统这么随意，有些不靠谱的样子啊，如果大家都不守规则，随意分叉，世界岂不乱套。别急，接下来咱们通过分析会发现，最终区块链肯定会恢复成稳定的一条。让我们回到第一个情况矿工B和矿工C分歧问题中，假设B的链条再进一步，成为了最长链条，这条链条也就成为比特币世界认定的合法链条。此时C有两个选择，一是放弃努力，乖乖的扔掉自己的区块链，使用B的。另一种选择是不甘心失败，扔坚持自己的区块链，希望自己能很快继续追平B并反超。选择前者是大家都开心的，比特币世界的区块链从此统一，选择后者实际上继续让区块链保持分叉状态。那么从理性角度，C应该如何做呢？实际上C此时应该果断放弃自己的链条。我们可以分析一下，当B和C的链条分叉时，此时比特币世界存在4种矿工、两种势力，B和拥护B的吃瓜矿工，C和拥护C的吃瓜矿工。此时B势力与C势力大体相当，所以大家各挖各的。当B势力先一步延长了B的链条后，此时C势力就会发生分化，绝大部分拥护C的吃瓜群众只要听到B链条延长的消息，马上会转投到B链条上，因为此时B链条更长，在更长的链条上继续挖矿显然更有前途。势力马上发生逆转，C会尴尬地发现，全世界都在与他为敌（哭）。所以C不得不放弃。当然，假设是C的势力先延长了区块链，那么情形正好相反，全世界的矿工都会马上投入C的怀抱。尽管可能确实是B先挖到的矿，但此时B也不得不选择放弃自己的那条已经无人问津的区块链。按照这种理性的假设，全世界大部分矿工都会安分守己的选择在最长的链条上工作，所以偶尔的分叉也不是什么大不了的事。当然仍存在一种极端情况，即B或C一个人的算力超过全世界算力的50%，这时候他们凭借一己之力就有可能反超。但是事实上，由于全世界都在参与，很难有人或组织有这么强的算力，其次即使C有这么强的算力，他老老实实地在最长链条上挖矿就好了，也没必要硬刚全世界，非要显示霸权只会让全世界都不陪他玩了，最后比特币失去价值，C损失更大。上面所说的第二种分叉情况的解决办法与第一种情况同理，坚持“唯一合法的区块链是当前最长的区块链”原则不动摇，最终合法的一条区块链只会记录B与C交易或B与D交易的其中一个，具体原因读者可以自己想一想。 讲了这么多，大家可以发现，比特币凭借区块链的巧妙设计，使得交易与发行以一种非常稳定的状态进行，而保持稳定的核心力量是什么呢？就是无数矿工提供的算力。只要矿工够多，算力够大，验证速度够快，比特币的交易就可以快速地被验证，不小心出现的区块链分叉状态可以很快结束，保证整个系统稳定运行。所以挖矿可不光只是费电，这些电能实际上转化成为维持整个系统稳定的能量！这也告诉我们为什么比特币可以一个币价值数万，而有些新发行的各种币一文不值，因为比特币做为历史最长、受众最广的电子货币，也拥有数量最多、分布最广泛的矿工和算力，是最稳定的电子货币。而新发行的货币矿工数量很少，参与的算力低，根本起不到稳定整个系统的作用，算力低也意味着每笔交易的验证时间会变长，从而降低货币的可用性，所以这样的新兴货币一文不值。好了，关于比特币以及比特币系统所用到的区块链技术就介绍到这里，如有大牛对文中内容有异议，欢迎拍砖探讨！ Satoshi《Bitcoin: A Peer-to-Peer Electronic Cash System》 ChenJunXuan / CC，17 年硕士毕业于上海交大，目前在阿里达摩院做计算机视觉方向/智能医学影像相关的算法开发，喜欢 Python。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    ", "img": ["http://wx3.sinaimg.cn/mw690/7cc829d3gy1fq7lkjvcdmj20sd0g445z.jpg"]}
{"title": "在 Git 中怎样克隆、修改、添加和删除文件？ - 文章 - 伯乐在线", "tag": ["IT技术", "Git", "Linux"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n在  开始使用 Git 时，我们创建了一个简单的 Git 仓库，并用我们的计算机连接到它，向其中添加一个文件。在本文中，我们将学习一些关于 Git 的其他内容，即如何克隆（下载）、修改、添加和删除 Git 仓库中的文件。假设你在 GitHub 上已经有一个 Git 仓库，并且想从它那里获取你的文件——也许你在你的计算机上丢失了本地副本，或者你正在另一台计算机上工作，但是想访问仓库中的文件，你该怎么办？从 GitHub 下载你的文件？没错！在 Git 术语中我们称之为“克隆clone”。（你也可以将仓库作为 ZIP 文件下载，但我们将在本文中探讨克隆方式。）让我们克隆在上一篇文章中创建的名为 Demo 的仓库。（如果你还没有创建 Demo 仓库，请跳回到并在继续之前执行那些步骤）要克隆文件，只需打开浏览器并导航到  (其中 <your_username>  是你仓库的名称。例如，我的仓库是 )。一旦你导航到该 URL，点击“克隆或下载Clone or download”按钮，你的浏览器看起来应该是这样的：正如你在上面看到的，“使用 HTTPS 克隆Clone with HTTPS”选项已打开。从该下拉框中复制你的仓库地址（），打开终端并输入以下命令将 GitHub 仓库克隆到你的计算机：然后，要查看  目录中的文件列表，请输入以下命令：终端看起来应该是这样的：现在我们已经克隆了仓库，让我们修改文件并在 GitHub 上更新它们。首先，逐个输入下面的命令，将目录更改为 ，检查  中的内容，添加新的（附加的）内容到 ，然后使用  检查状态:如果你逐一运行这些命令，终端看起开将会是这样：让我们看一下  的输出，并了解它的意思。不要担心这样的语句：因为我们还没有学习这些。（LCTT 译注：学了你就知道了）下一行说：（变化未筹划提交）；这是告诉你，它下面列出的文件没有被标记准备（“筹划stage”）提交。如果你运行 ，Git 会把这些文件标记为 （准备提交）；换句话说就是 （变化筹划提交）。在我们这样做之前，让我们用  命令来检查我们添加了什么到 Git 中，然后运行 。这里是终端输出：我们来分析一下： 是 Git 比较的内容（在这个例子中是 ）。 会显示从文件中删除的任何东西。 会显示从文件中添加的任何东西。任何添加到文件中的内容都以绿色文本打印，并在该行的开头加上  号。如果我们删除了任何内容，它将以红色文本打印，并在该行的开头加上  号。现在  显示 （变化将被提交），并列出文件名（即 ）以及该文件发生了什么（即它已经被  并准备提交）。提示：如果你已经运行了 ，现在你想看看文件有什么不同，通常  不会输出任何东西，因为你已经添加了文件。相反，你必须使用 。它会告诉你 Git 添加的当前版本和以前版本文件之间的差别。你的终端输出看起来会是这样：我们用一些新内容修改了  文件，现在是时候将它上传到 GitHub。让我们提交更改并将其推送到 GitHub。运行：这告诉 Git 你正在“提交”已经“添加”的更改，你可能还记得，从本系列的第一部分中，添加一条消息来解释你在提交中所做的操作是非常重要的，以便你在稍后回顾 Git 日志时了解当时的目的。（我们将在下一篇文章中更多地关注这个话题。） 是这个提交的消息——如果你认为这没有合理解释你所做的事情，那么请根据需要写下你的提交消息。运行 ，这会提示你输入用户名和密码，然后将文件上传到你的 GitHub 仓库。刷新你的 GitHub 页面，你应该会看到刚刚对  所做的更改。终端的右下角显示我提交了更改，检查了 Git 状态，并将更改推送到了 GitHub。 显示：第一行表示在本地仓库中有一个提交，但不在  中（即在 GitHub 上）。下一行指示我们将这些更改推送到  中，这就是我们所做的。（在本例中，请参阅本系列的第一篇文章，以唤醒你对  含义的记忆。我将在下一篇文章中讨论分支的时候，解释  的含义。）现在我们修改了一个文件并在 GitHub 上更新了它，让我们创建一个新文件，将它添加到 Git，然后将其上传到 GitHub。 运行：这将会创建一个名为  的新文件。如果使用  查看它：你将看到文件的内容。现在继续运行：Git 报告说你的仓库中有一个未跟踪的文件（名为 ）。这是 Git 告诉你说在你的计算机中的仓库目录下有一个新文件，然而你并没有告诉 Git，Git 也没有跟踪你所做的任何修改。我们需要告诉 Git 跟踪这个文件，以便我们可以提交并上传文件到我们的仓库。以下是执行该操作的命令：终端输出如下： 告诉你有  被修改，对于 Git 来说它是一个 ，Git 在此之前并不知道。现在我们已经为 Git 添加了 ，我们可以提交更改并将其推送到 。Git 现在已经将这个新文件上传到 GitHub；如果刷新 GitHub 页面，则应该在 GitHub 上的仓库中看到新文件 。通过这些步骤，你可以创建尽可能多的文件，将它们添加到 Git 中，然后提交并将它们推送到 GitHub。如果我们发现我们犯了一个错误，并且需要从我们的仓库中删除 ，该怎么办？一种方法是使用以下命令从本地副本中删除文件：如果你现在做 ，Git 就会说有一个文件 （未筹划提交），并且它已经从仓库的本地拷贝中删除了。如果我们现在运行：我知道我们正在删除这个文件，但是我们仍然运行 ，因为我们需要告诉 Git 我们正在做的， 可以用于我们添加新文件、修改一个已存在文件的内容、或者从仓库中删除文件时。实际上， 将所有更改考虑在内，并将这些筹划提交这些更改。如果有疑问，请仔细查看下面终端屏幕截图中每个命令的输出。Git 会告诉我们已删除的文件正在进行提交。只要你提交此更改并将其推送到 GitHub，该文件也将从 GitHub 的仓库中删除。运行以下命令：现在你的终端看起来像这样：你的 GitHub 看起来像这样：现在你知道如何从你的仓库克隆、添加、修改和删除 Git 文件。本系列的下一篇文章将检查 Git 分支。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/06/a9f8e32251fe9ed8030a42ac78ef2343.jpg"]}
{"title": "从 Linux 源码看 socket 的阻塞和非阻塞 - 文章 - 伯乐在线", "tag": ["IT技术", "socket", "阻塞", "非阻塞"], "goodNum": "1", "saveNum": " 5 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n笔者一直觉得如果能知道从应用到框架再到操作系统的每一处代码，是一件Exciting的事情。大部分高性能网络框架采用的是非阻塞模式。笔者这次就从linux源码的角度来阐述socket阻塞(block)和非阻塞(non_block)的区别。 本文源码均来自采用Linux-2.6.24内核版本。一个TCP非阻塞client端简单的例子如果我们要产生一个非阻塞的socket,在C语言中如下代码所示:由于网络协议非常复杂，内核里面用到了大量的面向对象的技巧，所以我们从创建连接开始，一步一步追述到最后代码的调用点。很明显，内核的第一步应该是通过AF_INET、SOCK_STREAM以及最后一个参数0定位到需要创建一个TCP的socket,如下图绿线所示:我们跟踪源码调用进一步分析__sock_create的代码判断:  *pf;   pf = rcu_dereference(net_families[family]); err = pf->create(net, sock, protocol);则通过源码可知，由于是AF_INET(PF_INET),所以net_families[PF_INET].create=inet_create(以后我们都用PF_INET表示)，即\npf->create = inet_create; 进一步追溯调用:上面的代码就是在INET中寻找SOCK_STREAM的过程了 我们再看一下inetsw[SOCK_STREAM]的具体配置:这边也用了重载，AF_INET有TCP、UDP以及Raw三种:从上述代码，我们可以清楚的发现sock->ops=&inet_stream_ops;即sock->ops->recvmsg = sock_common_recvmsg;\n同时sock->sk->sk_prot = tcp_prot;我们再看下tcp_prot中的各个函数重载的定义:fcntl控制socket的阻塞\\非阻塞状态我们用fcntl修改socket的阻塞\\非阻塞状态。 事实上: fcntl的作用就是将O_NONBLOCK标志位存储在sock_fd对应的filp结构的f_lags里,如下图所示。追踪setfl代码:上图中，由sock_fd在task_struct(进程结构体)->files_struct->fd_array中找到对应的socket的file描述符，再修改file->flags在调用socket.recv的时候我们跟踪源码调用:由上文可知: sock->ops->recvmsg = sock_common_recvmsg;值得注意的是,在sock_recmsg中,有对标识O_NONBLOCK的处理上述代码中sock关联的file中获取其f_flags,如果flags有O_NONBLOCK标识，那么就设置msg_flags为MSG_DONTWAIT(不等待)。\nfcntl与socket就是通过其共同操作File结构关联起来的。sock_common_recvmsg由上文可知: sk->sk_prot->recvmsg 其中sk_prot=tcp_prot,即最终调用的是tcp_prot->tcp_recvmsg,\n上面的代码可以看出，如果fcntl(O_NONBLOCK)=>MSG_DONTWAIT置位=>(flags & MSG_DONTWAIT)>0, 再结合tcp_recvmsg的函数签名,即如果设置了O_NONBLOCK的话，设置给tcp_recvmsg的nonblock参数>0,关系如下图所示:首先我们看下tcp_recvmsg的函数签名:显然我们关注焦点在(int nonblock这个参数上):上面的逻辑归结起来就是：\n(1)在设置了nonblock的时候，如果copied>0,则返回读了多少字节,如果copied=0，则返回-EAGAIN,提示应用重复调用。\n(2)如果没有设置nonblock，如果读取的数据>=期望，则返回读取了多少字节。如果没有则用sk_wait_data将当前进程等待。\n如下流程图所示:sk_wait_data代码-函数为:该函数调用schedule_timeout进入睡眠，其进一步调用了schedule函数，首先从运行队列删除，其次加入到等待队列，最后调用和体系结构相关的switch_to宏来完成进程间的切换。\n如下图所示:首先我们看下网络分组到来的内核路径，网卡发起中断后调用netif_rx将事件挂入CPU的等待队列，并唤起软中断(soft_irq)，再通过linux的软中断机制调用net_rx_action，如下图所示:注:上图来自PLKA(<<深入Linux内核架构>>)\n紧接着跟踪next_rx_action紧接着tcp_v4_rcv:在这里__wake_up_common将停在当前wait_queue_head_t中的进程唤醒，即状态改为task_running，等待CFS调度以进行下一步的动作,如下图所示。在前面调用sk_wait_event中调用了schedule_timeoutprocess_timeout函数即是将此进程重新唤醒总结linux内核源代码博大精深，阅读其代码很费周折。希望笔者这篇文章能帮助到阅读linux网络协议栈代码的人。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://wx2.sinaimg.cn/mw690/63918611gy1fq9n10wguaj20vi0katb1.jpg"]}
{"title": "命令行乐趣：嘲讽输错 Bash 命令的用户 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n你可以通过配置  命令去嘲讽输入错误密码的用户。但是现在，当用户在 shell 输错命令时，也能嘲讽他了（滥用？）。来自 Github 页面：当用户键入错误命令，随机嘲讽。它使用了一个 bash4.x. 版本的全新内置错误处理函数，叫 。键入下列 git 命令克隆一个仓库：示例输出：用文本编辑器，比如说使用 ，编辑你的  或者  文件：在其后追加这一行（具体了解请查看  和 ）：保存并关闭文件。重新登录，如果不想退出账号也可以手动运行它：尝试键入一些无效命令：示例输出:你需要编辑 ：示例代码：编辑  文件：追加下面这一行：或者像下面尾行增加一句嘲讽语：这是我的文件：试一试：样例对话： 游戏。当你错误的把  输入成 ，将会有一辆蒸汽机车穿过你的屏幕。[1]: https://bash.cyberciti.biz/guide/If..else..fi\n[2]: https://bash.cyberciti.biz/guide/Source_command\n[3]: https://www.cyberciti.biz/media/new/cms/2017/11/bash-insulter-Insults-the-user-when-typing-wrong-command.jpg\n[4]: https://www.cyberciti.biz/media/new/cms/2017/11/sudo-insults.jpg\n[5]: https://www.cyberciti.biz/tips/displays-animations-when-accidentally-you-type-sl-instead-of-ls.html\n[6]: https://www.cyberciti.biz/tips/displays-animations-when-accidentally-you-type-sl-instead-of-ls.html\n[7]: https://www.cyberciti.biz\n[8]: https://github.com/CYLeft\n[9]: https://github.com/wxy\n[10]: https://github.com/LCTT/TranslateProject\n[11]: https://linux.cn/article-9497-1.html?pr\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["https://dn-linuxcn.qbox.me/data/attachment/album/201803/30/102653o0g177wl8dug2kw2.jpg"]}
{"title": "在 Linux 中自动配置 IPv6 地址 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "IPv6", "Linux"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n在  一文中，我们学习了关于唯一本地地址unique local addresses（ULA）的相关内容。在本文中，我们将学习如何为 ULA 自动配置 IP 地址。唯一本地地址unique local addresses（ULA）使用  地址块，它类似于我们常用的 IPv4 的私有地址：、、以及 。但它们并不能直接替换。IPv4 的私有地址分类和网络地址转换（NAT）功能是为了缓解 IPv4 地址短缺的问题，这是个明智的解决方案，它延缓了本该被替换的 IPv4 的生命周期。IPv6 也支持 NAT，但是我想不出使用它的理由。IPv6 的地址数量远远大于 IPv4；它是不一样的，因此需要做不一样的事情。那么，ULA 存在的意义是什么呢？尤其是在我们已经有了本地链路地址link-local addresses（）时，到底需不需要我们去配置它们呢？它们之间（LCTT 译注：指的是唯一本地地址和本地链路地址）有两个重要的区别。一是，本地链路地址是不可路由的，因此，你不能跨子网使用它。二是，ULA 是你自己管理的；你可以自己选择它用于子网的地址范围，并且它们是可路由的。使用 ULA 的另一个好处是，如果你只是在局域网中“混日子”的话，你不需要为它们分配全局单播 IPv6 地址。当然了，如果你的 ISP 已经为你分配了 IPv6 的全局单播地址global unicast addresses，就不需要使用 ULA 了。你也可以在同一个网络中混合使用全局单播地址和 ULA，但是，我想不出这样使用的一个好理由，并且要一定确保你不使用网络地址转换（NAT）以使 ULA 可公共访问。在我看来，这是很愚蠢的行为。ULA 是仅为私有网络使用的，并且应该阻止其流出你的网络，不允许进入因特网。这很简单，在你的边界设备上只要阻止整个  范围的 IPv6 地址即可实现。ULA 不像本地链路地址那样自动配置的，但是使用 radvd 设置自动配置是非常容易的，radva 是路由器公告守护程序。在你开始之前，运行  或者  去查看你现有的 IP 地址。在生产系统上使用时，你应该将 radvd 安装在一台单独的路由器上，如果只是测试使用，你可以将它安装在你的网络中的任意 Linux PC 上。在我的小型 KVM 测试实验室中，我使用  命令把它安装在 Ubuntu 上。安装完成之后，我先不启动它，因为它还没有配置文件：这些所有的消息有点让人困惑，实际上 radvd 并没有运行，你可以使用经典命令  来验证这一点。因此，我们现在需要去创建  文件。拷贝这个示例，将第一行的网络接口名替换成你自己的接口名字：前缀（）定义了你的网络地址，它是地址的前 64 位。前两个字符必须是 ，前缀接下来的剩余部分你自己定义它，最后的 64 位留空，因为 radvd 将去分配最后的 64 位。前缀后面的 16 位用来定义子网，剩余的地址定义为主机地址。你的子网必须总是 。RFC 4193 要求地址必须随机生成；查看  学习创建和管理 ULAs 的更多知识。IPv6 转发必须要启用。下面的命令去启用它，重启后生效：取消注释或者添加如下的行到  文件中，以使它永久生效：启动 radvd 守护程序：这个示例在我的 Ubuntu 测试系统中遇到了一个怪事；radvd 总是停止，我查看它的状态却没有任何问题，做任何改变之后都需要重新启动 radvd。启动成功后没有任何输出，并且失败也是如此，因此，需要运行  去查看它的运行状态。如果有错误， 会告诉你。一般常见的错误都是  中的语法错误。在 Twitter 上抱怨了上述问题之后，我学到了一件很酷的技巧：当你运行  去调试  错误时，你的输出会被换行，然后，你就可以看到错误信息。现在检查你的主机，查看它们自动分配的新地址：本文到此为止，下周继续学习如何为 ULA 管理 DNS，这样你就可以使用一个合适的主机名来代替这些长长的 IPv6 地址。通过来自 Linux 基金会和 edX 的  免费课程学习更多 Linux 的知识。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "JAVA 程序员需要用到 10 个测试框架和库 - 文章 - 伯乐在线", "tag": ["工具与资源", "Groovy", "java", "JUnit"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n想要提高你的自动化测试技术？以下是 10 个优秀的测试框架和库，以及它们常见用法的概述。最近我写了一些文章，关于 Java 程序员今年应该学习什么，例如编程语言，库和框架等，如果只能学习或提高其中一项，那必然是自动化测试技能。测试是专业程序员区别于业余程序员的一项指标，作为专业程序员，并非必须采用 TDD，BDD 或其它测试方法论，但最低标准是通过编写代码的方式，来自动化测试自己的代码。许多 Java 程序员编写单元测试和集成测试，使用 Jenkins、TeamCity 等持续集成工具，在构建阶段自动运行。如果还有人对程序员是否应该关注自动化测试存有疑问，那么让我来回答，随着 DevOps 理念的增强和角色的涌现，自动化测试的重要性正在呈指数型增长。企业通常青睐那种擅长编写单元测试的程序员，这些程序员对各种单元测试框架、库和工具有着丰富的知识，比如 JUnit，Selenium，REST-Assured，Spock 框架等。作为 Java 程序员，我们在截然不同的领域工作，从编写 Java 核心代码到 JSP 页面，REST API，甚至有时为了构建自动化而去编写 Groovy 脚本，这就要求我们必需了解不同的自动化测试工具。举一个例子，很长一段时间内，我只了解 JUnit，但当不得不测试 JSP 页面时，我却束手无策，直到我找到了 Selenium。REST Assured 是另一个类似的例子，我通常使用 curl 命令测试 REST API，但 REST Assured 将 REST API 的单元测试水平提升到了另一个层次。Java 程序员需要用到十大单元测试和自动化集成测试工具我认为一个优秀的程序员，必然能够很好地利用手头上的工具，因此我总在业余时间学习和探索新的工具和库，以下列表是我部分研究成果。在这篇文章中，我将分享 10 个最为优秀且必不可少的工具，框架和库，这些可以帮助 java 程序员在各类 java 项目中编写单元测试和集成测试。JUnit 无须赘述，即便是初级Java程序员，可能也已经听说过它，你可以使用它编写 Java 代码的单元测试。几乎所有主流 IDE，例如 Eclipse，NetBeans 和 IntelliJ，都集成了 JUnit，可以直接在这些IDE中编写和运行单元测试。大多数人仍在使用 JUnit 4，即使 JUnit 5 已经发布，它很可能是今年下一个热点。通过 JUnit 5，可以将 JUnit 同时应用于单元测试和集成测试，并且它还支持 Java 8 的特性。用 Java 语言测试和验证 REST 服务，要难于 Groovy 这类动态语言。REST Assured 将这类语言的易用性带入了 Java 领域，是一个优秀的 REST API 的集成测试工具。Selenium 很可能是最流行的 Java UI 测试工具了，它可以让你在不必启动浏览器的情况下测试 JSP 页面。你可以使用 JUnit 和 Selenium 来测试 Web 程序的界面，它甚至允许你编写 Web 应用程序的验收测试。TestNG 是一个测试框架，其灵感来自 JUnit 和 NUnit，但同时引入了一些新的功能，使其功能更强大，使用更方便。例如可以使用注解，在任意大的线程池中，配置各种可用策略进行测试（例如所有方法都在自己的线程中，每一个测试类使用一个线程等）。因为 TestNG 使用 JUnit 4 的注解，同时又集成了 HAMCSTREST 匹配器，它与 JUnit 的差异已经减小了，但两者如何选择，这取决于你。Java 类有许多 Mock 框架，例如 PowerMock 和 JMock，但我个人偏向于 ，因为它有简单的 API，优秀的文档以及大量的示例。Mocking 是现代单元测试的一项关键技术，因为它允许你在没有任何依赖的情况下独立测试代码，这就是为什么我鼓励每个 Java 程序员在学习 JUnit 的同时，一起学习 Mocking 框架的原因。我最喜欢的 mocking 框架是 Mockito，但如果你愿意，也可以研究下 PowerMock 或 JMock。Spock 是另一个测试和规范框架，用于 Java 和 Groovy 应用程序。由于使用 Groovy 编写，Spock 成为一种兼具丰富表现力且简明扼要的规范语言。当你使用 Spock 时，你的测试将变得更容易阅读和维护，这得益于它采用的 JUnit 运行器，Spock 兼容大部分 IDE，构建工具和持续集成服务器。可惜我没有找到有助于学习 Spock 框架的课程，但阅读《》这本书是很好的开始。Cucumber 是另一个重要的自动化集成测试工具，但与其它同类别的工具不同的是它能够针对规格文档进行自动化测试。Cucumber 将规格文档和测试文档合成整个动态文档，同时 Cucumber 自动测试这个文档，使测试规范始终保持在最新版本。Spring MVC 自带一个很有用的测试框架，它可以在不引入 Web 容器的情况下进行深入测试。Spring Test 是为 Spring 程序编写自动化测试的最有用的库之一。为了给 Spring 驱动的应用程序（包括 MVC 控制器在内），编写单元测试和集成测试，Spring Test 提供了一流的支持。另外，Spring Test DbUnit 集成了 Spring Test 框架与 DbUnit；Spring Test MVC HtmlUnit 集成了Spring Test MVC 框架和 HtmlUnit。通过使用这些工具，你可以轻松地自动测试 Spring MVC 应用程序。数据库是许多 Java 应用程序，包括核心 Java 和 Web 应用程序中不可或缺的部分，也有可能是单元测试的最大障碍。在进行集成测试时，连接开发环境或用户验收测试的数据库并不可靠，因为任何人都可以更改数据模式和数据本身，例如表和存储过程等，这会导致自动化集成测试失败。DbUnit 是一个 JUnit 扩展，每次集成测试前，将数据库初始化成已知状态，确保数据库存储正确的数据。DbUnit 自身还存在着一些问题，但它是一个非常有用的工具，因为它可以帮助我们分离测试数据与测试代码。Robot 框架是一个基于 Python 的通用测试自动化框架，用于验收测试和验收测试驱动开发。它是一个由关键字驱动的，使用表格测试数据语法的测试框架，可以用来测试那些涉及多种技术和接口的分布式异构应用。如果你打算学习这个优秀的集成测试框架，那么你可以从 Udemy 上的《》的课程开始，这是一个很好的学习资源。该课程涵盖了两部分内容，Robot 框架基础和高级特性。以上列举了Java 程序员需要用到的单元测试和集成测试工具，框架和库。还有很多库没有包括在这个列表中，例如 AssertJ 和 Hamcrest，它们可以帮助你写出漂亮且流畅的测试，但学习需要一步步来。首先，学习一个可以应用于日常工作的工具或库。 例如，如果你正在使用 Java UI，那么首先应该学习 Selenium，这样你可以有更多时间专注在这个工具上。同样的，如果你的工作内容是 REST API，请学习 REST Assured（参阅 ）；如果你正在做很多核心 Java 的工作，那么 JUnit 5 可能是你首先需要关注的库。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2015/11/58175e1df62779046a3a4e2483575937.jpg"]}
{"title": "工程师思维，做不出好产品？ - 文章 - 伯乐在线", "tag": ["职场", " 2 评论 ", "工程师"], "goodNum": "1", "saveNum": "  收藏", "sayNum": " 2 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n这不是一个鸡汤文，也不是警世文，这文章没什么结论和重点，你不会从这篇文章中获得什么领悟。恭喜你，你选择继续往下看，代表你对这标题也有一定程度的好奇，或许你也有同样的疑惑？「你的想法太工程师了，不适用在「一般」用户上，怎么可能用一般用户的角度去思考产品呢？」会这样说可能是你就是从事市场或和技术半毛关系都没有的岗位上。我觉得这个指控实在很莫名其妙，农夫讲出关于种树的话，渔夫讲出关于捞鱼的话，本该是天经地义的事，然后现在我们要进森林开垦，凭什么渔夫说的就是道理，农夫说的就是歪理呢。况且重点还是，最后要操刀的是农夫啊！世间上的事，都不是完全都是两极化的对与错，一件事通常面向都会超过一个，就取决于那是站在那一面观看，我要说的正是，软件工程师如何设计好产品。马云说过一句差不多这样的话，他说：他就是 QA，他不会用的产品，大概就不是什么好产品，因为大部分人都和他一样，是一个不懂技术的人。就单凭这句话，很多人就会抛开技术思维，抛开一切，就只想自己要做的「大方向」就好，那是当然的，做为一个领导，作为一艘船的导航，确实需要一个明确的方向，大家就尽力前进。但前进的动力来自哪里呢？你可以知道人家背后有多少水手不断研究划船的方法，才可以说出这句那么铿锵有力的话。「我考第一名，我从来不念书！」马云那番话字面上理解，那个思维是成立的，但事实上，越是简单的产品，RD 就必须花更多的时间和精力去思考，如果做出「简单」而产品的「直觉和简单」仅仅只是技术演进的结果罢了，千万不要忽略过程。我只想要飞，就往断崖跳，就肯定会死的。想要飞的心情我理解，但我们能不能坐下来谈谈如何办到「飞」这回事呢？而越简单的东西，越难做出来。有一个箱子，里面很冷，食物不会坏；一个箱子，里面有画面，哎！箱子好占空间，做到跟墙一样薄行不行？我想要一个放在口袋的电脑，看到的脸就开锁，啊，要确保一定会开喔，不要让我 demo 的时候开不了。概念谁都会说，根本不需要花很多时间在这个地方上。一个好产品，重点是要解决问题，是不是废话？是。那么要解决问题，要靠技术？还是靠想法？…你开始质疑自己了吧，你没有马上选技术，或者你选了想法？因为一般人是不会有这个认知的。你不用怀疑，好产品解决问题的重点，就是技术。不是想法。这两者有什么区别？会讲不会做，就叫做想法；会讲也会做，那是技术。但产品人员最爱放在嘴巴的一句话就是「技术不难，可以做得出来」、「技术可以办到」大部分的概念都是来自于别家产品，至于如何实现，还是一种跟网恋一样的概念，还没见过本人，但是照片看起来还不错。时至今日要找出，只要好点子，就有好活路的故事太少了，技术突破不了，就是一个「和别人差不多」的东西。既然是差不多，就没有必要多一个，面对消费者，你要怎么说服人家用你家的产品呢？我写了一大堆都是在靠北，没什么重点，那我先讲一个重点。「讲 HOW 不要讲 WHAT 和 WHY」一个组织要做什么事，应该不难决定，那就是一个决定。试想想，最近我有个朋友在想开餐厅的事，我就默默的观察，他会如何思考开餐厅的流程。他从菜单一路讲到店面，从行销和定位，说到 SWOT 和五力分析。都还没说到，如何做饭这个点上。虽然只是比喻，但是你可以想像餐厅本身最关键的除了价格，就是味道，好吃！最直接的竞争力，就是要「HOW 做到很好吃」一个点就好。而 HOW 的精髓，就是技术（技巧），做菜需要技巧；写程序也需要技巧，如何用什么工具解决什么问题（这是重点，我只是没有特别强调）是很重要的一个概念。就跟为什么这个控肉饭那么好吃，它是怎么办到的？！靠，那就是靠技术啊，每天做研究啊，研究又试做啊，然后失败又再来啊，不然你以为咧。至于说，技术本身是没有意义的，除非它用来解决问题。那就是一个重点了，要讲出问题在哪里（WHAT），和为什么会发生（WHY），即便这些很有可能都是在猜的，要讲出几个点那也不是一件难的差事，只差你愿不愿意面对而已，因为就算你说错了，也没有什么证据证明你是错的，你顶多只能怀疑，这个家伙在胡说。技术本身是没有意义的，就让我想起一个名人说的话，钱本身是没有意义的，除非你利用它！说到我帐户有几万千还没开始「利用」一样。那个重点不是这句话，重点是我没有钱啊！技术本身有没有价值，我不好说，但重点是，我们要先研究出技术啊！而很多时候，我们只需要一个菜单，就那么简单。但是可怕的事还不是没有菜单，而是有菜单还有一叠厚厚的明细，随着不懂做菜的人进厨房，然后还帮你为每个做菜步骤列名时间和顺序，然后当你仔细一看，那个根本不是做菜步骤，是上菜和吃饭的步骤，里面写的跟做菜一点屁关系都没有。这群人根本不在乎怎么做菜啊。但不要误会，半点也没有怪他们「为何不关心」做菜这事上。因为很多时候，甚至极大部分时候，工程师也是不关心如何「上菜」的，也不关心味道如何，只要时间内上菜，老板没有埋怨，客户没有中毒死，更也别说口碑好不好，有的厨师本来就是抱着能吃就好的心情做菜，竟然吃不死，就是好料理啦。但这主题是说「好产品」就不是能吃就好的东西了，要对味道和整个用餐过程都很有要求。就算不是五星，也要老板亲切啊，服务态度 UX 要好，UX 不是一个人的工作，UX 是一个团队的工作，一个集体带来的效益。大部分团队就是设计出图，PM 画 flow，RD 写 code；就跟打传说有人坦克，有人输出，有人牵制，但如果要胜出，就可能互相帮打，坦克输出会补刀，输出火力也要帮忙牵制，但是如果规定了坦克就只能挨打，牵制就只能在那边躲起来发功，那就死定了。分工的结果就如参加一个比赛，的确是顺利的把比赛结束了，但也别想说有什么惊喜的表现。写程序的人就会用工具了，尤其是前端，现在光是设一个开发环境，就用了一堆东西，有些太久没有用它还更新改版了，有天有个朋友请我帮忙做个事，我就拿着笔电狂 Key，滴滴答答的，一个多小时之后，我就「yeah」喊了一声，他就问「你弄好咯，感谢啦」我说「还没，但可以开始弄了！yeah」但我以一个消费者的立场，做出产品，至于好不好，是消费者自己的看法。千万不要一直和我说你东西有多好吃，我自己有嘴巴好嘛！如果不好吃，你和我说一百遍也不会好吃啊。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/07/15cdc9eaec6ba9ac858b0eaebfb6b949.jpg"]}
{"title": "Linux 新用户？来试试这 8 款重要的软件 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n即便您不是计算机的新手，刚接触 Linux 时，通常都会面临选择使用应用软件的问题。在数百万 Linux 应用程序中，做起选择来并不轻松。本文中，您将能发现八个重要的 Linux 应用，帮助您快速选择应用程序。下面这些应用程序大多不是 Linux 独有的。如果有过使用 Windows/Mac 的经验，您很可能会熟悉其中一些软件。根据兴趣和需求，下面的程序可能不全符合您的要求，但是在我看来，清单里大多数甚至全部的软件，对于新用户开启 Linux 之旅都是有帮助的。 : 几乎不会不需要使用网页浏览器的用户。您可以看到陈旧的 Linux 发行版几乎都会附带 Firefox（火狐浏览器）或者其他 ，关于浏览器，强烈建议您尝试 。它是谷歌浏览器的开源版。Chromium 的主要优点是速度和安全性。它同样拥有大量的附加组件。 是一个开源办公套件，其包括文字处理（Writer）、电子表格（Calc）、演示（Impress）、数据库（Base）、公式编辑器（Math）、矢量图和流程图（Draw）应用程序。它与 Microsoft Office 文档兼容，如果其基本功能不能满足需求，您可以使用 。LibreOffice 显然是 Linux 应用中至关重要的一员，如果您使用 Linux 的计算机，安装它是有必要的。 是一款非常强大的开源图片处理程序，它类似于 Photoshop。通过 GIMP，您可以编辑或是创建用于 Web 或是打印的光栅图（位图）。如果您对专业的图片处理没有概念，Linux 自然提供有更简单的图像编辑器，GIMP 看上去可能会复杂一点。GIMP 并不单纯提供图片裁剪和大小调整，它更覆盖了图层、滤镜、遮罩、路径和其他一些高级功能。 也许就是最好的影音播放器了。它是跨平台的，所以您可能在 Windows 上也听说过它。VLC 最特殊的地方是其拥有大量解码器（并不是所有的解码器都开放源代码），所以它几乎可以播放所有的影音文件。 完全是关于通讯的。您可以借助它使用 Google talk、Facebook chat、Yahoo、ICQ 和 XMPP。它是用于音视频通话（包括电话会议），桌面流desktop streaming和群组聊天的多用户工具。会话会被加密。Jistsy 同样能帮助您传输文件或记录电话。 是一款基于 Debian 系统发行版的另一款应用程序安装程序。并不是所有基于 Debian 的 Linux 都安装有它，如果您使用基于 Debian 的 Linux 操作系统没有预装，也许您可以试一试。Synaptic 是一款用于添加或移除系统应用的 GUI 工具，甚至相对于许多发行版默认安装的  ，经验丰富的 Linux 用户更亲睐于 Sunaptic。 :  能支持您在计算机上运行虚拟机。当您想在当前 Linux 发行版上安装其他发行版或操作系统时，使用虚拟机会方便许多。您同样可以通过它运行 Windows 应用程序，性能可能会稍弱，但是如果您有一台强大的计算机，就不会那么糟。对于 Linux 的新用户来说，一款纸牌游戏并不是刚需，但是它真的太有趣了。当您进入这款纸牌游戏，您会发现，这是一款极好的纸牌游戏包。 是 Linux 标志性的应用程序，原因是 – 它涵盖超过八十种纸牌游戏，包括流行的 Klondike、Bakers Dozen、Camelot 等等，作为预警 – 它是会上瘾的，您可能会花很长时间沉迷于此！根据您所使用的发行版，这些软件会有不同的安装方法。但是大多数都可以通过您使用的发行版中的包管理器安装使用，甚至它们可能会预装在您的发行版上。安装并且尝试它们想必是最好的，如果不合您的胃口，您可以轻松地删除它们。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "du 及 df 命令的使用（附带示例） - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n在本文中，我将讨论  和  命令。 和  命令都是 Linux 系统的重要工具，来显示 Linux 文件系统的磁盘使用情况。这里我们将通过一些例子来分享这两个命令的用法。（disk usage 的简称）是用于查找文件和目录的磁盘使用情况的命令。 命令在与各种选项一起使用时能以多种格式提供结果。下面是一些例子：该命令的输出将显示  中的所有文件和目录以及显示块大小。它是  目录的总大小df（disk filesystem 的简称）用于显示 Linux 系统的磁盘利用率。（LCTT 译注： 可能应该是 disk free 的简称。）下面是一些例子。上面的命令以人类可读格式显示信息。 加上目标目录将以可读格式显示  的信息。虽然  和  命令有更多选项，但是这些例子可以让你初步了解。如果在这里找不到你要找的东西，那么你可以参考有关命令的 man 页面。另外，阅读我的其他帖子，在那里我分享了一些其他重要和经常使用的 Linux 命令。如往常一样，欢迎你留下评论和疑问，因此在下面留下你的评论和疑问，我会回复你。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/05/77d80105fd15f2465894827e23cc4842.jpeg"]}
{"title": "从业 24 年独立开发者：大多数同行都只看 5 年以内 - 文章 - 伯乐在线", "tag": ["职场", "游戏"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nGameLook报道/有人说，游戏行业的竞争越来越激烈，游戏数量的增加使得曝光率问题日益严重，但在Jeff Vogel看来，真正热爱游戏研发的人，是不会抱怨这些问题的，因为大多数人做开发者都是从1-5年的时间看待自己的游戏研发职业生涯，而真正想要把游戏当作职业的人，往往是考虑40年或者更长的周期。在24年的独立游戏研发生涯中，Spiderweb Software创始人Jeff Vogel学到了很多东西。在3月20日举行的GDC独立游戏峰会上，他分享了一些自己的心得，有些观点让人十分意外。Vogel强调，“游戏行业还是个朝阳产业，没有人无所不知，我们还有很多东西都需要弄明白，比如，如何设计这些游戏，如何创造、测试以及销售这些产品，如何为游戏做营销，如何给1亿美元预算的项目增加开箱子玩法而又不影响发布之后的口碑？”他提到自己的第一个游戏项目时候说，“这个项目并没有耗时太久，我当时有了一个想法，也就是小时候就喜欢的那些游戏，所以我要做的就是把小时候喜欢的游戏都回顾一遍，然后从每个游戏里汲取最好的创意。按照我的方法，我希望把它们变成让我觉得满意的游戏”。Jeff Vogel的第一款游戏截图独立游戏非常适合做创新，但创新并不是唯一的出路。你必须知道，我们游戏行业的每个人都是站在巨人的肩膀上，所有的玩法都是在原有的玩法之上演变而来，我只了解自己喜欢的，然后复制这个想法，这就是我的创意过程，他鼓励其他开发者们用类似的方式，按照自己的个人需求去寻找创意，有人把游戏创意说的很玄，比如追求自己的灵感，这样的建议，但我的建议是千万不要这样做，这是一个非常现实的建议，我来说说原因。大多数人思考自己在游戏行业生涯的时候，往往是从1-5年的角度考虑问题，对于一些刚开始做游戏研发的人们来说，追寻自己的灵感似乎是非常合理的事情。但是，如果你把自己从事独立游戏研发行业的期限延长到40年或者更久的时间考虑，或许会有所帮助。这是一个特别长的时间，如果你在一个行业工作这么久，就会达到最高的工作效率，因为你需要维持生存，需要一个对应的生活方式，一个长久的想法，一个可持续的过程，保持自己不至于破产，因为，如果你因为一些想法而失去了立足之本，在接下来的40年里，它都会让你不断吃亏。当然，Vogel的创意也并不只是抄袭其他游戏的玩法，他对自己游戏的要求也是相对较高的，比如研发续作的时候，前作25%最差的部分需要被替换，提高整体游戏质量。他非常喜欢重复使用资源、代码和引擎，并认为所有人都不应该因此感到羞辱，比如有一个狼的icon，他在15款不同的游戏里使用过，“人们一直拿这个梗开我的玩笑，但我还是没有因此失业”。虽然Spiderweb的游戏有一定的用户群，而且口碑还不错，但这些游戏对于更大的用户群缺乏吸引力，有很大一部分原因是画质无法和3A游戏媲美，但Vogel说，“我非常反感所有人吐槽我的画面质量不够好，我也是投入了资金，专门招聘了美术师的，有些美术资源也是从比较大的渠道获得的，然而还是有人经常说，我的游戏画面很差，我以后再也不会浪费精力去专门提高美术质量了”。对于独立游戏开发者而言，这种批评的声音也是经常遇到的，人性有一部分是刻薄的，会对某些事物提出不合理的需求，而且在Steam这样的分销平台没有出现之前，Vogel做电话销售的时候就遇到过类似的问题。而到了互联网时代，这种问题就更加严重，“通常最愤怒的人不是完全匿名的，他们可能是五年前你的游戏最忠实的粉丝，然后你对游戏做出了改变，而且改掉的恰好是他们最喜欢的东西，他们就不再是你的粉丝，你要知道，有时候爱与恨之间的界限很小”。作为一个想要长期在游戏行业生存的开发者，Vogel表示，远离各种形式的骚扰是很重要的，作为一个成年人，虽然你很少会被人轻易激怒，但仍有很多事情会让你抓狂，所以Vogel基本上不会看自己的游戏在Steam平台的评论，也不访问论坛，如果被人喷，他还会暂时不登陆Twitter，等待事情平息了之后再登录，如果与一些玩家的关系闹僵，他会毫不犹豫的放弃这部分用户。Vogel说，“不要怕得罪用户，他们说客户总是对的，但实际上并非如此，用户一直是错的。但差别在于，你永远吵不赢他们。有时候你不得不对一部分玩家说，‘我的游戏不适合你，所以我不能增加你要的功能、不能做这样的资料片、不能满足你的要求’，对于你无法让他们满意的用户，退款是最好的方法”。《Geneforge 3》截图对于论坛管理，他说，“如果有人在论坛挑事，直接封掉就是了。但如果有人说，‘这些人又不会影响你的生意，不应该封他们’，那你可以连这些人一起封掉，这些消极的负面声音只会给你的社区带来不利影响，真正支持你的玩家会理解你的做法”。和所有的工作室一样，Spiderweb也经历了起伏，Vogel指出，2004年是最艰难的时候，那一年他的两款游戏，《Blades of Avernum》和《Geneforge 3》的销量都不佳。有人说，游戏开发者就像是艺术家，遭遇挫折在所难免，但Vogel认为，作为艺术家，你必须成长，“我们更像是玩具制造者，我们卖的是娱乐体验，我们的作品是用来给人们的大脑带来消遣的，我们卖的是惊喜，而自满、平淡无奇和重复会扼杀惊喜。如果你想做续作，很好，但你的续作最好是加入一些新东西，而且是越早越好，因为，如果玩家们开始发现你的需走只是重复，那么就会以拒绝购买的方式让你看到他们的答案”。最后，Vogel还提醒同行们不要过度消耗自己的健康，“不要因为熬夜工作而感到自豪，你需要睡眠才能活的长久，最好是挑一把好的椅子，因为有一天如果你的脊椎不行了，就会追悔莫及”。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/03/db3f0f9a2c81173f5758eed4074b7543.jpg"]}
{"title": "Linux 中的“大内存页”（hugepage）是个什么？ - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n学习 Linux 中的大内存页hugepage。理解什么是“大内存页”，如何进行配置，如何查看当前状态以及如何禁用它。本文中我们会详细介绍大内存页huge page，让你能够回答：Linux 中的“大内存页”是什么？在 RHEL6、RHEL7、Ubuntu 等 Linux 中，如何启用/禁用“大内存页”？如何查看“大内存页”的当前值？首先让我们从“大内存页”的基础知识开始讲起。“大内存页”有助于 Linux 系统进行虚拟内存管理。顾名思义，除了标准的 4KB 大小的页面外，它们还能帮助管理内存中的巨大的页面。使用“大内存页”，你最大可以定义 1GB 的页面大小。在系统启动期间，你能用“大内存页”为应用程序预留一部分内存。这部分内存，即被“大内存页”占用的这些存储器永远不会被交换出内存。它会一直保留其中，除非你修改了配置。这会极大地提高像 Oracle 数据库这样的需要海量内存的应用程序的性能。在虚拟内存管理中，内核维护一个将虚拟内存地址映射到物理地址的表，对于每个页面操作，内核都需要加载相关的映射。如果你的内存页很小，那么你需要加载的页就会很多，导致内核会加载更多的映射表。而这会降低性能。使用“大内存页”，意味着所需要的页变少了。从而大大减少由内核加载的映射表的数量。这提高了内核级别的性能最终有利于应用程序的性能。简而言之，通过启用“大内存页”，系统具只需要处理较少的页面映射表，从而减少访问/维护它们的开销！运行下面命令来查看当前“大内存页”的详细内容。从上面输出可以看到，每个页的大小为 2MB（），并且系统中目前有  个“大内存页”（）。这里“大内存页”的大小可以从  增加到 。运行下面的脚本可以知道系统当前需要多少个巨大页。该脚本取之于 Oracle。将它以  为名保存到  中，然后运行之：你的输出类似如上结果，只是数字会有一些出入。这意味着，你系统需要 124 个每个 2MB 的“大内存页”！若你设置页面大小为 4MB，则结果就变成了 62。你明白了吧？本文最后一部分内容是配置上面提到的  ，然后重新加载。将下面内容添加到  中，然后输入  命令重新加载配置。注意我们这里多加了两个额外的页，因为我们希望在实际需要的页面数量之外多一些额外的空闲页。现在，内核已经配置好了，但是要让应用能够使用这些“大内存页”还需要提高内存的使用阀值。新的内存阀值应该为 126 个页 x 每个页 2 MB = 252 MB，也就是 258048 KB。你需要编辑  中的如下配置：某些情况下，这些设置是在指定应用的文件中配置的，比如 Oracle DB 就是在  中配置的。这就完成了！你可能还需要重启应用来让应用来使用这些新的巨大页。（LCTT 译注：此外原文有误，“透明大内存页”和“大内存页”不同，而且，在 Redhat 系统中，“大内存页” 不是默认启用的，而“透明大内存页”是启用的。因此这个段落删除了。） \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "用信鸽来解释 HTTPS - 文章 - 伯乐在线", "tag": ["IT技术", "HTTPS"], "goodNum": "1", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n密码学是一门难以理解的学科，因为它充满了数学定理。但是除非你要实际开发出一套加密算法系统，否则你是没必要强制理解那些深奥的数学定理的。如果你阅读本文的目的是想设计下一套 HTTPS 协议，那我只能抱歉的说本文的知识还远远不够；如果不是的话，那么就煮杯咖啡，轻松愉悦的阅读本文吧。你在互联网上从事的任何活动（阅读这篇文章、在亚马逊上购物、上传图片等）归结到底都是从某台服务器上发送和接收信息。这个说起来可能有点抽象，不如让我们假设这些消息都是由信鸽来传递的。我知道这个假设有些太过随意，但相信我 HTTPS 就是这样工作的，尽管它的速度快的多。我们先不谈服务器、客户端或者黑客攻击，先来聊一下爱丽丝、鲍伯和马洛里。如果这已不是你第一次接触密码学理论，你应该会认识这些名字，因为他们经常在各种密码学文献中被提及。如果爱丽丝想要给鲍勃发送一段信息，她会把信息绑在信鸽的腿上然后送往鲍勃那里。鲍勃收到了信息，并阅读了信息，非常完美。但如果马洛里拦截了爱丽丝的鸽子并且篡改了信息呢？鲍勃就没有办法去知道爱丽丝发出的信息在传递过程中遭到了修改。这就是 HTTP 如何运作的。看起来很可怕对吧？我是不会通过 HTTP 来发送我的银行资信证明的，并且你也不应如此。那么如果爱丽丝和鲍勃都非常的机智。他们一致认同使用一种隐蔽的密码来书写他们的信息。他们会将信息中的每个字母按照字母表中的顺序前移三位。比如，D→A，E→B，F→C。如此一来，原文为 “secret message” 的信息就变成了 “pbzobq jbppxdb” 。那现在如果马洛里再截获了信鸽，她既不能做出有意义的修改同时也不会知道信息的内容，因为她不知道隐蔽的密码到底是什么。然而鲍勃却可以很容易反转密码，依靠 A → D, B → E, C → F 之类的规则破译信息的内容。加密后的信息 “pbzobq jbppxdb” 会被破解还原为 “secret message” 。搞定！这就是，因为如果你知道如何加密一段信息那么你同样可以解密这段信息。上述的密码通常被称为凯撒码。在现实生活中，我们会使用更为奇特和复杂的密码，但原理相同。如果除了发信者和收信者之外没有人知道使用的是什么密匙，对称密匙加密是非常安全的。在凯撒加密中，密匙就是每个字母变到加密字母需要移动多少位的偏移量。我之前的距离中，使用的偏移量是 3 ，但是也可以用 4 或者 12 。问题是如果爱丽丝和鲍勃在开始用信鸽传信之前没有碰过头，他们没有一个安全的方式来确立密匙。如果他们自己来在信中传递密匙，马洛里就会截获信息并发现密匙。这就使得马洛里可以在爱丽丝和鲍勃开始加密他们的信息之前或之后，阅读到他们信息的内容并按照她的意愿来篡改信息。这是一个的典型例子，避免这个问题的唯一方法就是收发信的两方一起修改他们的编码系统。所以爱丽丝和鲍勃就想出了一个更好的系统。当鲍勃想要给爱丽丝发送信息时，他会按照如下的步骤来进行：鲍勃向爱丽丝送一只没有携带任何信息的鸽子。爱丽丝给鲍勃送回鸽子，并且这只鸽子带有一个有开着的锁的盒子，爱丽丝保管着锁的钥匙。鲍勃把信放进盒子中，把锁锁上然后把盒子送给爱丽丝。爱丽丝收到盒子，用钥匙打开然后阅读信息。这样马洛里就不能通过截获鸽子来篡改信息了，因为她没有打开盒子的钥匙。当爱丽丝要给鲍勃发送消息的时候同样按照上述的流程。爱丽丝和鲍勃所使用的流程通常被称为。之所以称之为非对称，是因为即使是你把信息编码（锁上盒子）也不能破译信息（打开锁住的盒子）。在术语中，盒子被称为而用来打开盒子的钥匙被称为。如果你稍加注意你就会发现还是存在问题。当鲍勃收到盒子时他如何能确定这个盒子来自爱丽丝而不是马洛里截获了鸽子然后换了一个她有钥匙能打开的盒子呢？爱丽丝决定签名标记一下盒子，这样鲍勃收到盒子的时候就可以检查签名来确定是爱丽丝送出的盒子了。那么你们之中的一些人可能就会想了，鲍勃如何打一开始就能识别出爱丽丝的签名呢？这是个好问题。爱丽丝和鲍勃也确实有这个问题，所以他们决定让泰德代替爱丽丝来标记这个盒子。那么谁是泰德呢？泰德很有名的，是一个值得信任的家伙。他会给任何人签名并且所有人都信任他只会给合法的人签名标记盒子。如果泰德可以确认索要签名的人是爱丽丝，他就会在爱丽丝的盒子上签名。因此马洛里就不可能搞到一个有着泰德代表爱丽丝签了名的盒子，因为鲍勃知道泰德只会给他确认过的人签名，从而识破马洛里的诡计。泰德的角色在术语中被称为。而你阅读此文时所用的浏览器打包存有许多认证机构的签名。所以当你首次接入一个网站的时候你可以信任来自这个站点的盒子因为你信任泰德而泰德会告诉你盒子是合法的。沉重的盒子现在爱丽丝和鲍勃有了一个可靠的系统来进行交流，然他们也意识到让鸽子携带盒子比原本只携带信件要慢一些。因此他们决定只有在选择用对称加密来给信息编码（还记得凯撒加密法吧？）的密匙时，使用传递盒子的方法（非对称加密）。这样就可以二者的优点兼具了，非对称加密的可靠性和对称加密的高效性。现实世界中我们不会用信鸽这样慢的送信手段，但用非对称加密来编码信息仍要慢于使用对称加密技术，所以我们只有在交换编码密匙的时候会使用非对称加密技术。现在你已经了解了HTTPS是如何工作的了，你的咖啡也应该准备好了。好好享用吧你受之无愧。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/04/9b4c9b679332b4ee36faf1fb4002ed2f.png"]}
{"title": "IT 职场新人碰到的几个常见误区 - 文章 - 伯乐在线", "tag": ["职场", " 6 评论 ", "职场"], "goodNum": "2", "saveNum": " 6 收藏", "sayNum": " 6 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n自己工作 10+ 年了，大概 5 年前从技术转管理后，多少还是发现一些职场新人职业发展的问题。表现惊艳的新人肯定有，这种人往往在学校里面或者进入职场后就养成了一些非常良好的做事方式和工作习惯，工作效率高，产出多，甚至很短时间内就可以带新人，年度最佳新人当之无愧。然而表现不到位的似乎更多一些，这些员工工作时间短（比如说应届毕业生或者不到两年）尤其性格内向的往往容易掉入错误泥潭，无法自拔，而这些错误的行为会对未来的发展造成非常负面的影响，从而导致职场发展往失败的道路上越走越远。我分别从以下角度来阐述一下，这种员工大多比较内向或者性情有点高冷，须不知三人行，必有我师。多向同事学习，互通有无，对自己以后的发展有百利而无一害。有导师制或者老员工带，情况或许会有所改善，但如果内因没有改变，最终效果依旧不容乐观。技术开发工作中遇到一些技术难题非常正常，当然独立思考固然可贵，但是公司项目往往有一定的时间限制，优先解决问题永远放在第一位，而不是一个人在那里苦苦挣扎和搜索解决方案。如果时间压力不大，多思考一下也未尝不可。考虑到交付压力，这个时候就需要积极和同事，技术经理沟通，寻找解决思路，通常情况下，积极的沟通好过自己的单打独斗。也许同事或者老板的一句话，就应了那据古诗，山重水复疑无路，柳暗花明又一村。与此同时也和同事建立了更好的友谊，在老板心里也留下了做事有方法的好印象。这种情况其实在职场中多见不仅是初级程序员，甚至工作五年以上的程序员也有类似的问题，不是自己的事情不闻不问，而且危害更大。公司项目往往大而全，如果仅仅专注自己的那个角落，那么永远都是只见树木，不见森林。我相信没有老板会介意下面的程序员多承担一些责任，多做一些事情，最后给项目组多一些产出。既然老板不介意，那么就应该大胆的跳出自己的职责范围，多看看公司的其他项目，丰富自己的行业知识。职责外的事情，帮的上的不要躲避,，努力承担更多的东西。帮助别人就是提高自己，教学相长就是这个意思。况且你这次帮了别人，下次你的项目紧或者遇到技术难题了，受助之人肯定投桃报李，这样就形成了良性互助氛围，整个项目组的产出也同步提升了。一般来说，公司要提升一个人，最好的策略就是先让候选人做一些将来职位才需要做的事情。做的好，理所当然就要提拔。做的不好，则可以提前发现该员工的问题，暂缓提拔，需要多考察一段时间。这样的试错成本毫无疑问是最低的。这里其实谈到了整个IT行业的问题，技术发展太快了。主要还是一个持续提升竞争力的一个话题。今天还是桌面开发，明天web开发就成为主流。好不容易掌握了关系型数据库，No-SQL成为主流。费了九牛二虎之力，熟练掌握Java, C#等静态语言，发现动态语言GO, Python成为云计算，机器学习的标配。移动开发昨天还是Object-C, Java, 今天就变成Swift, Kotlin。 当然这里不是说让大家紧跟潮流，扼住时尚。那样做除了疲于奔命，累死在工作台，没有其他的结果。其实只要选择一个方向，纵深学习和积累，必有所成。比如说，你熟悉 Java, 那么学习 Kotlin 绝对驾轻就熟。你有扎实的关系型数据库基础，那么掌握 MangoDB 肯定是件轻而易举的事情。编成思想和解决问题的思路都是相通的，平时的学习和工作中要善于思考，举一反三。并且做到与时俱进，及时更新自己的知识库和技能属性，保持良好的市场竞争力。做完事情后多思考，怎样做得更好，站在更好的要求上看问题.我举两个实际案例，程序员A在某国企里面，持续开发 Windows Form, 拖拉控件为主，对SQL Server数据库增删改查，时间长达五年之久，突然有一天打算离职，看看新的机会，以为有五年工作经验，可以很轻松找一个更好的工作。但是实际上求职之路异常艰辛，名义上的五年工作经验，其实就是极其单一的技能重复使用了五年。而且大环境也变了，主流已经是web开发，移动开发了。因为没有及时更新自己的知识库和技能储备，那么真要跳槽的时候可能已经跳不动了。程序员B在某外企，氛围比较安逸轻松，项目节奏慢，看似也作了不少项目，但做的项目几乎比较类似，难度一般，涉及面挺广，但技术点都是蜻蜓点水，浅尝辄止。这样过了三年，其实积累也是比较松散，知识的深度没有，核心技能并没有养成。作者本人就犯过类似的错误，幡然醒悟的时候，三年时间已经过去了。程序员的职业生涯里面最初的三年其实是一个非常重要的打磨和规划时期，如果在迷茫中度过，那么事后想起肯定会扼腕叹息，奈何流水已经东去，再无复返之理。有目标，而没有具体的计划，那么就是一个愿景而已。建议不管是初级还是高级程序员，都应该积极向前辈或者直属老板沟通，看看他们有没有值得借鉴的规划和建议。职场大忌就是被动等待命运的安排，作者本人也是在职业生涯初期等待老板来帮我规划未来，到现在为止，十年过去了，也没有等到。。。所以老板不会主动帮助你规划未来，最重要的事情还是自己对自身的要求和期望。 这也是一个非常好的话题，很多人都没有想明白，甚至包括一些工作十年之久的程序员。想明白这一点，工作积极性明显就会好太多。自我驱动, 让工作更加有趣和有意义。国内知名的互联网公司大老板说过一句话，非常值得深思。“我每年付你20万，五年也就是100万。如果你在这里混日子，那么最后吃亏的肯定是你。你的五年青春就只值100万吗？”所以职场新人的主人翁意识一定要加强，你要持续提升自己的能力，持续强化自己创造价值的能力。举个例子，比如说现在公司支付你20万每年，那么你应该有目标能给公司带来远超过20万的收益，多多益善。你有这个能力，公司肯定也会对你相应回报。如果公司不给你升职加薪，那么一走了之，潇洒痛快。优质的人才从来都是抢着要。这点倒是因人而异，不可强求。这个话题其实有点广义。如果你在某个方向做的非常好，而且回报也不错，那么不愿意涉足其他领域也无可厚非。这个世界唯一不变的东西就是世界一直在改变。今天还有的岗位，明天也许就要消失。世界要抛弃你，都不会打一声招呼。举个例子，你在公司是SQL Server或者Oracle专家，但是公司计划转非关系型数据库，如果你害怕改变甚至拒绝改变，那么意味着你可能要错过另外一个全新的数据存储平台。进而错过很多机会，而那些勇于接受变化，顺应趋势的人肯定会获得更好的时代回报。又比如说，你现在用的技术在日常项目中都刚好够用，那么从改善用户体验和使用更加主流的技术角度看，是不是应该要尝试一些新的东西，同时也刷新了自己的技术栈，一举两得，何乐而不为呢？还有一个例子是一位资深程序员习惯了长期的慢节奏的工作氛围，因为公司改组被裁员，不过自身条件不错，很快就加入国内一家一线互联网公司，但是完全适应不了互联网快节奏，工作一段时间就以公司管理”混乱”，战略规划”经常”改变为借口离职了，接下来很长一段时间找不到一个合适自己的工作，加上中年已到，如果自身不积极调整，接下来的工作和生活肯定困难重重。最后再简单小结一下，职场新人需要做的就是从小事做起，学会吃亏，以结果为目标导向，日常工作中积极和同事，老板沟通。工作中要善于总结方法，经常更新问题的思考模式，对职业负责，对目标负责，对自己负责，脚踏实地，主动找事情做，而不是被动等事情来找你。相信职场新人如果能成功避开上面说的几个误区，那么在职业发展道路上就可以少走一些弯路，少犯一些错误，从而更快地实现自己的小目标。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://wx2.sinaimg.cn/large/7cc829d3gy1fptsk9tvx8j20go0b441z.jpg"]}
{"title": "如何在 Linux 上安装应用程序 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "Linux"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n学习在你的 Linux 计算机上摆弄那些软件。如何在 Linux 上安装应用程序？因为有许多操作系统，这个问题不止有一个答案。应用程序可以可以来自许多来源 —— 几乎不可能数的清，并且每个开发团队都可以以他们认为最好的方式提供软件。知道如何安装你所得到的软件是成为操作系统高级用户的一部分。十多年来，Linux 已经在使用软件库来分发软件。在这种情况下，“仓库”是一个托管可安装软件包的公共服务器。Linux 发行版提供了一条命令，以及该命令的图形界面，用于从服务器获取软件并将其安装到你的计算机。这是一个非常简单的概念，它已经成为所有主流手机操作系统的模式，最近，该模式也成为了两大闭源计算机操作系统的“应用商店”。从软件仓库安装是在 Linux 上安装应用程序的主要方法，它应该是你寻找想要安装的任何应用程序的首选地方。从软件仓库安装，通常需要一个命令，如：实际使用的命令取决于你所使用的 Linux 发行版。Fedora 使用 ，OpenSUSE 使用 ，Debian 和 Ubuntu 使用 ，Slackware 使用 ，FreeBSD 使用 ，而基于 lllumos 的 Openlndiana 使用 。无论你使用什么，该命令通常要搜索你想要安装应用程序的正确名称，因为有时候你认为的软件名称不是它官方或独有的名称：一旦你找到要安装的软件包的名称后，使用  子命令执行实际的下载和自动安装：有关从软件仓库安装的具体信息，请参阅你的 Linux 发行版的文档。图形工具通常也是如此。搜索你认为你想要的，然后安装它。与底层命令一样，图形安装程序的名称取决于你正在运行的 Linux 发行版。相关的应用程序通常使用“软件（software）”或“包（package）”等关键字进行标记，因此请在你的启动项或菜单中搜索这些词汇，然后你将找到所需的内容。 由于开源全由用户来选择，所以如果你不喜欢你的发行版提供的图形用户界面（GUI），那么你可以选择安装替代品。 你知道该如何做到这一点。你的 Linux 发行版为其打包的软件提供了标准仓库，通常也有额外的仓库。例如， 服务于 Red Hat Enterprise Linux 和 CentOS， 服务于 Fedora，Ubuntu 有各种级别的支持以及个人包存档（PPA）， 为 OpenSUSE 提供额外的软件以及  为 Slackware 提供社区构建脚本。默认情况下，你的 Linux 操作系统设置为只查看其官方仓库，因此如果你想使用其他软件集合，则必须自己添加额外库。你通常可以像安装软件包一样安装仓库。实际上，当你安装例如  视频聊天， web 浏览器，谷歌浏览器等许多软件时，你的实际安装是访问他们的私有仓库，从中将最新版本的应用程序安装到你的机器上。你还可以通过编辑文本文件将仓库手动添加到你的软件包管理器的配置目录，或者运行命令来添加添加仓库。像往常一样，你使用的确切命令取决于 Linux 发行版本。例如，这是一个  命令，它将一个仓库添加到系统中：仓库模型非常流行，因为它提供了用户（你）和开发人员之间的链接。重要更新发布之后，系统会提示你接受更新，并且你可以从一个集中位置接受所有更新。然而，有时候一个软件包还没有放到仓库中时。这些安装包有几种形式。有时候，开发人员会以通用的 Linux 打包格式分发软件，例如 RPM、DEB 或较新但非常流行的 FlatPak 或 Snap 格式。你不是访问仓库下载的，你只是得到了这个包。例如，视频编辑器  为 APT 用户提供了一个  文件，RPM 用户提供了  文件。当你想要更新时，可以到网站下载最新的适合的文件。这些一次性软件包可以使用从仓库进行安装时所用的一样的工具进行安装。如果双击下载的软件包，图形安装程序将启动并逐步完成安装过程。或者，你可以从终端进行安装。这里的区别在于你从互联网下载的独立包文件不是来自仓库。这是一个“本地”安装，这意味着你的软件安装包不需要下载来安装。大多数软件包管理器都是透明处理的：在某些情况下，你需要采取额外的步骤才能使应用程序运行，因此请仔细阅读有关你正在安装软件的文档。一些开发人员以几种通用格式发布他们的包。常见的扩展名包括  和 。NVIDIA 显卡驱动程序、像 Nuke 和 Mari 这样的 Foundry visual FX 软件包以及来自  的许多非 DRM 游戏都是用这种安装程序。（LCTT 译注：DRM 是数字版权管理。）这种安装模式依赖于开发人员提供安装“向导”。一些安装程序是图形化的，而另一些只是在终端中运行。有两种方式来运行这些类型的安装程序。1、 你可以直接从终端运行安装程序：2、 另外，你可以通过标记其为可执行文件来运行它。要标记为安装程序可执行文件，右键单击它的图标并选择其属性。一旦你允许其运行，双击图标就可以安装了。对于其余的安装程序，只需要按照屏幕上的说明进行操作。AppImage 格式对于 Linux 相对来说比较新，尽管它的概念是基于 NeXT 和 Rox 的。这个想法很简单：运行应用程序所需的一切都应该放在一个目录中，然后该目录被视为一个“应用程序”。要运行该应用程序，只需双击该图标即可运行。不需要也要不应该把应用程序安装在传统意义的地方；它从你在硬盘上的任何地方运行都行。尽管它可以作为独立应用运行，但 AppImage 通常提供一些系统集成。如果你接受此条件，则将一个本地的  文件安装到你的主目录。 文件是 Linux 桌面的应用程序菜单和 mimetype 系统使用的一个小配置文件。实质上，只是将桌面配置文件放置在主目录的应用程序列表中“安装”应用程序，而不实际安装它。你获得了安装某些东西的所有好处，以及能够在本地运行某些东西的好处，即“便携式应用程序”。有时，开发人员只是编译一个应用程序，然后将结果发布到下载中，没有安装脚本，也没有打包。通常，这意味着你下载了一个 TAR 文件，然后 ，然后双击可执行文件（通常是你下载软件的名称）。当使用这种软件方式交付时，你可以将它放在你下载的地方，当你需要它时，你可以手动启动它，或者你可以自己进行快速但是麻烦的安装。这包括两个简单的步骤：将目录保存到一个标准位置，并在需要时手动启动它。将目录保存到一个标准位置，并创建一个  文件，将其集成到你的系统中。如果你只是为自己安装应用程序，那么传统上会在你的主目录中放个  （“二进制文件binary” 的简称）目录作为本地安装的应用程序和脚本的存储位置。如果你的系统上有其他用户需要访问这些应用程序，传统上将二进制文件放置在  中。最后，这取决于你存储应用程序的位置。下载通常以带版本名称的目录进行，如  或者 。由于假设你将在某个时候更新应用程序，因此将版本号删除或创建目录的符号链接是个不错的主意。这样，即使你更新应用程序本身，为应用程序创建的启动程序也可以保持不变。要创建一个  启动文件，打开一个文本编辑器并创建一个名为  的文件。 由  定义。下面是一个简单的启动器，用于一个名为 Twine 的游戏开发 IDE，安装在系统范围的  目录中：棘手的一行是  行。它必须包含一个有效的命令来启动应用程序。通常，它只是你下载的东西的完整路径，但在某些情况下，它更复杂一些。例如，Java 应用程序可能需要作为 Java 自身的参数启动。有时，一个项目包含一个可以运行的包装脚本，这样你就不必找出正确的命令：在这个 Twine 例子中，没有与该下载的软件捆绑的图标，因此示例  文件指定了 KDE 桌面附带的通用游戏图标。你可以使用类似的解决方法，但如果你更具艺术性，可以创建自己的图标，或者可以在 Internet 上搜索一个好的图标。只要  行指向一个有效的 PNG 或 SVG 文件，你的应用程序就会以该图标为代表。示例脚本还将应用程序类别主要设置为 Development，因此在 KDE、GNOME 和大多数其他应用程序菜单中，Twine 出现在开发类别下。为了让这个例子出现在应用程序菜单中，把  文件放这到两个地方之一：如果你将应用程序存储在你自己的家目录下，那么请将其放在 。如果你将应用程序存储在  目录或者其他系统范围的位置，并希望它出现在所有用户的应用程序菜单中，请将它放在  目录中。现在，该应用程序已安装，因为它需要与系统的其他部分集成。最后，还有真正的通用格式安装格式：源代码。从源代码编译应用程序是学习如何构建应用程序，如何与系统交互以及如何定制应用程序的好方法。尽管如此，它绝不是一个点击按钮式过程。它需要一个构建环境，通常需要安装依赖库和头文件，有时还要进行一些调试。要了解更多关于从源代码编译的内容，请阅读。有些人认为安装软件是一个神奇的过程，只有开发人员理解，或者他们认为它“激活”了应用程序，就好像二进制可执行文件在“安装”之前无效。学习许多不同的安装方法会告诉你安装实际上只是“将文件从一个地方复制到系统中适当位置”的简写。 没有什么神秘的。只要你去了解每次安装，不是期望应该如何发生，并且寻找开发者为安装过程设置了什么，那么通常很容易，即使它与你的习惯不同。重要的是安装器要诚实于你。 如果你遇到未经你的同意尝试安装其他软件的安装程序（或者它可能会以混淆或误导的方式请求同意），或者尝试在没有明显原因的情况下对系统执行检查，则不要继续安装。好的软件是灵活的、诚实的、开放的。 现在你知道如何在你的计算机上获得好软件了。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "为初学者准备的 ln 命令教程（5 个示例） - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n当我们在命令行上工作时，您可能需要在文件之间创建链接。这时，您可以可以借助一个专用命令，。本教程中，我们将通过一些简单易理解的例子来讨论此工具的基础知识。在此之前，值得一提的是，本教程所有例子都已在 Ubuntu 16.04 上测试通过。正如你现在所了解的， 命令能够让您在文件之间创建链接。下面就是  工具的语法（或者使用其他一些可行的语法）。下面是  工具 man 文档描述的内容：在第一种形式下，为目标位置（TARGET）创建一个叫 LINK_NAME 的链接。在第二种形式下，为目标位置（TARGET）在当前目录下创建一个链接（LCTT 译注：创建的为同名链接）。在第三和第四种形式中，在 DIRECTORY 目录下为每一个目标位置（TARGET）创建链接。默认创建硬链接，符号链接需要  选项。默认创建的每一个创建的链接（新链接的名字）都不能已经存在。当创建硬链接时，目标位置（TARGET）文件必须存在；符号链接可以保存任意文本，如果之后解析，相对链接的解析与其父目录有关。通过下面问答风格的例子，可能会给你更好的理解。但是在此之前，建议您先了解 .这很简单，你只需要像下面使用  命令：例如：如此，您便可以看见一个已经创建好的，名为  的硬链接。使用  命令行选项：例如： 文件就是一个软/符号链接，以天蓝色文本 。默认情况下， 不允许您在目标目录下创建已存在的链接。然而，如果一定要这么做，您可以使用  命令行选项覆盖此行为。提示：如果您想在此删除过程中有所交互，您可以使用  选项。如果您不想  删除同名的现有文件，您可以为这些文件创建备份。使用  即可实现此效果，以这种方式创建的备份文件，会在其文件名结尾处包含一个波浪号（）。使用  选项指定一个文件目录（除了当前目录）。比如：上述命令会为（当前目录下的）所有  文件创建链接，并放到桌面目录下。当然，尤其对于新手来说， 并不是日常必备命令。但是，这是一个有用的命令，因为你永远不知道它什么时候能够节省你一天的时间。对于这个命令，我们已经讨论了一些实用的选项，如果你已经完成了这些，可以查询  来了解更多详情。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "深入学习 Redis（1）：Redis 内存模型 - 文章 - 伯乐在线", "tag": ["IT技术", " 6 评论 ", "Redis", "数据库"], "goodNum": "3", "saveNum": " 10 收藏", "sayNum": " 6 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n前言Redis是目前最火爆的内存数据库之一，通过在内存中读写数据，大大提高了读写速度，可以说Redis是实现网站高并发不可或缺的一部分。我们使用Redis时，会接触Redis的5种对象类型（字符串、哈希、列表、集合、有序集合），丰富的类型是Redis相对于Memcached等的一大优势。在了解Redis的5种对象类型的用法和特点的基础上，进一步了解Redis的内存模型，对Redis的使用有很大帮助，例如：1、估算Redis内存使用量。目前为止，内存的使用成本仍然相对较高，使用内存不能无所顾忌；根据需求合理的评估Redis的内存使用量，选择合适的机器配置，可以在满足需求的情况下节约成本。2、优化内存占用。了解Redis内存模型可以选择更合适的数据类型和编码，更好的利用Redis内存。3、分析解决问题。当Redis出现阻塞、内存占用等问题时，尽快发现导致问题的原因，便于分析解决问题。这篇文章主要介绍Redis的内存模型（以3.0为例），包括Redis占用内存的情况及如何查询、不同的对象类型在内存中的编码方式、内存分配器(jemalloc)、简单动态字符串(SDS)、RedisObject等；然后在此基础上介绍几个Redis内存模型的应用。在后面的文章中，会陆续介绍关于Redis高可用的内容，包括主从复制、哨兵、集群等等，欢迎关注。 目录工欲善其事必先利其器，在说明Redis内存之前首先说明如何统计Redis使用内存的情况。在客户端通过redis-cli连接服务器后（后面如无特殊说明，客户端一律使用redis-cli），通过info命令可以查看内存使用情况：其中，info命令可以显示redis服务器的许多信息，包括服务器基本信息、CPU、内存、持久化、客户端连接信息等等；memory是参数，表示只显示内存相关的信息。返回结果中比较重要的几个说明如下：（1）Redis分配器分配的内存总量（单位是字节），包括使用的虚拟内存（即swap）；Redis分配器后面会介绍。used_memory_human只是显示更友好。（2）Redis进程占据操作系统的内存（单位是字节），与top及ps命令看到的值是一致的；除了分配器分配的内存之外，used_memory_rss还包括进程运行本身需要的内存、内存碎片等，但是不包括虚拟内存。因此，used_memory和used_memory_rss，前者是从Redis角度得到的量，后者是从操作系统角度得到的量。二者之所以有所不同，一方面是因为内存碎片和Redis进程运行需要占用内存，使得前者可能比后者小，另一方面虚拟内存的存在，使得前者可能比后者大。由于在实际应用中，Redis的数据量会比较大，此时进程运行占用的内存与Redis数据量和内存碎片相比，都会小得多；因此used_memory_rss和used_memory的比例，便成了衡量Redis内存碎片率的参数；这个参数就是mem_fragmentation_ratio。（3）内存碎片比率，该值是used_memory_rss / used_memory的比值。mem_fragmentation_ratio一般大于1，且该值越大，内存碎片比例越大。mem_fragmentation_ratio<1，说明Redis使用了虚拟内存，由于虚拟内存的媒介是磁盘，比内存速度要慢很多，当这种情况出现时，应该及时排查，如果内存不足应该及时处理，如增加Redis节点、增加Redis服务器的内存、优化应用等。一般来说，mem_fragmentation_ratio在1.03左右是比较健康的状态（对于jemalloc来说）；上面截图中的mem_fragmentation_ratio值很大，是因为还没有向Redis中存入数据，Redis进程本身运行的内存使得used_memory_rss 比used_memory大得多。（4）Redis使用的内存分配器，在编译时指定；可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc；截图中使用的便是默认的jemalloc。Redis作为内存数据库，在内存中存储的内容主要是数据（键值对）；通过前面的叙述可以知道，除了数据以外，Redis的其他部分也会占用内存。Redis的内存占用主要可以划分为以下几个部分：1、数据作为数据库，数据是最主要的部分；这部分占用的内存会统计在used_memory中。Redis使用键值对存储数据，其中的值（对象）包括5种类型，即字符串、哈希、列表、集合、有序集合。这5种类型是Redis对外提供的，实际上，在Redis内部，每种类型可能有2种或更多的内部编码实现；此外，Redis在存储对象时，并不是直接将数据扔进内存，而是会对对象进行各种包装：如redisObject、SDS等；这篇文章后面将重点介绍Redis中数据存储的细节。2、进程本身运行需要的内存Redis主进程本身运行肯定需要占用内存，如代码、常量池等等；这部分内存大约几兆，在大多数生产环境中与Redis数据占用的内存相比可以忽略。这部分内存不是由jemalloc分配，因此不会统计在used_memory中。补充说明：除了主进程外，Redis创建的子进程运行也会占用内存，如Redis执行AOF、RDB重写时创建的子进程。当然，这部分内存不属于Redis进程，也不会统计在used_memory和used_memory_rss中。3、缓冲内存缓冲内存包括客户端缓冲区、复制积压缓冲区、AOF缓冲区等；其中，客户端缓冲存储客户端连接的输入输出缓冲；复制积压缓冲用于部分复制功能；AOF缓冲区用于在进行AOF重写时，保存最近的写入命令。在了解相应功能之前，不需要知道这些缓冲的细节；这部分内存由jemalloc分配，因此会统计在used_memory中。4、内存碎片内存碎片是Redis在分配、回收物理内存过程中产生的。例如，如果对数据的更改频繁，而且数据之间的大小相差很大，可能导致redis释放的空间在物理内存中并没有释放，但redis又无法有效利用，这就形成了内存碎片。内存碎片不会统计在used_memory中。内存碎片的产生与对数据进行的操作、数据的特点等都有关；此外，与使用的内存分配器也有关系：如果内存分配器设计合理，可以尽可能的减少内存碎片的产生。后面将要说到的jemalloc便在控制内存碎片方面做的很好。如果Redis服务器中的内存碎片已经很大，可以通过安全重启的方式减小内存碎片：因为重启之后，Redis重新从备份文件中读取数据，在内存中进行重排，为每个数据重新选择合适的内存单元，减小内存碎片。1、概述关于Redis数据存储的细节，涉及到内存分配器（如jemalloc）、简单动态字符串（SDS）、5种对象类型及内部编码、redisObject。在讲述具体内容之前，先说明一下这几个概念之间的关系。下图是执行set hello world时，所涉及到的数据模型。图片来源：https://searchdatabase.techtarget.com.cn/7-20218/（1）dictEntry：Redis是Key-Value数据库，因此对每个键值对都会有一个dictEntry，里面存储了指向Key和Value的指针；next指向下一个dictEntry，与本Key-Value无关。（2）Key：图中右上角可见，Key（”hello”）并不是直接以字符串存储，而是存储在SDS结构中。（3）redisObject：Value(“world”)既不是直接以字符串存储，也不是像Key一样直接存储在SDS中，而是存储在redisObject中。实际上，不论Value是5种类型的哪一种，都是通过redisObject来存储的；而redisObject中的type字段指明了Value对象的类型，ptr字段则指向对象所在的地址。不过可以看出，字符串对象虽然经过了redisObject的包装，但仍然需要通过SDS存储。实际上，redisObject除了type和ptr字段以外，还有其他字段图中没有给出，如用于指定对象内部编码的字段；后面会详细介绍。（4）jemalloc：无论是DictEntry对象，还是redisObject、SDS对象，都需要内存分配器（如jemalloc）分配内存进行存储。以DictEntry对象为例，有3个指针组成，在64位机器下占24个字节，jemalloc会为它分配32字节大小的内存单元。下面来分别介绍jemalloc、redisObject、SDS、对象类型及内部编码。2、jemallocRedis在编译时便会指定内存分配器；内存分配器可以是 libc 、jemalloc或者tcmalloc，默认是jemalloc。jemalloc作为Redis的默认内存分配器，在减小内存碎片方面做的相对比较好。jemalloc在64位系统中，将内存空间划分为小、大、巨大三个范围；每个范围内又划分了许多小的内存块单位；当Redis存储数据时，会选择大小最合适的内存块进行存储。jemalloc划分的内存单元如下图所示：图片来源：http://blog.csdn.net/zhengpeitao/article/details/76573053例如，如果需要存储大小为130字节的对象，jemalloc会将其放入160字节的内存单元中。3、redisObject前面说到，Redis对象有5种类型；无论是哪种类型，Redis都不会直接存储，而是通过redisObject对象进行存储。redisObject对象非常重要，Redis对象的类型、内部编码、内存回收、共享对象等功能，都需要redisObject支持，下面将通过redisObject的结构来说明它是如何起作用的。redisObject的定义如下（不同版本的Redis可能稍稍有所不同）：redisObject的每个字段的含义和作用如下：type字段表示对象的类型，占4个比特；目前包括REDIS_STRING(字符串)、REDIS_LIST (列表)、REDIS_HASH(哈希)、REDIS_SET(集合)、REDIS_ZSET(有序集合)。当我们执行type命令时，便是通过读取RedisObject的type字段获得对象的类型；如下图所示：encoding表示对象的内部编码，占4个比特。对于Redis支持的每种类型，都有至少两种内部编码，例如对于字符串，有int、embstr、raw三种编码。通过encoding属性，Redis可以根据不同的使用场景来为对象设置不同的编码，大大提高了Redis的灵活性和效率。以列表对象为例，有压缩列表和双端链表两种编码方式；如果列表中的元素较少，Redis倾向于使用压缩列表进行存储，因为压缩列表占用内存更少，而且比双端链表可以更快载入；当列表对象元素较多时，压缩列表就会转化为更适合存储大量元素的双端链表。通过object encoding命令，可以查看对象采用的编码方式，如下图所示：5种对象类型对应的编码方式以及使用条件，将在后面介绍。lru记录的是对象最后一次被命令程序访问的时间，占据的比特数不同的版本有所不同（如4.0版本占24比特，2.6版本占22比特）。通过对比lru时间与当前时间，可以计算某个对象的空转时间；object idletime命令可以显示该空转时间（单位是秒）。object idletime命令的一个特殊之处在于它不改变对象的lru值。lru值除了通过object idletime命令打印之外，还与Redis的内存回收有关系：如果Redis打开了maxmemory选项，且内存回收算法选择的是volatile-lru或allkeys—lru，那么当Redis内存占用超过maxmemory指定的值时，Redis会优先选择空转时间最长的对象进行释放。refcount记录的是该对象被引用的次数，类型为整型。refcount的作用，主要在于对象的引用计数和内存回收。当创建新对象时，refcount初始化为1；当有新程序使用该对象时，refcount加1；当对象不再被一个新程序使用时，refcount减1；当refcount变为0时，对象占用的内存会被释放。Redis中被多次使用的对象(refcount>1)，称为共享对象。Redis为了节省内存，当有一些对象重复出现时，新的程序不会创建新的对象，而是仍然使用原来的对象。这个被重复使用的对象，就是共享对象。目前共享对象仅支持整数值的字符串对象。Redis的共享对象目前只支持整数值的字符串对象。之所以如此，实际上是对内存和CPU（时间）的平衡：共享对象虽然会降低内存消耗，但是判断两个对象是否相等却需要消耗额外的时间。对于整数值，判断操作复杂度为O(1)；对于普通字符串，判断复杂度为O(n)；而对于哈希、列表、集合和有序集合，判断的复杂度为O(n^2)。虽然共享对象只能是整数值的字符串对象，但是5种类型都可能使用共享对象（如哈希、列表等的元素可以使用）。就目前的实现来说，Redis服务器在初始化时，会创建10000个字符串对象，值分别是0~9999的整数值；当Redis需要使用值为0~9999的字符串对象时，可以直接使用这些共享对象。10000这个数字可以通过调整参数REDIS_SHARED_INTEGERS（4.0中是OBJ_SHARED_INTEGERS）的值进行改变。共享对象的引用次数可以通过object refcount命令查看，如下图所示。命令执行的结果页佐证了只有0~9999之间的整数会作为共享对象。ptr指针指向具体的数据，如前面的例子中，set hello world，ptr指向包含字符串world的SDS。综上所述，redisObject的结构与对象类型、编码、内存回收、共享对象都有关系；一个redisObject对象的大小为16字节：4bit+4bit+24bit+4Byte+8Byte=16Byte。4、SDSRedis没有直接使用C字符串(即以空字符’\\0’结尾的字符数组)作为默认的字符串表示，而是使用了SDS。SDS是简单动态字符串(Simple Dynamic String)的缩写。sds的结构如下：其中，buf表示字节数组，用来存储字符串；len表示buf已使用的长度，free表示buf未使用的长度。下面是两个例子。图片来源：《Redis设计与实现》通过SDS的结构可以看出，buf数组的长度=free+len+1（其中1表示字符串结尾的空字符）；所以，一个SDS结构占据的空间为：free所占长度+len所占长度+ buf数组的长度=4+4+free+len+1=free+len+9。SDS在C字符串的基础上加入了free和len字段，带来了很多好处：获取字符串长度：SDS是O(1)，C字符串是O(n)缓冲区溢出：使用C字符串的API时，如果字符串长度增加（如strcat操作）而忘记重新分配内存，很容易造成缓冲区的溢出；而SDS由于记录了长度，相应的API在可能造成缓冲区溢出时会自动重新分配内存，杜绝了缓冲区溢出。修改字符串时内存的重分配：对于C字符串，如果要修改字符串，必须要重新分配内存（先释放再申请），因为如果没有重新分配，字符串长度增大时会造成内存缓冲区溢出，字符串长度减小时会造成内存泄露。而对于SDS，由于可以记录len和free，因此解除了字符串长度和空间数组长度之间的关联，可以在此基础上进行优化：空间预分配策略（即分配内存时比实际需要的多）使得字符串长度增大时重新分配内存的概率大大减小；惰性空间释放策略使得字符串长度减小时重新分配内存的概率大大减小。存取二进制数据：SDS可以，C字符串不可以。因为C字符串以空字符作为字符串结束的标识，而对于一些二进制文件（如图片等），内容可能包括空字符串，因此C字符串无法正确存取；而SDS以字符串长度len来作为字符串结束标识，因此没有这个问题。此外，由于SDS中的buf仍然使用了C字符串（即以’\\0’结尾），因此SDS可以使用C字符串库中的部分函数；但是需要注意的是，只有当SDS用来存储文本数据时才可以这样使用，在存储二进制数据时则不行（’\\0’不一定是结尾）。Redis在存储对象时，一律使用SDS代替C字符串。例如set hello world命令，hello和world都是以SDS的形式存储的。而sadd myset member1 member2 member3命令，不论是键（”myset”），还是集合中的元素（”member1”、 ”member2”和”member3”），都是以SDS的形式存储。除了存储对象，SDS还用于存储各种缓冲区。只有在字符串不会改变的情况下，如打印日志时，才会使用C字符串。前面已经说过，Redis支持5种对象类型，而每种结构都有至少两种编码；这样做的好处在于：一方面接口与实现分离，当需要增加或改变内部编码时，用户使用不受影响，另一方面可以根据不同的应用场景切换内部编码，提高效率。Redis各种对象类型支持的内部编码如下图所示(图中版本是Redis3.0，Redis后面版本中又增加了内部编码，略过不提；本章所介绍的内部编码都是基于3.0的)：图片来源：《Redis设计与实现》关于Redis内部编码的转换，都符合以下规律：1、字符串字符串是最基础的类型，因为所有的键都是字符串类型，且字符串之外的其他几种复杂类型的元素也是字符串。字符串长度不能超过512MB。字符串类型的内部编码有3种，它们的应用场景如下：int：8个字节的长整型。字符串值是整型时，这个值使用long整型表示。embstr：<=39字节的字符串。embstr与raw都使用redisObject和sds保存数据，区别在于，embstr的使用只分配一次内存空间（因此redisObject和sds是连续的），而raw需要分配两次内存空间（分别为redisObject和sds分配空间）。因此与raw相比，embstr的好处在于创建时少分配一次空间，删除时少释放一次空间，以及对象的所有数据连在一起，寻找方便。而embstr的坏处也很明显，如果字符串的长度增加需要重新分配内存时，整个redisObject和sds都需要重新分配空间，因此redis中的embstr实现为只读。raw：大于39个字节的字符串示例如下图所示：embstr和raw进行区分的长度，是39；是因为redisObject的长度是16字节，sds的长度是9+字符串长度；因此当字符串长度是39时，embstr的长度正好是16+9+39=64，jemalloc正好可以分配64字节的内存单元。当int数据不再是整数，或大小超过了long的范围时，自动转化为raw。而对于embstr，由于其实现是只读的，因此在对embstr对象进行修改时，都会先转化为raw再进行修改，因此，只要是修改embstr对象，修改后的对象一定是raw的，无论是否达到了39个字节。示例如下图所示：2、列表列表（list）用来存储多个有序的字符串，每个字符串称为元素；一个列表可以存储2^32-1个元素。Redis中的列表支持两端插入和弹出，并可以获得指定位置（或范围）的元素，可以充当数组、队列、栈等。列表的内部编码可以是压缩列表（ziplist）或双端链表（linkedlist）。双端链表：由一个list结构和多个listNode结构组成；典型结构如下图所示：图片来源：《Redis设计与实现》通过图中可以看出，双端链表同时保存了表头指针和表尾指针，并且每个节点都有指向前和指向后的指针；链表中保存了列表的长度；dup、free和match为节点值设置类型特定函数，所以链表可以用于保存各种不同类型的值。而链表中每个节点指向的是type为字符串的redisObject。压缩列表：压缩列表是Redis为了节约内存而开发的，是由一系列特殊编码的(而不是像双端链表一样每个节点是指针)组成的顺序型数据结构；具体结构相对比较复杂，略。与双端链表相比，压缩列表可以节省内存空间，但是进行修改或增删操作时，复杂度较高；因此当节点数量较少时，可以使用压缩列表；但是节点数量多时，还是使用双端链表划算。压缩列表不仅用于实现列表，也用于实现哈希、有序列表；使用非常广泛。只有同时满足下面两个条件时，才会使用压缩列表：列表中元素数量小于512个；列表中所有字符串对象都不足64字节。如果有一个条件不满足，则使用双端列表；且编码只可能由压缩列表转化为双端链表，反方向则不可能。下图展示了列表编码转换的特点：其中，单个字符串不能超过64字节，是为了便于统一分配每个节点的长度；这里的64字节是指字符串的长度，不包括SDS结构，因为压缩列表使用连续、定长内存块存储字符串，不需要SDS结构指明长度。后面提到压缩列表，也会强调长度不超过64字节，原理与这里类似。3、哈希哈希（作为一种数据结构），不仅是redis对外提供的5种对象类型的一种（与字符串、列表、集合、有序结合并列），也是Redis作为Key-Value数据库所使用的数据结构。为了说明的方便，在本文后面当使用“内层的哈希”时，代表的是redis对外提供的5种对象类型的一种；使用“外层的哈希”代指Redis作为Key-Value数据库所使用的数据结构。内层的哈希使用的内部编码可以是压缩列表（ziplist）和哈希表（hashtable）两种；Redis的外层的哈希则只使用了hashtable。压缩列表前面已介绍。与哈希表相比，压缩列表用于元素个数少、元素长度小的场景；其优势在于集中存储，节省空间；同时，虽然对于元素的操作复杂度也由O(n)变为了O(1)，但由于哈希中元素数量较少，因此操作的时间并没有明显劣势。hashtable：一个hashtable由1个dict结构、2个dictht结构、1个dictEntry指针数组（称为bucket）和多个dictEntry结构组成。正常情况下（即hashtable没有进行rehash时）各部分关系如下图所示：图片改编自：《Redis设计与实现》下面从底层向上依次介绍各个部分：dictEntry结构用于保存键值对，结构定义如下：其中，各个属性的功能如下：key：键值对中的键；val：键值对中的值，使用union(即共用体)实现，存储的内容既可能是一个指向值的指针，也可能是64位整型，或无符号64位整型；next：指向下一个dictEntry，用于解决哈希冲突问题在64位系统中，一个dictEntry对象占24字节（key/val/next各占8字节）。bucket是一个数组，数组的每个元素都是指向dictEntry结构的指针。redis中bucket数组的大小计算规则如下：大于dictEntry的、最小的2^n；例如，如果有1000个dictEntry，那么bucket大小为1024；如果有1500个dictEntry，则bucket大小为2048。dictht结构如下：其中，各个属性的功能说明如下：table属性是一个指针，指向bucket；size属性记录了哈希表的大小，即bucket的大小；used记录了已使用的dictEntry的数量；sizemask属性的值总是为size-1，这个属性和哈希值一起决定一个键在table中存储的位置。一般来说，通过使用dictht和dictEntry结构，便可以实现普通哈希表的功能；但是Redis的实现中，在dictht结构的上层，还有一个dict结构。下面说明dict结构的定义及作用。dict结构如下：其中，type属性和privdata属性是为了适应不同类型的键值对，用于创建多态字典。ht属性和trehashidx属性则用于rehash，即当哈希表需要扩展或收缩时使用。ht是一个包含两个项的数组，每项都指向一个dictht结构，这也是Redis的哈希会有1个dict、2个dictht结构的原因。通常情况下，所有的数据都是存在放dict的ht[0]中，ht[1]只在rehash的时候使用。dict进行rehash操作的时候，将ht[0]中的所有数据rehash到ht[1]中。然后将ht[1]赋值给ht[0]，并清空ht[1]。因此，Redis中的哈希之所以在dictht和dictEntry结构之外还有一个dict结构，一方面是为了适应不同类型的键值对，另一方面是为了rehash。如前所述，Redis中内层的哈希既可能使用哈希表，也可能使用压缩列表。只有同时满足下面两个条件时，才会使用压缩列表：哈希中元素数量小于512个；哈希中所有键值对的键和值字符串长度都小于64字节。如果有一个条件不满足，则使用哈希表；且编码只可能由压缩列表转化为哈希表，反方向则不可能。下图展示了Redis内层的哈希编码转换的特点：4、集合集合（set）与列表类似，都是用来保存多个字符串，但集合与列表有两点不同：集合中的元素是无序的，因此不能通过索引来操作元素；集合中的元素不能有重复。一个集合中最多可以存储2^32-1个元素；除了支持常规的增删改查，Redis还支持多个集合取交集、并集、差集。集合的内部编码可以是整数集合（intset）或哈希表（hashtable）。哈希表前面已经讲过，这里略过不提；需要注意的是，集合在使用哈希表时，值全部被置为null。整数集合的结构定义如下：其中，encoding代表contents中存储内容的类型，虽然contents（存储集合中的元素）是int8_t类型，但实际上其存储的值是int16_t、int32_t或int64_t，具体的类型便是由encoding决定的；length表示元素个数。整数集合适用于集合所有元素都是整数且集合元素数量较小的时候，与哈希表相比，整数集合的优势在于集中存储，节省空间；同时，虽然对于元素的操作复杂度也由O(n)变为了O(1)，但由于集合数量较少，因此操作的时间并没有明显劣势。只有同时满足下面两个条件时，集合才会使用整数集合：集合中元素数量小于512个；集合中所有元素都是整数值。如果有一个条件不满足，则使用哈希表；且编码只可能由整数集合转化为哈希表，反方向则不可能。下图展示了集合编码转换的特点：5、有序集合有序集合与集合一样，元素都不能重复；但与集合不同的是，有序集合中的元素是有顺序的。与列表使用索引下标作为排序依据不同，有序集合为每个元素设置一个分数（score）作为排序依据。有序集合的内部编码可以是压缩列表（ziplist）或跳跃表（skiplist）。ziplist在列表和哈希中都有使用，前面已经讲过，这里略过不提。跳跃表是一种有序数据结构，通过在每个节点中维持多个指向其他节点的指针，从而达到快速访问节点的目的。除了跳跃表，实现有序数据结构的另一种典型实现是平衡树；大多数情况下，跳跃表的效率可以和平衡树媲美，且跳跃表实现比平衡树简单很多，因此redis中选用跳跃表代替平衡树。跳跃表支持平均O(logN)、最坏O(N)的复杂点进行节点查找，并支持顺序操作。Redis的跳跃表实现由zskiplist和zskiplistNode两个结构组成：前者用于保存跳跃表信息（如头结点、尾节点、长度等），后者用于表示跳跃表节点。具体结构相对比较复杂，略。只有同时满足下面两个条件时，才会使用压缩列表：有序集合中元素数量小于128个；有序集合中所有成员长度都不足64字节。如果有一个条件不满足，则使用跳跃表；且编码只可能由压缩列表转化为跳跃表，反方向则不可能。下图展示了有序集合编码转换的特点：了解Redis的内存模型之后，下面通过几个例子说明其应用。1、估算Redis内存使用量要估算redis中的数据占据的内存大小，需要对redis的内存模型有比较全面的了解，包括前面介绍的hashtable、sds、redisobject、各种对象类型的编码方式等。下面以最简单的字符串类型来进行说明。假设有90000个键值对，每个key的长度是7个字节，每个value的长度也是7个字节（且key和value都不是整数）；下面来估算这90000个键值对所占用的空间。在估算占据空间之前，首先可以判定字符串类型使用的编码方式：embstr。90000个键值对占据的内存空间主要可以分为两部分：一部分是90000个dictEntry占据的空间；一部分是键值对所需要的bucket空间。每个dictEntry占据的空间包括：1)       一个dictEntry，24字节，jemalloc会分配32字节的内存块2)       一个key，7字节，所以SDS(key)需要7+9=16个字节，jemalloc会分配16字节的内存块3)       一个redisObject，16字节，jemalloc会分配16字节的内存块4)       一个value，7字节，所以SDS(value)需要7+9=16个字节，jemalloc会分配16字节的内存块5)       综上，一个dictEntry需要32+16+16+16=80个字节。bucket空间：bucket数组的大小为大于90000的最小的2^n，是131072；每个bucket元素为8字节（因为64位系统中指针大小为8字节）。因此，可以估算出这90000个键值对占据的内存大小为：90000*80 + 131072*8 = 8248576。下面写个程序在redis中验证一下：运行结果：8247552理论值与结果值误差在万分之1.2，对于计算需要多少内存来说，这个精度已经足够了。之所以会存在误差，是因为在我们插入90000条数据之前redis已分配了一定的bucket空间，而这些bucket空间尚未使用。作为对比将key和value的长度由7字节增加到8字节，则对应的SDS变为17个字节，jemalloc会分配32个字节，因此每个dictEntry占用的字节数也由80字节变为112字节。此时估算这90000个键值对占据内存大小为：90000*112 + 131072*8 = 11128576。在redis中验证代码如下（只修改插入数据的代码）：运行结果：11128576；估算准确。对于字符串类型之外的其他类型，对内存占用的估算方法是类似的，需要结合具体类型的编码方式来确定。2、优化内存占用了解redis的内存模型，对优化redis内存占用有很大帮助。下面介绍几种优化场景。（1）利用jemalloc特性进行优化上一小节所讲述的90000个键值便是一个例子。由于jemalloc分配内存时数值是不连续的，因此key/value字符串变化一个字节，可能会引起占用内存很大的变动；在设计时可以利用这一点。例如，如果key的长度如果是8个字节，则SDS为17字节，jemalloc分配32字节；此时将key长度缩减为7个字节，则SDS为16字节，jemalloc分配16字节；则每个key所占用的空间都可以缩小一半。（2）使用整型/长整型如果是整型/长整型，Redis会使用int类型（8字节）存储来代替字符串，可以节省更多空间。因此在可以使用长整型/整型代替字符串的场景下，尽量使用长整型/整型。（3）共享对象利用共享对象，可以减少对象的创建（同时减少了redisObject的创建），节省内存空间。目前redis中的共享对象只包括10000个整数（0-9999）；可以通过调整REDIS_SHARED_INTEGERS参数提高共享对象的个数；例如将REDIS_SHARED_INTEGERS调整到20000，则0-19999之间的对象都可以共享。考虑这样一种场景：论坛网站在redis中存储了每个帖子的浏览数，而这些浏览数绝大多数分布在0-20000之间，这时候通过适当增大REDIS_SHARED_INTEGERS参数，便可以利用共享对象节省内存空间。（4）避免过度设计然而需要注意的是，不论是哪种优化场景，都要考虑内存空间与设计复杂度的权衡；而设计复杂度会影响到代码的复杂度、可维护性。如果数据量较小，那么为了节省内存而使得代码的开发、维护变得更加困难并不划算；还是以前面讲到的90000个键值对为例，实际上节省的内存空间只有几MB。但是如果数据量有几千万甚至上亿，考虑内存的优化就比较必要了。3、关注内存碎片率内存碎片率是一个重要的参数，对redis 内存的优化有重要意义。如果内存碎片率过高（jemalloc在1.03左右比较正常），说明内存碎片多，内存浪费严重；这时便可以考虑重启redis服务，在内存中对数据进行重排，减少内存碎片。如果内存碎片率小于1，说明redis内存不足，部分数据使用了虚拟内存（即swap）；由于虚拟内存的存取速度比物理内存差很多（2-3个数量级），此时redis的访问速度可能会变得很慢。因此必须设法增大物理内存（可以增加服务器节点数量，或提高单机内存），或减少redis中的数据。要减少redis中的数据，除了选用合适的数据类型、利用共享对象等，还有一点是要设置合理的数据回收策略（maxmemory-policy），当内存达到一定量后，根据不同的优先级对内存进行回收。《Redis开发与运维》《Redis设计与实现》https://redis.io/documentationhttp://redisdoc.com/server/info.htmlhttps://www.cnblogs.com/lhcpig/p/4769397.htmlhttps://searchdatabase.techtarget.com.cn/7-20218/http://www.cnblogs.com/mushroom/p/4738170.htmlhttp://www.imooc.com/article/3645http://blog.csdn.net/zhengpeitao/article/details/76573053 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/04/49961db8952e63d98b519b76a2daa5e2.png"]}
{"title": "常用排序算法总结（2） - 文章 - 伯乐在线", "tag": ["IT技术", "算法"], "goodNum": "1", "saveNum": " 5 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n，主要有，，，，，等。这篇文章中我们来探讨一下常用的非比较排序算法：，，。在一定条件下，它们的时间复杂度可以达到O(n)。这里我们用到的唯一数据结构就是数组，当然我们也可以利用链表来实现下述算法。计数排序(Counting Sort)计数排序用到一个额外的计数数组C，根据数组C来将原数组A中的元素排到正确的位置。通俗地理解，例如有10个年龄不同的人，假如统计出有8个人的年龄不比小明大（即小于等于小明的年龄，这里也包括了小明），那么小明的年龄就排在第8位，通过这种思想可以确定每个人的位置，也就排好了序。当然，年龄一样时需要特殊处理（保证稳定性）：通过反向填充目标数组，填充完毕后将对应的数字统计递减，可以确保计数排序的稳定性。计数排序的步骤如下：统计数组A中每个值A[i]出现的次数，存入C[A[i]]从前向后，使数组C中的每个值等于其与前一项相加，这样数组C[A[i]]就变成了代表数组A中小于等于A[i]的元素个数反向填充目标数组B：将数组元素A[i]放在数组B的第C[A[i]]个位置（下标为C[A[i]] – 1），每放一个元素就将C[A[i]]递减计数排序的实现代码如下：下图给出了对{ 4, 1, 3, 4, 3 }进行计数排序的简单演示过程计数排序的时间复杂度和空间复杂度与数组A的数据范围（A中元素的最大值与最小值的差加上1）有关，因此例如：对0到99之间的数字进行排序，计数排序是最好的算法，然而计数排序并不适合按字母顺序排序人名，　　基数排序(Radix Sort)基数排序的发明可以追溯到1887年赫尔曼·何乐礼在打孔卡片制表机上的贡献。它是这样实现的：将所有待比较正整数统一为同样的数位长度，数位较短的数前面补零。然后，从最低位开始进行基数为10的计数排序，一直到最高位计数排序完后，数列就变成一个有序序列（利用了计数排序的稳定性）。基数排序的实现代码如下：下图给出了对{ 329, 457, 657, 839, 436, 720, 355 }进行基数排序的简单演示过程基数排序的时间复杂度是O(n * dn)，其中n是待排序元素个数，dn是数字位数。这个时间复杂度不一定优于O(n log n)，dn的大小取决于数字位的选择（比如比特位数），和待排序数据所属数据类型的全集的大小；dn决定了进行多少轮处理，而n是每轮处理的操作数目。如果考虑和比较排序进行对照，基数排序的形式复杂度虽然不一定更小，但由于不进行比较，因此其基本操作的代价较小，而且如果适当的选择基数，dn一般不大于log n，所以基数排序一般要快过基于比较的排序，比如快速排序。由于整数也可以表达字符串（比如名字或日期）和特定格式的浮点数，所以基数排序并不是只能用于整数排序。　　桶排序(Bucket Sort)桶排序也叫箱排序。工作的原理是将数组元素映射到有限数量个桶里，利用计数排序可以定位桶的边界，每个桶再各自进行桶内排序（使用其它排序算法或以递归方式继续使用桶排序）。桶排序的实现代码如下：下图给出了对{ 29, 25, 3, 49, 9, 37, 21, 43 }进行桶排序的简单演示过程桶排序不是比较排序，不受到O(nlogn)下限的影响，它是鸽巢排序的一种归纳结果，当所要排序的数组值分散均匀的时候，桶排序拥有线性的时间复杂度。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2014/10/9184208f96827c412ab7d3570590ef76.jpg"]}
{"title": "使用 sar 和 kSar 来发现 Linux 性能瓶颈 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n 命令用用收集、报告、或者保存 UNIX / Linux 系统的活动信息。它保存选择的计数器到操作系统的  文件中。从收集的数据中，你可以得到许多关于你的服务器的信息：CPU 使用率内存页面和使用率网络 I/O 和传输统计进程创建活动所有的块设备活动每秒中断数等等 命令的输出能够用于识别服务器瓶颈。但是，分析  命令提供的信息可能比较困难，所以要使用 kSar 工具。kSar 工具可以将  命令的输出绘制成基于时间周期的、易于理解的图表。、、和  命令都是 sysstat 包的一部分。它是 Linux 包含的性能监视工具集合。：显示数据 和 ：收集和保存数据用于以后分析。 shell 脚本在  目录中每日写入一个报告。 shell 脚本将每日的系统活动信息以二进制数据的形式写入到文件中。sadc —— 系统活动数据收集器。你可以通过修改  和  脚本去配置各种选项。它们位于以下的目录：\n （64 位）或者  （32 位） —— 它调用  去记录报告到  格式。 （64 位）或者  （32 位） —— 它调用  去记录报告到  格式。\n在一个基于 CentOS/RHEL 的系统上，输入如下的  去安装 sysstat：示例输出如下：编辑  文件去指定日志文件保存多少天（最长为一个月）：示例输出如下 ：保存并关闭这个文件。 ：示例输出如下：使用一个文本编辑器去编辑  文件，比如使用  命令，输入如下：像下面的示例那样更新这个文件，以记录所有的硬盘统计数据（ 选项强制记录每个块设备的统计数据，而  选项强制记录所有系统中断的统计数据）：在 CentOS/RHEL 7.x 系统上你需要传递  选项去收集块设备的数据。传递  选项去采集如下所列的数据：磁盘分区系统中断SNMPIPv6保存并关闭这个文件。输入如下命令:示例输出如下：对于 CentOS/RHEL 7.x，运行如下的命令：示例输出：使用  命令去显示操作系统中选定的累积活动计数器输出。在这个示例中，运行  命令行，去实时获得 CPU 使用率的报告：示例输出：其中：3 表示间隔时间10 表示次数查看进程创建的统计数据，输入：查看 I/O 和传输率统计数据，输入：查看内存页面统计数据，输入：查看块设备统计数据，输入：查看所有中断的统计数据，输入：查看网络设备特定的统计数据，输入：查看 CPU 特定的统计数据，输入：查看队列长度和平均负载的统计数据，输入：查看内存和交换空间的使用统计数据，输入：查看 inode、文件、和其它内核表统计数据状态，输入：查看系统切换活动统计数据，输入：查看交换统计数据，输入：查看一个 PID 为 3256 的 Apache 进程，输入： 和  提供了基于命令行界面的输出。这种输出可能会使新手用户/系统管理员感到无从下手。因此，你需要使用 kSar，它是一个图形化显示你的  数据的 Java 应用程序。它也允许你以 PDF/JPG/PNG/CSV 格式导出数据。你可以用三种方式去加载数据：本地文件、运行本地命令、以及通过 SSH 远程运行的命令。kSar 可以处理下列操作系统的  输出：Solaris 8, 9 和 10Mac OS/X 10.4+Linux (Systat Version >= 5.0.5)AIX (4.3 & 5.3)HPUX 11.00+访问  网站去获得最新版本的源代码。使用  去下载源代码，输入：首先要确保你的机器上  已安装并能够正常工作。输入下列命令去启动 kSar：接下来你将看到 kSar 的主窗口，和有两个菜单的面板。左侧有一个列表，是 kSar 根据数据已经解析出的可用图表的列表。右侧窗口将展示你选定的图表。首先，你需要从命名为 server1 的服务器上采集  命令的统计数据。输入如下的命令：接下来，使用  命令从本地桌面拷贝到远程电脑上：切换到 kSar 窗口，点击 “Data” > “Load data from text file” > 从  中选择  > 点击 “Open” 按钮。现在，图表类型树已经出现在左侧面板中并选定了一个图形：通过移动你可以交互式缩放图像的一部分。在要缩放的图像的左上角点击并按下鼠标，移动到要缩放区域的右下角，可以选定要缩放的区域。返回到未缩放状态，点击并拖动鼠标到除了右下角外的任意位置，你也可以点击并选择 zoom 选项。我强烈建议你去阅读  和  命令的 man 页面：使用  命令和 kSar 工具，可以得到内存、CPU、以及其它子系统的详细快照。例如，如果 CPU 使用率在一个很长的时间内持续高于 80%，有可能就是出现了一个 CPU 瓶颈。使用  你可以找到大量消耗 CPU 的进程。 的输出（sysstat 包的一部分）也会帮你去了解 CPU 的使用率。但你可以使用 kSar 很容易地去分析这些信息。对 CPU 执行如下的调整：确保没有不需要的进程在后台运行。关闭 。使用  在一个非高峰时刻运行任务（比如，备份）。使用  去找出所有非关键的后台作业/服务。使用  去调整低优先级作业。使用  （卸载所使用的 CPU），即，绑定进程到不同的 CPU 上。例如，在 2# CPU 上运行 MySQL 数据库，而在 3# CPU 上运行 Apache。确保你的系统使用了最新的驱动程序和固件。如有可能在系统上增加额外的 CPU。为单线程应用程序使用更快的 CPU（比如，Lighttpd web 服务器应用程序）。为多线程应用程序使用多个 CPU（比如，MySQL 数据库服务器应用程序）。为一个 web 应用程序使用多个计算节点并设置一个 。 命令图形化显示了以前运行  命令时存储在二进制文件中的系统活动数据。 命令引用  并提取出它的数据来绘制图形。与 kSar 相比， 的选项比较少。本文作者是 nixCraft 的创始人和一位经验丰富的 Linux 操作系统/Unix shell 脚本培训师。他与包括 IT、教育、国防和空间研究、以及非营利组织等全球各行业客户一起合作。可以在 、、 上关注他。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/03/3791503078cd56e080b61c9795d145e9.jpg"]}
{"title": "剖析内存中的程序之秘 - 文章 - 伯乐在线", "tag": ["C/C++", "内存"], "goodNum": "2", "saveNum": " 6 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n内存管理是操作系统的核心任务；它对程序员和系统管理员来说也是至关重要的。在接下来的几篇文章中，我将从实践出发着眼于内存管理，并深入到它的内部结构。虽然这些概念很通用，但示例大都来自于 32 位 x86 架构的 Linux 和 Windows 上。这第一篇文章描述了在内存中程序如何分布。在一个多任务操作系统中的每个进程都运行在它自己的内存“沙箱”中。这个沙箱是一个，在 32 位的模式中它总共有 4GB 的内存地址块。这些虚拟地址是通过内核映射到物理地址的，并且这些虚拟地址是由操作系统内核来维护，进而被进程所消费的。每个进程都有它自己的一组页表，但是这里有点玄机。一旦虚拟地址被启用，这些虚拟地址将被应用到这台电脑上的 。因此，一部分虚拟地址空间必须保留给内核使用：但是，这并说内核就使用了很多的物理内存，恰恰相反，它只使用了很少一部分可用的地址空间映射到其所需要的物理内存。内核空间在内核页表中被标记为独占使用于  （ring 2 或更低），因此，如果一个用户模式的程序尝试去访问它，将触发一个页面故障错误。在 Linux 中，内核空间是始终存在的，并且在所有进程中都映射相同的物理内存。内核代码和数据总是可寻址的，准备随时去处理中断或者系统调用。相比之下，用户模式中的地址空间，在每次进程切换时都会发生变化：蓝色的区域代表映射到物理地址的虚拟地址空间，白色的区域是尚未映射的部分。在上面的示例中，众所周知的内存“饕餮” Firefox 使用了大量的虚拟内存空间。在地址空间中不同的条带对应了不同的内存段，像、等等。请注意，这些段只是一系列内存地址的简化表示，它与   。不过，这是一个在 Linux 进程的标准段布局：当计算机还是快乐、安全的时代时，在机器中的几乎每个进程上，那些段的起始虚拟地址都是的。这将使远程挖掘安全漏洞变得容易。漏洞利用经常需要去引用绝对内存位置：比如在栈中的一个地址，一个库函数的地址，等等。远程攻击可以闭着眼睛选择这个地址，因为地址空间都是相同的。当攻击者们这样做的时候，人们就会受到伤害。因此，地址空间随机化开始流行起来。Linux 会通过在其起始地址上增加偏移量来随机化、、以及。不幸的是，32 位的地址空间是非常拥挤的，为地址空间随机化留下的空间不多，因此 。在进程地址空间中最高的段是栈，在大多数编程语言中它存储本地变量和函数参数。调用一个方法或者函数将推送一个新的栈帧stack frame到这个栈。当函数返回时这个栈帧被删除。这个简单的设计，可能是因为数据严格遵循  的次序，这意味着跟踪栈内容时不需要复杂的数据结构 —— 一个指向栈顶的简单指针就可以做到。推入和弹出也因此而非常快且准确。也可能是，持续的栈区重用往往会在  中保持活跃的栈内存，这样可以加快访问速度。进程中的每个线程都有它自己的栈。向栈中推送更多的而不是刚合适的数据可能会耗尽栈的映射区域。这将触发一个页面故障，在 Linux 中它是通过  来处理的，它会去调用  来检查栈的增长是否正常。如果栈的大小低于  的值（一般是 8MB 大小），那么这是一个正常的栈增长和程序的合理使用，否则可能是发生了未知问题。这是一个栈大小按需调节的常见机制。但是，栈的大小达到了上述限制，将会发生一个栈溢出，并且，程序将会收到一个段故障Segmentation Fault错误。当映射的栈区为满足需要而扩展后，在栈缩小时，映射区域并不会收缩。就像美国联邦政府的预算一样，它只会扩张。动态栈增长是  ，当它去访问一个未映射的内存区域，如上图中白色部分，是允许的。除此之外的任何其它访问未映射的内存区域将触发一个页面故障，导致段故障。一些映射区域是只读的，因此，尝试去写入到这些区域也将触发一个段故障。在栈的下面，有内存映射段。在这里，内核将文件内容直接映射到内存。任何应用程序都可以通过 Linux 的  系统调用（ ）或者 Windows 的  /  来请求一个映射。内存映射是实现文件 I/O 的方便高效的方式。因此，它经常被用于加载动态库。有时候，也被用于去创建一个并不匹配任何文件的匿名内存映射，这种映射经常被用做程序数据的替代。在 Linux 中，如果你通过  去请求一个大的内存块，C 库将会创建这样一个匿名映射而不是使用堆内存。这里所谓的“大”表示是超过了 设置的字节数，它的缺省值是 128 kB，可以通过  去调整这个设置值。接下来讲的是“堆”，就在我们接下来的地址空间中，堆提供运行时内存分配，像栈一样，但又不同于栈的是，它分配的数据生存期要长于分配它的函数。大多数编程语言都为程序提供了堆管理支持。因此，满足内存需要是编程语言运行时和内核共同来做的事情。在 C 中，堆分配的接口是  一族，然而在支持垃圾回收的编程语言中，像 C#，这个接口使用  关键字。如果在堆中有足够的空间可以满足内存请求，它可以由编程语言运行时来处理内存分配请求，而无需内核参与。否则将通过  系统调用（）来扩大堆以满足内存请求所需的大小。堆管理是比较 ，在面对我们程序的混乱分配模式时，它通过复杂的算法，努力在速度和内存使用效率之间取得一种平衡。服务一个堆请求所需要的时间可能是非常可观的。实时系统有一个  去处理这个问题。堆也会出现  ，如下图所示：最后，我们抵达了内存的低位段：BSS、数据、以及程序文本。在 C 中，静态（全局）变量的内容都保存在 BSS 和数据中。它们之间的不同之处在于，BSS 保存   静态变量的内容，它的值在源代码中并没有被程序员设置。BSS 内存区域是  的：它没有映射到任何文件上。如果你在程序中写这样的语句 ， 的内容就保存在 BSS 中。反过来，数据段，用于保存在源代码中静态变量 的内容。这个内存区域是  的。它映射了程序的二进值镜像上的一部分，包含了在源代码中给定初始化值的静态变量内容。因此，如果你在程序中写这样的语句 ，那么， 的内容就保存在数据段中，并且初始值为 。尽管可以通过数据段映射到一个文件，但是这是一个私有内存映射，意味着，如果改变内存，它并不会将这种变化反映到底层的文件上。必须是这样的，否则，分配的全局变量将会改变你磁盘上的二进制文件镜像，这种做法就太不可思议了！用图去展示一个数据段是很困难的，因为它使用一个指针。在那种情况下，指针  的（一个 4 字节的内存地址）保存在数据段上。然而，它并没有指向一个真实的字符串。而这个字符串存在于文本段中，文本段是只读的，它用于保存你的代码中的类似于字符串常量这样的内容。文本段也会在内存中映射你的二进制文件，但是，如果你的程序写入到这个区域，将会触发一个段故障错误。尽管在 C 中，它比不上从一开始就避免这种指针错误那么有效，但是，这种机制也有助于避免指针错误。这里有一个展示这些段和示例变量的图：你可以通过读取  文件来检查 Linux 进程中的内存区域。请记住，一个段可以包含很多的区域。例如，每个内存映射的文件一般都在 mmap 段中的它自己的区域中，而动态库有类似于 BSS 和数据一样的额外的区域。下一篇文章中我们将详细说明“”的真正含义是什么。此外，有时候人们所说的“”是指“ + BSS + 堆”。你可以使用  和  命令去检查二进制镜像，去显示它们的符号、地址、段等等。最终，在 Linux 中上面描述的虚拟地址布局是一个“弹性的”布局，这就是这几年来的缺省情况。它假设  有一个值。如果没有值的话，Linux 将恢复到如下所示的“经典” 布局：这就是虚拟地址空间布局。接下来的文章将讨论内核如何对这些内存区域保持跟踪、内存映射、文件如何读取和写入、以及内存使用数据的意义。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/03/916f9d62e323d9f101c7d545e3fc030e.jpg"]}
{"title": "我只想安静地写代码，领导却跟我谈大局、讲奉献 - 文章 - 伯乐在线", "tag": ["职场", " 3 评论 ", "职场"], "goodNum": "1", "saveNum": " 7 收藏", "sayNum": " 3 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n编者按：是的，为什么你们这帮程序猿整天就只想写代码？难道做什么不比怎么做更重要吗？但凡你对公司有点奉献精神对业务有点关心的话都不会这样，一切都是你的错，对吧？不对，《Habits That Harm Your Technical Team》作者 Marcus Blankenship 说。我面试 Jamie 的时候，他看起来就像一位狂热的工程师。技术技能可靠，对流程和产品改进有想法，也有着很好的团队合作态度，是个明显的选择。不过 2 年后，Jamie 变成了“那个家伙”。你懂的，就是那个只想不被打扰、埋头写自己代码的家伙。我本来应该注意到迹象。现在回想起来，他没有站出来说过话，他没有像我预期那样贡献自己对流程或产品的想法，而他的“团队友好”型互动通常是挖苦别人。他经常讨论技术债务，说我们缺乏创新，以及拖我们后腿的“愚蠢”决定。而他的评论和反馈显示出他已经深受“我早就告诉过你了”的情绪之困扰。Jamie 可能曾考虑过要离开公司。如果他这么做，那我就不能说了。尽管我肯定希望他离开。不过我们现在人手不足，而且我需要能找到的所有帮助。结果呢？结果还是老一套，又一位只想着写代码的程序员被孤立了。太多经理认为问题出在 Jamie 身上了。如果他是一位好一点的员工、有奉献精神的员工，或者至少多一点关心的话，都不会发生这样的事情，对吧？不幸的是，不对。冰冻三尺非一日之寒，热忱的程序员变成偏执的程序员不是一夜之间的事情。但是事情的发展速度比你想象的要快。你如何处置新程序员的想法会发出重要信号。不管好坏，这都为他们的预期做好了准备。这决定了他们会不会在将来分享更多的想法……或者闭嘴不再多管闲事。当然，一些想法在你的环境未必可行。有的可能需要“等我们没那么忙”的时候再进行讨论。有的想法看起来很好，但跟这里的潜规则是有冲突的。不管是什么理由，鄙视或者贬低你的程序员的想法，尤其是在他们刚来的几个月内做出这种举动是糟糕的做法。满腔热情被泼冷水之后，他会试着换种方式表达自己的想法，为的是想得到成功的结果。但是如果还是好心被当成驴肝肺的话，他就会意识到唯一的取胜之道就是不玩了。这恰恰是你不希望你的程序员吸取的教训。他不再提出想法，不再要求跟客户见面，并且真诚地试图去理解业务。到最后就变成了双输的局面。记住，你的程序员在提出新想法的时候其实是在冒险。想法越大，风险越大。为什么是风险？因为我们的想法反映了我们自己、我们的观点以及我们的热情。我们不会推动自己不关心或者认为不可行的想法。我们把自己最好的想法贡献出来，希望能够被接受。这需要有暴露脆弱的勇气，我们只有在相当确定不会受辱的情况才会大胆吐露自己的想法。如果我们认为自己的想法不会被接受的话，就不会再说出去了。那么你的程序员退回去只做能让自己成功的事情，也就是写代码，就是很自然的事了。令人悲哀地，他满腔的创造、创新和开发热忱都没了。也许它已经变成了对代码质量或者代码指标不切实际的想法。他对市场份额和业务健康的担忧已经被对头衔和工资的担忧所取代。他变得更加关心自己挣了多少，自己的头衔是什么，以及自己 LinkedIn 的形象怎么样。他对改变世界的热情已经被对开发过程的挑剔所替代。不过更糟糕的是，他对“我们没有开发正确的东西”的担心会被“我们没有把东西开发正确。”的担心取代。他已经学会了不对要开发什么提供输入，于是他开始对怎么去开发变得痴迷。对于他来说，你的文化已经变成了适者生存。尽管你永远都不会直接说这些，但你的培训和文化也许会教这些：“我们的公司不喜欢小人物的大想法。”“你做好开发的事情就行了。我们会找出客户想要什么的。”“你就是个程序猿。”“嗯……为什么你有十万个为什么。你没有代码可写了吗？”文化不是贴在墙上的口号，也不是在面试的时候你介绍的公司使命。文化是大家的做事之道，是大家真正关心的东西。德州农工大学教授 Ifte Choudhury 指出：文化是一群人的生活方式——行为、理念、价值观以及他们接受的象征，一般都是潜移默化，通过一代代人的沟通和模仿而传递下去的。如果你不喜欢自己看到的东西，那就去改变它。文化不是命令。而是学习、榜样以及模仿。作为领导，值得别人效仿是你的工作。因为文化不是 Jamie 的错。文化是我们的错——团队领导、软件经理以及 CTO 的错。所以，别再指责 Jamie 了，开始做出你的文化需要的改变吧。越快越好。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/03/a0d3ddbd4770543de0a261f2585f4306.jpg"]}
{"title": "6 个开源的家庭自动化工具 - 文章 - 伯乐在线", "tag": ["IT技术", "智能家居", "自动化"], "goodNum": "2", "saveNum": " 2 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n用这些开源软件解决方案构建一个更智能的家庭。 不仅是一个时髦词，在现实中，自 2016 年我们发布了一篇关于家庭自动化工具的评论文章以来，它也在迅速占领着我们的生活。在 2017， 已经使用了一些智能家居技术；预计五年内，这一数字还将翻倍。随着这些数量持续增加的各种设备的使用，可以帮助你实现对家庭的自动化管理、安保、和监视，在家庭自动化方面，从来没有像现在这样容易和更加吸引人过。不论你是要远程控制你的 HVAC 系统，集成一个家庭影院，保护你的家免受盗窃、火灾、或是其它威胁，还是节省能源或只是控制几盏灯，现在都有无数的设备可以帮到你。但同时，还有许多用户担心安装在他们家庭中的新设备带来的安全和隐私问题 —— 这是一个很现实也很 。他们想要去控制有谁可以接触到这个重要的系统，这个系统管理着他们的应用程序，记录了他们生活中的点点滴滴。这种想法是可以理解的：毕竟在一个连你的冰箱都是智能设备的今天，你不想要一个基本的保证吗？甚至是如果你授权了设备可以与外界通讯，它是否是仅被授权的人访问它呢？ 是为什么开源对我们将来使用的互联设备至关重要的众多理由之一。由于源代码运行在他们自己的设备上，完全可以去搞明白控制你的家庭的程序，也就是说你可以查看它的代码，如果必要的话甚至可以去修改它。虽然联网设备通常都包含它们专有的组件，但是将开源引入家庭自动化的第一步是确保你的设备和这些设备可以共同工作 —— 它们为你提供一个接口 —— 并且是开源的。幸运的是，现在有许多解决方案可供选择，从 PC 到树莓派，你可以在它们上做任何事情。这里有几个我比较喜欢的。 是一个设计为全栈的家庭自动化平台，包含一个服务器应用程序、触摸屏界面、Web 应用程序、支持 iOS 和 Android 的原生移动应用、以及一个运行在底层的预配置好的 Linux 操作系统。Calaos 项目出自一个法国公司，因此它的支持论坛以法语为主，不过大量的介绍资料和文档都已经翻译为英语了。Calaos 使用的是  v3 的许可证，你可以在  上查看它的源代码。 是一个有大量设备库支持的家庭自动化系统，在它的项目网站上有大量的文档，从气象站到远程控制的烟雾探测器，以及大量的第三方  。它使用一个 HTML5 前端，可以从桌面浏览器或者大多数现代的智能手机上访问它，它是一个轻量级的应用，可以运行在像树莓派这样的低功耗设备上。Domoticz 是用 C++ 写的，使用  许可证。它的  在 GitHub 上。 是一个开源的家庭自动化平台，它可以轻松部署在任何能运行 Python 3 的机器上，从树莓派到网络存储（NAS），甚至可以使用 Docker 容器轻松地部署到其它系统上。它集成了大量的开源和商业的产品，允许你去连接它们，比如，IFTTT、天气信息、或者你的 Amazon Echo 设备，去控制从锁到灯的各种硬件。Home Assistant 以  发布，它的源代码可以从  上下载。从 2016 年起， 取得了很多的进展，我们把它作为一个“可以考虑的另外选择”列在这个清单上。它使用 Perl 脚本去监视任何东西，它可以通过一台计算机来查询或者控制任何可以远程控制的东西。它可以响应语音命令，查询当前时间、天气、位置、以及其它事件，比如去打开灯、唤醒你、记下你喜欢的电视节目、通报呼入的来电、开门报警、记录你儿子上了多长时间的网、如果你女儿汽车超速它也可以告诉你等等。它可以运行在 Linux、macOS、以及 Windows 计算机上，它可以读/写很多的设备，包括安全系统、气象站、来电显示、路由器、机动车位置系统等等。MisterHouse 使用  许可证，你可以在  上查看它的源代码。（开放家庭自动化总线的简称）是在开源爱好者中所熟知的家庭自动化工具，它拥有大量用户的社区以及支持和集成了大量的设备。它是用 Java 写的，OpenHAB 非常轻便，可以跨大多数主流操作系统使用，它甚至在树莓派上也运行的很好。支持成百上千的设备，OpenHAB 被设计为与设备无关的，这使开发者在系统中添加他们的设备或者插件很容易。OpenHAB 也支持通过 iOS 和 Android 应用来控制设备以及设计工具，因此，你可以为你的家庭系统创建你自己的 UI。你可以在 GitHub 上找到 OpenHAB 的 ，它使用 。 是一个开源的硬件和软件家庭自动化系统。它的设计目标是为控制设备提供一个综合的系统，而不是从不同的供应商处将各种设备拼接在一起。不像其它的系统主要是为了方便改装而设计的，OpenMotics 专注于硬件解决方案。更多资料请查阅来自 OpenMotics 的后端开发者 Frederick Ryckbosch的  。OpenMotics 使用  许可证，它的源代码可以从  上下载。当然了，我们的选择不仅有这些。许多家庭自动化爱好者使用不同的解决方案，甚至是他们自己动手做。其它用户选择使用单独的智能家庭设备而无需集成它们到一个单一的综合系统中。如果上面的解决方案并不能满足你的需求，下面还有一些潜在的替代者可以去考虑： 是一个开源的（）家庭影院自动化工具，它只能运行在 Microsoft Windows PC 上。它允许用户去控制多媒体电脑和连接的硬件，它通过触发宏指令的插件或者定制的 Python 脚本来使用。 是一个基于 JavaScript 的物联网平台，它能够控制灯、锁、空调、多媒体、网络摄像头等等。它可以运行在任何可以运行 Node.js 的硬件上，包括 Windows、Linux、以及 macOS，它使用 。 是一个由开源软件（）构成的家庭自动化平台，它可以控制灯、锁、多媒体等等。它包含一个移动应用程序（Android 和 iOS），并且可以运行在 Linux PC 上；该公司也销售 hub，它为配置家庭自动化提供一个现成的解决方案。 标称它是你的多媒体与电子设备之间的“数字粘合剂”。它运行在 Linux（包括树莓派）上，它基于 Pluto 开源  发布，它可以用于家庭安全、电话（VoIP 和语音信箱）、A/V 设备、家庭自动化、以及玩视频游戏。，和这一类中的其它解决方案一样，是一个控制灯、报警、应用程序等等的一个开源软件。它基于 Java 和 Apache Maven，可以运行在 Windows、macOS、以及 Linux —— 包括树莓派，它以  许可证发布。 是一个专注于硬件设备和软件的开源家庭自动化框架，而不仅是用户界面。它基于  许可证，它可用于控制灯、电器、以及空调、检测温度、提醒给植物浇水。现在该轮到你了：你已经准备好家庭自动化系统了吗？或者正在研究去设计一个。你对家庭自动化的新手有什么建议，你会推荐什么样的系统？ \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/03/1503a298ec77047d9314ddceef5e4ff7.jpg"]}
{"title": "20 个 OpenSSH 最佳安全实践 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux", "OpenSSH"], "goodNum": "2", "saveNum": " 6 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nOpenSSH 是 SSH 协议的一个实现。一般通过  或  用于远程登录、备份、远程文件传输等功能。SSH能够完美保障两个网络或系统间数据传输的保密性和完整性。尽管如此，它最大的优势是使用公匙加密来进行服务器验证。时不时会出现关于 OpenSSH 零日漏洞的。本文将描述如何设置你的 Linux 或类 Unix 系统以提高 sshd 的安全性。TCP 端口 – 22OpenSSH 服务配置文件 –  (位于 ）OpenSSH 服务支持各种验证方式。推荐使用公匙加密验证。首先，使用以下  命令在本地电脑上创建密匙对：1024 位或低于它的 DSA 和 RSA 加密是很弱的，请不要使用。当考虑 ssh 客户端向后兼容性的时候，请使用 RSA密匙代替 ECDSA 密匙。所有的 ssh 密钥要么使用 ED25519 ，要么使用 RSA，不要使用其它类型。示例：下一步，使用  命令安装公匙：示例：提示输入用户名和密码的时候，确认基于 ssh 公匙的登录是否工作：更多有关 ssh 公匙的信息，参照以下文章：禁用 root 用户登录前，确认普通用户可以以 root 身份登录。例如，允许用户 vivek 使用  命令以 root 身份登录。允许 sudo 组中的用户执行任何命令。 ：使用  验证用户组。在 CentOS/RHEL 和 Fedora 系统中允许 wheel 组中的用户执行所有的命令。使用  命令将用户 vivek 添加到 wheel 组中：测试并确保用户 vivek 可以以 root 身份登录执行以下命令：添加以下内容到  文件中来禁用 root 登录：更多信息参见“” 。所有的密码登录都应该禁用，仅留下公匙登录。添加以下内容到  文件中：CentOS 6.x/RHEL 6.x 系统中老版本的 sshd 用户可以使用以下设置：默认状态下，所有的系统用户都可以使用密码或公匙登录。但是有些时候需要为 FTP 或者 email 服务创建 UNIX/Linux 用户。然而，这些用户也可以使用 ssh 登录系统。他们将获得访问系统工具的完整权限，包括编译器和诸如 Perl、Python（可以打开网络端口干很多疯狂的事情）等的脚本语言。通过添加以下内容到  文件中来仅允许用户 root、vivek 和 jerry 通过 SSH 登录系统：当然，你也可以添加以下内容到  文件中来达到仅拒绝一部分用户通过 SSH 登录系统的效果。你也可以通过 来禁用或允许用户通过 sshd 登录。也可以允许或禁止一个通过 ssh 登录系统。你需要明确禁止空密码账户远程登录系统，更新  文件的以下内容：为密匙使用强密码和短语的重要性再怎么强调都不过分。暴力破解可以起作用就是因为用户使用了基于字典的密码。你可以强制用户避开并使用来检测弱密码。以下是一个随机密码生成器（放到你的  下）：运行：输出：你需要更新 // 或 pf 防火墙配置来为 ssh 的 TCP 端口 22 配置防火墙。一般来说，OpenSSH 服务应该仅允许本地或者其他的远端地址访问。更新  实现仅接受来自于 192.168.1.0/24 和 202.54.1.5/29 的连接，输入：如果同时使用 IPv6 的话，可以编辑  （Redhat 和其派生系统特有文件），输入：将  替换为实际的 IPv6 网段。，目的是提供一种用户友好的界面。输入：更多信息请参见 “”。如果使用 PF 防火墙  配置如下：ssh 默认监听系统中所有可用的网卡。修改并绑定 ssh 端口有助于避免暴力脚本的连接（许多暴力脚本只尝试端口 22）。更新文件  的以下内容来绑定端口 300 到 IP 192.168.1.5 和 202.54.1.5：当需要接受动态广域网地址的连接时，使用主动脚本是个不错的选择，比如 fail2ban 或 denyhosts。TCP wrapper 是一个基于主机的访问控制系统，用来过滤来自互联网的网络访问。OpenSSH 支持 TCP wrappers。只需要更新文件  中的以下内容就可以使得 SSH 只接受来自于 192.168.1.2 和 172.16.23.12 的连接：在 Linux/Mac OS X 和类 UNIX 系统中参见 。暴力破解是一种在单一或者分布式网络中使用大量（用户名和密码的）组合来尝试连接一个加密系统的方法。可以使用以下软件来应对暴力攻击： 是一个基于 Python SSH 安全工具。该工具通过监控授权日志中的非法登录日志并封禁原始 IP 的方式来应对暴力攻击。\nRHEL / Fedora 和 CentOS Linux 下如何设置 。\n 是另一个类似的用来预防针对 SSH 攻击的工具。 是一个使用 pf 来预防针对 SSH 和其他服务攻击的工具。 阻止滥用 SSH 尝试登录。 可以看做是 fail2ban 的一个简化版。netfilter 和 pf 都提供速率限制选项可以对端口 22 的传入速率进行简单的限制。以下脚本将会阻止 60 秒内尝试登录 5 次以上的客户端的连入。在你的 iptables 脚本中调用以上脚本。其他配置选项：其他细节参见 iptables 用户手册。以下脚本将限制每个客户端的连入数量为 20，并且 5 秒内的连接不超过 15 个。如果客户端触发此规则，则将其加入 abusive_ips 表并限制该客户端连入。最后 flush 关键词杀死所有触发规则的客户端的连接。是通过在一组预先指定的封闭端口上生成连接尝试，以便从外部打开防火墙上的端口的方法。一旦指定的端口连接顺序被触发，防火墙规则就被动态修改以允许发送连接的主机连入指定的端口。以下是一个使用 iptables 实现的端口敲门的示例：更多信息请参见：用户可以通过 ssh 连入服务器，可以配置一个超时时间间隔来避免无人值守的 ssh 会话。 打开  并确保配置以下值：以秒为单位设置一个空闲超时时间（300秒 = 5分钟）。一旦空闲时间超过这个值，空闲用户就会被踢出会话。更多细节参见。更新  文件如下行来设置用户的警示标语：`/etc/issue 示例文件：以上是一个标准的示例，更多的用户协议和法律细节请咨询你的律师团队。禁止读取用户的  和  文件。更新  文件中的以下内容：SSH 可以模拟过时的 rsh 命令，所以应该禁用不安全的 RSH 连接。禁用基于主机的授权，更新  文件的以下选项：推荐你使用类似 、 和  等工具保持系统安装了最新的安全补丁。默认设置下用户可以浏览诸如 、 等目录。可以使用 chroot 或者其他专有工具如  来保护 ssh 连接。从版本 4.8p1 或 4.9p1 起，OpenSSH 不再需要依赖诸如 rssh 或复杂的 chroot(1) 等第三方工具来将用户锁定在主目录中。可以使用新的  指令将用户锁定在其主目录，参见。工作站和笔记本不需要 OpenSSH 服务。如果不需要提供 ssh 远程登录和文件传输功能的话，可以禁用 sshd 服务。CentOS / RHEL 用户可以使用  禁用或删除 openssh-server：Debian / Ubuntu 用户可以使用 / 删除 openssh-server：有可能需要更新 iptables 脚本来移除 ssh 的例外规则。CentOS / RHEL / Fedora 系统可以编辑文件  和 。最后 服务：如果使用 6.7+ 版本的 OpenSSH，可以尝试下：使用以下命令获取 OpenSSH 支持的加密方法：在重启 sshd 前检查配置文件的有效性和密匙的完整性，运行：扩展测试模式：最后，根据系统的的版本： – 可以使用  或  启用多重身份验证。 – 密匙链是一个 bash 脚本，可以使得基于密匙的验证非常的灵活方便。相对于无密码密匙，它提供更好的安全性。 项目。用户手册: sshd(8)、ssh(1)、ssh-add(1)、ssh-agent(1)。如果知道这里没用提及的方便的软件或者技术，请在下面的评论中分享，以帮助读者保持 OpenSSH 的安全。作者是 nixCraft 的创始人，一个经验丰富的系统管理员和 Linux/Unix 脚本培训师。他曾与全球客户合作，领域涉及 IT，教育，国防和空间研究以及非营利部门等多个行业。请在 、、 上关注他。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2013/02/linux-ssh.jpg"]}
{"title": "Git 12 岁了，为你送上 12 个 Git 的使用技巧！ - 文章 - 伯乐在线", "tag": ["IT技术", "Git"], "goodNum": "1", "saveNum": " 6 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n使用这12个Git的诀窍与技巧来令你的版本控制经验更加有用。Git，一个分布式版本控制系统，它已经成为了开源世界的源码控制默认工具，在4月7号12岁了。但是使用Git中更另人沮丧的是，你需要了解多少才能让你更有效的使用它。同时这也是使用Git中比较美妙的一件事，因为没有什么比发现一个新的小技巧来简化或提高你的工作流的效率更加令人快乐了。为了纪念Git的12岁生日，这篇文章提供12个诀窍与技巧来让你的Git经验更加有用和强大，从一些你可能会忽视的基础开始到一些真正的强大技巧!\n\n在第一次用git命令来提交一个仓库的修改，你可能会首先看到像下面这种内容：你可能还没有意识到那些命令正在修改~/.gitconfig文件的内容，这个文件就是Git存储全局配置选项的文件。通过你的~/.gitconfig文件你可要做很多事情，包括定义别名，永久的打开（或关闭）一些特定的命令选项，还可以修改Git如何工作的方面（例如：git diff使用哪个diff算法，或者默认使用什么类型的的合并策略）。你甚至可以按条件地基于路径包含其他配置文件到一个仓库！使用“man git-config”查看所有细节。在之前的技巧中，你可能会想知道在git config 命令中的—global标识是做什么的。它告诉Git更新“global”配置，也就是~/.gitconfig发现的这个配置。当然，拥有一个全局的配置代表了一个本地配置，而且足够肯定的是，如果你省略—global选项，git config 会更新这个仓库自己的配置，这个配置文件存储在.git/config。\n在.git/config中设置的选项会推翻在~/.gitconfig文件中的对应设置。因此，例如，如果你需要在一个特定的仓库中使用一个不同的邮箱地址，你可以运行“git config user.email “also_you@example.com””。然后，你在这个仓库中提交会使用你单独配置的这个邮箱地址。如果你使用一个工作的电脑在开源项目中工作，但是希望在这个项目中使用个人的邮箱地址，而其他在主Git配置中仍然使用工作邮箱，这一点是非常有用的。\n在~/.gitconfig中可以设置的任何东西，都可以在.git/config中设置来对这个仓库做特定设置。在下面的这些技巧中，当我提到在你的~/.gitconfig文件中添加什么东西，同时也说明可以在特定的仓库的.git/config中添加来设置那个选项。别名是你可以在你的~/.gitconfig文件里做的另外一件事。他的工作原理就像shell命令行里的别名——设置一个新的命令名称来调用一个或者多个其他的命令，这些命令通常包括一些特定的选项或标识。别名对于你经常使用的那些又长又复杂的命令行是非常有效的。你可以使用git config命令来定义别名——例如，执行”git config —global —add  status”命令后，会使得执行git st与执行git status做的是同样的事情——然而，我发现当定义别名的时候，只需要直接在~/.gitconfig文件里编辑通常会更加容易。如果你选择这么做，你会发现~/.gitconfig文件就是一个INI文件，INI是一种带有特定段落的基础键值对文件格式。添加一个别名时，你将改变[alias]段落。例如：上面提到的定义相同的git st别名，需要添加下面这段代码：（如果已经有了[alias]这个段落，只需要在这个段落中添加到第二行）别名不仅仅是运行其他Git子命令——你也可以定义别名，这些别名可以运行其他shell命令。这是一个很好的方法来处理一个重复的、罕见的、复杂的任务：一旦你已经想到第一次怎么做，那就使用一个别名保存这个命令。例如，我有几个仓库是我fork了一个开源项目，而且在本地做了一些修改，这些修改不用贡献给这个项目。在项目的持续的开发的过程中我想保持最新的版本，同时保留我的本地修改。为了完成这个想法，我需要定期地从upstream仓库中合并这些修改到我的fork——我定义一个别名“upstream-merge”来完成这个操作。定义如下：别名定义开始的这个“!”是告诉Git来通过shell运行这个命令。这个例子包括了运行一些git命令，但是使用这种方式定义别名可以运行任何shell命令。\n（注意：如果你想复制我的upstream-merge别名，你将需要确认你有一个Git remote命名为upstream来指定这个你fork的upstream仓库。你可以通过“git remote add upstream <URL to repo>”来添加一个。）如果你从事的是一个有很多分支活动的项目，有时可能很难掌握所有正在发生的工作以及它们之间的相关性。各种GUI工具可让你弄清楚不同分支的概况以及在所谓的“提交图”中提交记录。例如，以下是我使用提交图查看器进行可视化的一个存储卡的部分截图：\nJohn Anderson, CC BY如果你是专注于命令行的用户，就可以不在多个工具之间切换导致分心，这个工具在命令行上实现了类似图形界面的提交视图。通过 –graph 参数获取 git 的记录：John Anderson, CC BY下面的命令可以得到一样的仓库可视化片段：–graph 选项将图表添加到日志的左侧，–abbrev-commit 存储提交使用了  方法，          –date=relative 表达式用相对的术语来表示日期，并且  –pretty 以 bit 格式处理自定义格式。我知道 git lg 的别名，它是我最常运行的10个命令之一。有时，就跟你尽量避免使用它一样困难的是，你会发现你需要运行 git push –force 来覆写你仓库的远程副本上的历史记录。你可能已得到了一些反馈，他们会要求你进行交互式的变基(rebase)，或者你可能已经搞砸了，并且希望隐藏证据。当他人在仓库的远程副本的同一分支上进行改动后，会发生强制推送的风险。当你强制推送已重写的历史记录时，某些提交将会丢失。这是 git push –force-with-lease 出现的原因 – 如果远程分支已更新，它不会允许你执行强制推送，这将确保你不会丢弃他人的工作。你是否使用过git commit -a在一次行动中提交你所有未完成的修改，只有在你push完你的提交后才发现git commit -a忽略了新添加的文件？解决这个问题你可以用git add -N（“通知”）来告诉Git你想把新添加的文件包含在提交中在你第一次实际提交之前。一最佳的实践为当使用Git时确保每个提交只包含一个逻辑更改–不管是修复一个bug还是（实现）一个新功能。然而，有时当你工作，会在你的仓库中出现一个以上的修改提交。你怎么样把事情分开，使每个提交只包含适当的修改呢？git add –patch来解救！这个标志将会使git add命令查看你工作副本中所有的变更，询问你是否愿意将它提交，跳过，或者推迟决定（还有其他一些更强大的选项，你可以通过在运行这命令后选择？来查看）。git add -p是一个神奇的工具来生产结构良好的提交。与 git add -p类似，git checkout命令将使用 –patch 或 -p 选项，这会使 git 在本地工作副本中展示每个“大块”的改动，并允许丢弃对应改动 —— 简单地说就是恢复本地工作副本到你改变之前的状态。某些场景下这非常有用，例如，在你跟踪一个 bug 时引入了一堆调试日志语句，在修正了这个 bug 之后，你可以先使用 git checkout -p 删除所有新加的调试日志，之后使用 git add -p 来添加 bug 修复。没有比组合一个极好的、结构良好的提交更令人满意的了！有些项目有一条规则，即存储库中的每个提交都必须处于可工作状态 – 也就是说，在每次提交时，代码应该是可编译的，或运行测试套件应该不会失败的。当你在某分支上工作时间长时，但如果你最终因为某种原因需要rebase时，那么跳过每个变基后的提交以确保你没有意外引入一个中断是有些冗长乏味的。幸运的是，git rebase已经支持了-x或–exec选项。git rebase -x <cmd>将在每次提交应用到rebase后运行该命令。因此，例如，如果你有一个项目，其中npm run tests会运行你的测试套件，那么在rebase期间应用每次提交后，git rebase -x npm run tests将会运行测试套件。这使你可以查看测试套件是否在任何变基后的提交中有失败情况，因此你可以确保测试套件在每次提交时仍能通过。很多Git子命令都接受一个修正的参数来决定命令作用于仓库的哪个部分，可能是某次特定的提交的 sha1 值，或者一个分支的名称，又或者是一个符号性的名称如 HEAD（代表当前检出分支最后一次的提交），除了这些简单的形式以外，你还可以附加一个指定的日期或时间作为参数，表示“这个时间的引用”。这个功能在某些时候会变得十分有用，比如当你处理最新出现的 bug，自言自语道：“这个功能明明昨天还是好好的，到底又改了些什么”，不用盯着满屏的 git 日志的输出试图弄清楚什么时候更改了提交，您只需运行 git diff HEAD@{yesterday}，会看到从昨天以来的所有修改，这也适用于较长的时间段（例如 git diff HEAD@{‘2 months ago’}） ，以及一个确切的日期（例如git diff HEAD@{‘2010-01-01 12:00:00’}）。您还可以将这些基于日期的修改参数与使用修正参数的任何 Git 子命令一起使用。在 gitrevisions 手册页中有关于具体使用哪种格式的详细信息。你是不是试过在 rebase 时干掉过某次提交，后来又发现你需要保留这次提交的一些东西？你可能觉得这些提交的东西已经永远找不回来了，只能从头再来了。其实不然，但如果你在本地工作副本中提交了，提交就会进入到 “引用日志” ，你仍然可以访问到。运行 git reflog 将在本地工作副本中显示当前分支的所有活动的列表，并为您提供每个提交的 SHA1 值。一旦发现你 rebase 时放弃的那个提交，你可以运行 git checkout  来检出该次提交，复制好你需要的信息，然后再运行 git checkout HEAD 返回到分支最新的提交去。希望这些技巧中至少有一个能教你一些关于 Git 的新知识，Git 已经 12 岁了，在这个持续创新，不断添加新特性的项目里，你最喜欢哪个技巧？\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/04/e38d25144c3ef2d81d73a884cacbf9c2.jpg"]}
{"title": "100 倍价值的工程师 - 文章 - 伯乐在线", "tag": ["职场", " 5 评论 ", "程序员", "职场"], "goodNum": "2", "saveNum": " 5 收藏", "sayNum": " 5 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n【导读】：工程师如何花同样的时间比其他人生产的价值多100倍：知道自己在做什么，不需要别人过多干预；不断对自己发出挑战，使工作更有效；一个人是无法成为100 倍价值工程师的，需要带动周围人一起提升生产力。几个月前一个新工程师加入了我们的团队。和往常一样，我花了些时间和他相处，来更好地了解他是哪种类型的人、他的驱动力是什么。我们经常讨论过去的经历，但更重要的是：未来的目标。结果发现，他有个有趣的目标：野心勃勃。我喜欢。但是，这让我思考了一个问题：成为“最好的程序员”实际上意味着什么。怎么衡量“好”？怎么知道他（她）是“”？这让我想起了上世纪 60 年代，Sackman、 Erikson 和 Grant 撰写的论文《Exploratory Experimental Studies Comparing Online and Offline Programming Performance》。该研究的目的是调查程序员在编程的多个方面的表现，无论他有电脑——那时是主机——的交互权限还是用“纸和笔”高效工作。尽管这个问题的答案几乎要过时了——谁还在纸上编程啊——仍然有几点发现现在仍然适用：研究对象中，最好和最差的程序员完成一个编程练习所用的编程时间有 的差距。调试时间有的差距。所写程序大小有差距。程序执行速度有 差距。研究对象都有几年的经验，事实上经验年数对这些数字似乎没有显著的影响。总之，差距还是挺显著的，不是吗？“10 倍价值程序员”这个概念起源于这篇论文。这个概念吸引了人们数十年，而且及其有争议。（10x programmer）。公平来讲，Sackman 等人的数字一定被夸大了，很多人都对他们的方法提出了质疑。但是几乎没有人反对在糟糕的程序员与优秀的程序员之间有着显著差距。甚至据传，每个人都认识一个人，他能在极短时间内写出惊人的软件。“所以……谁在乎？”你可能会问。为什么 10 倍价值程序员这么重要呢？一方面来说，10 倍价值程序员至少表面上对雇主来说是桩好买卖。理论上，雇主可以：1.炒掉 90% 的员工2.剩余 10% 雇佣 10 倍价值程序员3.付给他们大约 2 倍工资4.盈利简单，对吧？然而现实会有点不一样。首先，这假设你能招到一个 10 倍价值程序员的团队……祝你好运。由于你很可能做不到这一点，你得把他们整合进现存的一倍价值程序员团队中去。结果发现，团队中有一个比你高产的程序员并不是那么鼓舞人心。但是实际上，我不想太过详述 10 倍价值程序员这个概念。因为在我看来，有这么一群不同的“人种”，他们的影响力远超过 10 倍价值程序员。是谁呢？我们先来仔细研究一下“程序员”这个概念。在 Sackman 的研究中，他们完全只关注编程能力。练习是高度与算法相关的，像“假定某网格代表一个迷宫，编写一个程序找到通路”这样的类型。好“程序员”擅长这种类型的工作：输入编程挑战，输出代码。每个程序员都有自己的任务列，并且在逐个完成。输入代码。如果这是你喜欢的工作，我肯定你能找到如此工作的地方。然而，在我曾经工作的任何地方，实际编程都不是这样的。实话实说——谢天谢地。我觉得长期这样编程会无聊透顶的。我觉得更有趣的角色是的角色。工程师把想法变成实实在在的产品，他们也因此有更广阔的视野。他们手头有大量工具可以完成工作，当然编程也是工具之一。但是实话实说，并且我想我也可以在此说，我们真的超级不擅长在那些被过分吹嘘的技能。（a）行业均值：“每 1000 行代码中大约有 15 到 50 处错误。”他进一步声明这对那些背后有一定程度结构化编程、可能混有一些代码技巧的代码具有代表性。（b）微软应用：“内部测试时每 1000 行代码中大约有 10 到 20 处错误，发布产品中每 1000 行代码中大约有 0.5 处错误（Moore 1992）。”他将其归功于代码阅读技巧和独立检测的组合（在其著作的另一章中有进一步讨论）。（c）“Harlan Mills 开创了名为 ‘cleanroom development’ 的技巧，能实现在内部测试时每 1000 行代码有 3 处错误，在发布产品中每 1000 行代码有 0.1 处错误（Cobb 和 Mills 1990）。几个项目——例如飞船软件——利用了格式开发方法系统、同行审查和统计测试实现了在 500,000 行代码中有 0 处错误的水平。要我说——我们应该尽力避免编程，使世界免受每次在集成开发环境（IDE）中按下某键产生的所有 bug 的侵害。所以没错，10 倍价值程序员是个好主意，但是我要把门槛设置得高一点。到 2018 年了，世界已经变了。…………我喜欢延伸目标。它们经常引导我们后退一步，并带来思维的巨大转变。这个目标也一样。如果我们想成为 100 倍价值工程师——其影响力是老一倍价值工程师的 100 倍，该怎么实现呢？高产并不够——当然单单有编程天赋就可能实现 10 倍价值，但达到 100 倍价值就不可能了。尽管 100 倍价值听起来很极端，我在职业生涯中仍然和许多我认为有“100 倍价值的观念模式”、独特的思考、说话和行动方式的人合作过。可能让某些人吃惊的是，这些与编程能力、科技和编程语言没有任何关系。常见的口号是：“为什么我们还在用 Java？如果我们能只用 Scala、Clojure、Node，<<在此输入今日便好 insert flavor of the day here>>就会更高产！”现实是，一种不同的编程语言可能最多让你达到 1.5 倍到 2 倍。这与 100 倍价值相比简直是小巫见大巫。100 倍价值是完全不同的游戏。所以，到底什么是“100 倍价值的的观念模式”？让我们一起来讨论两个方面。100 倍价值工程师掌控他们所做的事。他们知道为什么这么做、怎么做、所做的是什么。在这本书中，两位前海豹突击队队员解释了他们的极端所有权（extreme ownership）概念。这个概念的核心是，当我说“拥有某物”时到底意味着什么。这意味着：接受你要对你所做的任何事情负责。最重要的是这意味着：。这不意味着所有事情都在你的控制之下，却意味着：当事情不可避免地出错时，你要对你如何反应负责。这意味着：你要负责预期可能发生的事情，并做好应急措施。这意味着你要从错误中学习，甚至从中汲取价值。掌控你所做事情的各个方面。要得到这种程度的所有权，我只知道一个方法：挑战。挑战你和被要求做的任何事情，这样你能理解并掌控每一个决定。100 倍价值工程师在三个维度进行挑战：1.这主要是关于范围的：我们在开发什么？是否仔细研究过？要求是否明确？我们确定所有这些都是重要的并且需要（马上）完成吗？2.这是关于在怎样机智地执行某事。有可以得到同样结果的更轻松方法吗？这也是关于过程的：我们怎么样得到想要的结果，以及怎样提高？3.这是关于业务环境的、关于完全理解为什么需要开发某个特性并检查产品经理的方法是否是满足用户需求的正确方法。来逐个看看更多细节。更快地提供某产品的唯一最好方法是：缩减范围。它拥有的特性是什么。可以在此应用我的“5 个真的吗？”技巧：产品经理：我们需要有所有这 10 个特性100 倍价值工程师：真的吗？产品经理：嗯。100 倍价值工程师：真的吗？产品经理：好吧，好吧，可能不需要第七个特性。但是剩下的都要。100 倍价值工程师：真的吗？产品经理：嗯，是的，我是这么想的……让我跟客户确认一下。好吧，他们可能需要第四个和第五个特性，但是我们可以之后再做这两个。剩下的都是必须的。100 倍价值工程师：真的吗？产品经理：是的。这可能听起来像个玩笑，但是产品经理常常会拿一张长长的必需特性清单出现。然后经过几小时、几天、有时是几个月的谈判后，你得到了一张几乎只有原清单四分之一的清单。这是自然的，想出要加上的新特性要比移除特性更容易。另一个在将范围降低到较低水平的方法，是使用“帕累托法则”，二八法则。：帕累托法则（也叫二八法则，关键少数法则，或者稀疏因子法则）表明，对很多事件来说，大约 80% 的影响来自于 20% 的原因。该法则有很多应用，软件开发就是其一。往往有很多种实现某特性的方法，使用极少的精力（比如说 20%）就能带来大多数收益（例如 80%）。这点吸引人，不仅仅是因为更少的工作量，还因为你能更经济地彻底检查特性，并且只在这些特性有价值、使用过后才进行完全开发。既然已经减少到一小部分了，仍然要通过挑战特性的实现方法来获得机动空间和好处。一般来说，实现某特性有很多方法。一旦团队想出一种方法，很多团队就满意了。100 倍价值工程师总会进一步寻找替代方法，根据各自的优缺点评估所有选择。“怎么做”也会被技术债务影响。经常有“变态的”方法来实现某些快、脏的特性，“合适的”方法来首先还清技术债务，再干净地实现特性。什么是最好的方法？100 倍价值工程师认识到不只有一个正确答案，并且这取决于不同情况和累积技术债务的费用。一个 100 倍价值工程师能在不同的情景中作出正确抉择，能在合适的时机和产品谈判来降低技术债务。“怎么做”的另一个方面是过程。我对 Scrum 很喜欢的一点是，它能有效设定一个基础，如果用得合适可以鼓励 100 倍价值的行为：•是讨论和挑战做什么、怎么做和为什么的好平台。产品所有者提出要开发的新特性，开发团队挑战做什么和为什么，来得到全面的背景，并相互挑战如何实现特性。• 针对下一步冲刺（sprint）做什么的计划也是通往“辉煌和头脑”的手段：记起到底需要做什么，并且计划团队如何合作来交付产品• 是团队提升的方法。在一次冲刺循环中，有些事情出错了，有些事情进展不顺利。回顾是 100 倍价值工程师挑战团队来提升、下次做得更好的时刻。回顾也能练习所有权。100 倍价值工程师不抱怨低产，不指向自己以外的其他人。上周我和一个工程师聊了聊，他刚刚发现自己花了整整 3 个月时间实现某特性，后来有发现对用户来说同样的价值本可以在 3 日内实现。显然不会是同一种功能，但是实现的目标是一样的。这种事情怎么会发生呢？除非工程师退后一步、扩大视野、挑战为什么，这种事情就会发生。为什么要开发这个特性？用户想要实现什么？他们的需求是什么？产品经理往往会提出非常具体的特性要求，偶尔具体化程度会比较低。他们的出发点是好的。然而更可能的情况是：产品经理也是人，也会遗漏。此外，风险在于工程师不再挑战更基础的问题：为什么我们要这么做？不是还有用其他更少的精力实现同样结果的方法吗？说起来容易做起来难。做起来也应该难，不是什么人都应该能跻身 100 倍价值工程师。然而，我们都可以渴望变得更好，并找到相应的方法。因此，看看 100 倍价值工程师的技能集合是值得的。你会注意到，这与 10 倍价值程序员是非常非常不同的。•——这点几乎明显得不用提了，但是它是重要的一点。100 倍价值工程师有优秀的沟通技巧。沟通是拥有 100 倍影响力的关键部分。•——显然这在 10 倍价值程序员中是常见的，但是所要求的创造力不是关于算法的，也不是关于灵巧的类继承结构（class inheritance structures）的，而是关于想出更有效的方法来实现目标。•——在“挑战所有”的长篇大论中隐藏着“生产力挑战”。那么我这么说意味着什么？让我用我的大儿子做例子来解释一下。他 4 岁了。4 岁小孩最喜欢的问题是什么？“为什么！？”这意味着我儿子是个 100 倍价值工程师吗？不。为什么不呢？因为他总是问“为什么？”，无论时机正确与否，无论有没有意义，无论他是不是让他的父母想自杀。拥有知道该挑战什么、怎么挑战和何时挑战的同理心也是 100 倍价值工程师的重要技能。•——好主意被高估了。人人都有好主意，但几乎没人真正实现这些想法。你知道需要实现一个想法，实现它的一个重要因素就是谈判——与其他开发人员谈判，与产品经理谈判，与其他利益相关者谈判。解释为什么某个主意是个好主意，以及为什么需要时间执行它们。100 倍价值工程师知道怎么做。所以当他们在场时，所有事情都似乎有可能实现。•——这是清单上的最后一点，但依然重要。虽然大多数提到的技巧都是“软实力”，但这并不意味着 100 倍价值工程师不需要技术。事实上，他（她）拥有领先的技术天赋是先决条件，原因有二：（1）挑战技术层面上的事情会产生巨大收益，也因此要求对技术有深层次的理解；（2）是重要的，如果 100 倍价值工程师没有高技术，就不会被同辈接受。你得是“我们的一员”。…………几个月后，“我想成为世界上最好的程序员”先生作为程序员工作得非常顺利。他有天赋、努力工作、高产而且非常聪明。他会成为世界上最好的程序员吗？我不知道。但是私下里，我希望这不重要。我希望某一天，不是现在，但是可能是几年后，他会想做更多事。那时他会调整他的理想，不仅仅要擅长这个叫“编程”狭窄领域，而且渴望拥有 100 倍价值工程师的影响力。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2017/11/90129c6662feee86738bd3663ce83108.png"]}
{"title": "为什么浏览器的用户代理字符串以 Mozilla 开头 - 文章 - 伯乐在线", "tag": ["IT技术", "浏览器"], "goodNum": "2", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n最早流行的浏览器是 NCSA Mosaic，它称自己为 NCSA_Mosaic/2.0 (Windows 3.1)；后来一个新浏览器出现了，它的名字叫 Mozilla，是 Mosaic Killer 的缩写，Mosaic 并不觉得这好笑，因此该浏览器改名为 Netscape，它称自己为 Mozilla/1.0 (Win3.1)。Netscape 支持框架（frame），而 Mosaic 不支持，因此用户代理嗅探（User Agent sniffing）出现了，网站在检测到 Mozilla 后就发送框架，如果不是就不发送。后来微软开发了 IE，希望它成为 Netscape Killer，IE 也支持框架，但由于它不是 Mozilla，网站没有向它发送框架。微软没有耐心等待网站修改而是声称它兼容于 Mozilla，因此冒充 Netscape 称自己为 Mozilla/1.22 (compatible; MSIE 2.0; Windows 95)。第一次浏览器战争以 Netscape 的失利结束，但 Netscape 以 Mozilla 的名字获得了新生。Mozilla 构建了 Gecko，称自己为 Mozilla/5.0 (Windows; U; Windows NT 5.0; en-US; rv:1.1) Gecko/20020826。Gecko 是一个渲染引擎，Mozilla 在此基础上开发了 Firefox，它称自己为 Mozilla/5.0 (Windows; U; Windows NT 5.1; sv-SE; rv:1.7.5) Gecko/20041108 Firefox/1.0。因为 Gecko 好于 IE，因此用户代理嗅探又出现了，网站在检测到 Gecko 后会提供更好的页面代码。Linux 上的浏览器 Konqueror 使用的渲染引擎是 KHTM，它只能冒充 Gecko 称自己为 Mozilla/5.0 (compatible; Konqueror/3.2; FreeBSD) (KHTML, like Gecko)。Opera 则提供了选项，让用户想冒充哪个浏览器就冒充哪个浏览器。苹果后来创建了 KHTML 的一个分支 WebKit，称自己为 Mozilla/5.0 (Macintosh; U; PPC Mac OS X; de-de) AppleWebKit/85.7 (KHTML, like Gecko) Safari/85.5。这就是为什么浏览器的用户代理字符串以 Mozilla 开头。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/03/47a58f731472797655f14eeebe80e7d7.png"]}
{"title": "如何统计 Linux 中文件和文件夹/目录的数量 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n嗨，伙计们，今天我们再次带来一系列可以多方面帮助到你的复杂的命令。 通过操作命令，可以帮助您计数当前目录中的文件和目录、递归计数，统计特定用户创建的文件列表等。在本教程中，我们将向您展示如何使用多个命令，并使用 、、 和  命令执行一些高级操作。 下面的命令将可用在多个方面。为了实验，我打算总共创建 7 个文件和 2 个文件夹（5 个常规文件和 2 个隐藏文件）。 下面的  命令的输出清楚的展示了文件和文件夹列表。统计当前目录的文件（不包括隐藏文件）。 运行以下命令以确定当前目录中有多少个文件，并且不计算点文件（LCTT 译注：点文件即以“.” 开头的文件，它们在 Linux 默认是隐藏的）。 ： 列出目录内容 ： 使用长列表格式 ： 列出有关文件的信息（默认为当前目录） ： 将一个程序的输出发送到另一个程序进行进一步处理的控制操作符 ： 打印符合模式的行 ： 通用输出控制 ： 以“-”开头的行（ 列出长列表时，行首的 “-” 代表普通文件）统计当前目录包含隐藏文件在内的文件。 包括当前目录中的点文件。运行以下命令来计数当前目录的文件和文件夹。 它会计算所有的文件和目录。 ： 列出目录内容 ： 使用长列表格式 ： 将一个程序的输出发送到另一个程序进行进一步处理的控制操作符 ： 这是一个统计每个文件的换行符、单词和字节数的命令 ： 输出换行符的数量统计当前目录包含隐藏文件和目录在内的文件和文件夹。递归计算当前目录的文件，包括隐藏文件。 ： 搜索目录结构中的文件 ： 文件类型 ： 常规文件 ： 这是一个统计每个文件的换行符、单词和字节数的命令 ： 输出换行符的数量使用  命令输出目录和文件数（不包括隐藏文件）。使用包含隐藏文件的  命令输出目录和文件计数。运行下面的命令递归计算包含隐藏目录在内的目录数。根据文件扩展名计数文件数量。 这里我们要计算  文件。组合使用  命令和  命令统计当前目录中的所有文件。  表示当前目录中的文件数量。组合使用  命令和  命令来统计当前目录中的所有目录。 第二个  表示当前目录中的目录数量。组合使用  命令和  命令来统计当前目录中的所有文件和目录。  表示当前目录中的目录和文件的数量。统计系统（整个系统）中的文件数。统计系统（整个系统）中的文件夹数。运行以下命令来计算系统（整个系统）中的文件、文件夹、硬链接和符号链接数。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "Linux 与 Unix 之差异 - 文章 - 伯乐在线", "tag": ["IT技术", " 3 评论 ", "Linux", "Unix"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": " 3 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n在计算机时代，相当一部分的人错误地认为  和  操作系统是一样的。然而，事实恰好相反。让我们仔细看看。在 IT 领域，以操作系统而为人所知的 Unix，是 1969 年 AT&T 公司在美国新泽西所开发的（目前它的商标权由国际开放标准组织所拥有）。大多数的操作系统都受到了 Unix 的启发，而 Unix 也受到了未完成的 Multics 系统的启发。Unix 的另一版本是来自贝尔实验室的 Play 9。作为一个操作系统，Unix 大多被用在服务器、工作站，现在也有用在个人计算机上。它在创建互联网、计算机网络或客户端/服务器模型方面发挥着非常重要的作用。支持多任务相比 Multics 操作更加简单所有数据以纯文本形式存储采用单一根文件的树状存储能够同时访问多用户账户 单核操作系统，负责低级操作以及由用户发起的操作，内核之间的通信通过系统调用进行。  系统工具  其他应用程序这是一个基于 Unix 操作系统原理的开源操作系统。正如开源的含义一样，它是一个可以自由下载的系统。它也可以通过编辑、添加及扩充其源代码而定制该系统。这是它最大的好处之一，而不像今天的其它操作系统（Windows、Mac OS X 等）需要付费。Unix 系统不是创建新系统的唯一模版，另外一个重要的因素是 MINIX 系统，不像 Linus，此版本被其缔造者（Andrew Tanenbaum）用于商业系统。Linux 由 Linus Torvalds 开发于 1991 年，这是一个其作为个人兴趣的操作系统。为什么 Linux 借鉴 Unix 的一个主要原因是因为其简洁性。Linux 第一个官方版本（0.01）发布于 1991 年 9 月 17 日。虽然这个系统并不是很完美和完善，但 Linus 对它产生很大的兴趣，并在几天内，Linus 发出了一些关于 Linux 源代码扩展以及其他想法的电子邮件。Linux 的基石是 Unix 内核，其基于 Unix 的基本特点以及  和单独的 。看起来，该操作系统官方名字取自于 ，其中其操作系统名称的尾部的 “x” 和 相联系。同时运行多任务（多任务）程序可以包含一个或多个进程（多用途系统），且每个进程可能有一个或多个线程。多用户，因此它可以运行多个用户程序。个人帐户受适当授权的保护。因此账户准确地定义了系统控制权。 的 Logo 作者是 Larry Ewing，他选择这个企鹅作为他的开源 的吉祥物。 最初提出这个新的操作系统的名字为 “Freax” ，即为 “自由（free）” + “奇异（freak）” + x（UNIX 系统）的结合字，而不像存放它的首个版本的 FTP 服务器上所起的名字（Linux）。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/02/94188358677004b2795678cd879cb6ec.jpg"]}
{"title": "为初学者准备的 MariaDB 管理命令 - 文章 - 伯乐在线", "tag": ["IT技术", "MariaDB", "数据库"], "goodNum": "1", "saveNum": "  收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n之前我们学过了，使之成为了 RHEL/CentOS 7 的默认数据库。现在我们再来看看一些有用的 MariaDB 管理命令。这些都是使用 MariaDB 最基础的命令，而且它们对 MySQL 也同样适合，因为 MariaDB 就是 MySQL 的一个分支而已。（推荐阅读：）要查看所安装数据库的当前版本，在终端中输入下面命令：该命令会告诉你数据库的当前版本。此外你也可以运行下面命令来查看版本的详细信息：要登录 MariaDB 服务器，运行：然后输入密码登录。要列出 MariaDB 当前拥有的所有数据库，在你登录到 MariaDB 中后运行：（LCTT 译注： 这里代表 shell 的提示符， 这里代表 MariaDB shell 的提示符。）在 MariaDB 中创建新数据库，登录 MariaDB 后运行：若想直接在终端创建数据库，则运行：这里， 就是新数据库的名称。要删除数据库，在已登录的 MariaDB 会话中运行：此外你也可以运行， 若在运行  命令时提示 “access denied” 错误，这应该是由于我们没有给 root 授权。要对 root 授权，请参照第 7 点方法，只是要将用户改成 root。为数据库创建新用户，运行：授权用户访问某个数据库，运行：这会赋予用户  对名为  的数据库完全操作的权限。我们也可以限定为用户只赋予 、、 权限。要赋予访问所有数据库的权限，将  替换成  。像这样：要创建单个数据库的备份，在终端窗口中运行下列命令，若要一次性创建多个数据库的备份则运行：要一次性导出多个数据库，则运行：要从备份中恢复数据库，运行：但这条命令成功的前提是预先没有存在同名的数据库。如果想要恢复数据库数据到已经存在的数据库中，则需要用到  命令：本例中我们会修改  的密码，但修改其他用户的密码也是一样的过程。登录 MariaDB 并切换到 ‘mysql’ 数据库：然后运行下面命令：下一步，重新加载权限：然后退出会话。我们的教程至此就结束了，在本教程中我们学习了一些有用的 MariaDB 管理命令。欢迎您的留言。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2014/04/d4136217171de6597b19a097f0127e0c.png"]}
{"title": "独立游戏开发者：我做对了所有事、但还是赔掉了房子 - 文章 - 伯乐在线", "tag": ["IT技术", "游戏"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nGameLook报道/随着游戏行业的竞争加剧，成功的概率变得越来越低。前不久，海外开发者Constantin Bacioiu在博客中表示，辞职做全职独立游戏研发之后，他赔掉了刚买的房子，因为游戏发布一个月的销量还不到200套，离最低目标都还差很远。Bacioiu从业经验超过7年，接触游戏研发超过10年，而且事前做了相对充分的准备，但他的《Ebony Spire: Heresy》为何还是如此惨败呢？以下是GameLook整理的内容：现在并不是我写博客的最佳时机，在进入全职独立游戏研发之前，家人、朋友和网上的同行们都劝过我不要这么做。但我觉得可以做得到，我只需要在Steam平台卖出700套就算是成功了。结果是，还差很远。我从业已经超过7年，曾在Gameloft以及Mobility-Games等公司做过外包，也做过兼职独立游戏开发者，在自行发布之前，还做过多款游戏，随着Steam平台的影响力、用户和收入的增加，我本来觉得自己是很有把握的，但现在，我已经不太确定自己的房子是否还保得住了。游戏截图2006年的时候，实际上我就已经用Basic和C++在游戏创造者论坛里做游戏了，当时还没有能够用得起的引擎，所以我费了九牛二虎之力学会了制作自己的工具，通过一些DirectX 以及OpenGL的wrappers作为引擎创作的基础。经过了10多年之后，我觉得通过我、我的团队以及我自己的计划，已经对游戏研发掌握了一定的知识和经验，虽然从来没有想过凭着游戏研发暴富，但觉得至少生存不成问题。2017年9月份的时候，我辞掉了全职工作，银行卡里有了足够让我支撑4个月的资金，并且希望最新研发的游戏能够带来更多收入，让我再撑过去6个月，这样我就能完成下一款游戏的研发，然后再决定做什么。最坏的情况下，我可以找一份工作做几个月，然后再次尝试独立游戏研发。但我从来都没有想到，游戏发布之后，我连4个月都没有撑到。在这里，我希望先告诉同行们的是，根据我的经验，在游戏研发之外，一定要做调研，学习并阅读所在地区的法律，提前做规划。我当时的确有支撑4个月的研发资金，而且我的游戏只需要再投入一个月就可以完成，但即使我按最坏的情况考虑，仍然是不足的。在辞职去做全职独立游戏研发之前，至少要在你认为可以支撑下去的资金基础上乘以3，这是最最重要的。在写辞职信的时候，我已经就开始准备书面文件了，我有注册资金，也了解了如何开一家公司，但却没有调研运营一家公司需要什么。而且，我说的不是办公室成本，只是日常的应对官僚主义开支，总的来说，注册公司和被通过只用了100美元不到。在准备了所有书面文件之后就遇到了第一个障碍，在我的国家，官僚主义现象十分严重，而且存在很多隐形成本，你还需要准备大量的额外书面工作，我甚至不得不签字打印一份给IRS（美国国税局）的保证书，内容如下：如果我通过银行转账收到一笔1.5万美元或者以上的资金，保证不用于洗钱并且向IRS报告资金流向，这个保证书用了150美元，比注册公司还贵。我选择找一名会计帮我做帐，希望能够避免一些不必要的麻烦，因此产生了每月30美元的费用，公证员给他的书面文件价格是80美元，而我需要两份，所以一开始我就遇到了超出预算190美元的开支。总的来说，开公司的费用比我预期的多了550美元。在2017年初的时候，我选择给自己买一套公寓，开公司之后把它当作了办公室，由于开发商没有尽职，所以我又投入了不少资金把公寓打理好（比如通电）。但后来我发现，当他们把电源关了之后，我只能卷铺盖去女朋友的居所，我也想起诉他们带来的损失，但没有那个律师费。这时候，实际开支又比预算多了5-600美元，这时候已经两个月过去了，你们可能会发现我还没有提到游戏研发的事情。虽然我的继续已经被减少了一半，但仍决定继续做独立游戏研发，我决定完成游戏并且发布到Steam，并且希望能够在11月底之前卖出去300套，总销量希望可以达到700套，这就足够支撑我一段时间了。游戏研发完成的很顺利，至少我从业10年的经验证明是有用的。我知道控制自己的预期，可能遇到什么问题，实际上游戏研发所用的时间比之前预计的还少了2天，我做了Steam报告，在Linux以及Windows平台做了测试而且没有重大bug。我在Steam做的beta测试很顺利，而且解决了反馈的所有问题。发布当天，我兴奋地把游戏发给认识的所有人，而且选择了整个11月游戏发布数量最少的一天，可能有人觉得这样似乎赢面很大。‘’被推荐截图我此前也参与过几款其他游戏的发布，但从没有像这款游戏带给我这么大的压力。按照我的经验，在发布之前两周，Steam愿望列表会每天更新一次，销量也会实时更新。我的游戏发布时间是当地晚上，所以购买游戏的很少。点了游戏发布按钮之后，我的游戏出现在了新游戏列表中，而且Discord平台的直播观看者也纷纷表示将会购买游戏，而且看到Steam好友里有一些人在玩，如果不出意外，我认识的人也能带来最高50套销量。需要注意的是，我做了力所能及的所有营销，给187个评测者和网站发了邮件，Twitter也有50次转发和1万次浏览量，我已经降低了预期，但没有想到结果还是差距如此之大。数小时之后，我发现有500人把它放进了愿望列表，销量达到60套，我当时还以为是Steam没有更新销售数据。第二天早上起来才发现，累计销量只有68套，而且是出现在新游戏推荐列表的情况下，我实在是难以置信。搜索相关结果之后我才发现，原来在我的游戏发布当天，没有一个Youtube视频出现、没有一家给出评测，也没有人传播游戏发布的消息。到了游戏论坛，我发现也只是有人提到了一些很小的bug，我几乎每天都做游戏补丁，提高游戏质量。我当时觉得，或许如果我持续改进游戏、听取反馈意见，他们就会发现我是一个很好的开发者，玩家们就一定会注意到，媒体也会看到。然而，经过了三周高频率更新之后，我甚至做了一个大版本更新，但结果却只是增加了不到90套销量。这期间，开始有人注意到了我的游戏，甚至有了一些支持者。但是，虽然Steam平台有三种语言的好评，但加起来也只有9个评价（目前增长到17个），甚至达不到Steam给出好评的标准要求。虽然在此期间我也一直在推广游戏，但很明显，300套的销量已经是没有希望了。所以，按照这个趋势下去，我将连房贷都还不起了，甚至会失去买来的房子，没有经济来源然后衣食住行都成问题。对于独立游戏研发，我从来没有太大的奢望，我只希望能够做一个底层开发者，足够谋生就可以。但很明显，我失败了。所以我的教训是，除非你能接受非常大的失败，否则不要做全职游戏研发，确保在游戏销量为0的情况下也能生存，这样才可以做全职研发。至于未来，我仍会继续更新游戏，但再也没有时间重新做一款游戏并且把所有希望都押在上面了。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/02/f8f720746dbbd4eaf269090ae70b7b53.jpg"]}
{"title": "Python 是各年龄段开发者最爱的语言 - 文章 - 伯乐在线", "tag": ["开发", " 3 评论 ", "Python", "编程语言"], "goodNum": "2", "saveNum": " 1 收藏", "sayNum": " 3 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n在 HackerRank 的 2018 开发者技能调查中，，但根据 HackerRank 的爱恨指数数据，Python 赢得了全年龄段开发者的芳心。开发者喜欢哪种语言？注：语言偏好图是基于爱恨指数（Love-Dislike Index），这个指数 = （喜欢某语言的开发者的百分比） – （不喜欢相同语言的开发者的百分比）。这有助于我们确定给定编程语言或框架的正面或负面情绪。100％的成绩=最喜欢的成绩，-100％的成绩 = 最不喜欢的成绩。PythonCC++、JavaJavaScript注：PythonC++CJavaScriptJavaPythonCGoJavaScriptTypeScriptPythonCGoTypeScriptC#PythonGoCTypeScriptC++Erlang （这个群体学习 Erlang 意愿好高）SwiftCPythonJavaC++Python 以其简单性，可读性和诸多科学计算库而闻名。它也是计算机科学入门课程的一部分。在新语言中有一种不同寻常的趋势：相比年老开发者，年轻开发者更喜欢较新的语言（如Go，Kotlin 和 Scala）。事实上，Go 创造了最大的分歧之一。 18-24 岁的开发者并不关心，但 45-54 岁的开发者认为这是他们最喜欢的语言之一。 JavaScript 则正好相反。Go 在内的许多新语言都体现了来自旧语言的学习。 Go 的主要设计师之一 Ken Thompson 以前参与创造了 C 语言。年轻开发者对知识有天生的渴望，他们更有可能全面学习语言，甚至是那些他们不喜欢的语言。年老开发者会根据自己的经验，选择他们认为经得起时间考验的语言。 《》《》\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://wx2.sinaimg.cn/mw690/7cc829d3gy1fo5u1rz85cj21hc0u00wa.jpg"]}
{"title": "八种在 Linux 上生成随机密码的方法 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n学习使用 8 种 Linux 原生命令或第三方实用程序来生成随机密码。在这篇文章中，我们将引导你通过几种不同的方式在 Linux 终端中生成随机密码。其中几种利用原生 Linux 命令，另外几种则利用极易在 Linux 机器上安装的第三方工具或实用程序实现。在这里我们利用像 , , , ,  这样的原生命令和 mkpasswd，randpw，pwgen，spw，gpg，xkcdpass，diceware，revelation，keepaasx，passwordmaker 这样的第三方工具。其实这些方法就是生成一些能被用作密码的随机字母字符串。随机密码可以用于新用户的密码，不管用户基数有多大，这些密码都是独一无二的。话不多说，让我们来看看 8 种不同的在 Linux 上生成随机密码的方法吧。 在基于 RHEL 的系统上随  软件包一起安装。在基于 Debian 的系统上  则在软件包  中。直接安装  软件包将会导致错误：RHEL 系统：软件包 mkpasswd 不可用。Debian 系统：错误：无法定位软件包 mkpasswd。所以按照上面所述安装他们的父软件包，就没问题了。运行  来获得密码这个命令在不同的系统上表现得不一样，所以工作方式各异。你也可以通过参数来控制长度等选项，可以查阅 man 手册来探索。几乎所有 Linux 发行版都包含 openssl。我们可以利用它的随机功能来生成可以用作密码的随机字母字符串。这里我们使用  编码随机函数，最后一个数字参数表示长度。设备文件  是另一个获得随机字符串的方法。我们使用  功能并裁剪输出来获得随机字符串，并把它作为密码。我们甚至可以使用  设备配合  来获取随机字符串。我们需要将结果通过  编码使它能被人类可读。你可以使用数值来获取想要的长度。想要获得更简洁的输出的话，可以将“标准错误输出”重定向到 。简洁输出的命令是：另一种获取可用作密码的随机字符串的方法是计算 MD5 校验值！校验值看起来确实像是随机字符串组合在一起，我们可以用作密码。确保你的计算源是个变量，这样的话每次运行命令时生成的校验值都不一样。比如  ！ 总会生成不同的输出。在这里我们将  命令的输出通过  得到了校验和！你也可以用  裁剪你需要的长度。 软件包在类似 （LCTT 译注：企业版 Linux 附加软件包）中。 更专注于生成可发音的密码，但它们不在英语词典中，也不是纯英文的。标准发行版仓库中可能并不包含这个工具。安装这个软件包然后运行  命令行。Boom !你的终端会呈现出一个密码列表！你还想要什么呢？好吧。你还想再仔细探索的话，  还有很多自定义选项，这些都可以在 man 手册里查阅到。GPG 是一个遵循 OpenPGP 标准的加密及签名工具。大部分 gpg 工具都预先被安装好了（至少在我的 RHEL7 上是这样）。但如果没有的话你可以寻找  或  软件包并它。使用下面的命令以从 gpg 工具生成密码。这里我们传了生成随机字节序列选项（），质量为 1（第一个参数），次数 12 （第二个参数）。选项  保证以  编码输出。著名的极客幽默网站 ，发表了一篇非常有趣的文章，是关于好记但又复杂的密码的。你可以在阅读。所以  工具就受这篇文章启发，做了这样的工作！这是一个 Python 软件包，可以在的 Python 的官网上找到它。所有的安装使用说明都在上面那个页面提及了。这里是安装步骤和我的测试 RHEL 服务器的输出，以供参考。现在运行  命令，将会随机给出你几个像下面这样的字典单词：你可以用这些单词作为其他命令，比如  的输入，来获取随机密码（就像下面这样），甚至你也可以用每个单词的第 N 个字母来生成你的密码！或者你甚至可以把所有单词串在一起作为一个超长的密码，不仅非常好记，也不容易被电脑程序攻破。Linux 上还有像 、 、 、  这样的工具，也可以考虑用来生成强随机密码。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2015/10/08b38b9c5e2d964171d1daf614bddc2c.jpg"]}
{"title": "当 CPU 空闲时它都在做什么？ - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "CPU"], "goodNum": "2", "saveNum": " 2 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n在  我说了操作系统行为的基本原理是，，在一个 CPU 上。但是，如果 CPU 无事可做的时候，又会是什么样的呢？事实证明，这种情况是非常普遍的，对于绝大多数的个人电脑来说，这确实是一种常态：大量的睡眠进程，它们都在等待某种情况下被唤醒，差不多在 100% 的 CPU 时间中，都处于虚构的“空闲任务”中。事实上，如果一个普通用户的 CPU 处于持续的繁忙中，它可能意味着有一个错误、bug、或者运行了恶意软件。因为我们不能违反我们的原理，。首先是因为，这是一个良好的设计：持续很长时间去遍历内核，检查是否一个活动任务，这种特殊情况是不明智的做法。最好的设计是。无论何时，你写一个  语句，Nyan Cat 就会喵喵喵。其次，我们需要使用空闲的 CPU 去做，让它们充满活力，你懂得，就是创建天网计划呗。因此，保持这种设计的连续性，并领先于那些邪恶计划一步，操作系统开发者创建了一个，当没有其它任务可做时就调度它去运行。我们可以在 Linux 的  中看到，这个空闲任务就是进程 0，它是由计算机打开电源时运行的第一个指令直接派生出来的。它在  中初始化，在  中初始化空闲调度类scheduling class。简而言之，Linux 支持像实时进程、普通用户进程等等的不同调度类。当选择一个进程变成活动任务时，这些类按优先级进行查询。通过这种方式，核反应堆的控制代码总是优先于 web 浏览器运行。尽管在通常情况下，这些类返回 ，意味着它们没有合适的任务需要去运行 —— 它们总是处于睡眠状态。但是空闲调度类，它是持续运行的，从不会失败：它总是返回空闲任务。好吧，我们来看一下这个空闲任务。下面是 ，感谢开源能让我们看到它的代码：我省略了很多的细节，稍后我们将去了解任务切换，但是，如果你阅读了这些源代码，你就会找到它的要点：由于这里不需要重新调度（即改变活动任务），它一直处于空闲状态。以所经历的时间来计算，这个循环和其它操作系统中它的“堂兄弟们”相比，在计算的历史上它是运行的最多的代码片段。对于 Intel 处理器来说，处于空闲状态意味着运行着一个  指令： 指令停止处理器中的代码执行，并将它置于  的状态。奇怪的是，全世界各地数以百万计的 Intel 类的 CPU 们花费大量的时间让它们处于  的状态，甚至它们在通电的时候也是如此。这并不是高效、节能的做法，这促使芯片制造商们去开发处理器的深度睡眠状态，以带来着更少的功耗和更长休眠时间。内核的  是这些节能模式能够产生好处的原因。现在，一旦我们告诉 CPU 去 （睡眠）之后，我们需要以某种方式让它醒来。如果你读过  ，你可能会猜到会参与其中，而事实确实如此。中断促使 CPU 离开  状态返回到激活状态。因此，将这些拼到一起，下图是当你阅读一个完全呈现的 web 网页时，你的系统主要做的事情：除定时器中断外的其它中断也会使处理器再次发生变化。如果你再次点击一个 web 页面就会产生这种变化，例如：你的鼠标发出一个中断，它的驱动会处理它，并且因为它产生了一个新的输入，突然进程就可运行了。在那个时刻，  返回 ，然后空闲任务因你的浏览器而被踢出而终止运行。如果我们呆呆地看着这篇文章，而不做任何事情。那么随着时间的推移，这个空闲循环就像下图一样：在这个示例中，由内核计划的定时器中断会每 4 毫秒发生一次。这就是滴答tick周期。也就是说每秒钟将有 250 个滴答，因此，这个是 250 Hz。这是运行在 Intel 处理器上的 Linux 的典型值，而其它操作系统喜欢使用 100 Hz。这是由你构建内核时在  选项中定义的。对于一个 来说，它看起来似乎是个无意义的工作。如果外部世界没有新的输入，在你的笔记本电脑的电池耗尽之前，CPU 将始终处于这种每秒钟被唤醒 250 次的地狱般折磨的小憩中。如果它运行在一个虚拟机中，那我们正在消耗着宿主机 CPU 的性能和宝贵的时钟周期。在这里的解决方案是 ，当 CPU 处于空闲状态时，定时器中断被 ，直到内核将有事情要做时（例如，一个进程的定时器可能要在 5 秒内过期，因此，我们不能再继续睡眠了），定时器中断才会重新发出。这也被称为。最后，假设在一个系统中你有一个，例如，一个长时间运行的 CPU 密集型任务。那样几乎就和一个空闲系统是相同的：这些示意图仍然是相同的，只是将空闲任务替换为这个进程，并且相应的描述也是准确的。在那种情况下，每 4 毫秒去中断一次任务仍然是无意义的：它只是操作系统的性能抖动，甚至会使你的工作变得更慢而已。Linux 也可以在这种单一进程的场景中停止这种固定速率的滴答，这被称为  模式。最终，这种固定速率的滴答可能会 。对于阅读一篇文章来说，CPU 基本是无事可做的。内核的这种空闲行为是操作系统难题的一个重要部分，并且它与我们看到的其它情况非常相似，因此，这将帮助我们理解一个运行中的内核。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/02/5127eb8de8c9e721e734ea303c0a8138.jpg"]}
{"title": "操作系统何时运行？ - 文章 - 伯乐在线", "tag": ["IT技术", "操作系统"], "goodNum": "2", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n这些问题并不复杂，但它们深入涉及到系统软件工作的本质。为了准确回答这些问题，我们需要透彻理解操作系统的行为模型，包括性能、安全和除错等方面。在该系列文章中，我们将以 Linux 为主举例来帮助你建立操作系统的行为模型，OS X 和 Windows 在必要的时候也会有所涉及。对那些深度探索者，我会在适当的时候给出 Linux 内核源码的链接。这里有一个基本认知，就是，在任意给定时刻，某个 CPU 上仅有一个任务处于活动状态。大多数情形下这个任务是某个用户程序，例如你的 Web 浏览器或音乐播放器，但它也可能是一个操作系统线程。可以确信的是，它是，不是两个或更多，也不是零个，对，是一个。这听上去可能会有些问题。比如，你的音乐播放器是否会独占 CPU 而阻止其它任务运行？从而使你不能打开任务管理工具去杀死音乐播放器，甚至让鼠标点击也失效，因为操作系统没有机会去处理这些事件。你可能会愤而喊出，“它究竟在搞什么鬼？”，并引发骚乱。此时便轮到大显身手了。中断就好比，一声巨响或一次拍肩后，神经系统通知大脑去感知外部刺激一般。计算机主板上的同样会中断 CPU 运行以传递新的外部事件，例如键盘上的某个键被按下、网络数据包的到达、一次硬盘读取的完成，等等。硬件外设、主板上的中断控制器和 CPU 本身，它们共同协作实现了中断机制。中断对于记录我们最珍视的资源——时间——也至关重要。计算机中，操作系统内核会设置一个硬件计时器以让其产生周期性，例如每隔 10 毫秒触发一次。每当计时中断到来，内核便会收到通知以更新系统统计信息和盘点如下事项：当前用户程序是否已运行了足够长时间？是否有某个 TCP 定时器超时了？中断给予了内核一个处理这些问题并采取合适措施的机会。这就好像你给自己设置了整天的周期闹铃并把它们用作检查点：我是否应该去做我正在进行的工作？是否存在更紧急的事项？直到你发现 10 年时间已逝去……这些内核对 CPU 周期性的劫持被称为滴答tick，也就是说，是中断让你的操作系统滴答了一下。不止如此，中断也被用作处理一些软件事件，如整数溢出和页错误，其中未涉及外部硬件。。对于学习电子工程的人而言，这些并无古怪，它们是操作系统赖以运行的机制。说到这里，让我们再来看一些实际情形。下图示意了 Intel Core i5 系统中的一个网卡中断。图片中的部分元素设置了超链，你可以点击它们以获取更为详细的信息，例如每个设备均被链接到了对应的 Linux 驱动源码。链接如下：让我们来仔细研究下。首先，由于系统中存在众多中断源，如果硬件只是通知 CPU “嘿，这里发生了一些事情”然后什么也不做，则不太行得通。这会带来难以忍受的冗长等待。因此，计算机上电时，每个设备都被授予了一根，或者称为 IRQ。这些 IRQ 然后被系统中的中断控制器映射成值介于 0 到 255 之间的。等到中断到达 CPU，它便具备了一个完好定义的数值，异于硬件的某些其它诡异行为。相应地，CPU 中还存有一个由内核维护的指针，指向一个包含 255 个函数指针的数组，其中每个函数被用来处理某个特定的中断向量。后文中，我们将继续深入探讨这个数组，它也被称作（IDT）。每当中断到来，CPU 会用中断向量的值去索引中断描述符表，并执行相应处理函数。这相当于，在当前正在执行任务的上下文中，发生了一个特殊函数调用，从而允许操作系统以较小开销快速对外部事件作出反应。考虑下述场景，Web 服务器在发送数据时，CPU 却间接调用了操作系统函数，这听上去要么很炫酷要么令人惊恐。下图展示了 Vim 编辑器运行过程中一个中断到来的情形。此处请留意，中断的到来是如何触发 CPU 到  内核模式的切换而未有改变当前活跃的任务。这看上去就像，Vim 编辑器直接面向操作系统内核产生了一次神奇的函数调用，但 Vim 还在那里，它的原封未动，等待着执行流返回。这很令人振奋，不是么？不过让我们暂且告一段落吧，我需要合理控制篇幅。我知道还没有回答完这个开放式问题，甚至还实质上翻开了新的问题，但你至少知道了在你读这个句子的同时正在发生。我们将在充实了对操作系统动态行为模型的理解之后再回来寻求问题的答案，对 Web 浏览器情形的理解也会变得清晰。如果你仍有问题，尤其是在这篇文章公诸于众后，请尽管提出。我将会在文章或后续评论中回答它们。下篇文章将于明天在 RSS 和 Twitter 上发布。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/02/b3cdad993159556fa1fb59172137e069.jpg"]}
{"title": "使用 Vi/Vim 编辑器：基础篇 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 ", "Linux", "Vim"], "goodNum": "1", "saveNum": " 4 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nVI 编辑器是一个基于命令行的、功能强大的文本编辑器，最早为 Unix 系统开发，后来也被移植到许多的 Unix 和 Linux 发行版上。在 Linux 上还存在着另一个 VI 编辑器的高阶版本 —— VIM（也被称作 VI IMproved）。VIM 只是在 VI 已经很强的功能上添加了更多的功能，这些功能有：支持更多 Linux 发行版，支持多种编程语言，包括 python、c++、perl 等语言的代码块折叠，语法高亮，支持通过多种网络协议，包括 http、ssh 等编辑文件，支持编辑压缩归档中的文件，支持分屏同时编辑多个文件。接下来我们会讨论 VI/VIM 的命令以及选项。本文出于教学的目的，我们使用 VI 来举例，但所有的命令都可以被用于 VIM。首先我们先介绍 VI 编辑器的两种模式。命令模式下，我们可以执行保存文件、在 VI 内运行命令、复制/剪切/粘贴操作，以及查找/替换等任务。当我们处于插入模式时，我们可以按下 （）键返回命令模式在插入模式下，我们可以键入文件内容。在命令模式下按下  进入插入模式。我们可以通过下述命令建立一个文件（LCTT 译注：如果该文件存在，则编辑已有文件）：一旦该文件被创建或者打开，我们首先进入命令模式，我们需要进入输入模式以在文件中输入内容。我们通过前文已经大致上了解这两种模式。如果是想从插入模式中退出，我们首先需要按下  键进入命令模式。接下来我们可以根据不同的需要分别使用两种命令退出 Vi。不保存退出 – 在命令模式中输入 保存并退出 – 在命令模式中输入 下面我们来讨论下那些在命令模式中移动光标的命令和选项： 将光标上移一行 将光标下移一行 将光标左移一个字母 将光标右移一个字母注意：如果你想通过一个命令上移或下移多行，或者左移、右移多个字母，你可以使用  或者 ，这两条命令会分别上移 4 行或者右移 5 个字母。 将光标移动到该行行首 将光标移动到该行行尾 将光标移动到第 n 行 将光标移动到文件的最后一行 将光标移动到上一段 将光标移动到下一段除此之外还有一些命令可以用于控制光标的移动，但上述列出的这些命令应该就能应付日常工作所需。这部分会列出一些用于命令模式的命令，可以进入插入模式来编辑当前文件 在光标所在行的行首插入内容 在光标所在行的行尾插入内容 在当前光标之前插入内容 在当前光标之后插入内容 在当前光标所在行之前添加一行 在当前光标所在行之后添加一行以下的这些命令都只能在命令模式下使用，所以首先需要按下  进入命令模式，如果你正处于插入模式： 删除光标所在的整行内容，可以在  前增加数字，比如  可以删除从光标所在行开始的两行 删除从光标所在行开始的所有行 删除从文件开始直到光标所在行的所有行 4  删除从光标所在位置直到下一个词开始的所有内容 复制当前行，在  前添加数字可以复制多行 在光标之后粘贴复制行 在光标之前粘贴复制行上述就是可以在 VI/VIM 编辑器上使用的一些基本命令。在未来的教程中还会继续教授一些更高级的命令。如果有任何疑问和建议，请在下方评论区留言。 \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2012/04/vim-logo.png"]}
{"title": "Linux 下各文件夹的结构说明及用途介绍 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 8 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n二进制可执行命令。\n设备特殊文件。\n系统管理和配置文件。\n启动的配 置文件和脚本。\n用户主目录的基点，比如用户user的主目录就是/home/user，可以用~user表示。\n标准程序设计库，又 叫动态链接共享库，作用类似windows里的.dll文件。\n系统管理命令，这 里存放的是系统管理员使用的管理程序。\n公用的临时文件存储 点。\n系统管理员的主目 录。\n系统提供这个目录是 让用户临时挂载其他的文件系统。\n这个 目录平时是空的，系统非正常关机而留下“无家可归”的文件就在这里。\n虚拟的目录，是系 统内存的映射。可直接访问这个目录来获取系统信息。\n某些大文件的溢出 区，比方说各种服务的日志文件。\n最庞大的目录，要用 到的应用程序和文件几乎都在这个目录。\n存放x window的目录。\n众多的应用程序。\n超级用户的一些管理程序。\nlinux文档。\nlinux下开发和编译应用程序所需要的头文件。\n常用的动态链接库和软件包的配置文件。\n帮助文档。\n源代码，linux内核的源代码就放在/usr/src/linux 里。\n本地增加的命令。\n本地增加的库根文件系统。通常情况下，根文件系统所占空间一般应该比较小，因为其中的绝大部分文件都不需要经常改动，而且包括严格的文件和一个小的 不经常改变的文件系统不容易损坏。除了可能的一个叫标准的系统引导映像之外，根目录一般不含任何文 件。所有其他文件在根文件系统的子目录中。\n\n目录包含了引导启动所需的命令或普通用户可能用的命令(可能在引导启动后)。这些命 令都是二进制文件的可执行程序(bin是binary的简称)，多是系统中重要的系统文件。\n\n目录类似 ，也用于存储二进制文件。因为其中的大部分文件多是系统管理员使用的基本的系统程序，所以虽然普通用户必要且允许时可以使用，但一般不给普通用户使 用。\n\n目录存放着各种系统配置文件，其中包括了用户信息文件， 系统初始化文件等。linux正是靠这些文件才得以正常地运行。\n\n/root目录是超级用户的目录。\n\n目录是根文件系统上的程序所需的共享库，存放了根文件系统程序运行所需的共享文件。 这些文件包含了可被许多程序共享的代码，以避免每个程序都包含有相同的子程序的副本，故可以使得可执行文件变得更小，节省空间。\n\n目录包含系统核心可加载各种模块，尤其是那些在恢复损坏的系统时重 新引导系统所需的模块(例如网络和文件系统驱动)。\n\n目录存放了设备文件，即设备驱动程序，用户通过这些文件访问外部设备。比如，用户可 以通过访问来访问鼠标的输入，就像访问其他文件一样。\n\n目录存放程序在运行时产生的信息和数据。但在引导启动后，运行的程序最好使用来 代替，因为前者可能拥有一个更大的磁盘空间。\n\n目录存放引导加载器(bootstrap loader)使用的文件，如lilo，核心映像也经常放在这里，而不是放在根目录中。但是如果有许多核心映像，这个目录就可能变得很大，这时使用单独的 文件系统会更好一些。还有一点要注意的是，要确保核心映像必须在ide硬盘的前1024柱面内。\n\n目录是系统管理员临时安装(mount)文件系统的安装点。程序并不自动支持安装到 。下面可以分为许多子目录，例如可能是使用 msdos文件系统的软驱，而可能是使用ext2文件系统的软驱，光 驱等等。\n\n其他文件系统的安装点。目录树可以分为小的部分，每个部分可以在自己的磁盘或分区上。主要部分是根、/usr 、/var 和 /home 文件系统。每个部分有不同的目的。\n每台机器都有根文件系统，它包含系统引导和使其他文件系统得以mount所必要的文件，根文件系统应该有单用户状态所必须的足够的内容。还应该包括修复损坏 系统、恢复备份等的工具。\n/usr 文件系统包含所有命令、库、man页和其他一般操作中所需的不改变的文件。 /usr 不应该有 一般使用中要修改的文件。这样允许此文件系统中的文件通过网络共享，这样可以更有效，因为这样节省了磁盘空间(/usr 很容易是数百兆)，且易于管理 (当升级应用时，只有主/usr 需要改变，而无须改变每台机器) 即使此文件系统在本地盘上，也可以只读mount，以减少系统崩溃时文件系统的损 坏。\n/var 文件系统包含会改变的文件，比如spool目录(mail、news、打印机等用的)， log文件、 formatted manual pages和暂存文件。传统上/var 的所有东西曾在 /usr 下的某个地方，但这样/usr 就不可能只读安装 了。\n/home 文件系统包含用户家目录，即系统上的所有实际数据。一个大的/home 可能要分为若干文件系统，需要在 /home 下加一级名字，如/home/students 、/home/staff 等。下面详细介绍：\n目录包含各种系统配置文件，下面说明其中的一些。其他的你应该知道它们属于哪个程序， 并阅读该程序的man页。许多网络配置文件也在/etc中。\n启动、或改变运行级时运 行的脚本或脚本的目录。\n用户数据库，其中的域给出了用户名、真实姓名、用户起始目 录、加密口令和用户的其他信息。\n软盘参数表，用以说明不同的软盘格式。可用setfdprm进 行设置。更多的信息见setfdprm的帮助页。\n指定启动时需要自动安装的文件系统列表。也包括用swapon -a启用的swap区的信息。\n类似 ，但说明的不是用户信息而是组的信息。包括组的各种数据。\ninit 的配置文件。\n包括用户在登录提示符前的输出信息。通常包括系统的一段短说明 或欢迎信息。具体内容由系统管理员确定。\n“file”的配置文件。包含不同文件格式的说 明，“file”基于它猜测文件类型。\nmotd是message of the day的缩写，用户成功登录后自动输出。内容由系统管理员确定。\n常用于通告信息，如计划关机时间的警告等。\n当前安装的文件系统列表。由脚本(scritp)初始化，并由 mount命令自动更新。当需要一个当前安装的文件系统的列表时使用(例如df命令)。\n在安装了影子(shadow)口令软件的系统上的影子口令 文件。影子口令文件将/etc/passwd文件中的加密口令移动到/etc/shadow中，而后者只对超级用户(root)可读。这使破译口令更困 难，以此增加系统的安全性。\nlogin命令的配置文件。\n类似/etc/termcap ，但针对打印机。语法不同。\n登 录或启动时bourne或cshells执行的文件。这允许系统管理员为所有用户建立全局缺省环境。\n确认安全终端，即哪个终端允许超级用户(root) 登录。一般只列出虚拟控制台，这样就不可能(至少很困难)通过调制解调器(modem)或网络闯入系统并得到超级用户特权。\n列出可以使用的shell。chsh命令允许用户在本文件 指定范围内改变登录的shell。提供一\n台机器ftp服务的服务进程ftpd检查用户shell是否列在文件 中，如果不是，将不允许该用户登录。\n终端性能数据库。说明不同的终端用什么“转义序列”控 制。写程序时不直接输出转义\n序列(这样只能工作于特定品牌的终端)，而是从中查找要做的工作的 正确序列。这样，多数的程序可以在多数终端上运行。\n目录包括所有设备的设备文件。设备文件用特定的约定命名，这在设备列表中说明。设备文件在安装时由系 统产生，以后可以用描述。/dev/makedev.local 是系统管理员为本地设备文件(或连接)写的描述文稿(即如一些非标准设备驱动不是标准makedev 的一部分)。下面简要介绍下 一些常用文件。\n系统控制台，也就是直接和系统连接的监视器。\nide硬盘驱动程序接口。如：/dev/hda指的是第一个硬 盘，had1则是指的第一个分区。如系统中有其他的硬盘，则依次为 .；如有多个分区则依次为hda1、hda2 . . . . . .\nscsi磁盘驱动程序接口。如系统有scsi硬盘，就不会访问， 而会访问。\n软驱设备驱动程序。如指 系统的第一个软盘，也就是通常所说的a盘指第二个软盘，. . . . . .而则表示访问驱动器1中的4.5高密盘。\nscsi磁带驱动器驱动程序。\n提供虚拟控制台支持。如指 的是系统的第一个虚拟控制台则是系统\n的第二个虚拟控制台。\n提供远程登陆伪终端支持。在进行telnet登录时就要用到设 备。\n计算机串行接口，对于dos来说就是“com1”口。\n计算机串行接口，与调制解调器一起使用的设备。\n“黑洞”，所有写入该设备的信息都将消失。例如：当想要将屏幕 上的输出信息隐藏起来\n时，只要将输出信息输入到/dev/null中即可。\n\n是个很重要的目录，通常这一文件系统很大，因为所有程序安装在这里。里 的所有文件一般来自linux发行版；本地安装的程序和其他东西在下，因为这样可以在升级新版系 统或新发行版时无须重新安装全部程序。/usr目录下的许多内容是可选的，但这些功能会使用户使用系统更加有效。/usr可容纳许多大型的软件包和它们的 配置文件。下面列出一些重要的目录(一些不太重要的目录被省略了)。\n包含x window系统的所有可执行程序、配置文件和支持文件。为简化x的开发和安装，x的文件没有集成到系统中。x window系统是一个功能强大的图形环境，提供了大量的图形工具程序。用户如果对microsoft windows比较熟悉的话，就不会对x window系统感到束手无策了。\n类似 ，但是是专门给x 11 release 5的。\n集中了几乎所有用户命令，是系统的软件库。另有些命令在或中。\n包括了根文件系统不必要的系统管理命令，例如多数服务程序。\n这些目录包含所有手册页、 gnu信息文档和各种其他文档文件。每个联机手册的“节”都有两个子目录。例如：/usr/man/man1中包含联机手册第一节的源码(没有格式化的原 始文件)，/usr/man/cat1包含第一节已格式化的内容。联机手册分为以下九节：内部命令、系统调用、库函数、设备、文件格式、游戏、宏软件包、 系统管理和核心程序。\n包含了c语言的头文件，这些文件多以.h结尾，用来描述c 语言程序中用到的数据结构、\n子过程和常量。为了保持一致性，这实际上应该放在下，但习惯上一直沿用了这 个名字。\n包含了程序或子系统的不变的数据文件，包括一些site – wide配置文件。名字lib来源于库(library); 编程的原始库也存在 里。当编译程序时，程序便会和其中的库进行连接。也有许多程序把配置文件存入其中。\n本地安装的软件和其他文件放在这里。这与/usr很相似。用户 可能会在这发现一些比较大\n的软件包，如tex、emacs等。\n包含系统一般运行时要改变的数据。通常这些数据所在的目录的大小是要经常变化或扩充 的。原来/var目录中有些内容是在/usr中的，但为了保持/usr目录的相对稳定，就把那些需要经常改变的目录放到/var中了。每个系统是特定的， 即不通过网络与其他计算机共享。下面列出一些重要的目录(一些不太重要的目录省略了)。\n包括了格式化过的帮助(man)页。帮助页的源文件一般存在 /usr/man/catman中；有些man页可能有预格式化的版本，存在/usr/man/cat中。而其他的man页在第一次看时都需要格式化，格 式化完的版本存在/var/man中，这样其他人再看相同的页时就无须等待格式化了。(/经常被 清除，就像清除临时目录一样。)\n存放系统正常运行时要改变的文件。\n存放中 安装的程序的可变数据(即系统管理员安装的程序)。注意，如果必要，\n即使本地安装的程序也会使用其他/var目录，例如/var/lock 。\n锁定文件。许多程序遵循在中 产生一个锁定文件的约定，以用来支持他们正在\n使用某个特定的设备或文件。其他程序注意到这个锁定文件时，就不会再使用这个设备或文件。\n各种程序的日志(log)文件，尤其是login (纪 录所有到系统的登录和注销) 和syslog (/ 纪录存储所有核心和系统程序信息)。/var/log 里的文件经常不确定地增长，应该定期清除。\n保存在下一次系统引导前有效的关于系统的信息文件。例如包 含当前登录的用户的信息。\n放置“假脱机(spool)”程序的目录，如mail、 news、打印队列和其他队列工作的目录。每\n个不同的spool在/var/spool下有自己的子目录，例如，用户的邮箱就存放在/var/spool/mail 中。\n比/tmp允许更大的或需要存在较长时间的临时文件。注意系统管理 员可能不允许/var/tmp有很旧的文件。\n文件系统是一个伪的文件系统，就是说它是一个实际上不存在的目录，因而这是一个非 常特殊的目录。它并不存在于某个磁盘上，而是由核心在内存中产生。这个目录用于提供关于系统的信息。下面说明一些最重要的文件和目录(/proc文件系统 在proc man页中有更详细的说明)。\n关于进程x的信息目录，这x是这一进程的标识号。每个进程在 /proc下有一个名为自己进程号的目录。\n存放处理器(cpu)的信息，如cpu的类型、制造商、 型号和性能等。\n当前运行的核心配置的设备驱动的列表。\n显示当前使用的dma通道。\n核心配置的文件系统信息。\n显示被占用的中断信息和占用者的信息，以及被占用 的数量。\n当前使用的i/o端口。\n系统物理内存映像。与物理内存大小完全一样，然而实际上没有 占用这么多内存；它仅\n仅是在程序访问它时才被创建。(注意：除非你把它拷贝到什么地方，否则/proc下没有任何东西占用任何磁盘空间。)\n核心输出的消息。也会被送到syslog。\n核心符号表。\n系统“平均负载”；3个没有意义的指示器指出系统当前 的工作量。\n各种存储器使用信息，包括物理内存和交换分区 (swap)。\n存放当前加载了哪些核心模块信息。\n网络协议状态信息。\n存放到查看的 程序的进程目录的符号连接。当2个进程查看时，这将会是不同\n的连接。这主要便于程序得到它自己的进程目录。\n系统的不同状态，例如，系统启动后页面发生错误的次数。\n系统启动的时间长度。\n核心版本。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "2018 开发者技能调查：这些编程语言受欢迎 - 文章 - 伯乐在线", "tag": ["开发", " 1 评论 ", "编程语言"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n近日国外开发者平台 HankerRank 发布了 2018 年开发者技能调查报告，本文摘录部分和编程语言相关的调查结果。尽管经常有新编程语言出现，但程序员需要掌握核心、传统语言也是非常重要的。 总的来说，在「雇主青睐的编程语言」中，JavaScript、Java、Python、C++、C、C# 和 PHP 排在前位。JavaScript 第一，Java 稍微比 JS 少一点排第二，Python 第三、C++ 第四、C 第五；JS 第一、Java 第二、Python 第三、C++ 第四、C# 第五；C 语言和 C++ 的需求量，明显高于其他语言。Python 第三、Java 第四、JS 第五；Java 第一、JS 第二、Python 第三、C# 第四、C++ 第五；Java 第一、JS 第二、C# 第三JS 第一、Java 第二、Python 第三、C# 第四JS 第一、Python 第二、Java 第三、PHP 第四Java 第一、JS 第二、Python 第三Java 第一、Python 第二、JS 第三、C++ 第四、C 第五；Java 第一、JS 第二、Python 第三、C++ 第四、C 第五；Go （得益于 Google）PythonScalaKotlinRubyRTypescriptSwiftRustHaskell\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://wx2.sinaimg.cn/large/7cc829d3ly1fnrhvezgh4j20jx0aggm9.jpg"]}
{"title": "2018 年，程序员要具备哪些核心竞争力？ - 文章 - 伯乐在线", "tag": ["职场", " 6 评论 ", "程序员", "职场"], "goodNum": "1", "saveNum": " 6 收藏", "sayNum": " 6 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n近日国外开发者平台 HankerRank 发布了 2018 年开发者技能调查报告，本文摘录程序员求职时必备技能相关的调查结果。问题解决能力（不管企业大小，都排第1）编程语言熟练程度（不管企业大小，排第2）调试（不管企业大小，排第3）系统设计（综合排第4）性能优化（综合排第5）剩下见下图相比中大型公司，小公司更为看中开发者对框架的熟练程度。因为小公司追求快启动，框架有助于开发者更快速地的推送代码。经历/经验portfolio/作品集（GitHub是开发者展现个人项目最佳方式之一）教育（学历/学位）培训（技能认证/证书）个人品牌有一种流行的观点认为，招聘人员更中意有名牌大学 CS 学位的人选。但事实证明，他们实际上关心的是你所做的，而不是你上学的地方。绝大多数的招聘经理表示，他们寻找开发者的技能证明，比如以往工作，多年的经验和项目/ GitHub。无论公司规模大小如何，90% 的招聘人员表示更看中开发者的「以往工作经验」和「多年的经验」。portfolio/作品集（GitHub是开发者展现个人项目最佳方式之一）以往工作经验工作年限教育（学历/学位）培训（技能认证/证书）个人品牌现在很多公司在招 IT 技术人才时，会查看候选人的 GitHub 上的实际项目，以作为简历之外的技能评估补充。相比多年工作经验，创始人、CTO、VP 等主管人群更看重 GitHub 上的项目。他们不像普通招聘人员（HR）那样看重「学历/学位」。这可能是因为候选人进入由高管面试轮时，上一轮的 HR 已经筛选过了。到了这一轮时，有更多时间来根据以往项目来评估候选人的技能。《》\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2016/07/b82c41ce36630a47a22e10059671eb52.jpg"]}
{"title": "软件复杂性正在杀死我们 - 文章 - 伯乐在线", "tag": ["业界", " 2 评论 "], "goodNum": "2", "saveNum": " 5 收藏", "sayNum": " 2 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n代码量少了不代表软件的复杂度降低了，而是编程语言的表达力更强了。太多开发人员痴迷于框架，过度追求软件灵活性、可组合性等等，而忘记自己是不是真的需要这些。在有软件之前，只有黑暗。自从时代的黎明到来后，一直存在一个不变的事实：企业想要构建价格更低、运行更快的软件。当然，这是可以理解并且值得称赞的目标——尤其是你曾经花费时间跟软件开发人员打过交道。每个工程师都应该全心支持此目标，并且在当前环境的约束下，应该始终努力尽可能有效率地创造产品。然而，事实上，我们经常做不到这一点。并非故意为之，只是随着时间流逝，在构建软件时会因为意料之外的复杂性而陷入困境，因此自我训练以寻找边界案例、差距分析以及所有可能起源于同一个需求要点的隐藏故障。我们被大量的复杂度以及设计优雅解决方案的精神执念所迷惑：另一层抽象！干起来！分离相关量！继承构成！这也是可以理解的，但是在这个过程中，我们经常忽略正在被解决的业务问题，忘记管理复杂度是软件开发人员的责任。在过去的几十年里，软件产业非常成功地降低了编写大多数软件所需要的自定义代码量。这种减少大部分是通过使编程语言更有表现性来实现的。像 Python、Ruby 或 JavaScript 这些语言可以用C 语言来实现相似的功能。使用 C 语言取代汇编语言编写程序也同样带来了类似的优势。可以预见，在未来，语言设计不大可能带来如同过去几十年一样的改进。然而也有很多其他不需要让语言更具有表现力的方法，可以精简构建软件的代码总量。截止到现在，在过去的二十年里，我们最大的收获是开源软件（OSS）。如果没有个人和公司将资金投入到他们为社区免费赠予的软件中，没有这么多的代价和努力，那么我们今天所构建的大部分软件将不会实现。这些项目使我们能够站在巨人的肩膀上解决问题，利用工具让我们更专注于解决业务问题，而不是花时间建设基础设施。也就是说，业务是复杂的。可笑的复杂，而且只会更多，开源软件非常适合生成用以构建系统的框架和工具，但在很大程度上为了获得关注，又必须解决大量人员共享的问题。因此，大多数开源项目要么是相对通用的，要么是处于非常受欢迎的领域。因此，这些工具中的大部分都是建立系统的绝佳平台，但最终我们仍然需要在日益复杂且要求苛刻的系统中构建所有业务逻辑和接口。所以我们剩下的是一个看起来像这样的栈（对于 web 应用程序）…<Our Code/我们的代码>\n<Libraries/库>\n<Web Framework/Web 框架>\n<Web Server/Web 服务器>\n<Data Stores/数据存储>\n<Operating System/操作系统>“Our Code”部分最终变得非常复杂，因为它反映了业务及其流程。如果我们有自定义的业务逻辑和自定义流程，那么我们只需编写组建应用程序的接口、工作流程和逻辑即可。当然，我们可以尝试用不同的方式来记录该逻辑（记住业务规则引擎？），但最终，没有其他人会为您的业务编写业务逻辑。实际上似乎没有办法解决这个问题……至少是在机器人到来并将我们从工作中解救出来之前。如果我们必须开发应用程序的接口、工作流程和逻辑，这听起来像是难住我们了，对吗？ 在某种程度上，是的，但我们仍有几个选择。对于大多数开发者来说，软件等于代码，现实并非如此。 开发软件有许多方法，其中一种是使用可视化工具。 在网络普及之前，视觉开发和 RAD 工具在市场上占有更大的地位。 诸如 PowerBuilder、visual Foxpro、Delphi、VB 和 Access 等工具都具有可视化设计功能，允许开发人员在不输入任何代码的情况下创建界面。这些工具涵盖了需要编写的代码，但总的来说，你可以直观地设计应用程序，然后编写大量代码来实现应用程序的逻辑。 在很多情况下，你仍然用编程操作接口，因为使用这些工具构建的接口通常是静态的。 但是，对于大量应用程序，这些工具通过舍弃其他性能获得了巨大的生产力，主要是以灵活性为代价。自从网络兴起后，这些工具可能已经不再流行，但公司对它们的渴望并没有降低，尤其是因为势不可挡的软件需求仍然持续不断。 整个行业最新趋势是“低代码”系统。 低代码开发工具是最新一代拖放式软件开发工具的现代术语。 这些工具和其他工具之间最大的区别在于，它们主要基于 Web（和移动端），并且通常被托管于云平台。许多公司正活跃于这些平台上。Salesforce（App Cloud）、Outsystems、Mendix 以及 Kony 等厂商承诺能够比“传统”应用程序开发快许多倍。 虽然他们的很多说法可能很夸张，但也有一定的可信度。依赖类似上述平台的所有弊端，可能的确导致某些类型的程序比使用 .NET 或 Java 的传统程序开发更快。的确有几个问题。 首先，有经验的开发人员经常讨厌这些工具。 大多数严肃的开发人员™ 喜欢使用真实代码™ 编写真正的软件™。 我知道这听起来像我正在迎合一群呜咽的婴儿（也许我有点儿），但如果你传递的核心价值是技术，那么采用顶尖开发人员不喜欢使用的工具并非是个好主意。其次，像我这样的人看着这些被封装的平台，说“不，不要在这里构建应用程序”。这是合情合理的忧虑，也是最让我困扰的事情。如果你 10 年前用 PHP 搭建了一个应用程序，那么这个应用程序可能会显老，但它现在仍然可以嗡嗡作响。 语言和生态系统都是开源的，并由社区维护的。 你需要保持应用程序持续更新，却不必担心供应商断定不再值得花时间支持。像我这样的人看着这些被封装的平台，说“不，不要在这里构建应用程序”。这是合情合理的忧虑，也是最让我困扰的事情。如果你 10 年前选择了有自己平台的供应商，那么如果他们关闭工具或频繁更改工具（），你可能会被迫重写程序。或者更糟，你的系统会停滞在一个停止更新、不再支持服务的平台上。有很多理由去警惕这类平台，但对许多企业来说，以更少的付出来搭建软件太具诱惑以至于不忍拒绝。 软件的复杂性仍在持续，不幸的是软件工程师帮不上任何忙。有高效的平台，可以让我们用真实代码™ 构建真正的软件™，但不幸的是，软件行业太过担心于跟随科技巨头地领导，以至于没有意识到他们的工具并没有对项目添加任何价值。我无法告诉你有多少次，曾遇到开发人员跟我说，相比于仅仅渲染 HTML，构建单一页面应用程序（SPA）类似的东西并不会增加开销。我曾听开发人员说过，所有应用都应该基于 NoSQL 数据库来开发，而关系数据库逐渐没落了。也曾听开发人员质疑为什么应用程序不是用 CQRS 和事件溯源编写的。正是这种思维过程和常规的开销导致公司认为软件开发过于昂贵。 你可能会说，“但事件溯源如此优雅！在微服务之上搭建 SPA 如此整洁！”当然，它可能是，但对你这种正在写十个微服务的人来说不是这样的。这种额外的复杂性往往是。作为从业人员，我们需要找到各种方法来简化搭建软件的过程，并且不忽视业务的合理复杂性。 我们需要承认，并非每个应用程序都需要与 Gmail 相同层次的界面复杂性和运营扩展性。 有很多应用程序需要经过深思熟虑的界面、复杂的逻辑、坚实的体系结构、流畅的工作流程等。但不需要微服务、AI、chatbots、NoSQL、Redux、Kafka、Containers 或任何类似的工具。如今很多开发人员似乎对技术能力非常着迷，以至于他们不能退后一步，问问自己是否真的需要这些。就像 MasterChef 上的人一样，他们以分子美食家的身份入场兜售自己。 他们将原料分成不同的组成部分，使用科学配对口味的方法，然后用大量的二氧化碳和液氮来制作你见过的最有创意的食物。 然后他们会在一两集之后被踢开，因为他们忘记了大多数烹饪的核心原则，即食物需要口感好。 他们似乎真的很惊讶于没有人喜欢他们发酵的茴香和芒果精华珍珠加上抹了鳀鱼沫的鳕鱼肉。对灵活性、可组合性和机敏性的痴迷正在给我们带来巨大的痛苦，并迫使公司远离我们所喜爱的平台和工具。 并不是说我上面列出的那些工具不会增加价值，尽管大公司在大规模操作系统时会遇到典型问题，工具也仅是为了解决真正的痛点而产生的。我所说的是，我们需要回到简单化的方向，并开始以更简单的方式创造事物，而不是仅仅一直讨论简单性。 也许我们可以依靠更多的技术栈来提供开箱即用的模式和工具，以便软件开发人员能够更高效地创建软件。我们将把越来越多的业务添加到“低代码”平台和其他通过简化、移除起初写过的代码来降低软件成本的工具中。我们需要停止假装二十行的程序是一些需要认真手工缝制的独特挂毯。写完之后，我仿佛听到一百万位开发人员磨刀的声音，但我相信如果我们继续坚持如下方向：想写所有东西、配置一切、编写所有内容、无论多大规模的问题都使用相同的堆栈，那么我们将把越来越多的业务添加到“低代码”平台和其他通过简化、移除起初写过的代码来降低软件成本的工具中。我们对业务日益复杂的回答不会增加开发过程的复杂性 – 无论它看起来多么优雅。我们必须设法通过简化开发流程来管理复杂性。 因为管理复杂性是次重要的责任，我们必须始终记住软件开发人员最重要的责任：通过使用软件来实现价值。\n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    ", "img": ["http://ww3.sinaimg.cn/mw690/7cc829d3gw1ezy0oepjyrj21hc0u0wk6.jpg"]}
{"title": "三款简单而优秀的 Linux 网络监视工具 - 文章 - 伯乐在线", "tag": ["IT技术", "Linux"], "goodNum": "1", "saveNum": " 2 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n通过 、  和  详细了解你的网络连接状态。你可以通过这三个 Linux 命令了解当前网络的大量信息。 通过进程号跟踪网络连接， 快速告知你哪些进程在占用你的带宽，而  以一个良好的轻量级守护进程在后台运行，并实时记录你的网络使用情况。令人称赞的  可以监听您指定的网络接口，并以 top 的样式呈现。这是一个不错的小工具，可以用于找出网络拥塞，测速和维持网络流量总量。看到自己到底在用多少带宽往往是非常惊人的，尤其是对于我们这些仍然记得电话线路、调制解调器，“高速”到令人惊叫的 kb 和实时波特率的老人们。我们在很久之前就不再使用波特率，转而钟情于比特率。波特率用于衡量信号变化，尽管有时候与比特率相同，但大多数情况下并非如此。如果你只有一个网络接口，直接运行  即可。不过  需要 root 权限：如果你有多个网络接口，那就指定你要监控的接口：就像  命令一样，你可以在命令运行时更改显示选项： 切换帮助界面。 是否解析域名。 切换源地址的显示， 则切换目的地址的显示。 是否显示端口号。 是否解析端口；若关闭解析则显示端口号。 切换文本显示界面。默认的显示方式需要 ncurses。我个人认为图 1 的显示方式在组织性和可读性都更加良好。 暂停显示更新。 退出程序。当你切换显示设置的时候， 并不会中断监测流量。当然你也可以单独监测一台主机。而这需要该主机的 IP 地址和子网掩码。现在，我很好奇 Pandora（LCTT 译注：一家美国的电台公司）能给我贫瘠的带宽带来多大的负载。因此我首先使用 dig 命令找到他们的 IP 地址：那子网掩码呢？ 会告诉我们：现在，将 IP 地址和子网掩码提供给 ：很棒的不是么？而我也很惊奇地发现，Pandora 在我的网络上，每小时大约使用 500kb。并且就像大多数流媒体服务一样，Pandora 的流量在迅速增长，并依靠缓存稳定下来。你可以使用  选项对 IPv6 地址执行相同的操作。查阅友好的 man 可以帮助你了解  的其他功能，包括使用个人配置文件自定义你的默认选项，以及使用自定义过滤（请参阅  来获取过滤指南）。当你想要快速了解是谁在吸取你的带宽的时候， 是个快速而简单的方法。你需要以 root 身份运行并指定要监听的接口。它会给你显示大量的应用程序及其进程号，所以如果你想的话，你可以借此杀死任一进程。 并没有多少选项：在 kb/s、kb、b、mb之间循环，按接收和发送的数据包排序，调整刷新延迟。具体请看，或者是运行 。是最容易使用的网络数据收集工具。它十分轻量并且不需要 root 权限。它以守护进程在后台运行，因此可以实时地记录你的网络数据。单个  命令就可以显示所累计的数据。默认情况下它会显示所有的网络接口。使用  选项来选择某个接口。也可以像这样合并多个接口的数据：你可以通过这几种方式过滤数据显示： 按小时显示统计信息。 按天显示统计信息. 和  分别按周和月份来显示统计信息。使用  选项查看实时更新。以下这条命令将会删除 wlan1 的数据库并不再监视它：而下面这条命令将会为你的一个网络接口创建一个别名。这个例子使用了 Ubuntu 16.04 的一个有线接口名称：默认情况下，vnstat 会监视 eth0。你可以在  对它进行修改，或者在你的家目录下创建你自己的个人配置文件。请参阅  以获取完整的指南。你也可以安装  来创建简单的彩图（图 2）:请参阅  以获取完整的选项。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2015/10/9aeba2223d66a3c6692233694383abce.jpg"]}
{"title": "机器学习如何发现你喜欢的音乐 - 文章 - 伯乐在线", "tag": ["IT技术", " 1 评论 "], "goodNum": "1", "saveNum": " 4 收藏", "sayNum": " 1 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n机器学习如何发现你喜欢的音乐：音乐个性化推荐背后的科学原理本周一，正如其它每个周一，一亿多 Spotify 用户每人都收到了一个崭新的歌单。这个叫做每周发现的歌单内混合了用户从未听过但是可能会喜欢的 30首歌曲。效果堪称神奇。我自己是 Spotify 的超级粉丝，对每周发现尤其喜爱。为什么呢？因为我觉得它懂我。它比我生命中的任何人都更清楚我的音乐品味。我很高兴每周它都能满足我的需求，一如既往地推荐一些我自己永远都不会找到或知道会喜欢的歌曲。对于那些两耳不闻窗外事的人们，请允许我介绍一下我的虚拟好友：[图片说明: 我的 Spotify 每周发现歌单]没想到，在这方面我不是一个人，不光是我对每周发现如此着迷 – 整个用户群体都趋之若鹜。这股热潮使得 Spotify 重新调整了它的重心，并在基于算法的歌单上投入了更多的资源。Dave Howitz: @Spotfiy 每周发现的歌单对我的了解程度简直毛骨悚然，熟悉到就像一个曾经与我有过一起濒死体验的前女友一样。Amanda Whitbred: 现在 @Spotify 的每周发现对我已经了解到如果它现在求婚，我也会说同意的地步了。自「每周发现」在 2015 年第一次上线以来，我就迫切想知道它是怎么运作的（而且由于我是 Spotify 公司的迷妹，我喜欢假装在那里工作并研究他们的产品）。 经过三周的疯狂Google，我终于满怀感恩地获取了一些幕后的知识。所以 Spotify 到底是如何成功做到给每人每周挑选 30 首歌曲的？我们先来仔细看下其它的音乐服务是如何做音乐推荐，以及 Spotify 是如何更胜一筹的。 跟 Songza 一样， Pandora 也是音乐甄选服务领域的早期玩家之一。它使用了一个略为更高级的方法来代替给歌曲属性手工打标签。即大众在听音乐的时候，对每首歌曲挑选一些描述性的词语来作为标签。进而，Pandora 的程序可以直接过滤特定的标签来生成包含相似歌曲的歌单。差不多同一时间，一个隶属于麻省理工学院媒体实验室的名叫 The Echo Nest 的音乐信息机构，采用了一个完全不同的高级策略来定制音乐。The Echo Nest 使用算法来分析音频和音乐的文本内容，以完成音乐识别，个性化推荐，歌单创建和分析等。最后，是 Last.fm 另辟蹊径，采取了另一个沿用至今的策略。那就是利用协同过滤来识别用户可能喜欢的音乐。稍后本文会展开讨论更多这方面的内容。所以说既然其他的音乐甄选服务都实现了推荐功能，Spotify 究竟是怎么操作自己的神奇引擎，来实现甩出竞争对手几条街的用户品味默契度的呢？ 事实上 Spotify 并没有使用什么单一的革命性推荐模型，而是Spotify 使用三种主要的推荐模型来创建每周发现：（即 Last.fm 最早使用的那些模型）。工作原理为分析你和用户的行为。模型 。工作原理为分析文本。模型。工作原理为分析。我们来具体看下这些推荐模型是怎么工作的！首先介绍下背景：当很多人听到协同过滤这几个词的时候，他们会立刻联想到 ，因为它是第一个利用协同过滤来实现推荐模型的公司之一。其做法主要是使用用户提交的电影星级来计算推荐那些电影给其他用户。自 将其成功应用以来，协同过滤开始快速流传开来。现在无论是谁想实现一个推荐模型的话，一般都会拿它作为初次尝试。与不同的是，Spotify 并没有用户对他们音乐的星级评价数据。Spotify 所用的数据是的，具体来说就是我们在线听歌的，以及其他额外信息，诸如用户是否保存歌曲到个人歌单，或者听完歌曲后是否接着访问艺术家主页等。但什么是协同过滤，到底它是如何工作的呢？下面用一段简短对话来做一个大致的介绍。啥情况? 原来这俩人里面每人都有自己的一些歌曲偏好 – 左边的人喜欢歌曲 P, Q, R 和 S; 右边的人喜欢 Q, R, S 和 T。协同过滤系统进而利用这些数据得出结论，系统然后建议右边的人去体验下歌曲 P，以及左边的人去体验下歌曲 T。听起来够简单吧？但是 Spotify 具体是怎么具体应用这个概念，来计算的用户偏好从而得出的用户歌曲推荐呢？ 现实中，此处提及的矩阵是极其庞大的。（如果你也用 Spotify，那么你也是这个矩阵中的一行），而每一列则代表了 Spotify 数据库中中的一首。然后，Python 库就开始跑这个漫长而复杂的矩阵分解公式：计算完成后，系统会生成两种类型的向量，在此分别命名为 X 和 Y。X 为用户向量，代表单个用户的音乐品味。Y 则为歌曲向量，代表单支歌曲的特征。现在我们得到了一亿四千万个用户向量，每人一个，还有三亿歌曲向量。这些向量的具体内容只是一些单独拎出来自身并无意义的数字，但是在后面进行比较时会非常有用。为了找到那些跟我相似品味的用户，协同过滤系统会拿我的向量跟其他用户的向量作比较，最终会找到那些跟我最相似的用户。对于 Y 向量，也是同样的流程 – 你可以拿一首歌的向量与其他的歌曲向量做比较，进而找出哪些歌曲是跟你现在正在看的歌曲最相似。协同过滤确实效果不错，但是 Spotify 深知再添加另外一个引擎的话效果会更出色。这就到了自然语言处理出场的时候了。 Spotify 采用的第二个推荐模型就是。这些模型的源数据，正如名字所示，就是一些普通的 – 例如歌曲的元数据，新闻文章，博客，和互联网上的其它文本等。 自然语言处理 – 计算机理解人类语言的能力 – 本身就是一个巨大的领域，通常通过情感分析应用编程接口（API）来进行操作处理。自然语言处理背后的具体原理超出了本文的讨论范畴，但是在此本文可以提供一些粗略的描述：Spotify 会在网上不断爬取博客帖子以及其它音乐相关的文本，并找出人们对特定的艺术家和歌曲的评论 – 比如说人们对这些歌曲经常使用哪些形容词和语言, 以及哪些其他艺术家和歌曲也会和它们放在一起讨论。虽然我不知道 Spotify 如何处理他们抓取的数据，但是我可以介绍下 The Echo Nest 是如何使用它们的。他们会把数据分类成“文化向量”和“最佳评语集”。每个艺术家和歌曲都有数以千计的每日更新的最佳评语集。每个评语都有一个相关的权重，来表示其描述的重要性（简单说就是某人可能会用该评语描述某个音乐的概率）。[ “Cultural vectors”, or “top terms”, as used by the Echo Nest. Table from Brian Whitman]然后，与协同过滤类似，自然语言处理模型用这些评语和权重来创建一个歌曲的表达向量，可以用来确定两首音乐是否相似。很酷吧？ 首先，你可能会问这个问题：额，首先要说的是，引入第三个模型会进一步提高这个已经很优秀的推荐服务的准确性。但实际上，采用这个模型还有另外一个次要目的：比如说，你的创作歌手朋友在 Spotify 上刚放上了一首新歌。可能它只有 50 次听歌记录，所以很少能有其他听众来一起协同过滤它。与此同时，它也在网上也没有留下多少痕迹，所以自然语言处理模型也不会注意到它。幸运的是，原始音频模型并不区分新歌曲和热门歌曲。所以有了它的帮忙，你朋友的歌曲也可以和流行歌曲一道出现在每周发现的歌单里面。好了，到了“如何”的部分了。我们如何才能分析这些看起来如此抽象的呢？…用卷积神经网络同样也是支撑面部识别的技术。只不过在 Spotify 的案例中，他们被稍作修改以基于音频数据处理而不是像素点。下面是一个神经网络架构的例子：[]这个特定的神经网络有四个，具体为图中左侧的宽柱，和右边的稍微窄些的三根柱。输入是音频帧的时频表示，进而连接起来形成频谱图。音频帧会穿过这些卷积层，经过最后一个卷积层，你可以看到一个“全局临时池”层。该层在整个时间轴上汇集数据，并有效计算和统计歌曲时长内的学习特征。处理完之后，神经网络会得出其对歌曲的理解，包括估计的等特征。下面就是 Draft Punk 的 “Around the World” 30 秒片段的数据图。[Image Credit: ]最终，对这些对歌曲关键特征的理解可以让 Spotify 来决定歌曲之间的相似度，以及根据用户听歌历史来判断哪些用户可能会喜欢它们。这些基本涵盖了为每周发现提供支持的推荐作业流程所依赖的三种主要模型。[ Cassandra instances]当然了，这些推荐模型也和 Spotify 其它更大的生态系统连接在一起，其中包括利用海量的数据存储以及的 Hadoop 集群来做推荐服务的扩展，使得引擎得以计算巨型矩阵，无穷无尽的互联网音乐文章和大量的音频文件。我希望本文可以对你有所启发，并且像当时它对我一样能够激起你的好奇。怀着对幕后的机器学习技术的了解和感激之情，现在我将通过我自己的每周发现来寻找我喜欢的音乐。文章结束。\n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    ", "img": ["http://wx2.sinaimg.cn/large/7cc829d3gy1fq7l3ts6p3j20ps0ocq78.jpg"]}
{"title": "堆和堆的应用：堆排序和优先队列 - 文章 - 伯乐在线", "tag": ["IT技术", "数据结构", "算法"], "goodNum": "1", "saveNum": " 3 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n1.堆)是一种重要的数据结构，是实现首选的数据结构。由于堆有很多种变体，包括二项式堆、斐波那契堆等，但是这里只考虑最常见的就是二叉堆（以下简称堆）。堆是一棵满足一定性质的二叉树，具体的讲堆具有如下性质：, 堆可以分为和，这里以为例，其主要包含的操作有：insert()extractMinpeek(findMin)delete(i)由于堆是一棵形态规则的二叉树，因此堆的父节点和孩子节点存在如下关系：\n由于二叉树良好的形态已经包含了父节点和孩子节点的关系信息，因此就可以不使用链表而简单的使用数组来存储堆。要实现堆的基本操作，涉及到的两个关键的函数 ： 将位置的元素向上调整，以满足堆得性质，常常是用于后，用于调整堆；：同理，常常是用于后，用于调整堆；具体的操作如下：可以看到和不停的在父节点和子节点之间比较、交换；在不超过的时间复杂度就可以完成一次操作。有了这两个基本的函数，就可以实现上述提及的堆的基本操作。首先是如何建堆，:一个是不断地（后调用的是）另一个将原始数组当成一个需要调整的堆，然后自底向上地\n在每个位置调用，完成后我们就可以得到一个满足堆性质的堆。这里考虑后一种思路：通常堆的操作是将元素插入到堆尾，由于新元素的插入可能违反堆的性质，因此需要调用操作自底向上调整堆；堆移除堆顶元素操作是将堆顶元素删除，然后将堆最后一个元素放置在堆顶，接着执行操作，同理替换堆顶元素也是相同的操作。那么建堆操作的时间复杂度是多少呢？答案是。虽然的操作时间是，但是由于高度在递减的同时，每一层的节点数量也在成倍减少，最后通过数列错位相减可以得到时间复杂度是。\n由于堆的固有性质，堆的根便是最小的元素，因此操作就是返回根元素即可；\n若要将删除，可以将末尾的元素覆盖,然后将堆得，调用调整堆。时间复杂度为。\n同上删除堆中位置为的节点，涉及到两个函数和，时间复杂度为,具体步骤是，将元素覆盖元素，然后检查是否需要删除中间节点21，将最后一个节点复制过来；由于没有进行操作，节点的值仍然为6，因此为确保堆的性质，执行操作；删除中间节点，将值为11的节点复制过来，执行操作；\n由于执行操作后，节点的值不再是，因此就不用再执行操作了，因为堆的性质在操作生效后已经得到了保持。可以看出，堆的基本操作都依赖于两个核心的函数和；较为完整的代码如下：2.堆的应用：堆排序运用堆的性质，我们可以得到一种常用的、稳定的、高效的排序算法————。堆排序的时间复杂度为，空间复杂度为，堆排序的思想是：\n对于含有个元素的无序数组, 构建一个堆(这里是小顶堆)，然后执行得到最小的元素，这样执行次得到序列就是排序好的序列。\n如果是降序排列则是小顶堆；否则利用大顶堆。由于执行完毕后，最后一个元素已经被移动到了，因此可以将返回的元素放置于最后，这样可以得到的堆排序算法。具体操作如下：当然，如果不使用前面定义的，则可以手动写堆排序，由于堆排序设计到和， 两个操作都公共依赖于函数，因此我们只需要实现即可。(trick:由于建堆操作可以采用或者，而是需要操作，因此取公共部分，则采用建堆)。这里便于和前面统一，采用小顶堆数组进行降序排列。3.堆的应用：优先队列优先队列是一种抽象的数据类型，它和堆的关系类似于，和数组、链表的关系一样；我们常常使用堆来实现优先队列，因此很多时候堆和优先队列都很相似，它们只是概念上的区分。\n优先队列的应用场景十分的广泛：\n常见的应用有：Dijkstra’s algorithm（单源最短路问题中需要在邻接表中找到某一点的最短邻接边，这可以将复杂度降低。）Huffman coding（贪心算法的一个典型例子，采用优先队列构建最优的前缀编码树()）Prim’s algorithm for minimum spanning treeBest-first search algorithms这里简单介绍上述应用之一：。Huffman编码是一种变长的编码方案，对于每一个字符，所对应的二进制位串的长度是不一致的，但是遵守如下原则：出现频率高的字符的二进制位串的长度小不存在一个字符的二进制位串是除外任意字符的二进制位串的前缀遵守这样原则的Huffman编码属于变长编码，可以无损的压缩数据，压缩后通常可以节省20%-90%的空间，具体压缩率依赖于数据的固有结构。Huffman编码的实现就是要找到满足这两种原则的  对照关系，即找到的编码方案（前缀码：没有任何字符编码后的二进制位串是其他字符编码后位串的前缀）。\n这里我们需要用到二叉树来表达最优前缀码，该树称为\n一棵最优前缀码树看起来像这样：算法思想：用一个属性为关键字的最小优先队列Q,将当前最小的两个元素x,y合并得到一个新元素z（z.frequence = x.freqeunce + y.frequence）,\n然后插入到优先队列中Q中，这样执行次合并后，得到一棵最优前缀码树（这里不讨论算法的证明）。一个常见的构建流程如下：树中指向某个节点左孩子的边上表示位,指向右孩子的边上的表示位，这样遍历一棵最优前缀码树就可以得到对照表。输出如下：4 堆的应用：海量实数中（一亿级别以上）找到TopK（一万级别以下）的数集合。A:通常遇到找一个集合中的TopK问题，想到的便是排序，因为常见的排序算法例如快排算是比较快了，然后再取出K个TopK数，时间复杂度为，当很大的时候这个时间复杂度还是很大的；B:另一种思路就是打擂台的方式,每个元素与K个待选元素比较一次，时间复杂度很高：，此方案明显逊色于前者。对于一亿数据来说，A方案大约是；C:由于我们只需要TopK，因此不需要对所有数据进行排序，可以利用堆得思想，维护一个大小为K的小顶堆，然后依次遍历每个元素, 若元素大于堆顶元素，则删除，将放在堆顶，然后调整，时间复杂度为；若小于或等于，则考察下一个元素。这样遍历一遍后，最小堆里面保留的数就是我们要找的，整体时间复杂度为约等于，大约是（由于k与n数量级差太多），这样时间复杂度下降了约一半。A、B、C三个方案中，C通常是优于B的，因为logK通常是小于k的，当和的数量级相差越大，这种方式越有效。以下为具体操作：ps:大致测试了一下，10亿个数中找到top5需要140秒左右，应该是很快了。5 总结堆是基于树的满足一定约束的重要数据结构，存在许多变体例如二叉堆、二项式堆、斐波那契堆（很高效）等。堆的几个基本操作都依赖于两个重要的函数和，堆的通常是在堆尾插入新元素并调整堆，而是在\n删除堆顶元素，然后将最后一个元素放置堆顶并调用调整堆。二叉堆是常用的一种堆，其是一棵二叉树；由于二叉树良好的性质，因此常常采用数组来存储堆。\n堆得基本操作的时间复杂度如下表所示：二叉堆通常被用来实现堆排序算法，堆排序可以，堆排序的时间复杂度的上界是，是一种很优秀的排序算法。由于存在相同键值的两个元素处于两棵子树中，而两个元素的顺序可能会在后续的堆调整中发生改变，因此堆排序不是稳定的。降序排序需要建立小顶堆，升序排序需要建立大顶堆。堆是实现抽象数据类型优先队列的一种方式，优先队列有很广泛的应用，例如Huffman编码中使用优先队列利用贪心算法构建最优前缀编码树。堆的另一个应用就是在海量数据中找到TopK个数，思想是维护一个大小为K的二叉堆，然后不断地比较堆顶元素，判断是否需要执行替换对顶元素的操作，采用\n此方法的时间复杂度为，当和的数量级差距很大的时候，这种方式是很有效的方法。6 references[1] )[2] [3] [4] [5] Thomas H.Cormen, Charles E.Leiserson, Ronald L.Rivest, Clifford Stein.算法导论[M].北京:机械工业出版社,2015:245-249[6] Jon Bentley.编程珠玑[M].北京:人民邮电出版社,2015:161-174\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2014/10/a1a4de99de0c75eab712542a7dac876f.png"]}
{"title": "Nginx 教程 （1）：基本概念 - 文章 - 伯乐在线", "tag": ["IT技术", " 2 评论 ", "Nginx", "Web"], "goodNum": "1", "saveNum": " 13 收藏", "sayNum": " 2 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n简介嗨！分享就是关心！所以，我们愿意再跟你分享一点点知识。我们准备了这个划分为三节的《Nginx教程》。如果你对 Nginx 已经有所了解，或者你希望了解更多，这个教程将会对你非常有帮助。我们会告诉你 Nginx 是如何工作的，其背后的概念有哪些，以及如何优化它以提升应用程序的性能。还会告诉你如何安装，如何启动、运行。这个教程包括三节：——你可以了解命令（directive）与环境（context）的区别、继承模式，以及 Nginx 选择服务器区块的顺序，还有安装位置。——提升速度的诀窍。我们将会讲解 gzip、缓存、缓冲区以及超时设置。——讲解用 HTTPS 来提供内容的设置步骤。我们的目标是创建一系列教程，让你可以轻松找到特定主题的正确配置，如 gzip、SSL 等，或者直接浏览一下那些配置。为了获得最佳的学习体验，我们建议你在自己的机器上安装 Nginx，并亲手实战一下。什么是 Nginx？Nginx 最初是作为一个 Web 服务器创建的，用于解决  的问题。作为一个 Web 服务器，它可以以惊人的速度为您的数据服务。但 Nginx 不仅仅是一个 Web 服务器，你还可以将其用作反向代理，与较慢的上游服务器（如：Unicorn 或 Puma）轻松集成。你可以适当地分配流量（负载均衡器）、流媒体、动态调整图像大小、缓存内容等等。基本的 nginx 体系结构由 master 进程和其 worker 进程组成。master 读取配置文件，并维护 worker 进程，而 worker 则会对请求进行实际处理。基本命令要启动 nginx，只需输入：当你的 nginx 实例运行时，你可以通过发送相应的信号来管理它：可用的信号：stop – 快速关闭quit – 优雅关闭 (等待 worker 线程完成处理)reload – 重载配置文件reopen – 重新打开日志文件指令和上下文nginx 的配置文件，默认的位置包括：,，或配置文件的由下面的部分构成:指令 – 可选项，包含名称和参数，以分号结尾上下文 – 分块，你可以声明指令 – 类似于编程语言中的作用域指令类型在多个上下文中使用相同的指令时，必须要小心，因为继承模型不同时有着不同的指令。有三种类型的指令，每种都有自己的继承模型。在每个上下文仅有唯一值。而且，它只能在当前上下文中定义一次。子级上下文可以覆盖父级中的值，并且这个覆盖值只在当前的子级上下文中有效。在同一上下文中添加多条指令，将添加多个值，而不是完全覆盖。在子级上下文中定义指令将覆盖给父级上下文中的值。行动是改变事情的指令。根据模块的需要，它继承的行为可能会有所不同。例如 rewrite 指令，只要是匹配的都会执行：如果用户想尝试获取 /sample：server的rewrite将会执行，从 /sample rewrite 到 /foobarlocation /foobar 会被匹配location的第一个rewrite执行，从/foobar rewrite到/foolocation的第二个rewrite执行，从/foo rewrite到/barreturn 指令提供的是不同的行为：在上述的情况下，立即返回200。处理请求在 Nginx 内部，你可以指定多个虚拟服务器，每个虚拟服务器用 server{} 上下文描述。这将告诉 Nginx 如何处理到来的请求。Nginx 将会首先通过检查 listen 指令来测试哪一个虚拟主机在监听给定的 IP 端口组合。然后，server_name 指令的值将检测 Host 头(存储着主机域名)。Nginx 将会按照下列顺序选择虚拟主机：匹配sever_name指令的IP-端口主机拥有default_server标记的IP-端口主机首先定义的IP-端口主机如果没有匹配，拒绝连接。例如下面的例子：server_name指令接受多个值。它还处理通配符匹配和正则表达式。当有歧义时，nginx 将使用下面的命令：确切的名字最长的通配符名称以星号开始，例如“* .example.org”。最长的通配符名称以星号结尾，例如“mail.**”首先匹配正则表达式（按照配置文件中的顺序）Nginx 会存储 3 个哈希表：确切的名字，以星号开始的通配符，和以星号结尾的通配符。如果结果不在任何表中，则将按顺序进行正则表达式测试。值得谨记的是是一个来自下面的缩写有一点不同， 存储在第二张表，这意味着它比显式声明的慢一点。在很多情况下，能够找到 listen 指令，接受IP:端口值然而，还可以指定 UNIX-domain 套接字。你甚至可以使用主机名但请慎用，由于主机可能无法启动 nginx，导致无法绑定在特定的 TCP Socket。最后，如果指令不存在，则使用 。最小化配置有了这些知识 – 我们应该能够创建并理解运行 nginx 所需的最低配置。root, location, 和 try_files 指令root 指令设置请求的根目录，允许 nginx 将传入请求映射到文件系统。根据给定的请求，指定 nginx 服务器允许的内容location指令根据请求的 URI 来设置配置。如果没有指定修饰符，则路径被视为前缀，其后可以跟随任何东西。以上例子将匹配此外，在给定的上下文中可以使用多个 location 指令。Nginx 也提供了一些修饰符，可用于连接 location。这些修饰符将影响 location 模块使用的地方，因为每个修饰符都分配了优先级。Nginx 会先检查精确匹配。如果找不到，我们会找优先级最高的。如果这个匹配依然失败，正则表达式匹配将按照出现的顺序进行测试。至少，最后一个前缀匹配将被使用。尝试不同的路径，找到一个路径就返回。所以对于  请求，它将尝试按以下顺序返回文件：$uri ( /foo.html )index.html如果什么都没找到则返回 404有趣的是，如果我们在服务器上下文中定义 try_files，然后定义匹配的所有请求的 location —— try_files 将不会执行。这是因为在服务器上下文中定义的 try_files 是它的 pseudo-location，这是最不可能的位置。因此，定义 location/ 将比 pseudo-location 更具体。因此，你应该避免在 server 上下文中出现 try_files:总结感谢您的阅读。如果没有大量的资源，这个系列是不可能完成的。在这一系列的写作中，我们发现了一些特别有用的网站：，和他的令人惊奇的书：我们会很感激你的反馈和评价，请随意讨论。你喜欢这系列吗？你有什么关于下一步应该解决什么问题的建议吗？或你发现了一个错误？告诉我们，下期再见。\r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2013/07/Nginx-Logo.jpg"]}
{"title": "操作系统级虚拟化概述 - 文章 - 伯乐在线", "tag": ["IT技术", "虚拟化"], "goodNum": "1", "saveNum": " 1 收藏", "sayNum": "  评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\nKVM、XEN等虚拟化技术允许各个虚拟机拥有自己独立的操作系统。与KVM、XEN等虚拟化技术不同，所谓操作系统级虚拟化，也被称作容器化，是操作系统自身的一个特性，它允许多个相互隔离的用户空间实例的存在。这些用户空间实例也被称作为容器。普通的进程可以看到计算机的所有资源而容器中的进程只能看到分配给该容器的资源。通俗来讲，操作系统级虚拟化将操作系统所管理的计算机资源，包括进程、文件、设备、网络等分组，然后交给不同的容器使用。容器中运行的进程只能看到分配给该容器的资源。从而达到隔离与虚拟化的目的。实现操作系统虚拟化需要用到Namespace及cgroups技术。在编程语言中，引入命名空间的概念是为了重用变量名或者服务例程名。在不同的命名空间中使用同一个变量名而不会产生冲突。Linux系统引入命名空间也有类似的作用。例如，在没有操作系统级虚拟化的Linux系统中，用户态进程从1开始编号(PID)。引入操作系统虚拟化之后，不同容器有着不同的PID命名空间，每个容器中的进程都可以从1开始编号而不产生冲突。目前，Linux中的命名空间有6种类型，分别对应操作系统管理的6种资源：挂载点(mount point) CLONE_NEWNS进程(pid) CLONE_NEWPID网络(net) CLONE_NEWNET进程间通信(ipc) CLONE_NEWIPC主机名(uts) CLONE_NEWUTS用户(uid) CLONW_NEWUSER将来还会引入时间、设备等对应的namespace.Linux 2.4.19版本引入了第一个命名空间——挂载点，因为那时还没有其他类型的命名空间，所以clone系统调用中引入的flag就叫做CLONE_NEWNS与命名空间相关的三个系统调用(system calls)下面3个系统调用用来操作命名空间：clone() —— 用来创建新的进程及新的命名空间，新的进程会被放到新的命名空间中unshare() —— 创建新的命名空间但并不创建新的子进程，之后创建的子进程会被放到新创建的命名空间中去setns() —— 将进程加入到已经存在的命名空间中注意：这３个系统调用都不会改变调用进程(calling process)的pid命名空间，而是会影响其子进程的pid命名空间命名空间本身并没用名字(囧)，不同的命名空间用不同的inode号来标识，这也符合Linux用文件一统天下的惯例。可以在proc文件系统中查看一个进程所属的命名空间，例如，查看PID为4123的进程所属的命名空间：下面的代码演示了如何利用上述3个系统调用来操作进程的命名空间：运行结果：如果说命名空间是从命名和编号的角度进行隔离，而控制组则是将进程进行分组，并真正的将各组进程的计算资源进行限制、隔离。控制组是一种内核机制，它可以对进程进行分组、跟踪限制其使用的计算资源。对于每一类计算资源，控制组通过所谓的子系统(subsystem)来进行控制，现阶段已有的子系统包括：cpusets: 用来分配一组CPU给指定的cgroup，该cgroup中的进程只等被调度到该组CPU上去执行blkio : 限制cgroup的块IOcpuacct : 用来统计cgroup中的CPU使用devices : 用来黑白名单的方式控制cgroup可以创建和使用的设备节点freezer : 用来挂起指定的cgroup，或者唤醒挂起的cgrouphugetlb : 用来限制cgroup中hugetlb的使用memory : 用来跟踪限制内存及交换分区的使用net_cls : 用来根据发送端的cgroup来标记数据包，流量控制器(traffic controller)会根据这些标记来分配优先级net_prio : 用来设置cgroup的网络通信优先级cpu :用来设置cgroup中CPU的调度参数perf_event : 用来监控cgroup的CPU性能与命名空间不同，控制组并没有增加系统调用，而是实现了一个文件系统，通过文件及目录操作来管理控制组。下面通过一个例子来看一看cgroup是如何利用cpuset子系统来把进程绑定到指定的CPU上去执行的。1. 创建一个一直执行的shell脚本2. 在后台执行这个脚本3. 查看该脚本在哪个CPU上运行可以看到PID为20553的进程运行在编号为3的CPU上，下面利用cgroups将其绑定到编号为2的CPU上去执行4. 挂载cgroups类型的文件系统到一个新创建的目录cgroups中5. 创建一个新的组group06. 将上面的进程20553加入到新建的控制组中：7. 限制该组的进程只能运行在编号为2的CPU上8. 查看PID为20553的进程所运行的CPU编号上面的例子简单的展示了如何使用控制组。控制组通过文件和目录来操作，文件系统又是树形结构，因此如果不对cgroups的使用做一些限制的话，配置会变得异常复杂和混乱。因此，在新版的cgroups中做了一些限制。本文简要介绍了操作系统虚拟化的概念，以及实现操作系统虚拟化的技术——命名空间及控制组。并通过两个简单的例子演示了命名空间及控制组的使用方法。\r\n                    \r\n                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/1b8322e1daff605d71fc81e724421f17.jpg"]}
{"title": "与 C 语言长别离 - 文章 - 伯乐在线", "tag": ["C/C++", " 2 评论 ", "别离"], "goodNum": "2", "saveNum": " 4 收藏", "sayNum": " 2 评论", "article": "\n                        \n                    \n                        \n                    \n                        \n                        \n                    \n                        \n                    \n                        \n                    \n                        \n                        \n                    \n\n\n\n\n\n\n\n\n\n如果你完全不认为这种情况令人震惊，那你很可能不是一个系统程序员。我知道有很多程序员使用更高级的语言工作。但是我把大部分时间都花在了深入打磨像 NTPsec、 GPSD 以及 giflib 这些东西上。熟练使用 C 语言在这几十年里一直就是我的专长。但是，现在我不仅是不再使用 C 语言写新的项目，甚至我都记不清我是什么时候开始这样做的了，而且……回头想想，我觉得这都不是本世纪发生的事情。这个对于我来说是件大事，因为如果你问我，我的五个最核心软件开发技能是什么，“C 语言专家” 一定是你最有可能听到的之一。这也激起了我的思考。C 语言的未来会怎样 ？C 语言是否正像当年的 COBOL 语言一样，在辉煌之后，走向落幕？我恰好是在 C 语言迅猛发展，并把汇编语言以及其它许多编译型语言挤出主流存在的前几年开始编程的。那场过渡大约是在 1982 到 1985 年之间。在那之前，有很多编译型语言争相吸引程序员的注意力，那些语言中还没有明确的领导者；但是在那之后，小众的语言就直接毫无声息的退出了舞台。主流的语言（FORTRAN、Pascal、COBOL）则要么只限于老代码，要么就是固守单一领域，再就是在 C 语言的边缘领域顶着愈来愈大的压力苟延残喘。而在那以后，这种情形持续了近 30 年。尽管在应用程序开发上出现了新的动向： Java、 Perl、 Python， 以及许许多多不是很成功的竞争者。起初我很少关注这些语言，这很大一部分是因为在它们的运行时的开销对于当时的实际硬件来说太大。因此，这就使得 C 的成功无可撼动；为了使用和对接大量已有的 C 语言代码，你得使用 C 语言写新代码（一部分脚本语言尝试过打破这种壁垒，但是只有 Python 有可能取得成功）。回想起来，我在 1997 年使用脚本语言写应用时本应该注意到这些语言的更重要的意义的。当时我写的是一个名为 SunSITE 的帮助图书管理员做源码分发的辅助软件，当时使用的是 Perl 语言。这个应用完全是用来处理文本输入的，而且只需要能够应对人类的反应速度即可（大概 0.1 秒），因此使用 C 或者别的没有动态内存分配以及字符串类型的语言来写就会显得很傻。但是在当时，我仅仅是把其视为一个试验，而完全没有想到我几乎再也不会在一个新项目的第一个文件里敲下  这样的 C 语言代码了。我说“几乎”，主要是因为 1999 年的 。 我想那是我最后一个用 C 从头开始写的项目了。在那之后我写的所有的 C 代码都是在为那些上世纪已经存在的老项目添砖加瓦，或者是在维护诸如 GPSD 以及 NTPsec 一类的项目。当年我本不应该使用 C 语言写 SNG 的。因为在那个年代，摩尔定律的快速迭代使得硬件愈加便宜，使得像 Perl 这样的语言的执行效率也不再是问题。仅仅三年以后，我可能就会毫不犹豫地使用 Python 而不是 C 语言来写 SNG。在 1997 年我学习了 Python， 这对我来说是一道分水岭。这个语言很美妙 —— 就像我早年使用的 Lisp 一样，而且 Python 还有很酷的库！甚至还完全遵循了 POSIX！还有一个蛮好用的对象系统！Python 没有把 C 语言挤出我的工具箱，但是我很快就习惯了在只要能用 Python 时就写 Python ，而只在必须使用 C 语言时写 C。（在此之后，我开始在我的访谈中指出我所谓的 “Perl 的教训” ，也就是任何一个没能实现和 C 语言语义等价的遵循 POSIX 的语言。在计算机科学的发展史上，很多学术语言的骨骸俯拾皆是，原因是这些语言的设计者没有意识到这个重要的问题。）显然，对我来说，Python 的主要优势之一就是它很简单，当我写 Python 时，我不再需要担心内存管理问题或者会导致核心转储的程序崩溃 —— 对于 C 程序员来说，处理这些问题烦的要命。而不那么明显的优势恰好在我更改语言时显现，我在 90 年代末写应用程序和非核心系统服务的代码时，为了平衡成本与风险都会倾向于选择具有自动内存管理但是开销更大的语言，以抵消之前提到的 C 语言的缺陷。而在仅仅几年之前（甚至是 1990 年），那些语言的开销还是大到无法承受的；那时硬件产业的发展还在早期阶段，没有给摩尔定律足够的时间来发挥威力。尽量地在 C 语言和 Python 之间选择 C —— 只要是能的话我就会从 C 语言转移到 Python 。这是一种降低工程复杂程度的有效策略。我将这种策略应用在了 GPSD 中，而针对 NTPsec , 我对这个策略的采用则更加系统化。这就是我们能把 NTP 的代码库大小削减四分之一的原因。但是今天我不是来讲 Python 的。尽管我觉得它在竞争中脱颖而出，Python 也未必真的是在 2000 年之前彻底结束我在新项目上使用 C 语言的原因，因为在当时任何一个新的学院派的动态语言都可以让我不再选择使用 C 语言。也有可能是在某段时间里在我写了很多 Java 之后，我才慢慢远离了 C 语言。我写这个回忆录是因为我觉得我并非特例，在世纪之交，同样的发展和转变也改变了不少 C 语言老手的编码习惯。像我一样，他们在当时也并没有意识到这种转变正在发生。在 2000 年以后，尽管我还在使用 C/C++ 写之前的项目，比如 GPSD ，游戏韦诺之战以及 NTPsec，但是我的所有新项目都是使用 Python 的。有很多程序是在完全无法在 C 语言下写出来的，尤其是  以及  这样的项目。由于 C 语言受限的数据类型本体论以及其脆弱的底层数据管理问题，尝试用 C 写的话可能会很恐怖，并注定失败。甚至是对于更小的项目 —— 那些可以在 C 中实现的东西 —— 我也使用 Python 写，因为我不想花不必要的时间以及精力去处理内核转储问题。这种情况一直持续到去年年底，持续到我创建我的第一个 Rust 项目，以及成功写出第一个。如前文所述，尽管我是在讨论我的个人经历，但是我想我的经历体现了时代的趋势。我期待新潮流的出现，而不是仅仅跟随潮流。在 98 年的时候，我就是 Python 的早期使用者。来自  的数据则表明，在 Go 语言脱胎于公司的实验项目并刚刚从小众语言中脱颖而出的几个月内，我就开始实现自己的第一个 Go 语言项目了。总而言之：直到现在第一批有可能挑战 C 语言的传统地位的语言才出现。我判断这个的标准很简单 —— 只要这个语言能让我等 C 语言老手接受不再写 C 的事实，这个语言才 “有可能” 挑战到 C 语言的地位 —— 来看啊，这有个新编译器，能把 C 转换到新语言，现在你可以让他完成你的了 —— 这样 C 语言的老手就会开心起来。Python 以及和其类似的语言对此做的并不够好。使用 Python 实现 NTPsec（以此举例）可能是个灾难，最终会由于过高的运行时开销以及由于垃圾回收机制导致的延迟变化而烂尾。如果需求是针对单个用户且只需要以人类能接受的速度运行，使用 Python 当然是很好的，但是对于以  运行的程序来说就不总是如此了 —— 尤其是在很高的多用户负载之下。这不只是我自己的判断 —— 因为拿 Go 语言来说，它的存在主要就是因为当时作为 Python 语言主要支持者的 Google 在使用 Python 实现一些工程的时候也遭遇了同样的效能痛点。Go 语言就是为了解决 Python 搞不定的那些大多由 C 语言来实现的任务而设计的。尽管没有一个全自动语言转换软件让我很是不爽，但是使用 Go 语言来写系统程序对我来说不算麻烦，我发现我写 Go 写的还挺开心的。我的很多 C 编码技能还可以继续使用，我还收获了垃圾回收机制以及并发编程机制，这何乐而不为？（有关于我第一次写 Go 的经验的更多信息）本来我想把 Rust 也视为 “C 语言要过时了” 的例证，但是在学习并尝试使用了这门语言编程之后，我觉得。也许 5 年以后，它才会成为 C 语言的对手。随着 2017 的尾声来临，我们已经发现了一个相对成熟的语言，其和 C 类似，能够胜任 C 语言的大部分工作场景（我在下面会准确描述），在几年以后，这个语言界的新星可能就会取得成功。这件事意义重大。如果你不长远地回顾历史，你可能看不出来这件事情的伟大性。 —— 这几乎就是我作为一个程序员的全部生涯，我们都没有等到一个 C 语言的继任者，也无法遥望 C 之后的系统编程会是什么样子的。而现在，我们面前突然有了后 C 时代的两种不同的展望和未来…………另一种展望则是下面这个语言留给我们的。我的一个朋友正在开发一个他称之为 “Cx” 的语言，这个语言在 C 语言上做了很少的改动，使得其能够支持类型安全；他的项目的目的就是要创建一个能够在最少人力参与的情况下把古典 C 语言修改为新语言的程序。我不会指出这位朋友的名字，免得给他太多压力，让他做出太多不切实际的保证。但是他的实现方法真的很是有意思，我会尽量给他募集资金。现在，我们看到了可以替代 C 语言实现系统编程的三种不同的可能的道路。而就在两年之前，我们的眼前还是一片漆黑。我重复一遍：这件事情意义重大。我是在说 C 语言将要灭绝吗？不是这样的，在可预见的未来里，C 语言还会是操作系统的内核编程以及设备固件编程的主流语言，在这些场景下，尽力压榨硬件性能的古老规则还在奏效，尽管它可能不是那么安全。现在那些将要被 C 的继任者攻破的领域就是我之前提到的我经常涉及的领域 —— 比如 GPSD 以及 NTPsec、系统服务以及那些因为历史原因而使用 C 语言写的进程。还有就是以 DNS 服务器以及邮件传输代理 —— 那些需要以机器速度而不是人类的速度运行的系统程序。现在我们可以对后 C 时代的未来窥见一斑，即上述这类领域的代码都可以使用那些具有强大内存安全特性的 C 语言的替代者实现。Go 、Rust 或者 Cx ，无论是哪个，都可能使 C 的存在被弱化。比如，如果我现在再来重新实现一遍 NTP ，我可能就会毫不犹豫的使用 Go 语言去完成。\n                    \n                     ·                 \n                    \n                                    \n                    \n                                    \n                    \n                     ·                 \n                    \n                                    \n                    \n                     ·                 \n    \n    \n    \n    \n    \n    ", "img": ["http://jbcdn2.b0.upaiyun.com/2018/01/5f9c96a67bd10a4615ff06707ba2295f.jpg"]}
